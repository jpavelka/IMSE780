<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>IMSE780</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <script>
      let baseLps = {
          prototypeLp: {
              xMin: -1,
              xMax: 8.99,
              yMin: -1,
              yMax: 10.99,
              obj: [3, 5],
              ineqs: [[3, 2, 18, "l"], [1, 0, 4, "l"], [0, 2, 12, "l"]],
              ineqTextPlaces: [[5, 2.5], [2.25, 8], [6, 6.9]]
          },
          roundingIp: {
              xMin: -1,
              xMax: 7.99,
              yMin: -1,
              yMax: 5.99,
              obj: [12, 10],
              ineqs: [[-7, 5, 5, "l"], [9, 7, 54, "l"]],
              ineqTextPlaces: [[3, 5.25], [4.25, 3]],
              plotIntegerFeasible: true,
              addFeasibleRegionText: false
          },
          bbExample1: {
              xMin: -1,
              xMax: 6.99,
              yMin: -1,
              yMax: 6.99,
              obj: [10, 12],
              ineqs: [[1, 1, 5, "l"], [2, 4, 15, "l"]],
              ineqTextPlaces: [[0.5, 5], [4, 2.25]],
              plotIntegerFeasible: true,
              addFeasibleRegionText: false
          },
          bbExample2: {
              xMin: -1,
              xMax: 6.99,
              yMin: -1,
              yMax: 6.99,
              obj: [10, 12],
              ineqs: [[1, 1, 5, "l"], [2, 4, 15, "l"], [1, 0, 2, "l", [1]], [1, 0, 3, "g", [2]]],
              ineqTextPlaces: [[0.5, 5], [4, 2.25], [0.625, 6.5], [3.125, 4]],
              plotIntegerFeasible: true,
              addFeasibleRegionText: false,
              extraMathText: [["P^1", 80, 230], ["P^2", 190, 265]]
          },
          gomoryExample1: {
              xMin: -1,
              xMax: 4.99,
              yMin: -1,
              yMax: 4.99,
              obj: [4, -1],
              ineqs: [[7, -2, 14, "l"], [0, 1, 3, "l"], [2, -2, 3, "l"]],
              ineqTextPlaces: [[-5, -5], [-5, -5], [-5, -5]],
              plotIntegerFeasible: true,
              addFeasibleRegionText: false
          }
      }
      const drawPlot = (svg, svgId) => {
          // parameters
          svg.id = svgId;
          const parentDiv = document.createElement('div');
          svg.parentNode.insertBefore(parentDiv, svg);
          parentDiv.appendChild(svg);
          svgDefs = document.createElementNS('http://www.w3.org/2000/svg', 'defs');
          svg.appendChild(svgDefs);
          goodDirColor = 'blue';
          badDirColor = 'red';
          goodArrowheadMarker = document.createElementNS('http://www.w3.org/2000/svg', 'marker');
          goodArrowheadMarker.id = goodDirColor + 'ArrowMarker';
          goodArrowheadMarker.setAttribute('markerWidth', 5);
          goodArrowheadMarker.setAttribute('markerHeight', 3);
          goodArrowheadMarker.setAttribute('refX', 0);
          goodArrowheadMarker.setAttribute('refY', 1.5);
          goodArrowheadMarker.setAttribute('orient', 'auto');
          arrowPoly = document.createElementNS('http://www.w3.org/2000/svg', 'polygon');
          arrowPoly.setAttribute('points', "0 0, 5 1.5, 0 3");
          arrowPoly.setAttribute('fill', goodDirColor);
          goodArrowheadMarker.appendChild(arrowPoly);
          badArrowheadMarker = goodArrowheadMarker.cloneNode(true);
          badArrowheadMarker.id = badDirColor + 'ArrowMarker'
          badArrowheadMarker.firstChild.setAttribute('fill', badDirColor);
          arrowheadMarker = goodArrowheadMarker.cloneNode(true);
          arrowheadMarker.id = 'blackArrowMarker'
          arrowheadMarker.firstChild.setAttribute('fill', 'black');
          svgDefs.appendChild(goodArrowheadMarker);
          svgDefs.appendChild(badArrowheadMarker);
          svgDefs.appendChild(arrowheadMarker);
          const args = { ...JSON.parse(JSON.stringify(baseLps))[svg.getAttribute('base')], ...JSON.parse(svg.getAttribute('altargs'))};
          const xMin = args['xMin'];
          const xMax = args['xMax'];
          const yMin = args['yMin'];
          const yMax = args['yMax'];
          const plotExtremePoints = [[0, 0], [xMax, 0], [xMax, yMax], [0, yMax]];
          let obj = args['obj'];
          if (Object.keys(args).includes('altObj')){
              obj = args['altObj'];
          }
          let initialIneqs = args['ineqs'];
          let ineqTextPlaces = args['ineqTextPlaces'];
          const removeConstraints = args['removeConstraints'] || [];
          const addConstraints = args['addConstraints'] || []
          if (removeConstraints.length > 0) {
              initialIneqs = initialIneqs.filter((x, i) => !removeConstraints.includes(i));
              ineqTextPlaces = ineqTextPlaces.filter((x, i) => !removeConstraints.includes(i));
          }
          if (addConstraints.length > 0) {
              for (const addConstr of addConstraints){
                  initialIneqs.push(addConstr[0]);
                  ineqTextPlaces.push(addConstr[1])
              }
          }
          const altFeasRegionTextPlace = args['altFeasRegionTextPlace']
          const showVertices = args['showVertices'] || false;
          const choosePoints = args['choosePoints'] || false;
          const chooseObjVals = args['chooseObjVals'] || false;
          const simplexStart = args['simplexStart'];
          const extraPoints = args['extraPoints'] || [];
          const extraText = args['extraText'] || [];
          const extraMathText = args['extraMathText'] || [];
          const extraLines = args['extraLines'] || [];
          const extraEqns = args['extraEqns'] || [];
          const plotIntegerFeasible = args['plotIntegerFeasible'] || false;
          let addFeasibleRegionText = args['addFeasibleRegionText'];
          if (addFeasibleRegionText === undefined) {
              addFeasibleRegionText = true;
          }
          const x1ObjStr = obj[0] == 0 ? '' : `${obj[0]}x_1`;
          const x2ObjStr = obj[1] == 0 ? '' : `${obj[1]}x_2`;
          const betweenObjStr = obj[0] == 0 ? '' : (obj[1] > 0 ? '+' : '');
          const objStr = x1ObjStr + betweenObjStr + x2ObjStr;
          const w = svg.getAttribute('width');
          const h = svg.getAttribute('height');
          const leq = String.fromCharCode(8804);
          const geq = String.fromCharCode(8805);
          const getObjVal = (x, y) => obj[0] * x + obj[1] * y;
          const unitPixToCoordX = (xMax - xMin) / w;
          const unitPixToCoordY = (yMax - yMin) / h;
          svg.style.marginLeft = -Math.abs(1 / unitPixToCoordX) / 2;
          
          // functions
          const coordToPix = (xCoord, yCoord) => {
              xPix = w * (xCoord - xMin) / (xMax - xMin);
              yPix = h - h * (yCoord - yMin) / (yMax - yMin);
              return [xPix, yPix]
          }
          const pixToCoord = (xPix, yPix) => {
              xCoord = xPix * ((xMax - xMin) / w) + xMin;
              yCoord = (yPix - h) * (-(yMax - yMin) / h) + yMin;
              return [xCoord, yCoord]
          }
          const lineBetweenCoords = (x1, y1, x2, y2, attrs) => {
              el = document.createElementNS('http://www.w3.org/2000/svg', 'line');
              const [x1Pix, y1Pix] = coordToPix(x1, y1);
              const [x2Pix, y2Pix] = coordToPix(x2, y2);
              el.setAttribute('x1', x1Pix);
              el.setAttribute('y1', y1Pix);
              el.setAttribute('x2', x2Pix);
              el.setAttribute('y2', y2Pix);
              attrs = attrs || {}
              attrs['style'] = attrs['style'] || 'stroke:black';
              for (const [k, v] of Object.entries(attrs)){
                  el.setAttribute(k, v);
              }
              svg.appendChild(el);
          }
          const addText = (text, x, y, attrs) => {
              txt = document.createElementNS('http://www.w3.org/2000/svg', 'text');
              txt.textContent = text;
              txt.setAttribute('x', x);
              txt.setAttribute('y', y);
              for (const [k, v] of Object.entries(attrs || {})){
                  txt.setAttribute(k, v);
              }
              svg.appendChild(txt);
          }
          const addMathText = (math, x, y, attrs) => {
              attrs = attrs || {};
              forObj = document.createElementNS('http://www.w3.org/2000/svg', 'foreignObject');
              mathEl = document.createElement('span');
              katex.render(math, mathEl, {
                  throwOnError: false
              });
              if (attrs['coordToPix'] || false) {
                  [x, y] = coordToPix(x, y)
              }
              forObj.setAttribute('x', x);
              forObj.setAttribute('y', y);
              attrs['height'] = attrs['height'] || '1.2rem';
              attrs['width'] = attrs['width'] || '15rem';
              attrs['font-size'] = attrs['font-size'] || '12pt';
              attrs['font-family'] = attrs['font-family'] || 'KaTeX_Main,Times New Roman,serif';
              for (const [k, v] of Object.entries(attrs || {})){
                  forObj.setAttribute(k, v);
              }
              forObj.appendChild(mathEl);
              textsToAdd.push(forObj);
          }
          const drawIneqs = () => {
              style = 'stroke:#777;padding:5pt';
              let ineqNum = 0;
              for ([xCoef, yCoef, rhs, sense] of ineqs) {
                  ineqNum += 1;
                  const ineqId = svgId + 'ineq' + ineqNum
                  plotEqn(xCoef, yCoef, rhs, {style: style, id: ineqId});
                  let [e1x, e1y, e2x, e2y] = getEqnEndpoints(xCoef, yCoef, rhs);
                  hoverLineId = svgId + 'ineq' + ineqNum + 'hoverLine';
                  lineBetweenCoords(e1x, e1y, e2x, e2y, {'style': 'stroke:black;stroke-width:5;opacity:0', 'id': hoverLineId})
                  const hoverLine = document.getElementById(hoverLineId);
                  polyId = svgId + 'ineq' + ineqNum + 'shaded';
                  ((xCoef, yCoef, rhs, sense, polyId) => {
                      hoverLine.onmouseover = () => {
                          const cornerPoints = plotExtremePoints;
                          let pts = getIntersectionWithPoly(xCoef, yCoef, rhs, cornerPoints, false);
                          const cpts = cornerPoints.filter(cp => ineqSatisfied(...cp, xCoef, yCoef, rhs, sense));
                          const getPtStr = (p) => p[0] + '---' + p[1];
                          const usedPtStrs = pts.map(p => getPtStr(p));
                          skipPts = [];
                          foundFirstCorner = false;
                          lastUsed = pts[pts.length - 1];
                          for (cp of cpts) {
                              cpStr = getPtStr(cp)
                              if (cpStr in usedPtStrs) {
                                  continue
                              }
                              if (foundFirstCorner) {
                                  usedPtStrs.push(cpStr);
                                  pts.push(cp);
                              } else {                            
                                  if (cp[0] == lastUsed[0] || cp[1] == lastUsed[1]) {
                                      foundFirstCorner = true;
                                      usedPtStrs.push(cpStr);
                                      pts.push(cp);
                                  } else {
                                      skipPts.push(cp);
                                  }
                              }
                          }
                          pts = pts.concat(skipPts);
                          polygonFromPoints(pts, {id: polyId, style: 'fill:rgb(212,212,212);fill:rgb(212,212,212,0.5)'});
                      }
                      hoverLine.onmouseout = () => {
                          shadePoly = document.getElementById(polyId)
                          if (!!shadePoly){
                              shadePoly.remove();
                          }
                      }
                  })(xCoef, yCoef, rhs, sense, polyId)
              }
          }
          const plotEqn = (xCoef, yCoef, rhs, attrs) => {
              lineBetweenCoords(...getEqnEndpoints(xCoef, yCoef, rhs), attrs);
          }
          const getEqnEndpoints = (xCoef, yCoef, rhs) => {
              if (xCoef === 0) {
                  pts = [0, rhs / yCoef, xMax, rhs / yCoef];
              } else if (yCoef === 0) {
                  pts = [rhs / xCoef, 0, rhs / xCoef, yMax];
              } else {
                  pts = [0, rhs / yCoef, rhs / xCoef, 0];
              }
              if (pts[1] < 0) {
                  pts[1] = (rhs - xCoef * xMax) / yCoef;
                  pts[0] = xMax;
              }
              if (pts[2] < 0) {
                  pts[2] = (rhs - yCoef * yMax) / xCoef;
                  pts[3] = yMax;
              }
              return pts
          }
          const drawTickMarks = () => {
              xTick = 0
              style = {'font-size': '10pt', 'font-family': 'KaTeX_Main,Times New Roman,serif'}
              while (xTick <= xMax) {
                  if (xTick >= 0) {
                      lineBetweenCoords(xTick, 0, xTick, (yMax - yMin) / 30);
                      [xText, yText] = coordToPix(xTick, -(yMax - yMin) / 30);
                      addText(xTick, xText - 4, yText + 4, style);
                      xTick += 1;
                  }
              }
              yTick = 0
              while (yTick <= yMax) {
                  if (yTick >= 0) {
                      lineBetweenCoords(0, yTick, (xMax - xMin) / 30, yTick);
                      [xText, yText] = coordToPix(-(xMax - xMin) / 30, yTick);
                      addText(yTick, xText - 4, yText + 4, style);
                      yTick += 1;
                  }
              }
          }
          const isFeasible = (x, y, returnViolated=false, altIneqs=undefined) => {
              let feasible = true;
              let violated = [];
              for ([xCoef, yCoef, rhs, sense] of (altIneqs || allIneqs)) {
                  if (!ineqSatisfied(x, y, xCoef, yCoef, rhs, sense)){
                      feasible = false;
                      if (returnViolated) {
                          violated.push([xCoef, yCoef, rhs])
                      } else {                        
                          break
                      }
                  }
              }
              if (returnViolated) {
                  return [feasible, violated];
              }
              return feasible
          }
          const onPlot = (x, y) => {
              if (x < 0 || x > xMax || y < 0 || y > yMax) {
                  return false
              }
              return true
          }
          const ineqSatisfied = (x, y, xCoef, yCoef, rhs, sense) => {
              if (sense === "l") {
                  return x * xCoef + y * yCoef <= rhs + 0.0001
              } else {
                  return x * xCoef + y * yCoef >= rhs - 0.0001
              }
          }
          const getVertices = (includePlotEdges=false) => {
              let ineqsToUse = allIneqs;
              if (includePlotEdges) {
                  ineqsToUse = ineqsToUse.concat([[1, 0, xMax, 'l'], [0, 1, yMax, 'l']]);
              }
              let intersections = [];
                  for ([i, [xCoef, yCoef, rhs, sense]] of ineqsToUse.entries()) {
                      for ([j, [xCoef1, yCoef1, rhs1, sense1]] of ineqsToUse.entries()){
                          if (j <= i){
                              continue
                          }
                          denom = xCoef * yCoef1 - xCoef1 * yCoef
                          if (denom === 0){
                              continue
                          }
                          num = xCoef * rhs1 - xCoef1 * rhs;
                          yIntersect = num / denom;
                          if (xCoef === 0 && yCoef1 === 0 && rhs !== 0 && rhs1 !== 0){
                              intersections.push([rhs1 / xCoef1, rhs / yCoef, i, j])
                              continue
                          }
                          else if (xCoef === 0) {
                              xIntersect = rhs1 / xCoef1;
                              if (rhs !== 0) {
                                  xIntersect = rhs * xIntersect;
                              }
                          } else {
                              xIntersect = (rhs / xCoef) - (yCoef / xCoef) * num / denom;
                          }
                          if (xIntersect == 0){
                              xIntersect = 0;
                          }
                          if (yIntersect == 0){
                              yIntersect = 0;
                          }
                          intersections.push([xIntersect || 0, yIntersect, i, j]);
                      }
                  }
                  let vertexStrs = [];
                  let vertices = [];
                  for ([x, y, i, j] of intersections) {
                      if (isFeasible(x, y) && onPlot(x, y)) {
                          vertices.push([x, y, i, j]);
                      }
                  }
                  orderedVertexIndices = [0];
                  while (orderedVertexIndices.length < vertices.length) {
                      nextIndex = [...vertices.entries()].filter((val, ind) => {
                          if (orderedVertexIndices.includes(ind)) {
                              return false
                          }
                          lastInd = orderedVertexIndices[orderedVertexIndices.length - 1];
                          return (
                              vertices[ind][2] == vertices[lastInd][2] ||
                              vertices[ind][2] == vertices[lastInd][3] ||
                              vertices[ind][3] == vertices[lastInd][2] ||
                              vertices[ind][3] == vertices[lastInd][3]
                          )
                      })[0][0]
                      orderedVertexIndices.push(nextIndex);
                  }
              if (vertices.length === 0) {
                  return []
              }
              return orderedVertexIndices.map(i => vertices[i].slice(0, 2))
          }
          const polygonFromPoints = (points, attrs) => {
              const poly = document.createElementNS('http://www.w3.org/2000/svg', 'polygon');
              poly.setAttribute('points', points.map(v => coordToPix(...v)).join(' '));
              for (const [k, v] of Object.entries(attrs || {})){
                  poly.setAttribute(k, v);
              }
              svg.appendChild(poly);
          }
          const shadeFeasibleRegion = () => {
              const verts = getVertices(true);
              if (verts.length === 0){
                  return
              }
              polygonFromPoints(verts, {'style': "fill:#ddd;stroke:black"})
              if (!!altFeasRegionTextPlace) {
                  const [xPix, yPix] = coordToPix(...altFeasRegionTextPlace);
              } else {
                  const xWeighted = verts.map(v => v[0]).reduce((a, b) => a + b) / verts.length;
                  const yWeighted = verts.map(v => v[1]).reduce((a, b) => a + b) / verts.length;
                  const [xPix, yPix] = coordToPix(xWeighted, yWeighted);
              }
              if (addFeasibleRegionText) {
                  addText("Feasible", xPix - 30, yPix, {'font-size': '12pt'});
                  addText("Region", xPix - 30, yPix + 20, {'font-size': '12pt'});
              }
          }
          const placePoint = (x, y, attrs) => {
              circ = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
              const [xPix, yPix] = coordToPix(x, y);
              circ.setAttribute('cx', xPix);
              circ.setAttribute('cy', yPix);
              circ.setAttribute('r', 3.5);
              for (const [k, v] of Object.entries(attrs || {})){
                  circ.setAttribute(k, v);
              }
              svg.appendChild(circ);
          }
          const plotVertices = () => {
              const vertices = getVertices();
              for ([x, y] of vertices) {
                  placePoint(x, y);
              }
          }
          const drawAxes = () => {
              const fontStyle = {'font-size': '12pt', 'font-family': 'KaTeX_Main,Times New Roman,serif'};
              lineBetweenCoords(0, 0, xMax, 0);
              xDiff = 10 * unitPixToCoordX
              yDiff = 4 * unitPixToCoordY
              polygonFromPoints([[xMax, 0], [xMax - xDiff, yDiff], [xMax - xDiff, -yDiff]], {'style': "fill:black;stroke:black"});
              [xLabelPix, yLabelPix] = coordToPix(Math.ceil(xMax) - 0.5, 0);
              addMathText('x_1', xLabelPix, yLabelPix, fontStyle);
              [xLabelPix, yLabelPix] = coordToPix(0, Math.ceil(yMax) - 0.5);
              addMathText('x_2', xLabelPix - 24, yLabelPix - 20, fontStyle);
              lineBetweenCoords(0, 0, 0, yMax);
              xDiff = 4 * unitPixToCoordX
              yDiff = 10 * unitPixToCoordY
              polygonFromPoints([[0, yMax], [xDiff, yMax - yDiff], [-xDiff, yMax - yDiff]], {'style': "fill:black;stroke:black"});
          }
          const labelIneqs = () => {
              for (i in ineqTextPlaces || []) {
                  ineq = initialIneqs[i];
                  ineqText = ''
                  ineqText += ineq[0] === 0 ? '' : (ineq[0] == 1 ? '' : ineq[0]) + 'x_1'
                  ineqText += ineq[1] === 0 ? '' : (ineqText === '' ? '' : ' + ') + (ineq[1] == 1 ? '' : ineq[1]) + 'x_2'
                  ineqText += ' ' + (ineq[3] === 'l' ? leq : geq) + ' ' + ineq[2];
                  fontStyle = {'font-size': '12pt'}
                  addMathText(ineqText, ...coordToPix(...ineqTextPlaces[i]), fontStyle);
              }
          }
          const getIntersectionWithPoly = (xCoef, yCoef, rhs, points, checkFeas=true, altIneqs=undefined) => {
              let intersections = [];
              let intersectionStrs = [];
              for (i=0; i<points.length; i++){
                  const [p1, p2] = points[i];
                  const [q1, q2] = points[(i + 1) % points.length];
                  const m1 = (p2 - q2) / (p1 - q1);
                  const b1 = p2 - m1 * p1;
                  const m2 = -xCoef / yCoef;
                  const b2 = rhs / yCoef;
                  if (m1 === m2) {
                      continue
                  }
                  if (Math.abs(m1) === Infinity) {
                      xIntersect = p1;
                      yIntersect = m2 * xIntersect + b2;
                  } else if (Math.abs(m2) === Infinity) {
                      xIntersect = rhs / xCoef;
                      yIntersect = m1 * xIntersect + b1
                  } else {
                      xIntersect = (b2 - b1) / (m1 - m2);
                      yIntersect = m1 * xIntersect + b1;
                  }
                  xIntersect = Math.round(1000000 * xIntersect) / 1000000;
                  yIntersect = Math.round(1000000 * yIntersect) / 1000000;
                  interStr = xIntersect + '---' + yIntersect;
                  p = [xIntersect, yIntersect]
                  if (!intersectionStrs.includes(interStr) && xIntersect === xIntersect && yIntersect === yIntersect) {
                      if ((!checkFeas || isFeasible(...p, false, altIneqs)) && onPlot(...p)) {
                          intersectionStrs.push(interStr);
                          intersections.push(p)
                      }
                  }
              }
              return intersections
          }
          const gcd = (a, b) => {
              if (!b) {
                  return Math.abs(a);
              }
              return Math.abs(gcd(b, a % b));
          }
          const addIntegerFeasiblePoints = () => {
              let xVal = Math.ceil(xMin);
              while (xVal <= xMax) {
                  let yVal = Math.ceil(yMin);
                  while (yVal <= yMax) {
                      if (isFeasible(xVal, yVal)) {
                          placePoint(xVal, yVal);
                      }
                      yVal += 1;
                  }
                  xVal += 1;
              }
          }
          const choosePointsFunc = (allIneqs) => {
              const underDiv = document.createElement('div');
              underDiv.classList = ['underPlot']
              parentDiv.appendChild(underDiv);
              const objDiv = document.createElement('div');
              objDiv.classList = ['pointChooseText'];
              underDiv.appendChild(objDiv);
              katex.render(`\\text{Objective: }${objStr}`, objDiv, {throwOnError: false});
              const pointChooseDiv = document.createElement('div');
              pointChooseDiv.classList = ['pointChooseDiv'];
              underDiv.appendChild(pointChooseDiv);
              const input1 = document.createElement('input');
              const label1 = document.createElement('label');
              label1.classList = ['pointChooseLabel']
              katex.render('x_1:', label1, {throwOnError: false});
              const input2 = document.createElement('input');
              const label2 = document.createElement('label');
              label2.classList = ['pointChooseLabel'];
              katex.render('x_2:', label2, {throwOnError: false});
              const textDiv = document.createElement('div');
              textDiv.classList = ['pointChooseText'];
              underDiv.appendChild(textDiv);
              katex.render('\\text{Select values for }x_1\\text{ and }x_2', textDiv, {throwOnError: false})
              for (inputEl of [input1, input2]) {
                  inputEl.setAttribute('type', 'number');
                  inputEl.setAttribute('min', 0);
                  inputEl.classList = ['pointChooseInput'];
              }
              input1.setAttribute('max', Math.floor(xMax));
              input2.setAttribute('max', Math.floor(yMax));  // todo: enforce min/max in onchange function
              const inputChangeFunc = () => {
                  [x1, x2] = [input1.value, input2.value];
                  const lineClass = 'violatedIneq' + svgId;
                  if (x1 == parseFloat(x1) && x2 == parseFloat(x2)){
                      for (violEl of [...document.getElementsByClassName(lineClass)]){
                          violEl.remove();
                      }
                      const pointId = svgId + 'placedPoint';
                      const pointEl = document.getElementById(pointId);
                      if (!!pointEl) {
                          pointEl.remove();
                      }
                      const [feas, violated] = isFeasible(x1, x2, true, allIneqs);
                      const color = feas ? 'black' : 'red';
                      textDiv.innerHTML = '';
                      if (feas) {
                          textDiv.textContent = `(${x1}, ${x2}) is feasible, objective value ${getObjVal(x1, x2)}.`
                      }
                      else {
                          textDiv.textContent = `(${x1}, ${x2}) is infeasible.`
                          for (v of violated) {
                              plotEqn(...v, {'style': 'stroke:red;stroke-width:0', 'class': 'violatedIneq ' + lineClass})
                          }
                      }
                      placePoint(input1.value, input2.value, {'id': pointId, 'style': `stroke:${color};fill:${color}`});
                  }
              }
              input1.addEventListener("change", inputChangeFunc);
              input2.addEventListener("change", inputChangeFunc);
              svg.onclick = (e) => {                
                  let rect = svg.getBoundingClientRect();
                  let x = e.clientX - rect.left;
                  let y = e.clientY - rect.top;
                  [xPix, yPix] = pixToCoord(x, y);
                  input1.value = Math.round(10 * xPix) / 10;
                  input2.value = Math.round(10 * yPix) / 10;
                  inputChangeFunc();
              }
              for (el of [label1, input1, label2, input2]) {
                  pointChooseDiv.appendChild(el);
              }
          }
          const chooseObjValsFunc = (allIneqs, verticesAndPlotEdges) => {
              const underDiv = document.createElement('div');
              underDiv.classList = ['underPlot']
              parentDiv.appendChild(underDiv);
              const pointChooseDiv = document.createElement('div');
              pointChooseDiv.classList = ['pointChooseDiv'];
              underDiv.appendChild(pointChooseDiv);
              const pointValDiv = document.createElement('div');
              pointValDiv.classList = ['pointChooseDiv'];
              underDiv.appendChild(pointChooseDiv);
              const input = document.createElement('input');
              const label = document.createElement('label');
              label.classList = ['pointChooseLabel'];
              katex.render(`\\text{Plotting objective: }${objStr}=`, label, {throwOnError: false});
              const textDiv = document.createElement('div');
              textDiv.classList = ['pointChooseText'];
              underDiv.appendChild(textDiv);
              textDiv.textContent = 'Select a value to plot an objective line.'
              input.setAttribute('type', 'number');
              input.setAttribute('min', 0);
              maxObjVal = 0;
              for (extreme of plotExtremePoints) {
                  exObjVal = getObjVal(...extreme);
                  if (exObjVal > maxObjVal) {
                      maxObjVal = exObjVal;
                  }
              }
              input.setAttribute('max', maxObjVal);
              input.classList = ['pointChooseInput'];
              const inputChangeFunc = () => {
                  z = input.value;
                  if (z == parseFloat(z)){
                      eqnId = svgId + 'objEqn';
                      eqnEl = document.getElementById(eqnId);
                      if (!!eqnEl) {
                          eqnEl.remove();
                      }
                      plotEqn(...obj, z, {id: eqnId});
                      const intersectPoints = getIntersectionWithPoly(...obj, z, verticesAndPlotEdges, true, allIneqs);
                      const intersectLineId = svgId + 'objLineIntersect';
                      intersectLine = document.getElementById(intersectLineId);
                      if (!!intersectLine) {
                          intersectLine.remove();
                      }
                      if (intersectPoints.length === 0) {
                          textDiv.textContent = 'No feasible solutions with objective value ' + z;
                      } else if (intersectPoints.length === 1) {
                          textDiv.textContent = `Single feasible solution (${intersectPoints[0]}) with objective value ${z}`;
                          placePoint(...intersectPoints[0], {'style': 'fill:purple', 'id': intersectLineId})
                      } else {
                          textDiv.textContent = `Multiple feasible solutions have objective value ${z}`;
                          lineBetweenCoords(...intersectPoints[0], ...intersectPoints[1], {'style': 'stroke:purple;stroke-width:2pt', 'id': intersectLineId});
                      }
                  }
              }
              input.addEventListener("change", inputChangeFunc);
              svg.onclick = (e) => {                
                  let rect = svg.getBoundingClientRect();
                  let x = e.clientX - rect.left;
                  let y = e.clientY - rect.top;
                  let z = getObjVal(...pixToCoord(x, y));
                  input.value = Math.round(10 * z) / 10;
                  inputChangeFunc();
              }
              for (el of [label, input]) {
                  pointChooseDiv.appendChild(el);
              }
          
          }
          const simplexStartFunc = () => {
              let nextPoint = simplexStart;
              let pointHistory = [];
              const underDiv = document.createElement('div');
              underDiv.classList = ['underPlot']
              parentDiv.appendChild(underDiv);
              const objDiv = document.createElement('div');
              objDiv.classList = ['pointChooseText'];
              underDiv.appendChild(objDiv);
              katex.render(`\\text{Objective: }${objStr}`, objDiv, {throwOnError: false});
              const currentPlaceText = document.createElement('div');
              currentPlaceText.classList = ['pointChooseText'];
              const possibleDirections = document.createElement('div');
              possibleDirections.classList = ['pointChooseText'];
              const status = document.createElement('div');
              status.classList = ['pointChooseText'];
              const buttonsDiv = document.createElement('div');
              buttonsDiv.classList = ['pointChooseText'];
              const backButton = document.createElement('button');
              backButton.textContent = '<<'
              const resetButton = document.createElement('button');
              resetButton.textContent = 'Reset'
              const forwardButton = document.createElement('button');
              forwardButton.textContent = '>>'
              buttonsDiv.appendChild(backButton);
              buttonsDiv.appendChild(resetButton);
              buttonsDiv.appendChild(forwardButton);
              underDiv.appendChild(currentPlaceText);
              underDiv.appendChild(possibleDirections);
              underDiv.appendChild(buttonsDiv);
              underDiv.appendChild(status);
              const simplexPointId = svgId + 'SimplexPoint';
              const getArrowClass = () => svgId + 'SimplexArrowDir';
              const getArrowIdFromCheckId = (checkId) => checkId + 'TargetArrow';
              const changePoint = () => {
                  currentPoint = pointHistory.length === 0 ? simplexStart : pointHistory[pointHistory.length - 1];
                  simplexPointEl = document.getElementById(simplexPointId);
                  if (!!simplexPointEl) {
                      simplexPointEl.remove();
                      for (arrowEl of [...document.getElementsByClassName(getArrowClass())]){
                          arrowEl.remove();
                      }
                  }
                  katex.render(
                      `\\text{Current solution: }(${currentPoint[0]}, ${currentPoint[1]}),\\text{ objective }${getObjVal(...currentPoint)}`,
                      currentPlaceText
                  );
                  const vertices = getVertices();
                  const vertInd = vertices.map((x, i) => i).filter(i => {
                      return vertices[i][0] === currentPoint[0] && vertices[i][1] === currentPoint[1]
                  })[0];
                  adjacents = [vertInd - 1, vertInd + 1].map(i => {
                      return vertices[(i + vertices.length) % vertices.length]    
                  });
                  adjDir = adjacents.map(adj => {
                      dir = [adj[0] - currentPoint[0], adj[1] - currentPoint[1]];
                      dirGcd = gcd(...dir);
                      return [dir[0] / dirGcd, dir[1] / dirGcd];
                  });
                  possibleDirections.innerHTML = '';
                  possibleDirections.textContent = 'Adjacent solution directions:'
                  const tab = document.createElement('table');
                  tab.classList = ['simplexDirectionTable'];
                  const dirHead = document.createElement('th');
                  dirHead.textContent = 'Direction';
                  const objHead = document.createElement('th');
                  objHead.innerHTML = '&Delta; Obj / Unit';
                  const useDir = document.createElement('th');
                  useDir.innerHTML = 'Use?';
                  tab.appendChild(dirHead);
                  tab.appendChild(objHead);
                  tab.appendChild(useDir);
                  possibleDirections.appendChild(tab);
                  dirGains = [];
                  const getCheckId = i => simplexPointId + 'DirCheck' + i
                  for ([i, adj] of adjDir.entries()) {
                      const tr = document.createElement('tr');
                      tab.appendChild(tr);
                      const dirTd = document.createElement('td');
                      dirTd.textContent = `(${adj[0]}, ${adj[1]})`;
                      adjDirNorm = Math.sqrt(adj[0] ** 2 + adj[1] ** 2);
                      unitObjGain = getObjVal(...adj) / adjDirNorm;
                      const arrowHeadCoord = adj.map((ad, iAd) => currentPoint[iAd] + 45 * unitPixToCoordX * ad / adjDirNorm);
                      const plotColor = unitObjGain > 0 ? goodDirColor : badDirColor;
                      attrs = {
                          'style': 'stroke-width:2pt;stroke:' + plotColor,
                          'marker-end': `url(#${plotColor}ArrowMarker)`,
                          'class': getArrowClass(),
                          'id': getArrowIdFromCheckId(getCheckId(i))
                      }
                      lineBetweenCoords(...currentPoint, ...arrowHeadCoord, attrs);
                      dirGains.push(unitObjGain);
                      const objTd = document.createElement('td');
                      objTd.textContent = Math.round(100 * unitObjGain) / 100;
                      const useTd = document.createElement('td');
                      const useInput = document.createElement('input');
                      useInput.id = getCheckId(i);
                      useInput.setAttribute('type', 'checkbox');
                      useInput.onchange = (e) => {
                          for (inputInd = 0; inputInd < adjacents.length; inputInd++){
                              inEl = document.getElementById(getCheckId(inputInd));
                              if (inEl !== e.target){
                                  inEl.checked = false;
                                  document.getElementById(getArrowIdFromCheckId(inEl.id)).classList.remove('simplexArrowChosen');
                              } else {
                                  if (e.target.checked) {
                                      nextPoint = adjacents[inputInd];
                                      document.getElementById(getArrowIdFromCheckId(e.target.id)).classList.add('simplexArrowChosen');
                                  } else {
                                      nextPoint = undefined;
                                      document.getElementById(getArrowIdFromCheckId(e.target.id)).classList.remove('simplexArrowChosen');
                                  }   
                              }                            
                              buttonStatusChange();
                          }
                      }
                      if (unitObjGain <= 0){
                          useInput.disabled = true;
                          tr.style.color = 'red';
                      }
                      useTd.appendChild(useInput);
                      tr.appendChild(dirTd);
                      tr.appendChild(objTd);
                      tr.appendChild(useTd);
                  }                
                  placePoint(...currentPoint, {'id': simplexPointId, 'r': '4.5'});
                  const maxDirGain = Math.max(...dirGains);
                  const numImprovingDirections = dirGains.filter(g => g > 0).length;
                  if (maxDirGain < 0) {
                      status.innerHTML = 'No improving directions, <b>optimal solution found!</b>';
                      nextPoint = undefined;
                  } else {
                      const bestInd = adjacents.map((adj, i) => i).filter(i => dirGains[i] === maxDirGain)[0];
                      const bestDir = adjDir[bestInd];
                      status.textContent = `${numImprovingDirections} improving direction${numImprovingDirections === 1 ? '.' : 's to choose from.'}`;
                      const bestCheck = document.getElementById(getCheckId(bestInd));
                      bestCheck.checked = true;
                      bestCheck.onchange({target: bestCheck});
                      nextPoint = adjacents[bestInd];
                  }
                  buttonStatusChange();
              }
              const buttonStatusChange = () => {                
                  backButton.disabled = pointHistory.length === 0;
                  forwardButton.disabled = !nextPoint;
              }
              forwardButton.onclick = () => {
                  pointHistory.push(nextPoint);
                  changePoint();
              }
              resetButton.onclick = () => {
                  nextPoint = undefined;
                  pointHistory = [];
                  changePoint();
              }          
              backButton.onclick = () => {
                  pointHistory.pop(pointHistory.length - 1);
                  changePoint();
              }
              changePoint();
          
          }

          // logic
          allSystemNums = new Set();
          textsToAdd = [];
          for ([xCoef, yCoef, rhs, sense, systemNums] of initialIneqs) {
              if (!!systemNums) {
                  for (sysNum of systemNums) {
                      allSystemNums.add(sysNum);
                  }
              }
          }
          if (allSystemNums.size === 0){
              allSystemNums.add(0);
          }
          labelIneqs();
          for (sysNum of allSystemNums) {
              ((sysNum) => {
                  ineqs = initialIneqs.filter(ineq => {
                      [xCoef, yCoef, rhs, sense, sysNums] = ineq;
                      if (!sysNums) {
                          return true
                      }
                      return sysNums.includes(sysNum)
                  })
                  allIneqs = ineqs.concat([[1, 0, 0, "g"], [0, 1, 0, "g"]]);
                  drawIneqs();
                  shadeFeasibleRegion();
                  drawTickMarks();
                  if (showVertices){
                      plotVertices();
                  }
                  drawAxes();
                  for (pt of extraPoints) {
                      placePoint(...pt);
                  }
                  for (ln of extraLines) {
                      lineBetweenCoords(...ln);
                  }
                  for (tx of extraText) {
                      addText(...tx);
                  }
                  for (tx of extraMathText) {
                      addMathText(...tx);
                  }
                  if (choosePoints) {
                      choosePointsFunc(allIneqs);
                  }
                  if (chooseObjVals) {
                      const verticesAndPlotEdges = getVertices(true);
                      chooseObjValsFunc(allIneqs, verticesAndPlotEdges);
                  }
                  if (simplexStart) {
                      simplexStartFunc();
                  }
                  if (plotIntegerFeasible) {
                      addIntegerFeasiblePoints();
                  }
              })(sysNum)
          }
          for (textObj of textsToAdd) {
              svg.appendChild(textObj);
          }
      }
      const drawAllSvgPlots = () => {
          for ([i, svgEl] of document.querySelectorAll('svg.lpDraw').entries()){
              ((i, svgEl) => {
                  drawPlot(svgEl, 'svg' + i);
              })(i, svgEl)
          }
      }
  </script>
  <style>   
      #classModeDiv {
          position: fixed;
          width: min(max(80%, calc(100% - min(50%, 300px) - 1rem)), 700px);
          padding: 30pt;
          top: 200px;
          left: 50%;
          transform: translateX(-50%);
          background-color: white;
          border: 2pt solid;
          border-radius: 10pt;
          padding: 10px;
          box-shadow: 5px 5px rgb(200, 200, 200);
          visibility: hidden;
      }
  </style>
  <script>
      const classModeSetup = () => {
          const classMode = document.getElementById('classModeDiv');
          let noClassModeHref = window.location.href.split('#')[0];
          if (noClassModeHref[noClassModeHref.length - 1] !== '/') {
              noClassModeHref += '/';
          }
          noClassModeHref += '?classmode=false';
          classMode.onclick = closeClassMode;
          classMode.innerHTML = `
              <div>
                  Welcome to class mode! This is your friendly reminder to check that:
                  <ul>
                      <li>The mics are on.</li>
                      <li>The camera is pointed at the whiteboard.</li>
                      <li>PIP is off.</li>
                  </ul>
                  Click anywhere to close this window.
                  <div>To turn off class mode, click <a href=${noClassModeHref}>here</a>.</div>
              </div>
          `
      }
      const closeClassMode = () => {
          const classMode = document.getElementById('classModeDiv');
          const noClassModeHref = window.location.href.split('?')[0] + '/?classmode=false';
          const minutesBetweenReminders = 30;
          if (classMode.style.visibility === "visible") {
              classMode.style.visibility = "hidden";
              classMode.innerHTML = `
                  <div>
                      <div style='padding: 0.5rem;'>Hi! This is your periodic class mode reminder to:</div>
                      <div style='text-align:center;font-size:1.2rem;'><b>Check the microphone!</b></div>
                      <div style='padding: 0.5rem;'>Click anywhere to close this window.</div>
                      <div style='padding: 0.5rem;'>To turn off class mode, click <a href=${noClassModeHref}>here</a>.</div>
                  </div>
              `
              setTimeout(() => classMode.style.visibility = "visible", 1000 * 60 * minutesBetweenReminders);
          }
      }
  </script>
  <script>
      document.onreadystatechange = () => {
          if (document.readyState !== "complete") {
              document.querySelector("#main").style.display = "none";
              document.querySelector(".navbar").style.display = "none";
              document.querySelector("#loader").style.visibility = "visible";
              document.querySelector("#classModeDiv").style.visibility = "hidden";
          } else {
              document.querySelector("#loader").style.display = "none";
              document.querySelector(".navbar").style.display = "flex";
              document.querySelector("#main").style.display = "block";
              if (getUrlParameter('classmode') !== 'false') {
                  document.querySelector("#classModeDiv").style.visibility = "visible";
              }
          }
      };
      window.onload = () => {
          appendixSecNo = renumberAppendix();
          addMathContainers();
          theoremHelpers();
          addRefsToToc();
          eqRefExpandLinksAndAddTooltips();
          citeRefExpandLinksAndAddTooltips();
          secRefExpandLinksAndAddBackArrow(appendixSecNo);
          addFootnoteTooltips();
          addCodeCopyButtons();
          tocHelpers();
          drawAllSvgPlots();
          classModeSetup();
          videoEmbeds();
          document.onclick = closeClassMode;
          document.getElementById('main').onclick = closeNavIfSmall;
          makeAssignmentLink();
          drawPlotlyCharts();
          drawBBTrees();
          drawAllPlotlyFunctions();
      }
      drawPlotlyCharts = () => {
          for ([ind, el] of [...document.getElementsByClassName('plotlyLineChart')].entries()) {
              chartId = 'plotyChart' + ind;
              el.id = chartId;
              plotData = JSON.parse(el.getAttribute('data-plot-data'));
              plotLayout = JSON.parse(el.getAttribute('data-plot-layout') || '{}');
              Plotly.newPlot(chartId, plotData, plotLayout)
          }
      }
      makeAssignmentLink = () => {
          toAssignmentsEl = document.getElementById('toAssignments');
          if (!!toAssignmentsEl){
              toAssignmentsEl.setAttribute('href',
                  window.location.href.split('#')[0].split('?')[0] + 'assignments.html'
              )
          }
      }
      getUrlParameter = (name) => {
          name = name.replace(/[\[]/, '\\[').replace(/[\]]/, '\\]');
          var regex = new RegExp('[\\?&]' + name + '=([^&#]*)');
          var results = regex.exec(location.search);
          return results === null ? '' : decodeURIComponent(results[1].replace(/\+/g, ' '));
      };
      addMathContainers = () => {
          for (el of document.querySelectorAll('.math.display')) {
              katexContainer = document.createElement('div');
              katexContainer.classList = ['katexContainer'];
              el.parentNode.insertBefore(katexContainer, el);
              katexContainer.appendChild(el);
          }
      }
      renumberAppendix = () => {
          const appendixEl = document.getElementById('appendix') || document.getElementById('sec:appendix');
          const appendixSecNo = appendixEl.getAttribute('data-number');
          appendixEl.setAttribute('data-number', 'A');
          appendixEl.firstChild.remove();
          const appendixSections = [...document.getElementsByTagName('*')].filter(el => {
              return (el.getAttribute('data-number') || 'a').split('.')[0] === appendixSecNo;
          })
          for (apSec of appendixSections) {
              const numSplit = apSec.getAttribute('data-number').split('.');
              const secNo = 'A.' + numSplit.slice(1).join('.');
              apSec.setAttribute('data-number', secNo);
              apSec.firstChild.textContent = secNo;
          }
          const tocEls = [...document.getElementsByClassName('toc-section-number')].filter(el => {
              return (el.textContent).split('.')[0] === appendixSecNo;
          })
          for (tocEl of tocEls) {
              if (tocEl.textContent == appendixSecNo) {
                  tocEl.remove();
              } else {
                  const numSplit = tocEl.textContent.split('.');
                  const secNo = 'A.' + numSplit.slice(1).join('.');
                  tocEl.textContent = secNo;
              }
          }
          return appendixSecNo
      }
      tocHelpers = () => {
          for (el of document.querySelectorAll('#TOC a')) {
              const hrefId = el.getAttribute('href').slice(1);
              let parentEl = el.parentNode;
              let numUlsNested = 0;
              while (!!parentEl) {
                  numUlsNested += (parentEl.tagName == 'UL') ? 1 : 0
                  parentEl = parentEl.parentNode
              }
              innerHTML = el.innerHTML;
              el.innerHTML = '';
              newEl = document.createElement('div');
              newEl.innerHTML = innerHTML;
              newEl.style.marginLeft = numUlsNested * 0.4 + 'rem';
              newEl.style.display = 'flex';
              newEl.innerHTML = innerHTML;
              if (numUlsNested > 1) {
                  el.parentNode.classList.add('tocHideable');
                  el.parentNode.classList.add('tocHidden');
              }
              liParent = el.parentNode;
              if (liParent.getElementsByTagName('UL').length > 0) {
                  expandEl = document.createElement('span');
                  expandEl.innerHTML = '&nbsp;+&nbsp;';
                  expandEl.classList = ['tocExpand'];
                  newEl.appendChild(expandEl);
                  ((expandEl, liParent) => {
                      expandEl.onclick = (e) => {
                          for (hideable of [...liParent.getElementsByClassName('tocHideable')]) {
                              let hideableParent = hideable.parentNode;
                              while (hideableParent.tagName !== 'LI') {
                                  hideableParent = hideableParent.parentNode
                              }
                              if (hideableParent !== liParent) {
                                  continue
                              }
                              if ([...hideable.classList].includes('tocHidden')) {
                                  hideable.classList.remove('tocHidden');
                                  expandEl.innerHTML = '&nbsp;-&nbsp;';
                              } else {
                                  hideable.classList.add('tocHidden');
                                  expandEl.innerHTML = '&nbsp;+&nbsp;';
                              }
                          };
                          e.preventDefault();
                      }
                  })(expandEl, liParent)
              }
              el.appendChild(newEl);
          }
      }
      addCodeCopyButtons = () => {
          buttonAddFunc = () => {
              copyButtons = document.querySelectorAll('.copyButton');
              wide = 700;
              if (copyButtons.length > 0) {
                  if (window.innerWidth < wide) {
                      for (cb of copyButtons) {
                          cb.remove();
                      }
                  }
              } else {
                  if (window.innerWidth >= wide) {
                      for (el of document.querySelectorAll('div.sourceCode')) {
                          copyEl = document.createElement('span');
                          el.insertBefore(copyEl, el.firstChild);
                          copyEl.innerHTML = '📋';
                          copyEl.classList = ['copyButton'];
                          ((el, copyEl) => {
                              copyEl.onclick = () => {
                                  text = el.getElementsByTagName('pre')[0].textContent;
                                  navigator.clipboard.writeText(text);
                                  infoEl = document.createElement('div');
                                  infoEl.textContent = 'Copied!';
                                  infoEl.classList = ['copyMessage']
                                  copyEl.appendChild(infoEl);
                                  setTimeout(() => infoEl.remove(), 2000);
                              };
                          })(el, copyEl)
                      }
                  }
              }
          }
          buttonAddFunc();
          window.addEventListener("resize", buttonAddFunc);
      }
      addRefsToToc = () => {
          liEl = document.createElement('li');
          aEl = document.createElement('a');
          aEl.href = '#References';
          aEl.innerHTML = 'References';
          ulEl = document.getElementById('TOC').getElementsByTagName('ul')[0];
          liEl.appendChild(aEl);
          ulEl.appendChild(liEl);
      }
      addTooltips = (els, includeLinkBacks, arrowFloat = false) => {
          for ([i, el] of els.entries()) {
              if ([...el.classList].includes('refNotFound')) {
                  continue;
              }
              ((el, i) => {
                  refId = el.getAttribute('href');
                  refEl = document.getElementById(refId.slice(1));
                  el.setAttribute('href', '#');
                  el.classList = ['eqnRef'];
                  nextEl = document.createElement('span');
                  el.parentNode.insertBefore(nextEl, el.nextSibling);
                  popupId = refId + 'popup' + i;
                  elId = popupId + 'Ref';
                  nextEl.id = elId;
                  ((a, b, c, d, e) => {
                      a.onclick = () => {
                          footnoteOnTooltipClick(b, c, d, e);
                          return false
                      };
                  })(el, popupId, refEl.innerHTML, elId, includeLinkBacks ? refId.slice(1) : null)
                  if (includeLinkBacks) {
                      backId = 'back' + refId;
                      backEl = document.getElementById(backId);
                      if (!!!backEl) {
                          backEl = document.createElement('div');
                          backEl.id = backId;
                          backEl.classList = ['backRefElement'];
                          backArrowEl = document.createElement('a');
                          backArrowEl.id = backId + 'Arrow';
                          backArrowEl.innerHTML = "↩︎";
                          backArrowEl.style.display = 'none';
                          backEl.onclick = () => backEl.style.display = 'none';
                          backEl.appendChild(backArrowEl);
                          refEl.appendChild(backEl);
                      }
                  }
              })(el, i)
          }
      }
      expandLinks = (els, prevWordInclude) => {
          for (const el of els) {
              sib = el.previousSibling;
              sibTextSplit = sib.textContent.split(/\s+/).filter(s => s !== '');
              prevWord = sibTextSplit[sibTextSplit.length - 1].replace('(', '');
              if (prevWordInclude.includes(prevWord)) {
                  repS = RegExp(`${prevWord}[^a-zA-Z]$`);
                  el.innerHTML = prevWord + ' ' + el.innerHTML;
                  sib.textContent = sib.textContent.replace(repS, '');
              }
          }
      }
      eqRefExpandLinksAndAddTooltips = () => {
          els = document.querySelectorAll('[href^="\#eq:"]');
          expandLinks(els, ['eq.', 'Equation']);
          addTooltips(els, true);
      }
      secRefExpandLinksAndAddBackArrow = (appendixSecNo) => {
          els = [...document.querySelectorAll('[href^="\#sec:"]')].filter(el => {
              return el.parentNode.tagName !== 'LI'
          });
          const appendixStr = 'the appendix';
          for (el of els) {
              if (el.textContent == appendixSecNo) {
                  sib = el.previousSibling;
                  sib.remove();
                  el.textContent = appendixStr;
              } else {
                  el.textContent = document.getElementById(el.getAttribute('href').slice(1)).getAttribute('data-number');
              }
          }
          expandLinks(els.filter(el => el.textContent !== appendixStr), ['section']);
          for ([i, el] of els.entries()) {
              const secId = el.getAttribute('href').slice(1);
              const elId = 'linkToSec' + secId + i;
              el.id = elId;
              const toSec = document.getElementById(secId);
              el.onclick = () => {
                  backArrowId = secId + 'ReturnLink';
                  let backArrowEl = document.getElementById(backArrowId);
                  if (!!backArrowEl) {
                      backArrowEl.remove();
                  }
                  backArrowEl = document.createElement('a');
                  backArrowEl.id = backArrowId
                  backArrowEl.setAttribute('href', '#' + elId);
                  backArrowEl.style.float = 'right';
                  backArrowEl.innerHTML = "↩︎";
                  backArrowEl.onclick = () => backArrowEl.remove();
                  toSec.appendChild(backArrowEl);
              }
          }
      }
      citeRefExpandLinksAndAddTooltips = () => {
          els = document.getElementById('main').getElementsByClassName('citation');
          addTooltips([...els].map(el => el.getElementsByTagName('a')[0]), false);
          for (el of els) {
              textContent = el.textContent;
              el.getElementsByTagName('a')[0].textContent = textContent;
              for (childEl of el.childNodes) {
                  if (!!!childEl.tagName) {
                      childEl.textContent = '';
                  }
              }
          }
      }
      addFootnoteTooltips = () => {
          for (fnBack of [...document.getElementById('main').getElementsByClassName('footnote-back')]) {
              fnBack.remove();
          }
          els = document.getElementById('main').getElementsByClassName('footnote-ref');
          addTooltips([...els], false);
          footnotesEl = document.getElementById('footnotes');
          if (!!footnotesEl) {
              footnotesEl.remove();
          }
          for (el of document.getElementsByClassName('eqnRef')) {
              const childEl = el.firstChild;
              if (childEl.tagName === 'SUP') {
                  childEl.textContent = 'note';
                  childEl.style.fontSize = '0.5rem';
              }
          }
      }
  </script>
  <style>
      .theorem p {
          display: inline;
      }
      .theorem {
          border: 1pt solid gray;
          padding: 1rem;
          background-color: #eee;
          font-style: italic;
          margin: 0;
      }
      .theoremLabel {
          font-weight: bold;
          font-style: normal;
      }
      .proof::after {
          display: block;
          content: '\00220E';
          margin-top: -1.25rem;
          margin-bottom: 1rem;
      }
      .theorem .backRefElement {
          float: right;
      }
  </style>
  <script>
      const theoremHelpers = () => {
          let theoremObj = {};
          for (thm of document.getElementsByClassName('theorem')) {
              ((thm) => {
                  let headerEl = thm.previousSibling;
                  while ( !['H1', 'H2', 'H3'].includes(headerEl.tagName)) {
                      headerEl = headerEl.previousSibling;
                  }
                  section = headerEl.getAttribute('data-number').split('.')[0];
                  theoremObj[thm.id] = {
                      'theorem': thm,
                      'proof': undefined,
                      'section': section
                  };
              })(thm)
          }
          for (prf of document.getElementsByClassName('proof')) {
              ((prf) => {
                  theoremObj[prf.getAttribute('for')].proof = prf;
                  firstP = prf.getElementsByTagName('p')[0];
                  firstP.innerHTML = '<b>Proof: </b>' + firstP.innerHTML;
              })(prf)
          }
          secNumThms = {};
          for ([thmId, thmObj] of Object.entries(theoremObj)) {
              ((thmId, thmObj) => {
                  thm = document.getElementById(thmId);
                  sec = thmObj.section;
                  el = thmObj.theorem;
                  proof = thmObj.proof;
                  if (!Object.keys(secNumThms).includes(sec)) {
                      secNumThms[sec] = 0;
                  }
                  secNumThms[sec] += 1;
                  thmTypeStr = thm.getAttribute('data-thm-type') || 'theorem';
                  thmTypeStr = thmTypeStr[0].toUpperCase() + thmTypeStr.slice(1);
                  el.setAttribute('refStr', `${thmTypeStr} ${sec}.${secNumThms[sec]}`)
                  labelSpan = document.createElement('span');
                  labelSpan.classList = ['theoremLabel'];
                  let preTheoremStr = `${thmTypeStr} ${sec}.${secNumThms[sec]}`
                  if (!!thm.getAttribute('data-display-name')) {
                      preTheoremStr += ` (${thm.getAttribute('data-display-name')})`
                  }
                  labelSpan.textContent = preTheoremStr + ': ';
                  el.insertBefore(labelSpan, el.firstChild);
                  const main = document.getElementById('main');
                  if (!!proof) {
                      if (proof.getAttribute('data-placement') === 'appendix') {
                          const appLink = document.createElement('p');
                          const thmClone = thm.cloneNode(true);
                          thmClone.id = thm.id + 'AppendixVersionWithProof';
                          thmCloneLabel = thmClone.firstChild;
                          thmCloneLabel.innerHTML = `<a href="#${thm.id}">${thmCloneLabel.textContent.trim()}</a>&nbsp;`
                          appLink.innerHTML = `(<a href="#${thmClone.id}">Proof</a> in the appendix.)`;
                          main.insertBefore(appLink, thm.nextSibling);
                          const refs = document.getElementById('References');
                          main.insertBefore(thmClone, refs);
                          main.insertBefore(proof, refs);
                      }
                  }
              })(thmId, thmObj)
          }
          const refEls = document.getElementsByClassName('thmRef');
          for (ref of refEls) {
              ((ref) => {
                  thm = document.getElementById(ref.getAttribute('for'));
                  if (!!thm) {
                      ref.innerHTML = `<a href="#${thm.id}">${thm.getAttribute('refStr')}</a>`
                  } else {
                      ref.innerHTML = '<span class="refNotFound">!!reference not found!!</span>'
                  }
              })(ref)
          }
          addTooltips([...refEls].map(el => el.firstChild), true);
      }
  </script>
  <script>
      videoEmbeds = () => {
          for (el of document.getElementsByClassName('lectureVideoEmbed')) {
              ((el) => {
                  const descHTML = el.innerHTML;
                  const dt = el.getAttribute('data-video-date');
                  const dtStr = `${parseInt(dt.slice(5, 7))}/${parseInt(dt.slice(8, 10))}`
                  el.innerHTML = `&#127909;<small class="tinyText">Lecture video ${dtStr}</small>`;
                  el.style.cursor = 'pointer';
                  const embedIndentDiv = document.createElement('div');
                  embedIndentDiv.classList = ['embedIndent'];
                  el.appendChild(embedIndentDiv);
                  el.onclick = () => {
                      embedIndentDiv.style.display = embedIndentDiv.style.display == 'block' ? 'none' : 'block';
                      if (!!!vidIframe.getAttribute('src')) {
                          vidIframe.setAttribute('src', `https://mediasite.k-state.edu/mediasite/Play/${el.getAttribute('data-video-id')}?player=NextGenSystemPlayer&amp;cover=true&amp;lockControls=false&amp;coverTitle=false&amp;autoStart=false&amp;useExtensions=false&amp;disableXR=false&amp;quizzes=false&amp;hotspots=false&amp;clickToPlay=true&amp;playfrom=0`);
                          embedIndentDiv.appendChild(vidIframe);
                      }
                  }
                  const textDiv = document.createElement('div');
                  textDiv.innerHTML = `<b>Class lecture ${dtStr}: </b>` + descHTML;
                  embedIndentDiv.appendChild(textDiv);
                  const vidIframe = document.createElement('iframe');
                  vidIframe.classList = ['lectureEmbedIframe'];
              })(el)
          }
      }
  </script>
  <script>
      const drawAllPlotlyFunctions = () => {
          let plotNum = 0;
          for (el of document.getElementsByClassName('plotlyFunctionPlot')) {
              if (!!!el.id){
                  el.id = 'plotlyFunctionPlotNum' + plotNum;
              }
              drawPlotlyFunction(
                  el.getAttribute('data-expression'),
                  el.id,
                  JSON.parse(el.getAttribute('data-xRange')),
                  JSON.parse(el.getAttribute('data-extraPoints')),
                  el.getAttribute('data-lineBetweenPoints') === 'true',
                  el.getAttribute('data-arrowsOnLines') === 'true',
                  JSON.parse(el.getAttribute('data-layoutExtra') || '{}')
              );
              plotNum += 1;
          }
      }
      const drawPlotlyFunction = (expression, elId, xRange, extraPoints, lineBetweenPoints, arrowsOnLines, layoutExtra) => {
          // compile the expression once
          const expr = math.compile(expression)

          // evaluate the expression repeatedly for different values of x
          const stepSize = (xRange[1] - xRange[0]) / 50
          const xValues = math.range(xRange[0], xRange[1] + stepSize, stepSize).toArray()
          const yValues = xValues.map(function (x) {
              return expr.evaluate({x: x})
          })

          // render the plot using plotly
          const trace1 = {
              x: xValues,
              y: yValues,
              type: 'scatter',
              mode: 'lines',
              line: {color: 'black'}
          }
          let data = [trace1]
          if (!!extraPoints) {
              for (ep of extraPoints) {
                  try {
                      x = math.compile(ep[0]).evaluate();
                  } catch {
                      x = ep[0];
                  }
                  if (ep[1] === 'eval') {
                      y = expr.evaluate({x: x})
                  } else {
                      try {
                          y = math.compile(ep[1]).evaluate();
                      } catch {
                          y = ep[1];
                      }
                  }
                  color = ep.length >= 3 ? ep[2] : 'black';
                  size = ep.length >= 4 ? ep[3] : 10;
                  data.push({
                      x: [x],
                      y: [y],
                      type: 'scatter',
                      mode: 'markers',
                      marker: {color: color, size: size}
                  })
              }
          }
          if (lineBetweenPoints) {
              let x = [];
              let y = [];
              let color = 'black';
              for (i in data) {
                  if (i != 0) {     
                      x.push(data[i].x[0]);
                      y.push(data[i].y[0]);
                      color = data[i].marker.color;
                  }
              }
              mode = 'lines';
              marker = {};
              if (arrowsOnLines) {
                  mode = 'lines+markers';
                  marker = {symbol: 'arrow-bar-up', angleref: "previous", size: 10}
              }
              data.push({
                  x: x,
                  y: y,
                  type: 'scatter',
                  mode: mode,
                  line: {color: color},
                  marker: marker
              })
          }
          let layout = {
              hovermode: false,
              showlegend: false,
              margin: {t: 25, b: 25, l: 25, r: 25},
              xaxis: {fixedrange: true},
              yaxis: {fixedrange: true}
          }
          if (Object.keys(layoutExtra).length > 0) {
              for ([k, v] of Object.entries(layoutExtra)) {
                  layout[k] = v;
              }
          }
          Plotly.newPlot(elId, data, layout, {displayModeBar: false})
      }
  </script>
  <style>
      .eqnos {
          display: flex;
          align-items: center;
          width: 100%;
          overflow-x: auto;
      }
      .eqnos br {
          display: none;
      }
      .eqnos-number {
          margin-left: auto;
          padding-left: 1rem;
      }
      .katexContainer {
          flex-grow: 1;
          overflow-x: auto;
      }
  </style>
  <style>
      #main {
          font-size: max(1rem, min(calc(0.9rem + 0.4vw), 22pt));
          width: min(max(90%, calc(100% - min(60%, 350px) - 1rem)), 800px);
          position: absolute;
          left: 50%;
          transform: translateX(-50%);
          transition: margin-left .5s;
          padding: 20px;
          padding-bottom: 30px;
      }
      html {
          scroll-padding-top: 2.5rem;
          overflow-y: auto;
      }
      body {
          scroll-padding-top: 2.5rem;
          overflow-y: hidden;
          max-width: none !important;
      }
      .loadingMessage {
          text-align: center;
          margin-top: 40vh;
          font-size: 1.2rem;
      }
      blockquote {
          margin: 1rem 0.5rem;
          padding-left: 0.5em;
          padding-right: 0.5em;
          border-left: 2px solid #e6e6e6;
          border-right: 2px solid #e6e6e6;
          color: #444;
          background-color: #ebebeb;
      }
      blockquote p {
          padding-top: 0.5rem;
          padding-bottom: 0.5rem;
      }
      details {
          cursor: pointer;
      }
      figure {
          margin-inline: 0.5rem;
      }
      figure img {
          display: block;
          margin-left: auto;
          margin-right: auto;
          max-width: 100%;
      }
      figure figcaption {
          font-size: max(0.9rem, min(calc(0.8rem + 0.4vw), 20pt));;
          text-align: center;
      }
      a {
          color: blue;
      }
      a:visited {
          color: purple;
      }
      h1 {
          position: relative;
          margin-top: 5rem;
      }
      h1:before {
          content: '';
          position: absolute;
          width: 100%;
          height: 1px;
          background: black;
          bottom: 150%;
          left: 0;
      }
      *[role="doc-biblioref"] {
          color: green !important;
      }
      div.sourceCode {
          background-color: #dfdfdf;
          padding: 0.5rem;
          border: 1pt solid black;
          font-size: max(12pt, 1.1rem);
      }
      .copyButton {
          float: right;
          cursor: pointer;
      }
      .header-section-number::after {
          content: ':'
      }
      @keyframes fade {
          0%,100% { opacity: 0 }
          15% { opacity: 1 }
          85% { opacity: 1 }
      }
      .copyMessage {
          position: absolute;
          transform: translate(-2rem, -2.8rem);
          width: 4rem;
          font-size: max(10pt, 0.7rem);
          text-align: center;
          background-color: #eee;
          border: 1pt solid black;
          border-radius: 0.25rem;
          animation: fade 2s linear;
      }
      .backRefElement {
          margin-top: auto;
      }
      footer {
          position: fixed;
          bottom: 0;
          text-align: center;
          width: 100%;
          background: white;
          left: 50%;
          transform: translateX(-50%);
          border-top: 1pt solid lightgray;
          font-size: 0.7rem;
          display: flex;
          justify-content: space-between;
      }
      .embedIndent {
          margin: 0 1rem;
          display: none;
      }
      .lectureEmbedIframe {
          width: min(600px, 80vw);
          height: calc(9 * min(600px, 80vw) / 16);
      }
      .tinyText {
          font-size: 0.5rem;
      }
      .mathSmall {
          font-size: 1rem;
      }
      .katexSideBySide {
          align-self: center;
      }
      .katexSideBySide .katexContainer {
          overflow-x: hidden;
      }
      .basicCenter {
          position: relative;
          left: 50%;
          transform: translateX(-50%);
      }
      .refNotFound {
          color: red;
      }
  </style>
  <script>
      BBGraphData = {
          bbTree1: {
              'edges': [
                  ['P', 'P^1', 'x_1 \\leq 2'],
                  ['P', 'P^2', 'x_1 \\geq 3']
              ],
              'nodes': {
                  'P': {lp: '\\frac{59}{7}', state: 'branched'},
                  'P^1': {},
                  'P^2': {}
              }
          },
          depthFirstTree: {
              nodes: {
                  'P': {lp: '22', state: 'branched'},
                  'P^1': {lp: '20', state: 'branched'},
                  'P^2': {},
                  'P^3': {lp: '17', state: 'branched'},
                  'P^4': {},
                  'P^5': {lp: '16', state: 'branched'},
                  'P^6': {},
                  'P^7': {lp: '15', state: 'integer'},
                  'P^8': {},
              },
              edges: [
                  ['P', 'P^1', 'x_1 \\leq 0'],
                  ['P', 'P^2', 'x_1 \\geq 1'],
                  ['P^1', 'P^3', 'x_2 \\leq 0'],
                  ['P^1', 'P^4', 'x_2 \\geq 1'],
                  ['P^3', 'P^5', 'x_3 \\leq 0'],
                  ['P^3', 'P^6', 'x_3 \\geq 1'],
                  ['P^5', 'P^7', 'x_3 \\leq 0'],
                  ['P^5', 'P^8', 'x_3 \\geq 1']
              ],
              rootPlacement: 0.67,
              siblingSep: 1.4,
              childSep: 3
          },
          bestNodeTree: {
              nodes: {
                  'P': {lp: '22', state: 'branched'},
                  'P^1': {lp: '19', state: 'branched'},
                  'P^2': {lp: '20', state: 'branched'},
                  'P^3': {},
                  'P^4': {},
                  'P^5': {},
                  'P^6': {}
              },
              edges: [
                  ['P', 'P^1', 'x_1 \\leq 0'],
                  ['P', 'P^2', 'x_1 \\geq 1'],
                  ['P^1', 'P^3', 'x_2 \\leq 0'],
                  ['P^1', 'P^4', 'x_2 \\geq 1'],
                  ['P^2', 'P^5', 'x_3 \\leq 0'],
                  ['P^2', 'P^6', 'x_3 \\geq 1']
              ],
          },
          fullTree3d: {
              nodes: {
                  'P': {lp: '', state: 'branched'},
                  'P^1': {lp: '', state: 'branched'},
                  'P^2': {lp: '', state: 'branched'},
                  'P^3': {lp: '', state: 'branched'},
                  'P^4': {lp: '', state: 'branched'},
                  'P^5': {lp: '', state: 'branched'},
                  'P^6': {lp: '', state: 'branched'},
                  'P^7': {},
                  'P^8': {},
                  'P^9': {},
                  'P^{10}': {},
                  'P^{11}': {},
                  'P^{12}': {},
                  'P^{13}': {},
                  'P^{14}': {}
              },
              edges: [
                  ['P', 'P^1', 'x_1 = 0'],
                  ['P', 'P^2', 'x_1 = 1'],
                  ['P^1', 'P^3', 'x_2 = 0'],
                  ['P^1', 'P^4', 'x_2 = 1'],
                  ['P^2', 'P^5', 'x_2 = 0'],
                  ['P^2', 'P^6', 'x_2 = 1'],
                  ['P^3', 'P^7', 'x_3 = 0'],
                  ['P^3', 'P^8', 'x_3 = 1'],
                  ['P^4', 'P^9', 'x_3 = 0'],
                  ['P^4', 'P^{10}', 'x_3 = 1'],
                  ['P^5', 'P^{11}', 'x_3 = 0'],
                  ['P^5', 'P^{12}', 'x_3 = 1'],
                  ['P^6', 'P^{13}', 'x_3 = 0'],
                  ['P^6', 'P^{14}', 'x_3 = 1']
              ],
              siblingSep: 1.7,
              childSep: 3,
              includeLb: false
          }
      }
      
      BBGraphData.bbTree2 = JSON.parse(JSON.stringify(BBGraphData.bbTree1));
      BBGraphData.bbTree2.nodes['P^1'] = {lp: '\\frac{15}{2}', state: 'branched'};
      BBGraphData.bbTree2.nodes['P^3'] = {};
      BBGraphData.bbTree2.nodes['P^4'] = {};
      BBGraphData.bbTree2.edges.push(['P^1', 'P^3', 'x_2 \\leq 0']);
      BBGraphData.bbTree2.edges.push(['P^1', 'P^4', 'x_2 \\geq 1']);

      BBGraphData.bbTree3 = JSON.parse(JSON.stringify(BBGraphData.bbTree2));
      BBGraphData.bbTree3.nodes['P^2'] = {lp: '-\\infty', state: 'infeasible'};

      BBGraphData.bbTree4 = JSON.parse(JSON.stringify(BBGraphData.bbTree3));
      BBGraphData.bbTree4.nodes['P^4'] = {lp: '7', state: 'integer'};

      BBGraphData.bbTree5 = JSON.parse(JSON.stringify(BBGraphData.bbTree4));
      BBGraphData.bbTree5.nodes['P^3'] = {lp: '6', state: 'bounded'};
  </script>
  <style>
      .ytEmbedContainer {
          position: relative;
          padding-bottom: 56.25%;
          height: 0;
          overflow: hidden;
          max-width: 100%;
      } .ytEmbedContainer iframe, .ytEmbedContainer object, .ytEmbedContainer embed {
          position: absolute;
          top: 0;
          left: 0;
          width: 100%;
          height: 100%;
      }
      .ytEmbedContainerContainer {
          max-width: 640px;
      }
  </style>
  <!-- TOC styling adapted from https://www.w3schools.com/howto/howto_js_sidenav.asp -->
  <style>
      nav#TOC:nth-child(2) {
          margin-top: 0.6rem;
          box-shadow: rgba(0, 0, 0, 0.2) 2px 0px 10px 1px;
      }
      nav#TOC li {
          list-style-type: none;
      }
      nav#TOC > ul {
          margin-bottom: 1.5rem;
          margin-top: 2rem;
          line-height: 1.9rem;
      }
      #TOC ul {
          padding-left: 0;
      }
      nav#TOC {
          height: 100%;
          width: 0;
          position: fixed;
          z-index: 1;
          top: 0;
          left: 0;
          background-color: #ebebeb;
          overflow-x: hidden;
          padding-top: 1rem;
          transition: 0.5s;
          overflow-y: scroll;
      }
      nav#TOC a {
          text-decoration: none;
          font-size: max(1rem, min(calc(0.9rem + 0.4vw), 22pt));;
          color: #000;
          display: block;
          transition: 0.3s;
          padding-top: 0.2rem;
          padding-bottom: 0.3rem;
          border-bottom: 1pt solid lightgray;
      }
      nav#TOC a:hover {
          color: #888;
      }
      #TOC .toc-section-number::after {
          content: ':\00a0'
      }
      #tocTop {
          height: 1.5em;
          display: flex;
          justify-content: space-between;
          padding-top: 0.5rem;
          padding-bottom: 0.65rem;
          position: fixed;
          top: 0;
          visibility: hidden;
          background-color: #ebebeb;
          z-index: 1;
          border-bottom: 1pt solid gray;
      }
      .tocHidden {
          display: none     
      }
      .tocExpand {
          margin-left: auto;
          font-size: 30pt !important;
          font-family: 'Courier New', Courier, monospace;
      }
      .navbar {
          position: fixed;
          top: 0;
          left: 0;
          right: 0;
          font-size: 1.1rem;
          background-color: #ebebeb;
          width: 100%;
          border-bottom: 1pt solid gray;
          padding-top: 0.5rem;
          padding-bottom: 0.5rem;
          display: flex;
          justify-content: space-between;
          z-index: 2;
      }
      @media screen and (max-height: 450px) {
          .sidenav {
              padding-top: 15px;
          }

          .sidenav a {
              font-size: 18px;
          }
      }
  </style>
  <script>
      function openCloseNav() {
          const tocTop = document.getElementById("tocTop")
          if (tocTop.style.visibility == "visible") {
              closeNav();
              return
          }
          const screenWidth = window.innerWidth;
          const tocWidth = Math.min(0.75 * screenWidth, 350);
          const leftoverWidth = screenWidth - tocWidth;
          const main = document.getElementById("main");
          const mainWidth = main.offsetWidth;
          document.getElementById("TOC").style.width = tocWidth + 'px';
          tocTop.style.width = tocWidth + 'px';
          tocTop.style.visibility = "visible";
          if (leftoverWidth >= mainWidth) {
              main.style.marginLeft = tocWidth / 2 + 'px';
          }
      }
      function closeNav() {
          document.getElementById("TOC").style.width = "0";
          document.getElementById("main").style.marginLeft = null;
          document.getElementById("tocTop").style.visibility = "hidden";
      }
      function closeNavIfSmall() {
          if (document.getElementById("tocTop").style.visibility == "visible" && document.getElementById("main").style.marginLeft == 0){
              closeNav()
          }
      }
  </script>
  <style>
      .lpDraw {
          position: relative;
          left: 50%;
          transform: translateX(-50%);
      }
      .bbTreeDraw {
          position: relative;
          left: 50%;
          transform: translateX(-50%);
      }
      .pointChooseDiv {
          text-align: center;
      }
      .pointChooseInput {
          border: solid 1pt black;
          border-radius: 2pt;
          width: 2rem;
          height: 1.1rem;
      }
      .pointChooseLabel {
          font-size: 14pt;
          padding-left: 5pt;
          padding-right: 5pt;
      }
      .pointChooseText {
          text-align: center;
          font-size: max(12pt, 1rem);
      }
      .underPlot {
          margin-top: -10pt;
      }
      @keyframes append-animate {
          0% {
              stroke-width: 0;
          }
          25% {
              stroke-width: 4;
          }
          50% {
              stroke-width: 0;
          }
      }
      .violatedIneq {
          animation: append-animate 4s infinite;
      }
      @keyframes simplex-arrow-flash {
          0% {
              stroke-width: 3;
          }
          5% {
              stroke-width: 4;
          }
          10% {
              stroke-width: 3;
          }
          100% {
              stroke-width: 3;
          }
      }
      .simplexArrowChosen {
          animation: simplex-arrow-flash 12s infinite;
      }
      .simplexDirectionTable {
          margin: 0;
          margin-left: auto;
          margin-right: auto;
          width: 350px;
      }
      .pointChooseText button {
          font-size: 0.8rem;
          padding: 0.5rem;
          margin: 0 0.1rem;
      }
      .forwardBackwardButton {
          font-size: 0.8rem;
          padding: 0.5rem;
          margin: 0 0.1rem;
      }
  </style>
  <script>
      const drawBBTrees = () => {
          for (svg of document.getElementsByClassName('bbTreeDraw')) {
              graphInfo = JSON.parse(JSON.stringify(BBGraphData[svg.getAttribute('base')]));
              rootPlacement = graphInfo.rootPlacement || 0.5;
              childSep = graphInfo.childSep || 5;
              siblingSep = graphInfo.siblingSep || 2;
              includeLb = graphInfo.includeLb;
              includeLb = includeLb === undefined ? true : includeLb;
              textsToAdd = [];
              for (n of Object.keys(graphInfo['nodes'])) {
                  graphInfo['nodes'][n]['level'] = 0;
                  graphInfo['nodes'][n]['children'] = [];
              }
              for (e of graphInfo['edges']) {
                  graphInfo['nodes'][e[1]]['level'] = graphInfo['nodes'][e[0]]['level'] + 1;
                  graphInfo['nodes'][e[1]]['parent'] = e[0];
              }
              r = 25
              const drawNode = (x, y, attrs) => {
                  circ = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
                  circ.setAttribute('cx', x);
                  circ.setAttribute('cy', y);
                  circ.setAttribute('r', r);
                  circ.setAttribute('fill', 'lightgray');
                  circ.setAttribute('stroke-width', '2pt');
                  circ.setAttribute('stroke', 'gray');
                  for (const [k, v] of Object.entries(attrs || {})) {
                      circ.setAttribute(k, v);
                  }
                  svg.appendChild(circ);
              }
              const addMathText = (math, x, y, attrs) => {
                  attrs = attrs || {};
                  forObj = document.createElementNS('http://www.w3.org/2000/svg', 'foreignObject');
                  mathEl = document.createElement('span');
                  katex.render(math, mathEl, {
                      throwOnError: false
                  });
                  if (attrs['coordToPix'] || false) {
                      [x, y] = coordToPix(x, y)
                  }
                  forObj.setAttribute('x', x);
                  forObj.setAttribute('y', y);
                  attrs['height'] = attrs['height'] || '1.2rem';
                  attrs['width'] = attrs['width'] || '15rem';
                  attrs['font-size'] = attrs['font-size'] || '12pt';
                  attrs['font-family'] = attrs['font-family'] || 'KaTeX_Main,Times New Roman,serif';
                  for (const [k, v] of Object.entries(attrs || {})) {
                      forObj.setAttribute(k, v);
                  }
                  forObj.appendChild(mathEl);
                  textsToAdd.push(forObj);
              }
              const drawLine = (x1, y1, x2, y2, attrs) => {
                  el = document.createElementNS('http://www.w3.org/2000/svg', 'line');
                  el.setAttribute('x1', x1);
                  el.setAttribute('y1', y1);
                  el.setAttribute('x2', x2);
                  el.setAttribute('y2', y2);
                  attrs = attrs || {}
                  attrs['style'] = attrs['style'] || 'stroke:gray';
                  for (const [k, v] of Object.entries(attrs)) {
                      el.setAttribute(k, v);
                  }
                  svg.appendChild(el);
              }
              incumbentVal = undefined;
              maxLevel = Math.max(...Object.values(graphInfo.nodes).map(n => n.level));
              for ([n, d] of Object.entries(graphInfo.nodes)) {
                  x = parseFloat(svg.getAttribute('width')) * rootPlacement;
                  if (d.parent) {
                      parentInfo = graphInfo.nodes[d['parent']];
                      d.childNum = parentInfo.children.length;
                      side = d.childNum === 0 ? -1 : 1;
                      dist = siblingSep * (Math.max(3, maxLevel + 1) - d.level) * r;
                      if (d['level'] == 1) {
                          dist += 1.5 * r;
                      }
                      x = parentInfo.x + side * dist;
                      parentInfo.children.push(n);
                  }
                  y = (2 + childSep * d.level) * r - 0.5 * r;
                  graphInfo['nodes'][n]['level'] = d.level;
                  graphInfo['nodes'][n]['x'] = x;
                  graphInfo['nodes'][n]['y'] = y;
                  addMathText(n, x - 8, y - 10);
                  if (d.state === 'integer') {
                      incumbentVal = incumbentVal === undefined ? d.lp : Math.max(incumbentVal, d.lp);
                      d.lp += '^*';
                  }
                  if (!!d.lp) {
                      addMathText(d.lp, x + 25, y - 30);
                  }
              }
              for (e of graphInfo.edges) {
                  coords = []
                  for (i of [0, 1]) {
                      for (j of ['x', 'y']) {
                          coords.push(graphInfo.nodes[e[i]][j]);
                      }
                  }
                  drawLine(...coords);
                  textX = (coords[0] + coords[2]) / 2;
                  textY = (coords[1] + coords[3]) / 2 - 20;
                  if (graphInfo.nodes[e[1]].childNum === 0) {
                      textX -= 55;
                  } else {
                      textX += 0;
                  }
                  addMathText(e[2], textX, textY);
              }
              for (d of Object.values(graphInfo.nodes)) {
                  if (d.level === 0 && includeLb) {
                      incumbentText = incumbentVal === undefined ? '-\\infty' : `${incumbentVal}`
                      addMathText(incumbentText, d.x + 28, d.y + 5);
                  }
                  attrs = {}
                  if (d.state === 'branched') {
                      attrs.stroke = 'blue';
                      attrs.fill = 'lightblue';
                  }
                  if (d.state === 'infeasible') {
                      attrs.stroke = 'red';
                      attrs.fill = 'lightpink';
                  }
                  if (d.state === 'integer') {
                      attrs.stroke = 'purple';
                      attrs.fill = 'plum';
                  }
                  if (d.state === 'bounded') {
                      attrs.stroke = 'darkorange';
                      attrs.fill = 'peachpuff';
                  }
                  drawNode(d.x, d.y, attrs);
              }
              for (textObj of textsToAdd) {
                  svg.appendChild(textObj);
              }
          }
      }
  </script>
  <style>
      .footnoteTooltipClose {
          color: #222;
          font-size: 30pt;
          font-weight: bold;
          margin-left: auto;
          margin-top: -1rem;
          margin-bottom: -1rem;
      }
      .footnoteTooltipClose:hover, .footnoteTooltipClose:focus {
          color: black;
          text-decoration: none;
          cursor: pointer;
      }
      .footnote-ref sup, .eqnRef {
          cursor: pointer;
          color: green !important;
      }
      .footnoteTooltip {
          background-color: #ebebeb;
          padding: 1rem;
          border: 1px solid #888;
          position: absolute;
          z-index: 1;
          width: 75%;
          left: 50%;
          transform: translateX(-50%);
          margin-top: 2rem;
          font-size: max(1rem, min(calc(0.9rem + 0.4vw), 22pt));
          overflow-x: auto;
          display: flex;
          flex-direction: column;
      }
      .eqnRef .footnoteTooltip {
          color: black;
      }
      .seeOriginalEq {
          font-size: 1rem;
          margin-left: auto;
      }
  </style>
  <script>
      function footnoteOnTooltipClick(id, innerHTML, refElOrId, origId) {
          innerHTML = innerHTML.replaceAll('@@@', '"');
          const tooltipEl = document.getElementById(id);
          if (tooltipEl == null) {
              const newEl = document.createElement("span");
              closeEl = document.createElement("div");
              closeEl.classList = ['footnoteTooltipClose'];
              closeEl.innerHTML = '&times;';
              newEl.appendChild(closeEl);
              if (typeof(refElOrId) === 'string'){
                  closeEl.setAttribute("onclick", "removeElById('" + id + "')");
                  document.getElementById(refElOrId).appendChild(newEl);
              } else {
                  closeEl.onclick = () => removeElById(id);
                  refElOrId.append(newEl);
              }
              newEl.id = id;
              newEl.innerHTML += innerHTML;
              newEl.classList = ['footnoteTooltip'];
              for (numEl of newEl.getElementsByClassName('eqnos-number')){
                  numEl.remove();
              }
              if (!!origId) {
                  seeOrigEl = document.createElement('a');
                  seeOrigEl.setAttribute('href', '#' + origId);
                  seeOrigEl.innerHTML = 'jump to';
                  seeOrigEl.classList = ['seeOriginalEq']
                  seeOrigEl.onclick = () => {
                      backEl = document.getElementById('back#' + origId + 'Arrow');
                      backEl.style.display = 'inline';
                      backEl.setAttribute('href', '#' + id)
                  }
                  newEl.appendChild(seeOrigEl);
              }
          } else {
              tooltipEl.remove();
          }
          
      }
      function removeElById(id) {
          document.getElementById(id).remove();
      }
  </script>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<script src='https://cdn.plot.ly/plotly-2.26.0.min.js'></script>
<script src="https://unpkg.com/mathjs@11.11.2/lib/browser/math.js"></script>
<div class="navbar">
    <div onclick="openCloseNav()" style="padding-left: 1rem; cursor: pointer; color: blue">Contents</div>
    <div style="text-align: center">IMSE 780</div>
    <div style="text-align: right; padding-right: 1rem">Fall 2023</div>
</div>
<div id="loader" class="loadingMessage">Loading...</div>
<nav id="TOC" role="doc-toc">
<div id="tocTop"></div>
<ul>
<li><a href="#welcome" id="toc-welcome"><span
class="toc-section-number">1</span> Welcome!</a>
<ul>
<li><a href="#course-materials" id="toc-course-materials"><span
class="toc-section-number">1.1</span> Course materials</a></li>
<li><a href="#notes-on-these-notes" id="toc-notes-on-these-notes"><span
class="toc-section-number">1.2</span> Notes on these notes</a></li>
</ul></li>
<li><a href="#introduction-to-or" id="toc-introduction-to-or"><span
class="toc-section-number">2</span> Introduction to OR</a>
<ul>
<li><a href="#what-is-operations-research"
id="toc-what-is-operations-research"><span
class="toc-section-number">2.1</span> What is Operations
Research?</a></li>
<li><a href="#example-or-problems" id="toc-example-or-problems"><span
class="toc-section-number">2.2</span> Example OR problems</a>
<ul>
<li><a href="#sec:tsp" id="toc-sec:tsp"><span
class="toc-section-number">2.2.1</span> Traveling Salesman
Problem</a></li>
<li><a href="#job-shop-scheduling" id="toc-job-shop-scheduling"><span
class="toc-section-number">2.2.2</span> Job-shop scheduling</a></li>
<li><a href="#portfolio-optimization"
id="toc-portfolio-optimization"><span
class="toc-section-number">2.2.3</span> Portfolio optimization</a></li>
</ul></li>
<li><a href="#or-in-practice" id="toc-or-in-practice"><span
class="toc-section-number">2.3</span> OR in practice</a>
<ul>
<li><a href="#origins-of-or" id="toc-origins-of-or"><span
class="toc-section-number">2.3.1</span> Origins of OR</a></li>
<li><a href="#case-studies" id="toc-case-studies"><span
class="toc-section-number">2.3.2</span> Case studies</a></li>
<li><a href="#edelman-prize" id="toc-edelman-prize"><span
class="toc-section-number">2.3.3</span> Edelman Prize</a></li>
</ul></li>
<li><a href="#topics-well-cover" id="toc-topics-well-cover"><span
class="toc-section-number">2.4</span> Topics we’ll cover</a></li>
</ul></li>
<li><a href="#python-crash-course" id="toc-python-crash-course"><span
class="toc-section-number">3</span> Python crash course</a>
<ul>
<li><a href="#google-colab-notebooks"
id="toc-google-colab-notebooks"><span
class="toc-section-number">3.1</span> Google Colab notebooks</a></li>
<li><a href="#some-python-basics" id="toc-some-python-basics"><span
class="toc-section-number">3.2</span> Some Python basics</a></li>
<li><a href="#sec:pythonEnvironments"
id="toc-sec:pythonEnvironments"><span
class="toc-section-number">3.3</span> Other coding environments</a>
<ul>
<li><a href="#local-development" id="toc-local-development"><span
class="toc-section-number">3.3.1</span> Local development</a></li>
<li><a href="#cloud-hosted" id="toc-cloud-hosted"><span
class="toc-section-number">3.3.2</span> Cloud hosted</a></li>
</ul></li>
</ul></li>
<li><a href="#linear-programming" id="toc-linear-programming"><span
class="toc-section-number">4</span> Linear programming</a>
<ul>
<li><a href="#sec:exampleLp" id="toc-sec:exampleLp"><span
class="toc-section-number">4.1</span> An example LP</a>
<ul>
<li><a href="#formulating-our-first-lp"
id="toc-formulating-our-first-lp"><span
class="toc-section-number">4.1.1</span> Formulating our first
LP</a></li>
</ul></li>
<li><a href="#lp-terminology" id="toc-lp-terminology"><span
class="toc-section-number">4.2</span> LP terminology</a></li>
<li><a href="#sec:lpVisualized" id="toc-sec:lpVisualized"><span
class="toc-section-number">4.3</span> LP visualized</a>
<ul>
<li><a href="#solving-an-lp-visually"
id="toc-solving-an-lp-visually"><span
class="toc-section-number">4.3.1</span> Solving an LP visually</a></li>
<li><a href="#visualizing-other-scenarios"
id="toc-visualizing-other-scenarios"><span
class="toc-section-number">4.3.2</span> Visualizing other
scenarios</a></li>
</ul></li>
<li><a href="#sec:lpSoftware" id="toc-sec:lpSoftware"><span
class="toc-section-number">4.4</span> Solving LPs with software</a>
<ul>
<li><a href="#modeling-languages" id="toc-modeling-languages"><span
class="toc-section-number">4.4.1</span> Modeling languages</a></li>
<li><a href="#solvers" id="toc-solvers"><span
class="toc-section-number">4.4.2</span> Solvers</a></li>
<li><a href="#solving-our-lp-with-python"
id="toc-solving-our-lp-with-python"><span
class="toc-section-number">4.4.3</span> Solving our LP with
Python</a></li>
<li><a href="#sec:lpModelDataSep" id="toc-sec:lpModelDataSep"><span
class="toc-section-number">4.4.4</span> Model/data separation</a></li>
</ul></li>
<li><a href="#sec:lpForms" id="toc-sec:lpForms"><span
class="toc-section-number">4.5</span> LP forms</a>
<ul>
<li><a href="#standard-form" id="toc-standard-form"><span
class="toc-section-number">4.5.1</span> Standard form</a></li>
<li><a href="#minimization-problems"
id="toc-minimization-problems"><span
class="toc-section-number">4.5.2</span> Minimization problems</a></li>
<li><a href="#sec:lpConstraintTransform"
id="toc-sec:lpConstraintTransform"><span
class="toc-section-number">4.5.3</span> Different constraint
forms</a></li>
<li><a href="#sec:lpVariableBoundTransform"
id="toc-sec:lpVariableBoundTransform"><span
class="toc-section-number">4.5.4</span> Variable bounds</a></li>
<li><a href="#recap-of-allowed-forms"
id="toc-recap-of-allowed-forms"><span
class="toc-section-number">4.5.5</span> Recap of allowed forms</a></li>
<li><a href="#different-notation" id="toc-different-notation"><span
class="toc-section-number">4.5.6</span> Different notation</a></li>
</ul></li>
<li><a href="#sec:simplex" id="toc-sec:simplex"><span
class="toc-section-number">4.6</span> The simplex method</a>
<ul>
<li><a href="#corner-point-solutions"
id="toc-corner-point-solutions"><span
class="toc-section-number">4.6.1</span> Corner-point solutions</a></li>
<li><a href="#sec:simplexVisualized"
id="toc-sec:simplexVisualized"><span
class="toc-section-number">4.6.2</span> Simplex visualized</a></li>
<li><a href="#augmented-form-and-basic-solutions"
id="toc-augmented-form-and-basic-solutions"><span
class="toc-section-number">4.6.3</span> Augmented form and basic
solutions</a></li>
<li><a href="#sec:simplexExample" id="toc-sec:simplexExample"><span
class="toc-section-number">4.6.4</span> Solving the sample LP with
simplex</a></li>
<li><a href="#simplex-in-matrix-notation"
id="toc-simplex-in-matrix-notation"><span
class="toc-section-number">4.6.5</span> Simplex in matrix
notation</a></li>
<li><a href="#presenting-finally-the-simplex-algorithm-mostly"
id="toc-presenting-finally-the-simplex-algorithm-mostly"><span
class="toc-section-number">4.6.6</span> Presenting (finally) the simplex
algorithm (mostly)</a></li>
<li><a href="#sec:lpOtherConsiderations"
id="toc-sec:lpOtherConsiderations"><span
class="toc-section-number">4.6.7</span> Other considerations</a></li>
<li><a href="#the-revised-simplex-method"
id="toc-the-revised-simplex-method"><span
class="toc-section-number">4.6.8</span> The revised simplex
method</a></li>
</ul></li>
<li><a href="#sec:lpDuality" id="toc-sec:lpDuality"><span
class="toc-section-number">4.7</span> Duality</a>
<ul>
<li><a href="#sec:corporateTakeover"
id="toc-sec:corporateTakeover"><span
class="toc-section-number">4.7.1</span> The corporate takeover</a></li>
<li><a href="#defining-the-dual-lp" id="toc-defining-the-dual-lp"><span
class="toc-section-number">4.7.2</span> Defining the dual LP</a></li>
<li><a href="#properties-of-the-dual-lp"
id="toc-properties-of-the-dual-lp"><span
class="toc-section-number">4.7.3</span> Properties of the dual
LP</a></li>
<li><a href="#simplex-and-the-dual-problem"
id="toc-simplex-and-the-dual-problem"><span
class="toc-section-number">4.7.4</span> Simplex and the dual
problem</a></li>
<li><a href="#primaldual-feasibilityboundedness-relationships"
id="toc-primaldual-feasibilityboundedness-relationships"><span
class="toc-section-number">4.7.5</span> Primal/dual
feasibility/boundedness relationships</a></li>
</ul></li>
<li><a href="#sec:lpPostOpt" id="toc-sec:lpPostOpt"><span
class="toc-section-number">4.8</span> Post-optimality analysis</a>
<ul>
<li><a href="#sec:lpReopt" id="toc-sec:lpReopt"><span
class="toc-section-number">4.8.1</span> Re-optimization</a></li>
<li><a href="#sec:shadowPrices" id="toc-sec:shadowPrices"><span
class="toc-section-number">4.8.2</span> Shadow Prices</a></li>
<li><a href="#sec:sensitivityAnalysis"
id="toc-sec:sensitivityAnalysis"><span
class="toc-section-number">4.8.3</span> Sensitivity Analysis</a></li>
</ul></li>
<li><a href="#notes-and-further-reading"
id="toc-notes-and-further-reading"><span
class="toc-section-number">4.9</span> Notes and further reading</a></li>
</ul></li>
<li><a href="#integer-programming" id="toc-integer-programming"><span
class="toc-section-number">5</span> Integer programming</a>
<ul>
<li><a href="#definitions" id="toc-definitions"><span
class="toc-section-number">5.1</span> Definitions</a></li>
<li><a href="#sec:ipRoundingNotEnough"
id="toc-sec:ipRoundingNotEnough"><span
class="toc-section-number">5.2</span> Rounding is not enough</a></li>
<li><a href="#ip-modeling" id="toc-ip-modeling"><span
class="toc-section-number">5.3</span> IP modeling</a>
<ul>
<li><a href="#general-integer-variables"
id="toc-general-integer-variables"><span
class="toc-section-number">5.3.1</span> General integer
variables</a></li>
<li><a href="#sec:binVarTricks" id="toc-sec:binVarTricks"><span
class="toc-section-number">5.3.2</span> Binary variable tricks</a></li>
<li><a href="#sec:ipWordProblems" id="toc-sec:ipWordProblems"><span
class="toc-section-number">5.3.3</span> Example word problems</a></li>
<li><a href="#sec:ipModelDataSep" id="toc-sec:ipModelDataSep"><span
class="toc-section-number">5.3.4</span> Model/data separation</a></li>
</ul></li>
<li><a href="#solving-ips-with-software"
id="toc-solving-ips-with-software"><span
class="toc-section-number">5.4</span> Solving IPs with software</a>
<ul>
<li><a href="#solvers-1" id="toc-solvers-1"><span
class="toc-section-number">5.4.1</span> Solvers</a></li>
<li><a href="#sec:solvingIpsWithPython"
id="toc-sec:solvingIpsWithPython"><span
class="toc-section-number">5.4.2</span> Solving IPs with Python</a></li>
</ul></li>
<li><a href="#sec:complexityIntro" id="toc-sec:complexityIntro"><span
class="toc-section-number">5.5</span> Intro to complexity</a>
<ul>
<li><a href="#combinatorial-explosion"
id="toc-combinatorial-explosion"><span
class="toc-section-number">5.5.1</span> Combinatorial explosion</a></li>
<li><a href="#complexity-definitions"
id="toc-complexity-definitions"><span
class="toc-section-number">5.5.2</span> Complexity
“definitions”</a></li>
<li><a href="#the-classes-mathcalp-and-mathcalnp"
id="toc-the-classes-mathcalp-and-mathcalnp"><span
class="toc-section-number">5.5.3</span> The classes <span
class="math inline">\mathcal{P}</span> and <span
class="math inline">\mathcal{NP}</span></a></li>
<li><a href="#mathcalnp-complete-and-mathcalnp-hard-problems"
id="toc-mathcalnp-complete-and-mathcalnp-hard-problems"><span
class="toc-section-number">5.5.4</span> <span
class="math inline">\mathcal{NP}</span>-complete and <span
class="math inline">\mathcal{NP}</span>-hard problems</a></li>
<li><a href="#what-makes-ips-hard" id="toc-what-makes-ips-hard"><span
class="toc-section-number">5.5.5</span> What makes IPs hard</a></li>
<li><a href="#all-hope-is-not-lost" id="toc-all-hope-is-not-lost"><span
class="toc-section-number">5.5.6</span> All hope is not lost</a></li>
</ul></li>
<li><a href="#branch-and-bound" id="toc-branch-and-bound"><span
class="toc-section-number">5.6</span> Branch and bound</a>
<ul>
<li><a href="#sec:divideAndConquer" id="toc-sec:divideAndConquer"><span
class="toc-section-number">5.6.1</span> Divide and Conquer</a></li>
<li><a href="#dropping-dead-weight" id="toc-dropping-dead-weight"><span
class="toc-section-number">5.6.2</span> Dropping dead weight</a></li>
<li><a href="#algorithm-basics" id="toc-algorithm-basics"><span
class="toc-section-number">5.6.3</span> Algorithm basics</a></li>
<li><a href="#sec:bnbExample" id="toc-sec:bnbExample"><span
class="toc-section-number">5.6.4</span> A branch and bound
example</a></li>
<li><a href="#the-branch-and-bound-algorithm"
id="toc-the-branch-and-bound-algorithm"><span
class="toc-section-number">5.6.5</span> The branch and bound
algorithm</a></li>
<li><a href="#sec:choosingBNBNodes" id="toc-sec:choosingBNBNodes"><span
class="toc-section-number">5.6.6</span> Next nodes and branching
variables</a></li>
<li><a href="#correctness-and-complexity"
id="toc-correctness-and-complexity"><span
class="toc-section-number">5.6.7</span> Correctness and
complexity</a></li>
</ul></li>
<li><a href="#cutting-planes" id="toc-cutting-planes"><span
class="toc-section-number">5.7</span> Cutting planes</a>
<ul>
<li><a href="#sec:integerHull" id="toc-sec:integerHull"><span
class="toc-section-number">5.7.1</span> The integer hull</a></li>
<li><a href="#network-flows---ip-for-free"
id="toc-network-flows---ip-for-free"><span
class="toc-section-number">5.7.2</span> Network flows - IP for
free!</a></li>
<li><a href="#valid-inequalities" id="toc-valid-inequalities"><span
class="toc-section-number">5.7.3</span> Valid inequalities</a></li>
<li><a href="#a-general-procedure-for-generating-cuts"
id="toc-a-general-procedure-for-generating-cuts"><span
class="toc-section-number">5.7.4</span> A general procedure for
generating cuts</a></li>
<li><a href="#the-chvátalgomory-procedure"
id="toc-the-chvátalgomory-procedure"><span
class="toc-section-number">5.7.5</span> The Chvátal–Gomory
procedure</a></li>
<li><a href="#gomorys-fractional-cutting-plane-algorithm"
id="toc-gomorys-fractional-cutting-plane-algorithm"><span
class="toc-section-number">5.7.6</span> Gomory’s fractional cutting
plane algorithm</a></li>
<li><a href="#branch-and-cut" id="toc-branch-and-cut"><span
class="toc-section-number">5.7.7</span> Branch and cut</a></li>
</ul></li>
<li><a href="#practical-miscellany" id="toc-practical-miscellany"><span
class="toc-section-number">5.8</span> Practical miscellany</a></li>
<li><a href="#notes-and-further-reading-1"
id="toc-notes-and-further-reading-1"><span
class="toc-section-number">5.9</span> Notes and further reading</a></li>
</ul></li>
<li><a href="#nonlinear-programming"
id="toc-nonlinear-programming"><span class="toc-section-number">6</span>
Nonlinear programming</a>
<ul>
<li><a href="#example-nonlinear-programs"
id="toc-example-nonlinear-programs"><span
class="toc-section-number">6.1</span> Example nonlinear programs</a>
<ul>
<li><a href="#price-elasticity" id="toc-price-elasticity"><span
class="toc-section-number">6.1.1</span> Price elasticity</a></li>
<li><a href="#investment-risk" id="toc-investment-risk"><span
class="toc-section-number">6.1.2</span> Investment risk</a></li>
</ul></li>
<li><a href="#single-variable-unconstrained-optimization"
id="toc-single-variable-unconstrained-optimization"><span
class="toc-section-number">6.2</span> Single-variable unconstrained
optimization</a>
<ul>
<li><a href="#calculus-review" id="toc-calculus-review"><span
class="toc-section-number">6.2.1</span> Calculus review</a></li>
<li><a href="#convexity-and-concavity"
id="toc-convexity-and-concavity"><span
class="toc-section-number">6.2.2</span> Convexity and concavity</a></li>
<li><a href="#analytical-vs.-numerical-methods"
id="toc-analytical-vs.-numerical-methods"><span
class="toc-section-number">6.2.3</span> Analytical vs. numerical
methods</a></li>
<li><a href="#bisection-method" id="toc-bisection-method"><span
class="toc-section-number">6.2.4</span> Bisection method</a></li>
<li><a href="#newtons-method" id="toc-newtons-method"><span
class="toc-section-number">6.2.5</span> Newton’s method</a></li>
</ul></li>
</ul></li>
<li><a href="#appendix" id="toc-appendix"><span
class="toc-section-number">7</span> Appendix</a>
<ul>
<li><a href="#sec:symbols" id="toc-sec:symbols"><span
class="toc-section-number">7.1</span> Special symbols</a></li>
<li><a href="#sec:linearAlgebra" id="toc-sec:linearAlgebra"><span
class="toc-section-number">7.2</span> Linear algebra review</a>
<ul>
<li><a href="#sec:matrixMath" id="toc-sec:matrixMath"><span
class="toc-section-number">7.2.1</span> Matrix math</a></li>
<li><a href="#properties-of-matrix-operations"
id="toc-properties-of-matrix-operations"><span
class="toc-section-number">7.2.2</span> Properties of matrix
operations</a></li>
<li><a href="#special-matrices" id="toc-special-matrices"><span
class="toc-section-number">7.2.3</span> Special matrices</a></li>
<li><a href="#rank-and-inverse" id="toc-rank-and-inverse"><span
class="toc-section-number">7.2.4</span> Rank and inverse</a></li>
<li><a href="#systems-of-equations" id="toc-systems-of-equations"><span
class="toc-section-number">7.2.5</span> Systems of equations</a></li>
<li><a href="#sec:elementaryRowOperations"
id="toc-sec:elementaryRowOperations"><span
class="toc-section-number">7.2.6</span> Elementary operations</a></li>
</ul></li>
<li><a href="#writing-mathematics-in-a-colab-notebook"
id="toc-writing-mathematics-in-a-colab-notebook"><span
class="toc-section-number">7.3</span> Writing mathematics in a Colab
notebook</a></li>
<li><a href="#sec:badIpModels" id="toc-sec:badIpModels"><span
class="toc-section-number">7.4</span> Examples of bad IP modeling</a>
<ul>
<li><a href="#boolean-algebra" id="toc-boolean-algebra"><span
class="toc-section-number">7.4.1</span> Boolean algebra</a></li>
</ul></li>
<li><a href="#sec:appendixSelectedProofs"
id="toc-sec:appendixSelectedProofs"><span
class="toc-section-number">7.5</span> Selected proofs</a></li>
</ul></li>
</ul>
</nav>
<div id="main">
<h1 data-number="1" id="welcome"><span
class="header-section-number">1</span> Welcome!</h1>
<div class="lectureVideoEmbed"
data-video-id="97611387a9ca4d1bae07842bec132e081d"
data-video-date="2023-08-21">
Going over the syllabus, class/instructor introduction.
</div>
<p>You’re reading the class notes for <em>IMSE 780: Methods of
Operations Research</em> taught at Kansas State University during the
Fall 2023 semester. This course is intended to give an overview of
Operations Research (OR) at the graduate level. After this course,
students will have a basic familiarity with various OR methodologies and
be able to recognize when the methods can be applied in real-life
scenarios. Students should also be able to apply the chosen methodology
via Python code.</p>
<h2 data-number="1.1" id="course-materials"><span
class="header-section-number">1.1</span> Course materials</h2>
<p>The core of this course will be taught from these notes.
Additionally, I encourage students to use the textbook <em>Introduction
to Operations Research</em> <span class="citation"
data-cites="classText">(<a href="#ref-classText"
role="doc-biblioref">Hillier and Lieberman 2021</a>)</span> as a
reference<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>. The syllabus, assignments, and
other course materials may be found via the <a
href="https://k-state.instructure.com/">class Canvas site</a>. Course
homeworks/assignments may be found <a id='toAssignments'>here</a>.</p>
<h2 data-number="1.2" id="notes-on-these-notes"><span
class="header-section-number">1.2</span> Notes on these notes</h2>
<p>I wrote the notes in this format in an attempt to alleviate all my
past frustrations from reading academic material in all formats. Things
like unlinked references, or links requiring context switches and
without back navigation. Or static elements that could be more effective
if animated or interactive. So I tried to fix some of those issues with
this format.</p>
<p>That means these notes were necessarily made with my desires in mind,
and not yours, the reader trying to learn from them. So I’d love any
feedback you have on how the notes are presented, or anything you think
I could add to help your learning. I can’t guarantee I’ll be able to
change much substantial at this point, but at the very least future
iterations of these notes could incorporate your changes and help future
learners.</p>
<p>Also, errors. I’m trying my best to keep these notes free of typos
and factual errors, but inevitably several will slip through. I’d be
grateful if you can point these out as you see them. I’ll even keep a
leaderboard of who has pointed out the most errors, and will have a
prize at the end of the semester for the largest contributors.</p>
<p>I made these notes mostly for consumption on your web browser on a
laptop/desktop computer, or a tablet in landscape orientation. You can
still access them on your phone, of course, and I’ve tried to style
things such that the content is as usable as possible on a narrow
screen, but your best experience will be on a larger screen. If you’d
like hard copies of these notes, your only option for now is to print
from your browser. With some extra work, I could make pdf versions
available as well, although you will necessarily lose some functionality
in that format. If this is something you’d be interested in, please let
me know.</p>
<p>These notes were created for educational use. With proper
attribution, readers may freely copy, distribute, or produce derivative
work from this content, in whole or in part, for any non-commercial
use.</p>
<h1 data-number="2" id="introduction-to-or"><span
class="header-section-number">2</span> Introduction to OR</h1>
<div class="lectureVideoEmbed"
data-video-id="36726575b4244fecb73986d444ffae771d"
data-video-date="2023-08-23">
Chapter 2, Edelman prize, a little about Python at the end.
</div>
<p>In this section we’ll cover the big picture questions: What is
Operations Research? Where did it come from? What can I do with it? I
hope to impress upon you that OR is a seriously set of tools, and that
it has a huge impact on the world today.</p>
<h2 data-number="2.1" id="what-is-operations-research"><span
class="header-section-number">2.1</span> What is Operations
Research?</h2>
<p>If you’re like me, one of the first things you’ll do when learning a
new subject is look it up on Wikipedia. As of this writing, <a
href="https://en.wikipedia.org/wiki/Operations_research">their page on
Operations Research</a> first defines OR as:</p>
<blockquote>
<p>The discipline that deals with the development and application of
analytical methods to improve decision-making.</p>
</blockquote>
<p>I think this is a good first definition! Continuing on a bit, the
article gets a little more specific:</p>
<blockquote>
<p>Employing techniques from other mathematical sciences, such as
modeling, statistics, and optimization, operations research arrives at
optimal or near-optimal solutions to decision-making problems.</p>
</blockquote>
<p>Right. So the practice of OR involves using mathematical techniques
to find the best decision possible in a given situation (“optimal” is
just fancy way of saying “best”<a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a>).</p>
<h2 data-number="2.2" id="example-or-problems"><span
class="header-section-number">2.2</span> Example OR problems</h2>
<p>The above definitions were great, but maybe it’s feeling a little too
abstract at this point. Fair enough. Let’s outline a few common problems
in the OR space.</p>
<h3 data-number="2.2.1" id="sec:tsp"><span
class="header-section-number">2.2.1</span> Traveling Salesman
Problem</h3>
<p>There are many well-known problems in the world of OR, but I reckon
the <a
href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">Traveling
Salesman Problem</a> (TSP) is the best-known and most-loved among them.
The setup is simple: Some old-timey door-to-door salesman is heading out
on the road to sell his product to the masses. He plans to visit a
certain group of cities, and thanks to his trusty atlas he knows the way
between any pair of cities. Less clear, however, is the shortest path
that will lead you through <em>all</em> of the cities, and this is the
aim of the TSP: In which order should you visit the cities such that
your total distance traveled is minimized?</p>
<p>As I said, this a famous problem in the OR space<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. I
think it’s due to the simple, relatable exposition, paired with the fact
that it is actually quite computationally challenging. And yet despite
the challenges, modern methods are able to solve problem instances where
the number of cities is in the 10,000s! The image below shows the
optimal tour through selected cities in the continental US<a href="#fn4"
class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>.</p>
<figure>
<img
src="https://www.math.uwaterloo.ca/tsp/usa50/img/newsweek_medium.jpg"
alt="The shortest tour through 49 US cities (“Waterloo TSP,” n.d.)" />
<figcaption aria-hidden="true">The shortest tour through 49 US cities
<span class="citation" data-cites="tspPic">(<a href="#ref-tspPic"
role="doc-biblioref"><span>“Waterloo TSP,”</span>
n.d.</a>)</span></figcaption>
</figure>
<h3 data-number="2.2.2" id="job-shop-scheduling"><span
class="header-section-number">2.2.2</span> Job-shop scheduling</h3>
<p>You run a machine shop, and have a certain number of jobs to complete
in a day. Each job requires a certain number of tasks to be done by one
of your many machines, and the tasks are at least partially ordered,
such that you must complete some of the tasks in a certain order. Each
machine can only work on one task at a time. You get to decide the work
schedule, assigning machines to tasks at certain times in the day. What
is the schedule that lets you complete all the jobs in the least amount
of time?</p>
<p>An example: You have a woodworking shop, and today you’re making 20
table, 30 chairs, 15 doors, and 20 bookcases. Each of these jobs
requires some time on your table saw, your mill, and your belt sander.
And the order of operations matters, e.g. you have to cut a piece of
wood before you sand the edges. When you begin the day, what job will
you have each of your machines work on? And as they complete those jobs,
which ones should they take up next? How much time can you save with the
right schedule of work?</p>
<h3 data-number="2.2.3" id="portfolio-optimization"><span
class="header-section-number">2.2.3</span> Portfolio optimization</h3>
<p>You have some money to invest, and a list of potential project/assets
to invest in. You’d like to invest in a way that gives you a high
expected return, but there is risk involved as well. Each project comes
with its own risks, and some projects may be highly correlated such that
failure in one would suggest a high chance of failure in another. How
can you deploy your capital in a way that minimizes downside risk while
still likely generating a good profit?</p>
<h2 data-number="2.3" id="or-in-practice"><span
class="header-section-number">2.3</span> OR in practice</h2>
<p>So we’ve given a few broad classes of OR problems, but these are
still just hypotheticals. You’d probably like some concrete examples,
instances where OR has been used in the real world, and what the results
were.</p>
<h3 data-number="2.3.1" id="origins-of-or"><span
class="header-section-number">2.3.1</span> Origins of OR</h3>
<p>We’ll come to the present day soon, but let’s start with a (brief)
history lesson. Most sources trace the beginning of OR back to early
1900s and the two World Wars. This <em>research</em> on military
<em>operations</em> is where the discipline’s name derives. Here’s how
<span class="citation" data-cites="classText">Hillier and Lieberman (<a
href="#ref-classText" role="doc-biblioref">2021</a>)</span> explains
it:</p>
<blockquote>
<p>The roots of OR can be traced back many decades, when early attempts
were made to use a scientific approach in the management of
organizations. However, the beginning of the activity called operations
research has generally been attributed to the military services early in
World War II. Because of the war effort, there was an urgent need to
allocate scarce resources to the various military operations and to the
activities within each operation in an effective manner. Therefore, the
British and then the U.S. military management called upon a large number
of scientists to apply a scientific approach to dealing with this and
other strategic and tactical problems. In effect, they were asked to do
<em>research</em> on (military) <em>operations</em>. These teams of
scientists were the first OR teams. By developing effective methods of
using the new tool of radar, these teams were instrumental in winning
the Air Battle of Britain. Through their research on how to better
manage convoy and antisubmarine operations, they also played a major
role in winning the Battle of the North Atlantic. Similar efforts
assisted the Island Campaign in the Pacific.</p>
</blockquote>
<p>After the war, these techniques were adopted by industry as well. As
the sheer scale of organizations began to grow, so did the potential
benefit of the optimized systems brought by OR methodologies. As
techniques and (especially) computing power improved, the types and
scale of problems that were tackled continued to grow. Today almost all
major corporations benefit from OR.</p>
<h3 data-number="2.3.2" id="case-studies"><span
class="header-section-number">2.3.2</span> Case studies</h3>
<p>Your textbook handily comes full of case studies explaining how
companies have used OR to inform their decision-making. Below I’ve
copied part of the summary table. Check out the book to get more
background on anything that piques your interest.</p>
<figure>
<img src="images/or-case-studies.png"
alt="Selected OR case studies (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Selected OR case studies <span
class="citation" data-cites="classText">(<a href="#ref-classText"
role="doc-biblioref">Hillier and Lieberman 2021</a>)</span></figcaption>
</figure>
<p>It’s pretty staggering to look at the figures in the “Annual Savings”
column, which taken together sum to the billions. OR is an enormously
valuable tool.</p>
<h3 data-number="2.3.3" id="edelman-prize"><span
class="header-section-number">2.3.3</span> Edelman Prize</h3>
<p>Now, admittedly, some of those case studies are a little stale. But
don’t fret, OR is still relevant in industry today. A great showcase for
the most recent impactful OR work is the annual Edelman Prize, awarded
by the <a href="https://www.informs.org/">Institute for Operations
Research and Management Science (INFORMS)</a>. The winners of this award
were judged to have demonstrated the best application of OR
methodologies in industry. You can take a look at the <a
href="https://3449182.fs1.hubspotusercontent-na1.net/hubfs/3449182/2023_Edelman_Gala_Book.pdf">program
for the 2023 edition of the award</a> and find cases submitted by names
like DHL, Huawei, Lyft, and the winner Walmart.</p>
<h2 data-number="2.4" id="topics-well-cover"><span
class="header-section-number">2.4</span> Topics we’ll cover</h2>
<p>OR is a wide-ranging topic, and as such we can’t cover everything.
Since the class is meant to be an overview, we won’t get overly deep
into any one topic either<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a>. But we should be able to cover the
basics in a handful of important topics, as well as getting you some
hand-on experience using these methods to solve problems. I’ve outlined
the planned programming below, but note that we are still early in the
semester, so some of this may be subject to change.</p>
<p>My main goal for this course is for you to be able to apply the
methods we learn. We will accomplish this using various packages written
for the Python programming language. While this is not a programming
course, I realize some of you may have limited (or no) knowledge of the
language, thus I’ve provided a small unit on the basics. But if you are
a true beginner this may not suffice, and you may need to spend time on
your own to get comfortable with it.</p>
<p>After that, we will jump into the first big success in Operations
Research history, linear programming. We’ll learn about the basics of
these models, a little history, and a few ways to solve them (with
special emphasis on the simplex method). We’ll also touch on the theory
of duality and sensitivity analysis.</p>
<p>After linear programming comes its cousin, integer programming. As
far as solving techniques, we’ll focus on branch-and-bound and
branch-and-cut. Since integer programming is so powerful, we will spend
significant time talking about how to model these problems, and how to
set them up and solve them with Python.</p>
<p>Next will be several topics in nonlinear programming where we will
talk about convexity, optimality conditions, and selected solution
procedures.</p>
<p>We will also include a section on Stochastic Processes, where we will
cover topics in Markov chains, queueing theory, and perhaps Markov
Decision Processes.</p>
<p>There are a few other topics on my mind (dynamic programming, network
models) that I may decide to cover depending on time and class
interest.</p>
<h1 data-number="3" id="python-crash-course"><span
class="header-section-number">3</span> Python crash course</h1>
<div class="lectureVideoEmbed"
data-video-id="ec3e6d7c7e5e4e63bc3541c58c8a54c91d"
data-video-date="2023-08-25">
Python basics. The video cut off a bit at the end, but you don’t miss
anything important.
</div>
<p>A main focus of the course is to show you how to model and solve
real-world problems. In order to do that, you’ll need some programming
abilities. <a href="https://www.python.org/">Python</a> is a great
choice for this since it is widely-used and relatively easy to learn.
You may have some experience with Python already, which is great! If
you’ve never used Python before, don’t worry. We’ll spend a little time
on the basics here, and we won’t require you to do much out of the
ordinary. Beginners will want to get some more practice outside of
class.</p>
<h2 data-number="3.1" id="google-colab-notebooks"><span
class="header-section-number">3.1</span> Google Colab notebooks</h2>
<p>You can code Python in many different environments, but I think the
easiest way to get started is with <a
href="https://colab.google/">Google Colab</a>. This is a <a
href="https://jupyter.org/">Jupyter</a>-like<a href="#fn6"
class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>
notebook environment that is free to use and requires only a web
browser. I’ll be using this in class to go through coding examples. Note
that you need a Google account in order to fully use Colab<a href="#fn7"
class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a>.</p>
<p>In Colab (and other notebook environments) code is organized into
cells where related blocks of code are written. You can execute code one
cell at a time to work through the notebook and check outputs as you go.
I’ll use a Colab notebook in the next section to walk through some
basics of Python.</p>
<h2 data-number="3.2" id="some-python-basics"><span
class="header-section-number">3.2</span> Some Python basics</h2>
<p>Below, you should see a read-only image of a Colab notebook. The
notebook gives some exposition and samples of basic Python principles.
Click the “Open in Colab” button to open a copy in your browser.</p>
<script src="https://gist.github.com/dcd6305c13b79bbdba7c49dc5c76d3c7.js"></script>
<h2 data-number="3.3" id="sec:pythonEnvironments"><span
class="header-section-number">3.3</span> Other coding environments</h2>
<p>I suggest Colab because it is free and easy to set up, and it should
work well for what you’ll need during the course. But it is far from the
only option for Python, and often not the best option depending on your
needs. Here are a few other options to explore on your own:</p>
<h3 data-number="3.3.1" id="local-development"><span
class="header-section-number">3.3.1</span> Local development</h3>
<p>Unlike Colab, where the computing is done on a cloud-based virtual
machine accessed through your web browser, these next few options run
completely on your local machine. They’ll all require installing
Python<a href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a> along with other software, but you
won’t need an internet connection to use them. This is not an exhaustive
list, just tools that I’ve used and liked.</p>
<ul>
<li><a href="https://jupyter.org/">Jupyter</a>: The first popular
notebook environment for Python. It functions much like Colab does,
though there are minor differences. Several places offer web-hosted
versions of Jupyter too.</li>
<li><a href="https://www.jetbrains.com/pycharm/">Pycharm</a>: Pycharm is
an <a
href="https://en.wikipedia.org/wiki/Integrated_development_environment">IDE</a>
built for Python, and as such comes with support for debugging,
refactoring, run configurations, and more. There is a free version and a
pro version, but the free version has plenty of functionality and is
more than sufficient for the coding in this course.</li>
<li><a href="https://code.visualstudio.com/">Visual Studio Code</a>: VS
Code is a popular, free IDE that supports many different programming
languages. It is highly customizable and there is a broad ecosystem of
extensions that can enhance functionality.</li>
</ul>
<h3 data-number="3.3.2" id="cloud-hosted"><span
class="header-section-number">3.3.2</span> Cloud hosted</h3>
<p>There are several cloud-hosted options available for running Python.
We’ve already mentioned Colab, and there are myriad other places that
offer cloud-hosted notebooks at varying price points. Offerings that I’m
familiar with<a href="#fn9" class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a>:</p>
<ul>
<li><a href="https://ide.cloud.google.com">Google Cloud Shell/IDE</a>:
If you have a Google Cloud Platform account, you have access to a
cloud-based virtual machine known as the Google Cloud Shell. The shell
comes with Python and other common developer tools pre-installed, and
you can interact with it using their Cloud IDE, a hosted VS Code-like
environment. The shell runs a pretty small machine, but it is free to
use and you can use the IDE for up to 50 hours per week.</li>
<li><a
href="https://cloud.google.com/vertex-ai/docs/workbench/introduction">Vertex
AI Notebooks</a>: Managed Jupyter notebooks on Google Cloud Platform.
You do have to pay for the service and the associated compute time and
storage. There are similar offerings from <a
href="https://aws.amazon.com/sagemaker/notebooks/">Amazon Web
Services</a> and <a
href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-run-jupyter-notebooks?view=azureml-api-2">Microsoft
Azure</a></li>
<li><a href="https://www.gitpod.io/">Gitpod</a>: Gitpod is a service
that offers on-demand cloud development environments that are highly
customizable. This one is a little more advanced, and all machine
instances need to be backed by some <a
href="https://git-scm.com/">git</a> repository (e.g. on <a
href="https://github.com/">GitHub</a>). So I wouldn’t start here, but
for the right use-case it is a nice service. Their free plan gets you up
to 50 hours per month.</li>
</ul>
<h1 data-number="4" id="linear-programming"><span
class="header-section-number">4</span> Linear programming</h1>
<div class="lectureVideoEmbed"
data-video-id="0b552ccb31c34eab8f6f6d658afd32c61d"
data-video-date="2023-08-28">
Intro to linear programming (sections 4.1-4.3)
</div>
<p>In the family of OR techniques, linear programming (LP) is certainly
the matriarch. It was among the first methods to be seriously studied
and find broad applications. To this day, LPs are relevant and used
across industry to inform decision-making and help best make use of
scarce resources.</p>
<p>So, what is an LP? Let’s step back a bit - linear programming is a
special type of mathematical programming problem. The word
<em>programming</em>, in the language of the pre-computer-revolution era
where these topics were first studied, was more or less a synonym for
<em>planning</em>. So mathematical programming just means using math to
make a plan.</p>
<p>And the linear part? This refers to the form of the mathematical
objects used. All mathematical programs have <em>variables</em>
(quantities you get to set in order to get a desirable result),
<em>constraints</em> (limitations on how you can set your variables),
and an <em>objective</em> (the quantity you want to maximize/minimize).
In linear programming, all constraints and objectives must be
<em>linear</em> functions of your variables. Meaning, you can multiply
the variables by constants and add them together. No higher order terms,
like squaring a variable or multiplying two variables together. We’ll
see an example in the next section.</p>
<h2 data-number="4.1" id="sec:exampleLp"><span
class="header-section-number">4.1</span> An example LP</h2>
<p>Before we pile up too many definitions, maybe we should see an
example problem where we can get more hands-on. The following comes from
<span class="citation" data-cites="classText">Hillier and Lieberman (<a
href="#ref-classText" role="doc-biblioref">2021</a>)</span>, section
3.1.</p>
<blockquote>
<p>The Wyndor Glass Co. produces high-quality glass products, including
windows and glass doors. It has three plants. Aluminum frames and
hardware are made in Plant 1, wood frames are made in Plant 2, and Plant
3 produces the glass and assembles the products. Because of declining
earnings, top management has decided to revamp the company’s product
line. Unprofitable products are being discontinued, releasing production
capacity to launch two new products having large sales potential:</p>
<ul>
<li>Product 1: An 8-foot glass door with aluminum framing</li>
<li>Product 2: A 4 x 6 foot double-hung wood-framed window</li>
</ul>
<p>Product 1 requires some of the production capacity in Plants 1 and 3,
but none in Plant 2. Product 2 needs only Plants 2 and 3. The marketing
division has concluded that the company could sell as much of either
product as could be produced by these plants. However, because both
products would be competing for the same production capacity in Plant 3,
it is not clear which mix of the two products would be most
profitable.</p>
</blockquote>
<p>Together with management, the company’s OR team defines the problem
as follows:</p>
<blockquote>
<p>Determine what the production rates should be for the two products in
order to maximize their total profit, subject to the restrictions
imposed by the limited production capacities available in the three
plants. (Each product will be produced in batches of 20, so the
production rate is defined as the number of batches produced per week.)
Any combination of production rates that satisfies these restrictions is
permitted, including producing none of one product and as much as
possible of the other.</p>
</blockquote>
<p>The team’s next task is to gather data on production runs and
potential profits. The findings are summarized in the table below:</p>
<figure>
<img src="images/lp-example-data.png"
alt="Data for the Wyndor Glass Co. problem (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Data for the Wyndor Glass Co. problem
<span class="citation" data-cites="classText">(<a href="#ref-classText"
role="doc-biblioref">Hillier and Lieberman 2021</a>)</span></figcaption>
</figure>
<h3 data-number="4.1.1" id="formulating-our-first-lp"><span
class="header-section-number">4.1.1</span> Formulating our first LP</h3>
<p>How do we go about formulating this problem mathematically? We must
first decide on the <em>decision variables</em>, the quantities we get
to choose in order to affect profit. In this case, the variables are the
quantities of Product 1 and Product 2 that we choose to produce. We will
denote these quantities by <span class="math inline">x_1</span> and
<span class="math inline">x_2</span> respectively. That is, <span
class="math inline">x_1</span> is the number of batches of Product 1 we
will produce in a week, and <span class="math inline">x_2</span> is the
number of batches of Product 2 we produce in a week.</p>
<p>Next let’s talk about the problem’s <em>objective function</em>, the
quantity that we are trying to optimize. Naturally, we’d like to
maximize profit. From the table, we know that we get $3,000 in profit
per batch of Product 1 and $5,000 per batch of Product 2. Thus the
formula</p>
<p><span class="math display">
3x_1 + 5x_2
</span></p>
<p>tells us (in thousands of dollars) how much profit we expect for a
given selection of <span class="math inline">x_1</span> and <span
class="math inline">x_2</span>.</p>
<p>Now, we can’t select <span class="math inline">x_1</span> and <span
class="math inline">x_2</span> to be arbitrarily high. We are restricted
by the available production time at each plant. So we will add
<em>constraints</em> relating to these availabilities. We know that each
batch of Product 1 requires 1 hour of time in Plant 1, while Product 2
does not require any time at Plant 1. So, knowing that 4 hours of
production time is available per week, the constraint associated with
production at Plant 1 is simply <span class="math inline">x_1 \leq
4</span>. Similarly, at Plant 2, Product 2 is the only one that requires
processing, at 2 hours per batch. With 12 hours per week available, the
constraint for Plant 2 becomes <span class="math inline">2x_2 \leq
12</span>.<a href="#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a></p>
<p>What about Plant 3? Both products require time at this facility, so
they could both contribute to the depletion of its 18 hours per week.
Every batch of Product 1 requires 3 hours, while every batch of Product
2 requires 2 hours. So the constraint imposed by Plant 3 is simply <span
class="math inline">3x_1 + 2x_2 &lt;= 18</span>.</p>
<p>Lastly, we know that <span class="math inline">x_1</span> and <span
class="math inline">x_2</span> cannot be negative (there is no way to
produce a negative number of products), so <span class="math inline">x_1
\geq 0</span> and <span class="math inline">x_2 \geq 0</span> must be
part of our formulation as well. Bringing it all together, we can write
the problem formulation as:</p>
<p><span id="eq:prototypeLp" class="eqnos"><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq \ \ 4  \\
     &amp;&amp; 2x_2 &amp; \leq 12 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18 \\
     &amp;&amp; x_1,x_2 &amp; \geq \ \ 0
\end{align*}
</span><span class="eqnos-number">(1)</span></span></p>
<h2 data-number="4.2" id="lp-terminology"><span
class="header-section-number">4.2</span> LP terminology</h2>
<p>With this example in hand, let’s get back to some definitions. The
<strong>decision variables</strong> are the quantities we’re deciding
how to set. In our example these are <span
class="math inline">x_1</span> and <span class="math inline">x_2</span>,
the number of batches run per week for the two products. The
<strong>objective</strong> is the value we’d like to optimize, which in
the example is the profit equation <span class="math inline">3x_1 +
5x_2</span>. In this case we’d like to maximize the objective, but
minimization is possible as well. The <strong>constraints</strong> are
the limitations on how we set the decision variables, which in this case
is everything after the “s.t.”<a href="#fn11" class="footnote-ref"
id="fnref11" role="doc-noteref"><sup>11</sup></a>. Notice that the final
constraint, <span class="math inline">x_1,x_2\geq0</span>, is really two
constraints so this is abusing notation a bit. But these types of
constraints (called <strong>variable bound</strong> constraints, or in
this case <em>non-negativity</em> constraints since they restrict
variables to <span class="math inline">\geq0</span>) are often treated
separately in solution techniques, so it is common to see them grouped
or written slightly differently like this. We call the rest of the
constraints the <strong>functional constraints</strong>.</p>
<p>A <strong>solution</strong> to an LP is any specification of values
for the decision variables. And I do mean <em>any</em><a href="#fn12"
class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>,
it doesn’t matter if the values imply a good objective value or even if
they satisfy the constraints. They are still called a solution. Hence
each of:</p>
<ul>
<li><span class="math inline">x_1=0, x_2=0</span></li>
<li><span class="math inline">x_1=-20, x_2=6</span></li>
<li><span class="math inline">x_1=2, x_2=3</span></li>
</ul>
<p>are all solutions to our sample problem, even though the second one
violates non-negativity.</p>
<p>A <strong>feasible solution</strong> is a solution that satisfies all
of the problem constraints. In contrast, an <strong>infeasible
solution</strong> is one that violates <em>at least one</em> constraint.
The <strong>feasible region</strong> is the set of all feasible
solutions. It is possible for a problem to have no feasible solutions,
in which case the problem itself is said to be
<strong>infeasible</strong>.</p>
<p>When solving an LP, the goal is to find an <strong>optimal
solution</strong>, a feasible solution that gives the most favorable
value<a href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a> of the objective function. Notice
we said <em>an</em> optimal solution, not <em>the</em> optimal solution,
as it is entirely possible for a problem to have more than one solution
attain the optimal value. It is also possible to have no optimal
solutions at all, as in the case of an infeasible problem. Another
situation with no optimal solution is an <strong>unbounded</strong>
problem, where the objective value can become arbitrarily favorable.</p>
<h2 data-number="4.3" id="sec:lpVisualized"><span
class="header-section-number">4.3</span> LP visualized</h2>
<p>Let’s get hands-on again to see our new definitions in action. Since
our sample problem includes only two decision variables, we can
visualize what’s going on in a plot:</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;choosePoints&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Here we have a plot with <span class="math inline">x_1</span> on the
horizontal axis, <span class="math inline">x_2</span> on the vertical
axis, and a line drawn for each <strong>constraint boundary</strong>
(the line that forms the boundary of what is permitted by the
corresponding constraint) for the constraints of eq. <a
href="#eq:prototypeLp">1</a>. Moreover, if you hover over a constraint
boundary, the side of the line satisfied by the inequality is shaded
light gray<a href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a>. The feasible region is the portion
of the plot where all the constraints are satisfied, and it is plainly
visible as the gray-shaded region in the bottom-left. Such an
intersection of linear inequalities is called a
<strong>polyhedron</strong>, and in cases such as this where the
polyhedron is bounded (i.e. doesn’t go off to infinity in some
direction) we also call it a <strong>polytope</strong>.</p>
<p>If you click on the plot (or enter values in the text boxes) a
solution will be drawn. If the point is a feasible solution, it will be
colored black and the objective value at the solution is show below the
plot. Otherwise the solution is infeasible, the point will be colored
red, and the violated inequalities will flash.</p>
<p>How can we visualize the objective? Since the objective is given by
<span class="math inline">3x_1 + 5x_2</span>, any line we draw of the
form <span class="math inline">3x_1 + 5x_2 = Z</span> (for some number
<span class="math inline">Z</span>) will show the solutions that give
objective value <span class="math inline">Z</span>. You can try this
with the plot below: put your chosen <span class="math inline">Z</span>
value in the input box (or click on the plot to get a line going through
that point). The line will show up on the plot, and the intersection
with the feasible region (if any exists) will be highlighted. These
highlighted solutions each give objective value <span
class="math inline">Z</span>.</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;chooseObjVals&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<h3 data-number="4.3.1" id="solving-an-lp-visually"><span
class="header-section-number">4.3.1</span> Solving an LP visually</h3>
<p>We actually have the tools to solve this problem now. For problems in
two dimensions, it is fairly straightforward to draw a graph and see
where the best solution is. This is not a good (or usually even
feasible) method in practice, but for a toy problem it can really help
build some intuition.</p>
<p>Let’s look back at the above plot. Since we’re maximizing, we’d like
to choose the largest <span class="math inline">Z</span> such that the
line intersects the feasible region. Let’s start with something too big,
say <span class="math inline">Z=50</span>. When we plot that, we see it
is way too high above the feasible region. So we can start moving it
lower. Maybe go to <span class="math inline">Z=40</span>. It’s still
completely above the feasible region, so that’s not it either. Now jump
to <span class="math inline">Z=30</span>. This intersects the plot, but
there is a section of the feasible region above the line, and hence
feasible solutions with a better objective value.</p>
<p>So keep searching. When you come to <span
class="math inline">Z=36</span> the situation looks different. The line
intersects the plot at a single point, <span class="math inline">x_1=2,
x_2=6</span>. If you move the objective up just a little bit, say to
36.1, you get no intersection with the feasible region<a href="#fn15"
class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>.
Thus we know we’ve found the optimal solution<a href="#fn16"
class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>,
and in this case it is unique.</p>
<h3 data-number="4.3.2" id="visualizing-other-scenarios"><span
class="header-section-number">4.3.2</span> Visualizing other
scenarios</h3>
<p>Let see some examples of the other scenarios we defined above. In
each case, we’ll take our initial model eq. <a
href="#eq:prototypeLp">1</a> and modify it to show the desired
property.</p>
<h4>
An infeasible problem
</h4>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;addConstraints&quot;: [[[1, 3, 30, &quot;g&quot;], [5, 9.25]]], &quot;choosePoints&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>In this plot, we’ve added the constraint <span
class="math inline">x_1 + 3x_2 \geq 30</span>. All the points satisfying
this inequality are well above the previous feasible region, so no
solutions are feasible.</p>
<h4>
An unbounded problem
</h4>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;removeConstraints&quot;: [0, 1], &quot;altFeasRegionTextPlace&quot;: [4.5, 3.5], &quot;chooseObjVals&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Here we’ve removed two constraints, with the only one remaining being
<span class="math inline">2x_2 &lt;= 12</span>. We can see there is no
constraint on <span class="math inline">x_1</span> at all now, so we can
choose it arbitrarily large and still be in the feasible region<a
href="#fn17" class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a>.</p>
<h4>
Multiple optima
</h4>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;altObj&quot;: [6, 4], &quot;chooseObjVals&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>In this example, we’ve altered the objective function to <span
class="math inline">6x_1 + 4x_2</span> so that it has the same slope as
one of our constraints. We can see by moving the objective up and down
that the optimal solution comes at <span
class="math inline">Z=36</span>, where the objective line intersects an
entire face (bounding line) of the feasible region. Since any point on
that bounding line attains the optimal objective value, they are all
optimal solutions.</p>
<h2 data-number="4.4" id="sec:lpSoftware"><span
class="header-section-number">4.4</span> Solving LPs with software</h2>
<div class="lectureVideoEmbed"
data-video-id="b84d7d439309417aabb870fd25751e001d"
data-video-date="2023-09-01">
Python coding environments (section <a
href="#sec:pythonEnvironments">3.3</a>), solving LPs with Python
</div>
<p>Let’s pause briefly now to explain, practically, how LPs can be
solved in the real world. By which I mean: if given an LP in practice,
what would you do to find the answer? I’m not talking about the theory
behind what LP solving software does (we’ll get the that later), just
how to <em>use</em> the software. This won’t be a comprehensive
discussion, really just giving you enough to solve our example LP. We’ll
expand on this discussion some when we get to modeling in the integer
programming section.</p>
<p>There are two key components to solving mathematical programming
problems in practice: the modeling language and the solver.</p>
<h3 data-number="4.4.1" id="modeling-languages"><span
class="header-section-number">4.4.1</span> Modeling languages</h3>
<p>The job of a modeling language is to take a model specification like
eq. <a href="#eq:prototypeLp">1</a> and turn it into something the
computer can understand and solve. Some popular modeling languages are
their own standalone software, such as <a
href="https://ampl.com/">AMPL</a> and <a
href="https://www.gams.com/">GAMS</a>. The modeling languages we’ll use
are instead shipped as Python<a href="#fn18" class="footnote-ref"
id="fnref18" role="doc-noteref"><sup>18</sup></a> libraries. Sometimes
these languages are built for use with a single solver, while others try
to be compatible with several different solvers.</p>
<h3 data-number="4.4.2" id="solvers"><span
class="header-section-number">4.4.2</span> Solvers</h3>
<p>The solver is the software that takes the modeled problem and applies
the necessary algorithms to solve it. There are several options here as
well. The best solvers all require paid licenses to use fully for
commercial purposes<a href="#fn19" class="footnote-ref" id="fnref19"
role="doc-noteref"><sup>19</sup></a>. The two biggest names in this
space are <a href="https://www.gurobi.com/">Gurobi</a> and <a
href="https://www.ibm.com/products/ilog-cplex-optimization-studio/cplex-optimizer">CPLEX</a>,
though <a
href="https://www.fico.com/en/products/fico-xpress-optimization">Xpress</a>
and <a href="https://www.shanshu.ai/copt/">COPT</a> are competitive as
well. There are also free, open-source options, but these generally
perform much worse than the commercial offerings. Some names in this
space are <a href="https://www.coin-or.org/">COIN-OR</a>, <a
href="https://www.gnu.org/software/glpk/">GLPK</a>, and <a
href="https://scipopt.org/">SCIP</a>.</p>
<h3 data-number="4.4.3" id="solving-our-lp-with-python"><span
class="header-section-number">4.4.3</span> Solving our LP with
Python</h3>
<p>In the following notebook, I show how we can model and solve our
sample LP in two different ways. The first way uses Gurobi as the solver
and its purpose-built Python library <code>gurobipy</code> as the
modeler. I should mention that since Gurobi is a commercial solver, we
need some sort of license for unrestricted use. However, we do get a
limited license automatically with the install of <code>gurobipy</code>
which is good for problems with up to 2000 variables and 2000 linear
constraints. This is pretty limiting for practical industry use, but
most everything we’ll do in this class will fall comfortably within
those bounds.</p>
<p>The second option is a fully open-source option using PuLP, a Python
modeling language maintained by COIN-OR. By default, this will use
COIN-OR’s linear programming solver CLP to solve the model. However, a
nice feature of PuLP is that it is solver-agnostic. This means that you
can use it to model your problem but switch between any of the popular
solvers (including the commercial ones). This is nice to avoid being
locked-in to a single solver. But it also may be slightly less
performant, or may lack some solver-specific features that come with a
solver’s built-in API.</p>
<script src="https://gist.github.com/9c7e1b589a3efb40590606ba6eed102f.js"></script>
<h3 data-number="4.4.4" id="sec:lpModelDataSep"><span
class="header-section-number">4.4.4</span> Model/data separation</h3>
<p>Our Python models from the last notebook certainly work for the
sample problem, but that’s about it. The real power of programming comes
when you can write one bit of code that can be applied in a wide range
of contexts.</p>
<p>Our sample LP is in the form of a <em>resource allocation
problem</em>, where the decision is how much to engage in a certain set
of possible activities, while staying within the bounds of the available
resources. We’d be better off to use Python to set the <em>model
logic</em> for such a problem, leaving placeholders where we can inject
the particular <em>problem data</em> for any given instance. We’ll do
that in the next notebook.</p>
<script src="https://gist.github.com/0a3d429db92daf96fac2eeb23a3197f7.js"></script>
<h2 data-number="4.5" id="sec:lpForms"><span
class="header-section-number">4.5</span> LP forms</h2>
<div class="lectureVideoEmbed"
data-video-id="d82d2e52c5e74e7283d5b095d5f8a9031d"
data-video-date="2023-08-30">
LP forms, notation, and an intro to simplex
</div>
<p>We’re <em>almost</em> ready to talk about algorithms for solving LPs,
but first we should make a note on some different forms LPs can take.
Crucially, it will turn out that all the forms we talk about here are,
in a sense, equivalent. Thus no matter the specifics of how an LP is
presented, we know we’ll be able to solve it using the general
methods.</p>
<h3 data-number="4.5.1" id="standard-form"><span
class="header-section-number">4.5.1</span> Standard form</h3>
<p>Our formulation of the sample LP in eq. <a
href="#eq:prototypeLp">1</a> is in what is known as <strong>standard
form</strong>. Generally, a linear program with <span
class="math inline">n</span> variables and <span
class="math inline">m</span> constraints is in standard form if it is
written as:</p>
<p><span id="eq:standardFormLp" class="eqnos"><span
class="math display">
\begin{align*}
\text{max}&amp;&amp; c_1x_1 + c_2x_2 + \cdots + c_nx_n &amp;&amp;
&amp;&amp; \\
\text{s.t.}&amp;&amp; a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n
&amp;&amp; \leq &amp;&amp; b_1 \\
     &amp;&amp; a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n &amp;&amp;
\leq &amp;&amp; b_2 \\
     &amp;&amp;                                            &amp;&amp;
\vdots &amp;&amp; \\
     &amp;&amp; a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n &amp;&amp;
\leq &amp;&amp; b_m \\
     &amp;&amp; x_1, x_2, \cdots , x_n &amp;&amp; \geq &amp;&amp; 0
\end{align*}
</span><span class="eqnos-number">(2)</span></span></p>
<p>Where all the <span class="math inline">a</span>, <span
class="math inline">b</span>, and <span class="math inline">c</span>
values (known as the <strong>problem data</strong>) are real numbers.
Our sample problem, and many other practical LP problems, are naturally
formulated like this. But it might at first glance feel a bit limiting.
What if you’d rather minimize instead of maximizing? Or let your
variables take negative values? We’ll see in the following sections that
such considerations are indeed possible, and we can consider them in the
same framework as standard form problems.</p>
<h3 data-number="4.5.2" id="minimization-problems"><span
class="header-section-number">4.5.2</span> Minimization problems</h3>
<p>What if your optimization problem is a minimization problem and not a
maximization problem? For example, instead of maximizing profit, you’d
like to minimize cost? No worries, it is actually quite straightforward
to convert from minimization to maximization - just turn everything
negative! The minimum cost is the same as the maximum “negative cost”
<span class="math inline">(-1\cdot\text{cost})</span>. So</p>
<p><span class="math display">
\text{min}\ c_1x_1 + c_2x_2 + \cdots + c_nx_n
</span></p>
<p>is the same as</p>
<p><span class="math display">
\text{max}-c_1x_1 -c_2x_2 - \cdots -c_nx_n.
</span></p>
<p>Since the problem data can be any real number (so, in particular,
negative numbers are fine) this still follows the form of eq. <a
href="#eq:standardFormLp">2</a>.</p>
<h3 data-number="4.5.3" id="sec:lpConstraintTransform"><span
class="header-section-number">4.5.3</span> Different constraint
forms</h3>
<p>What if you wanted “greater than or equal” constraints instead of
“less than or equal” constraints? This is again another case of a sign
switch since if you take any inequality you can:</p>
<ul>
<li>multiply both sides by -1, and</li>
<li>switch the direction of the inequality</li>
</ul>
<p>to end up with a logically equivalent inequality<a href="#fn20"
class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a>.
Thus any inequality of the form:</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n \geq b_i
</span></p>
<p>can be written as</p>
<p><span class="math display">
-a_{i1}x_1 - a_{i2}x_2 - \cdots - a_{in}x_n \leq -b_i
</span></p>
<p>which brings us back into line with the standard form inequalities in
eq. <a href="#eq:standardFormLp">2</a>.</p>
<p>What about equality constraints? That is, constraints of the form</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n = b_i.
</span></p>
<p>Can these be converted into standard form? The answer is yes, but it
comes at the cost of an extra constraint in the formulation. Because
using the above constraint has the same effect as using these two in
combination:</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n \leq b_i \\
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n \geq b_i
</span></p>
<p>Now, that second inequality does not fit in standard form since it is
a “<span class="math inline">\geq</span>” constraint, but we already
know how to convert it. So the final standard-form-conforming
formulation is:</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n \leq b_i \\
-a_{i1}x_1 - a_{i2}x_2 - \cdots - a_{in}x_n \leq -b_i
</span></p>
<p>Great, so we can go from equality constraints to inequality
constraints, but what about the other way? That is possible too, but
this time we’ll need to add a <em>variable</em> to the formulation. In
particular, to convert the inequality</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n \leq b_i
</span></p>
<p>to equality form, we’ll add a so-called <strong>slack
variable</strong> <span class="math inline">s_i</span>. We’ll enforce
<span class="math inline">s_i\geq0</span> and rewrite the constraint
as</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n + s_i = b_i.
</span></p>
<p>This works since, for any selection of the <span
class="math inline">x</span> values that satisfies the inequality, we
can simply select the value of <span class="math inline">s_i</span> as
the difference between <span class="math inline">b_i</span> and the
<span class="math inline">a_{i1}x_1 + a_{i2}x_2 + \cdots +
a_{in}x_n</span>, i.e. the <em>slack</em> in the constraint. Going the
other way, any variable selections that satisfy the equality will also
satisfy the inequality since, by rearranging the equality, we get</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n = b_i - s_i
</span></p>
<p>and <span class="math inline">s_i</span> is non-negative, so the
left-hand side is less than (or equal to) <span
class="math inline">b_i</span>.</p>
<h3 data-number="4.5.4" id="sec:lpVariableBoundTransform"><span
class="header-section-number">4.5.4</span> Variable bounds</h3>
<p>In the standard form problem, we enforce that all of our variables
are non-negative. But what if we don’t want any explicit bounds on the
variables? Is this a different class of problems? As it turns out, we
can freely switch back and forth between non-negative variables and
these so-called <strong>unrestricted</strong> or <strong>free
variables</strong>.</p>
<p>How do we do the transformations? The first direction is
straightforward; say you have a formulation with non-negative variables
and you’d like to remove the variable bounds. Well, we still have the
functional constraints, where we are allowed to use inequalities. So
we’ll “remove” the variable bound constraint <span
class="math inline">x_j\geq0</span> by creating a new functional
constraint</p>
<p><span class="math display">
a_1x_1 + \cdots + a_jx_j + \cdots + a_nx_n \leq b
</span></p>
<p>where <span class="math inline">b=0</span>, <span
class="math inline">a_j=-1</span>, and all other coefficients equal
<span class="math inline">0</span> (i.e. <span
class="math inline">-x_j\leq0\Leftrightarrow x_j\geq 0</span>).</p>
<p>Now the less obvious transformation. Say we have a formulation where
the variable <span class="math inline">x_j</span> is unrestricted. How
do we convert to non-negative variables? One way is to define two more
variables, call them <span class="math inline">w_j</span> and <span
class="math inline">z_j</span>, which will be our new non-negative
variables. What we’ll do is simply replace <span
class="math inline">x_j</span> with <span
class="math inline">w_j-z_j</span>, so that the constraints become</p>
<p><span class="math display">
a_{i1}x_1 + \cdots + a_{ij}w_j - a_{ij}z_j + \cdots + a_{in}x_n \leq b_i
</span></p>
<p>for each <span class="math inline">i</span><a href="#fn21"
class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a>,
and a similar replacement is done in the objective function.</p>
<h3 data-number="4.5.5" id="recap-of-allowed-forms"><span
class="header-section-number">4.5.5</span> Recap of allowed forms</h3>
<p>As a recap: we defined the standard form LP where the objective is
maximized, the functional constraints are <span
class="math inline">\leq</span> inequalities, and variables are
non-negative. But it turns out there are several equivalent ways to
formulate LPs, namely:</p>
<ul>
<li>Objectives can be either minimized or maximized.</li>
<li>Constraints can be in <span class="math inline">\leq</span>, <span
class="math inline">\geq</span>, or <span class="math inline">=</span>
form.</li>
<li>Variables may be bounded or not.</li>
</ul>
<p>Crucially, any of these forms can be transformed into any of the
others, so no matter how we specify a particular LP, any of the results
and techniques we discuss here apply!</p>
<h3 data-number="4.5.6" id="different-notation"><span
class="header-section-number">4.5.6</span> Different notation</h3>
<p>Last up for this section, let’s discuss notation. I don’t know about
you, but I get a little overwhelmed when I look at formulations like
eq. <a href="#eq:standardFormLp">2</a>. There’s a lot to look at there,
and while I think it’s good initially to see things written in full
detail with simple notation like this, returns begin diminishing
quickly. Especially in a case like this where there’s a lot of
repetition with minimal changes from line to line.</p>
<p>So, from here on out and where appropriate, I’ll start using more
concise notation. For example, eq. <a href="#eq:standardFormLp">2</a>
can be written more concisely like so:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \sum_{j=1}^n c_jx_j    &amp; \\
\text{s.t.}&amp;&amp; \sum_{j=1}^n a_{ij}x_j &amp; \leq b_i\quad \forall
i\in\{1,...,m\} \\
     &amp;&amp; x_j                    &amp; \geq 0\quad \forall
j\in\{1,...,n\}
\end{align*}
</span></p>
<p>This looks much cleaner to my eyes, and each line communicates
different important information about the formulation. But to benefit
from the compactness, one needs to be familiar with the notation used. I
assume everyone reading this has seen the summation notation <span
class="math inline">\sum</span> before, but some other notation (set
inclusion <span class="math inline">\in</span> and “for all” <span
class="math inline">\forall</span> in particular) may be new. And
sometimes new is intimidating. But fear not! These things get clearer
and clearer the more you see them, and I think the benefit is worth it.
There is a section in the appendix (section <a
href="#sec:symbols">7.1</a>) dedicated to special symbols. Beyond that,
if you’re ever confused about something, you can always ask me!</p>
<p>We’ll see more notation like the above as we formulate more specific
problems, but for much of the theory sections to come I actually much
prefer matrix notation. You should already be familiar with linear
algebra (section <a href="#sec:linearAlgebra">7.2</a> in the appendix
gives a brief review), so you should be able to notice how matrix
algebra fits nicely with the formulations we’ve already given. For some
<span class="math inline">m\times n</span> matrix <span
class="math inline">\mathbf{A}</span> and <span
class="math inline">n</span> vector <span
class="math inline">\mathbf{x}</span>, if we multiply them we have:</p>
<p><span class="math display">
\begin{align*}
\mathbf{A}\mathbf{x}&amp;=\begin{bmatrix}
    a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
    a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn} \\
\end{bmatrix}\begin{bmatrix}
    x_1 \\ x_2 \\ \vdots \\ x_n
\end{bmatrix}\\
&amp;=\begin{bmatrix}
    a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n \\
    a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n \\
    \vdots \\
    a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n \\
\end{bmatrix}
\end{align*}
</span></p>
<p>which looks just like the constraint section of the standard form LP
eq. <a href="#eq:standardFormLp">2</a>. Due to the conciseness, my
favorite notation for the standard form LP is</p>
<p><span id="eq:standardFormLpMatrix" class="eqnos"><span
class="math display">
\begin{align*}
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}\\
\text{s.t.}&amp;&amp; \mathbf{A}\mathbf{x}&amp;\leq\mathbf{b}\\
     &amp;&amp; \mathbf{x}&amp;\geq\mathbf{0}
\end{align*}
</span><span class="eqnos-number">(3)</span></span></p>
<p>Much nicer on the eyes, right!</p>
<p>Further, you may have noticed that though we’ve devoted significant
time to it already, we haven’t formally defined linear programming yet!
I was waiting for this moment to do so. A <strong>linear
program</strong> is an optimization problem in the form of eq. <a
href="#eq:standardFormLpMatrix">3</a>.</p>
<h2 data-number="4.6" id="sec:simplex"><span
class="header-section-number">4.6</span> The simplex method</h2>
<div class="lectureVideoEmbed"
data-video-id="3bffb2e146dc437488375242ef326b511d"
data-video-date="2023-09-06">
Simplex walkthrough. Unfortunately I do some board work in this one but
didn’t switch the recording to focus on the board, so some of that might
be hard to make out.
</div>
<p>We’re just about ready to talk about LP solving algorithms, and we’re
of course starting with the <strong>simplex method</strong> (also
sometimes called the <strong>simplex algorithm</strong>). Arguably the
most important breakthrough in the history of OR was the development of
the simplex method by George Dantzig<a href="#fn22" class="footnote-ref"
id="fnref22" role="doc-noteref"><sup>22</sup></a> during the late
1940s<a href="#fn23" class="footnote-ref" id="fnref23"
role="doc-noteref"><sup>23</sup></a>. It was perhaps the first practical
algorithm developed for linear programming, and it continues to be the
workhorse in linear and integer programming solvers today<a href="#fn24"
class="footnote-ref" id="fnref24"
role="doc-noteref"><sup>24</sup></a>.</p>
<h3 data-number="4.6.1" id="corner-point-solutions"><span
class="header-section-number">4.6.1</span> Corner-point solutions</h3>
<p>Before we get to the algorithm itself, let’s take a moment to dwell
on some geometric insights the method relies on. We’ll return to our
sample problem eq. <a href="#eq:prototypeLp">1</a> and once again we’ll
graph it below.</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;showVertices&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>This time we’ve also plotted the solutions in the corners of the
feasible region, because they are important to the simplex algorithm. We
call these solutions <strong>corner-point feasible (CPF)
solutions</strong><a href="#fn25" class="footnote-ref" id="fnref25"
role="doc-noteref"><sup>25</sup></a> or <strong>vertices</strong><a
href="#fn26" class="footnote-ref" id="fnref26"
role="doc-noteref"><sup>26</sup></a>, which are feasible solutions that
come at the intersection of two constraint boundaries (in the general
case, for LPs in standard form eq. <a href="#eq:standardFormLp">2</a>
with <span class="math inline">n</span> decision variables, the CPF
solutions come at the intersection of <span class="math inline">n</span>
constraints boundaries).</p>
<p>The simplex algorithm makes use of the following key fact of linear
programs:</p>
<div id="thm:cornerPointOpt" class="theorem">
<p>If a linear program has an optimal solution (i.e. not unbounded or
infeasible), then it has an optimal solution that is a corner-point
solution.</p>
</div>
<div class="proof" for="thm:cornerPointOpt" data-placement="appendix">
<p>We won’t actually give a full proof of this theorem, instead we’ll
only consider the case of a standard form LP (eq. <a
href="#eq:standardFormLpMatrix">3</a>) with only two decision variables.
Those of you that are familiar with <a
href="https://en.wikipedia.org/wiki/Mathematical_induction">proofs by
induction</a> may be able to see how to generalize this to any number of
variables.</p>
<p>In two dimensions we can visualize this, so let’s continue to use the
sample LP of eq. <a href="#eq:prototypeLp">1</a> as our example. Any
feasible solution to a two-dimensional LP must fall under exactly one of
these categories:</p>
<ol type="1">
<li>An interior solution (not on any constraint boundaries).</li>
<li>On a single constraint boundary.</li>
<li>A corner-point feasible (CPF) solution (i.e. at the intersection of
two constraint boundaries).</li>
</ol>
<p>What we can show is that for any solution of type 1 or 2, we can find
a CPF solution with equal or greater objective value, and we will
illustrate this in the plot below. To that end, suppose we have some
solutions <span class="math inline">\mathbf{z}</span> on the interior of
the feasible region, and <span class="math inline">\mathbf{y}</span>
that lies on a single constraint boundary.</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;extraPoints&quot;: [[2, 1], [3, 4.5]], &quot;extraLines&quot;: [[2, 1, 3, 1.5, {&quot;style&quot;: &quot;stroke-width:2pt;stroke:black&quot;, &quot;marker-end&quot;: &quot;url(#blackArrowMarker)&quot;}], [3, 4.5, 2.5, 5.25, {&quot;style&quot;: &quot;stroke-width:2pt;stroke:black&quot;, &quot;marker-end&quot;: &quot;url(#blackArrowMarker)&quot;}]], &quot;extraMathText&quot;: [[&quot;y&quot;, 3.25, 5, {&quot;coordToPix&quot;: true}], [&quot;z&quot;, 1.75, 1.75, {&quot;coordToPix&quot;: true}], [&quot;v&quot;, 2, 5.75, {&quot;coordToPix&quot;: true}], [&quot;u&quot;, 3.25, 1.75, {&quot;coordToPix&quot;: true}]]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Let <span class="math inline">\mathbf{v}</span> be a (unit) vector
that points in the same direction as the constraint boundary that <span
class="math inline">\mathbf{y}</span> is on. Let <span
class="math inline">\mathbf{c}</span> be the vector of objective
function coefficients (so in our sample LP we would have <span
class="math inline">\mathbf{c}=\begin{bmatrix}3\\5\end{bmatrix}</span>).
The objective value at solution <span
class="math inline">\mathbf{y}</span> is <span
class="math inline">\mathbf{y}\mathbf{c}</span>. In contrast, if we move
some amount <span class="math inline">\delta</span> from <span
class="math inline">\mathbf{y}</span> along direction <span
class="math inline">\mathbf{v}</span>, the objective value is (due to
distributivity of matrix operations) <span
class="math inline">(\mathbf{y} + \delta\mathbf{v})\mathbf{c}=
\mathbf{y}\mathbf{c}+ \delta\mathbf{v}\mathbf{c}</span>.</p>
<p>If <span class="math inline">\mathbf{v}\mathbf{c}\geq0</span>, then
moving from <span class="math inline">\mathbf{y}</span> along the
constraint boundary in the direction of <span
class="math inline">\mathbf{v}</span> improves the objective value. So
we can continue in that direction until we meet another constraint,
yielding a CPF solution with greater-or-equal objective value than <span
class="math inline">y</span>. If, on the other hand, <span
class="math inline">\mathbf{v}\mathbf{c}&lt;0</span>, then we can move
in the direction of <span class="math inline">-\mathbf{v}</span> to a
CPF solution with greater objective value than <span
class="math inline">\mathbf{y}</span>. So either way, there is some CPF
solution with objective value at least as good as <span
class="math inline">\mathbf{y}</span>.</p>
<p>The proof for the interior point <span
class="math inline">\mathbf{z}</span> is very similar. Select some
direction <span class="math inline">\mathbf{u}</span>, and then travel
from <span class="math inline">\mathbf{z}</span> along directions <span
class="math inline">\mathbf{u}</span> or <span
class="math inline">\mathbf{u}</span> until you hit a constraint
boundary. One of these points will yield an objective value at least as
good as <span class="math inline">\mathbf{z}</span>, and it will be on
either:</p>
<ul>
<li>The intersection of two constraints, in which case we’ve found the
CPF solution with at least as good a value as <span
class="math inline">\mathbf{z}</span>.</li>
<li>A single constraint, in which case we can repeat the procedure shown
above for <span class="math inline">\mathbf{y}</span> to find the CPF
solution.</li>
</ul>
<p>In either case, we’ve found our required CPF solution, thus the proof
is complete.</p>
</div>
<p>Thanks to this theorem<a href="#fn27" class="footnote-ref"
id="fnref27" role="doc-noteref"><sup>27</sup></a> we know that we only
need to check CPF solutions when solving an LP! We make use of this fact
during the simplex method, which only checks CPF solutions. We won’t
check <em>every</em><a href="#fn28" class="footnote-ref" id="fnref28"
role="doc-noteref"><sup>28</sup></a> CPF solution, though. The key to
simplex is that we jump from one CPF solution to the next while taking
care that each move improves the objective value.</p>
<p>In fact, the set of solutions we can move to in any iteration is
limited to only the solutions that are adjacent to the current solution.
In a standard-form LP with <span class="math inline">n</span> decision
variables, two CPF solutions are <strong>adjacent</strong> if they share
<span class="math inline">n-1</span> constraint boundaries. Recall that
CPF solutions lie at the intersection of <span
class="math inline">n</span> constraint boundaries, so we can also say
that two adjacent CPF solutions share all but one boundary in
common.</p>
<p>We have all the definitions now to describe simplex in a nutshell:
The simplex method solves a linear programming problem by successively
moving from one CPF solution to another, adjacent CPF solution, making
sure each such move improves the objective function, until no such
improvement exists<a href="#fn29" class="footnote-ref" id="fnref29"
role="doc-noteref"><sup>29</sup></a>.</p>
<h3 data-number="4.6.2" id="sec:simplexVisualized"><span
class="header-section-number">4.6.2</span> Simplex visualized</h3>
<p>Now that we have the basic idea, let’s go ahead and walk through the
steps of the simplex algorithm. We won’t go fully general on our first
time through, though. Let’s again consider our sample problem of eq. <a
href="#eq:prototypeLp">1</a>, which we’ve plotted again below. This
time, though, the plot contains some controls that let us step through
the simplex method one iteration at a time. I should stress that the
simplex method does not work <em>exactly</em> like what we’ll talk
through below, but all the intuitions are the same and the exercise is,
I think, a useful one.</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;simplexStart&quot;: [0, 0]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>The first step is to find an initial CPF solution. In our case (and
lots of practical instances too) the solution <span
class="math inline">(0, 0)</span> is a feasible solution, and a corner
point as well. It’s not a particularly desirable solution in the context
of our problem since it brings us no profit, but we don’t care about
desirability yet.</p>
<p>After initialization, we begin the algorithm’s main loop. First we
have to determine if there are any adjacent CPF solutions with improving
objective value. Recall that an adjacent solution will share <span
class="math inline">n-1</span> constraint boundaries with the current
solution. Since we’re in two dimensions, the adjacent solutions share
one constraint boundary with the current solution. To find the adjacent
solutions, we travel out from <span class="math inline">(0,0)</span>
along the two boundary lines it sits on, which in this case are the two
axes. Thus the two directions we can move in are <span
class="math inline">(1,0)</span> and <span
class="math inline">(0,1)</span>.</p>
<p>How do we know if a solution in any particular direction is improving
the objective value? Let’s consider the direction <span
class="math inline">(1,0)</span>. Since we’re moving from <span
class="math inline">(0,0)</span> to some point in the direction of <span
class="math inline">(1,0)</span>, the resulting solution will look like
<span class="math inline">(0,0) + \alpha(1,0)</span> for some number
<span class="math inline">\alpha</span>. The objective value of any
point <span class="math inline">\mathbf{x}</span> is <span
class="math inline">\mathbf{c}\mathbf{x}</span> where <span
class="math inline">\mathbf{c}</span> is the vector of objective
coefficients (which is <span class="math inline">(3,5)</span> in our
sample problem). So the objective value of <span
class="math inline">(0,0) + \alpha(1,0)</span> is</p>
<p><span class="math display">
([0\ 0] + \alpha[1\ 0])\begin{bmatrix}3\\5\end{bmatrix}
</span></p>
<p>and since matrix multiplication distributes through addition, this is
the same as</p>
<p><span class="math display">
[0\ 0]\begin{bmatrix}3\\5\end{bmatrix} + \alpha[1\
0]\begin{bmatrix}3\\5\end{bmatrix}.
</span></p>
<p>That first term, <span class="math inline">[0\
0]\begin{bmatrix}3\\5\end{bmatrix}</span>, is just the objective value
associated with the current solution <span
class="math inline">(0,0)</span>. So the second term <span
class="math inline">\alpha[1\ 0]\begin{bmatrix}3\\5\end{bmatrix}</span>,
is the <em>improvement</em> associated with the move.</p>
<p>We have two directions in which we can move, <span
class="math inline">(1,0)</span> and <span
class="math inline">(0,1)</span>. To keep things standardized we’ll want
to re-scale our directions to be unit vectors (i.e. vectors with length
one), but in this case they’re already unit vectors. The improvements
associated with unit moves in these directions are <span
class="math inline">[1\ 0]\begin{bmatrix}3\\5\end{bmatrix}=3</span> and
<span class="math inline">[0\
1]\begin{bmatrix}3\\5\end{bmatrix}=5</span>. These are both positive
numbers, and since we’re trying to maximize the objective value, that
means that solutions in either direction are improvements.</p>
<p>All that information is summarized in the table below the plot. The
two directions are listed, as well as the per-unit change in objective
function (under the heading <span class="math inline">\Delta</span> Obj
/ Unit<a href="#fn30" class="footnote-ref" id="fnref30"
role="doc-noteref"><sup>30</sup></a>). Since both directions improve the
objective, you have the option to choose either one using the checkboxes
in the final column.</p>
<p>Let’s go ahead and choose the <span class="math inline">(0,1)</span>
direction, since it gives the highest per-unit objective change<a
href="#fn31" class="footnote-ref" id="fnref31"
role="doc-noteref"><sup>31</sup></a>. Press the forward button on the
plot, and you’ll see it finds the adjacent solution in that direction,
<span class="math inline">(0,6)</span>, and the directions to its
adjacent solutions. But only one of the directions is improving, so we
choose to move in that direction <span class="math inline">(1,0)</span>
to the adjacent CPF solution <span class="math inline">(2,6)</span>. At
this point none of the adjacent directions are improvements, so the
current point is optimal and the algorithm is finished.</p>
<p>One thing to note before we move on: All the information we gather
during an iteration is in some sense “local” to the current CPF
solution. We compute only the <em>directions</em> to the neighboring
solutions, not the actual solutions themselves. Only once we decide on a
direction do we find the actual CPF solution. This is because finding
the solutions is much more expensive computationally speaking, and we’d
like to defer that step and only compute solutions when necessary. This
isn’t such a big deal on a small, two-dimensional example like this, but
in larger scale instances this saves a good amount of time.</p>
<h3 data-number="4.6.3" id="augmented-form-and-basic-solutions"><span
class="header-section-number">4.6.3</span> Augmented form and basic
solutions</h3>
<p>We’ll return again to our sample problem from eq. <a
href="#eq:prototypeLp">1</a>. The first thing we’ll need to do is change
the form of the problem. While we modeled the sample problem in standard
form eq. <a href="#eq:standardFormLpMatrix">3</a>, the simplex method
requires constraints in equality form (along with the non-negative
variables and maximizing the objective). We call this the
<strong>augmented form</strong> linear program, which we write as</p>
<p><span id="eq:augmentedFormLpMatrix" class="eqnos"><span
class="math display">
\begin{align*}
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}\\
\text{s.t.}&amp;&amp; \mathbf{A}\mathbf{x}&amp;=\mathbf{b}\\
     &amp;&amp; \mathbf{x}&amp;\geq\mathbf{0}
\end{align*}
</span><span class="eqnos-number">(4)</span></span></p>
<p>To transform our sample problem into augmented form, we’ll steal a
trick from section <a href="#sec:lpConstraintTransform">4.5.3</a>. We’ll
turn the inequality constraints into equations by adding a slack
variable to each constraint, yielding the following formulation:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 + x_3 &amp; = \ \ 4  \\
     &amp;&amp; 2x_2 + x_4 &amp; = 12 \\
     &amp;&amp; 3x_1 + 2x_2 + x_5 &amp; = 18 \\
     &amp;&amp; x_1,x_2,x_3,x_4,x_5 &amp; \geq \ \ 0
\end{align*}
</span></p>
<p>We call <span class="math inline">x_3</span> the <em>slack
variable</em> for the first constraint because its value in a feasible
solution tells you how far away the solution’s values for <span
class="math inline">x_1</span> and <span class="math inline">x_2</span>
were from the constraint boundary in eq. <a
href="#eq:prototypeLp">1</a>.</p>
<p>Simplex involves lots of matrix manipulations, so let’s rewrite this
in matrix form. Following usual convention, we’ll also add an extra
variable <span class="math inline">Z</span> which is equal to the
problem’s objective value. So in this case, we have</p>
<p><span class="math display">
Z = 3x_1 + 5x_2.
</span></p>
<p>Additionally, we’ll go rogue a bit and neglect writing the
non-negativity constraints. They’re still there, but the simplex
algorithm will take care of them implicitly. So in matrix form, our
problem looks like:</p>
<p><span class="math display">
\begin{bmatrix}
1 &amp; -3 &amp; -5 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1  &amp;  0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0  &amp;  2 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 3  &amp;  2 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 4 \\ 12 \\ 18
\end{bmatrix}
</span></p>
<p>Recall in section <a href="#sec:simplexVisualized">4.6.2</a> we made
use of <span class="thmRef" for="thm:cornerPointOpt"></span> to solve
the LP, jumping from CPF solution to CPF solution while increasing the
objective value at every step. We’ll do similar algebraically now, but
instead of a CPF solution (which made sense in the standard-form world
of eq. <a href="#eq:standardFormLpMatrix">3</a>) we’ll make use of
<strong>basic feasible (BF) solutions</strong>, the augmented-form
analogue. Indeed, the only real difference between corner-point and
basic solutions is whether or not the slack variables are included.</p>
<p>That said, basic solutions have their own important properties.
Studying the system of equations in the above matrix, we see that we
have 5 variables but only 3 (linearly independent) constraints. As you
may recall from linear algebra class, this means we have 2 <em>degrees
of freedom</em>, and thus two of the variables may be set arbitrarily
while solving the system. In the simplex method, these two variables
will take the value 0. The variables set to 0 are called the
<strong>non-basic variables</strong>. We can then solve the system of
equations to retrieve values for the other 3 variables, which are called
the <strong>basic variables</strong>, and collectively the
<strong>basis</strong>. Together, the values of the basic and non-basic
variables make up a <strong>basic solution</strong>.</p>
<p>The key properties of basic solutions are the following (quoting from
<span class="citation" data-cites="classText">Hillier and Lieberman (<a
href="#ref-classText" role="doc-biblioref">2021</a>)</span>):</p>
<blockquote>
<ul>
<li>Each variable is designated as either a nonbasic variable or a basic
variable.</li>
<li>The number of basic variables equals the number of functional
constraints (now equations). Therefore, the number of nonbasic variables
equals the total number of variables minus the number of functional
constraints.</li>
<li>The nonbasic variables are set equal to zero.</li>
<li>The values of the basic variables are obtained as the simultaneous
solution of the system of equations (functional constraints in augmented
form).</li>
<li>If the basic variables satisfy the non-negativity constraints, the
basic solution is a BF solution.</li>
</ul>
</blockquote>
<p>Two BF solutions are said to be <strong>adjacent</strong> if <em>all
but one</em> of their non-basic variables are the same. Note that this
means also that all but one of their basic variables are the same. Also
note that we don’t mean that these basic variables take on the same
<em>values</em>, just that the identity of the variables are the same.
So e.g. one basic solution with basic variables <span
class="math inline">x_1, x_2</span> and <span
class="math inline">x_3</span> is adjacent to another solution with
basic variables <span class="math inline">x_1, x_2, x_4</span>, no
matter the values taken by those variables in the respective
solutions.</p>
<h3 data-number="4.6.4" id="sec:simplexExample"><span
class="header-section-number">4.6.4</span> Solving the sample LP with
simplex</h3>
<p>To recap with our new terminology, the goal of the simplex method is
to take an LP in augmented form, and iteratively move from one BF
solution to another, adjacent BF solution while improving the objective
value at every step. We’ve already converted our sample problem to
augmented form, summarized by the following matrix:</p>
<p><span id="eq:simplexExampleMatrix1" class="eqnos"><span
class="math display">
\begin{bmatrix}
1 &amp; -3 &amp; -5 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1  &amp;  0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0  &amp;  2 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 3  &amp;  2 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 4 \\ 12 \\ 18
\end{bmatrix}
</span><span class="eqnos-number">(5)</span></span></p>
<h4>
Find an initial BF Solution
</h4>
<p>We’d like to start iterating between adjacent BF solutions, but to do
that we need a BF solution to start with. We’ll go into more details on
how to find initial BF solutions later in section <a
href="#sec:lpOtherConsiderations">4.6.7</a>, but for now let’s notice
that using the slack variables as the initial basis will make this
system very easy to solve. Why? Since <span
class="math inline">x_1</span> and <span class="math inline">x_2</span>
are non-basic, we set their values to 0. Thus the system eq. <a
href="#eq:simplexExampleMatrix1">5</a> reduces to:</p>
<p><span class="math display">
\begin{bmatrix}
1 &amp; -3 &amp; -5 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1  &amp;  0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0  &amp;  2 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 3  &amp;  2 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ 0 \\ 0 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 4 \\ 12 \\ 18
\end{bmatrix}
</span></p>
<p>or, equivalently:</p>
<p><span class="math display">
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 4 \\ 12 \\ 18
\end{bmatrix}
</span></p>
<p>So the initial BF solution is <span class="math inline">(x_1, x_2,
x_3, x_4, x_5)</span> = <span class="math inline">(0, 0, 4, 12,
18)</span>, yielding objective value <span
class="math inline">Z=0</span>.</p>
<p>This BF solution was easy to solve for because of how the system was
set up. The portion of the matrix corresponding to the basic variables
was essentially an identity matrix, so we just needed to read the values
off the right-hand side. Indeed, as we move from one BF solution to
another, we will explicitly manipulate the matrix (using basic row
operations, as in section <a
href="#sec:elementaryRowOperations">7.2.6</a>) to yield an identity
structure in the basic columns.</p>
<p>But we’re not there yet. We just have an initial BF solution, and
need to figure out how to move to an adjacent one while improving the
objective value. Recall that adjacent solutions share all their basic
variables in common except 1, so the decisions to make are</p>
<ol type="1">
<li>Does an improving solution exist?</li>
<li>If so, which of the current non-basic variables should we move into
the basis?</li>
<li>In light of the last decision, which of the current basic variables
should we remove from the basis?</li>
</ol>
<h4>
Optimality test
</h4>
<p>To decide whether an improving adjacent solution exists, we’ll take a
look at the top row of our matrix eq. <a
href="#eq:simplexExampleMatrix1">5</a>, which we set up to track the
objective value <span class="math inline">Z</span>. When multiplied by
the variable vector, that top row currently reads as <span
class="math inline">Z - 3x_1 - 5x_2 = 0</span>, simply a rearranging of
the usual objective <span class="math inline">Z = 3x_1 + 5x_2</span>.
Thus a negative value in the top row indicates that including that
variable in the basis will improve the objective value. Since we have
negative values in the top row, we conclude that the current solution is
not optimal.</p>
<h4>
Determine the incoming variable
</h4>
<p>Since both <span class="math inline">x_1</span> and <span
class="math inline">x_2</span> have negative values in the objective
row, we now have two choices of incoming basic variables that will
improve the objective value. As we did in section <a
href="#sec:simplexVisualized">4.6.2</a>, we will choose the variable
that gives the highest such improvement per unit change in the variable,
which in this case is <span class="math inline">x_2</span> (which has a
coefficient of -5 in the top row, vs. -3 for <span
class="math inline">x_1</span>).</p>
<h4>
Determine the outgoing variable
</h4>
<p>We’ve decided that we want <span class="math inline">x_2</span> to
enter the basis, i.e. we’d like its value to increase from 0 in the
current solution to some positive value in the next solution. What
effect does increasing <span class="math inline">x_2</span> have on the
constraints? All of the equations are currently satisfied, so changing
the value of <span class="math inline">x_2</span> means that we must
change the values of other variables to compensate. Luckily, the way the
matrix is set up, each constraint has only one basic variable with a
non-zero coefficient. For example, the third row of eq. <a
href="#eq:simplexExampleMatrix1">5</a>, when multiplied out, reads:</p>
<p><span class="math display">
2x_2 + x_4 = 12.
</span></p>
<p>Importantly, <span class="math inline">x_4</span> is the only
non-basic variable in this constraint, and this is the <em>only</em>
constraint that <span class="math inline">x_4</span> shows up in (due to
the identity matrix structure in the basic variables). So each unit
increase in <span class="math inline">x_2</span> will require a 2-unit
<em>decrease</em> in <span class="math inline">x_4</span> to balance the
constraint. Since each variable (and so in particular, <span
class="math inline">x_4</span>) must stay non-negative, we can only
increase <span class="math inline">x_2</span> from 0 to 6 and still
remain feasible.</p>
<p>So we carry out this procedure with each constraint in eq. <a
href="#eq:simplexExampleMatrix1">5</a> (rows 2-4). <span
class="math inline">x_2</span> has a coefficient of 0 in the second row,
so this constraint will not be violated no matter how much we change
<span class="math inline">x_2</span>. Row four gives the equation <span
class="math inline">x_1 + 2x_2 + x_5 = 18</span>, so again a unit
increase in <span class="math inline">x_2</span> requires a 2-unit
decrease in <span class="math inline">x_5</span>. Since the right-hand
side is 18, we can only increase <span class="math inline">x_2</span> to
9 before <span class="math inline">x_5</span> will go negative.</p>
<p>Let’s summarize what we’ve done now: for each constraint, we’ve
compared the contribution of <span class="math inline">x_2</span> to the
contribution of the corresponding basic variable. We saw above that when
the coefficient on <span class="math inline">x_2</span> is zero for a
given constraint, then changing the value of <span
class="math inline">x_2</span> will not affect that constraint at all.
We didn’t have an example of this, but if the coefficient on <span
class="math inline">x_2</span> were negative then increasing <span
class="math inline">x_2</span> is counteracted by an <em>increase</em>
in the current basic variable. Variables must be non-negative, but there
is no <em>upper</em> bound, so we are free to increase a variable as
much as we want. Thus the only constraints that restrict <span
class="math inline">x_2</span> are the ones where the coefficient on
<span class="math inline">x_2</span> is strictly positive.</p>
<p>So the rows where the <span class="math inline">x_2</span>
coefficient is positive are where we need to worry about the current
basic variable going negative, and where we need to calculate how much
<span class="math inline">x_2</span> can increase before that happens.
You may or may not have noticed, but because of the identity matrix
structure in the basis, all we need to do for this calculation is divide
the right-hand side (rhs) value by the coefficient on <span
class="math inline">x_2</span> in each constraint! Thus our concern is
the following ratios:</p>
<p><span class="math display">
x_2\text{ column: }\begin{bmatrix}0 \\ 2 \\ 2\end{bmatrix}\
\text{ rhs: }\begin{bmatrix}4 \\ 12 \\ 18\end{bmatrix}\
\text{ ratio: }\begin{bmatrix}- \\ 12/2 \\ 18/2\end{bmatrix} =
\begin{bmatrix}- \\ 6 \\ 9\end{bmatrix}
</span></p>
<p>Then the variable leaving the basis should be the one in the
constraint that gives the smallest such ratio (we call this process the
<strong>minimum ratio test</strong>). Why? As we discussed above, the
ratio in each column is the bound on how much we can increase the
entering variable before the basic variable decreases to 0. So we must
take the minimum such increase in order to keep the entire system
feasible. In our case, the minimum ratio comes in the second constraint.
The basic variable included in that constraint is <span
class="math inline">x_4</span>, so we must choose <span
class="math inline">x_4</span> to leave the basis<a href="#fn32"
class="footnote-ref" id="fnref32"
role="doc-noteref"><sup>32</sup></a>.</p>
<h4>
Solve the new system
</h4>
<p>Now that we’ve identified the variables entering and exiting the
basis, what remains is to find the values of the variables at the new
solution. Since <span class="math inline">x_1</span> and <span
class="math inline">x_4</span> are non-basic, their values will be 0. To
find the other values, we’ll essentially do <a
href="https://en.wikipedia.org/wiki/Gaussian_elimination">Gaussian
elimination</a> on the matrix system eq. <a
href="#eq:simplexExampleMatrix1">5</a> to yield an identity matrix
structure over the columns corresponding to our basis.</p>
<p>Our basis variable swap came from the model’s second constraint,
which corresponds to row 3 in the matrix. This will be the “identity”
row for the entering variable <span class="math inline">x_2</span>, so
we’ll multiply that row by <span class="math inline">1/2</span> to get a
new matrix:</p>
<p><span class="math display">
\begin{bmatrix}
1 &amp; -3 &amp; -5 &amp; 0 &amp; 0   &amp; 0 \\
0 &amp; 1  &amp;  0 &amp; 1 &amp; 0   &amp; 0 \\
0 &amp; 0  &amp;  1 &amp; 0 &amp; 1/2 &amp; 0 \\
0 &amp; 3  &amp;  2 &amp; 0 &amp; 0   &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 4 \\ 6 \\ 18
\end{bmatrix}
</span></p>
<p>To complete the identity matrix structure, we must change all other
coefficients in the <span class="math inline">x_2</span> column to equal
zero. So we’ll do the following:</p>
<ul>
<li>Multiply the third row by 5 and add it to the first row.</li>
<li>Multiply the third row by -2 and add it to the fourth row.</li>
</ul>
<p>Our new matrix will have the identity structure we’re after:</p>
<p><span id="eq:simplexExampleMatrix2" class="eqnos"><span
class="math display">
\begin{bmatrix}
1 &amp; -3 &amp; 0 &amp; 0 &amp; 5/2 &amp; 0 \\
0 &amp; 1  &amp; 0 &amp; 1 &amp; 0   &amp; 0 \\
0 &amp; 0  &amp; 1 &amp; 0 &amp; 1/2 &amp; 0 \\
0 &amp; 3  &amp; 0 &amp; 0 &amp; -1  &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
30 \\ 4 \\ 6 \\ 6
\end{bmatrix}
</span><span class="eqnos-number">(6)</span></span></p>
<p>Lastly, as before, we can simply read the values of the objective and
the basic variables from the rhs of the system: <span
class="math inline">Z=30, x_3=4, x_2=6, x_5=6</span>.</p>
<h4>
Keep iterating
</h4>
<p>We’ve now completed initialization and the first iteration of the
method. So we continue iterating, starting from the optimality testing
phase. In this case, the non-basic variable <span
class="math inline">x_1</span> has a negative coefficient in the top row
of eq. <a href="#eq:simplexExampleMatrix2">6</a>, so we do not have on
optimal solution.</p>
<p>The other non-basic variable, <span class="math inline">x_4</span>,
has a positive coefficient in the top row. So <span
class="math inline">x_1</span> is our only candidate for entering the
basis. Now let’s set up our ratio test:</p>
<p><span class="math display">
x_1\text{ column: }\begin{bmatrix}1 \\ 0 \\ 3\end{bmatrix}\
\text{ rhs: }\begin{bmatrix}4 \\ 6 \\ 6\end{bmatrix}\
\text{ ratio: }\begin{bmatrix}4/1 \\ - \\ 6/3\end{bmatrix} =
\begin{bmatrix}4 \\ - \\ 2\end{bmatrix}
</span></p>
<p>Then at most we can increase <span class="math inline">x_1</span> to
2, as going any further will make <span class="math inline">x_5</span>
(the basic variable in the last constraint) negative. So we’ll replace
<span class="math inline">x_5</span> with <span
class="math inline">x_1</span> as the basic variable in the last
constraint. Using elimination to build our identity structure yields the
following matrix:</p>
<p><span id="eq:simplexExampleFinalMatrix" class="eqnos"><span
class="math display">
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp;  3/2 &amp;    1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp;  1/3 &amp; -1/3 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp;  1/2 &amp;    0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; -1/3 &amp;  1/3 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
36 \\ 2 \\ 6 \\ 2
\end{bmatrix}
</span><span class="eqnos-number">(7)</span></span></p>
<p>Thus our new solution is <span class="math inline">x_1=2, x_2=6,
x_3=2, x_4=0</span>, and <span class="math inline">x_5=0</span><a
href="#fn33" class="footnote-ref" id="fnref33"
role="doc-noteref"><sup>33</sup></a>. Since the top row has all positive
coefficients, increasing these variables would only serve to decrease
the objective. So we’ve passed the optimality test, and can terminate
with the optimal solution!</p>
<h3 data-number="4.6.5" id="simplex-in-matrix-notation"><span
class="header-section-number">4.6.5</span> Simplex in matrix
notation</h3>
<div class="lectureVideoEmbed"
data-video-id="aa0f8c8329cd4138a5313757a8f8f1a51d"
data-video-date="2023-09-08">
Simplex with matrices
</div>
<p>Now that we have the mechanics down, let’s tidy up our presentation
of the simplex method by writing out the steps in matrix notation.
Recall that for simplex we need equality constraints and non-negative
variables, so our problem is formulated as in eq. <a
href="#eq:augmentedFormLpMatrix">4</a>. Additionally, we will assume
that the <span class="math inline">m\times n</span> matrix <span
class="math inline">A</span> is has rank <span
class="math inline">m</span> and is <em>non-singular</em>, so in
particular <span class="math inline">n\geq m</span> and there are no
<em>redundant</em> constraints (which would be any constraint that is a
linear combination of some of the others). The rank assumption can be
done without loss of generality, because any redundant system can be
reduced to non-redundant by removing constraints<a href="#fn34"
class="footnote-ref" id="fnref34"
role="doc-noteref"><sup>34</sup></a>.</p>
<p>At each step of the simplex method, the matrix calculations required
rely on the sub-matrix of <span class="math inline">\mathbf{A}</span>
corresponding to the basic variables. Let’s recall eq. <a
href="#eq:simplexExampleMatrix1">5</a>, the initial set of equations
defining our sample LP when we solved it in section <a
href="#sec:simplexExample">4.6.4</a>. In this case, our matrix <span
class="math inline">\mathbf{A}</span> is given by</p>
<p><span class="math display">
\mathbf{A}= \begin{bmatrix}
1  &amp;  0 &amp; 1 &amp; 0 &amp; 0 \\
0  &amp;  2 &amp; 0 &amp; 1 &amp; 0 \\
3  &amp;  2 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
</span></p>
<p>The sub-matrix we’re after at any given iteration, which we’ll call
<span class="math inline">\mathbf{B}</span> is the subset of columns
corresponding to our basic variables. Our initial basis in section <a
href="#sec:simplexExample">4.6.4</a> was <span
class="math inline">\{x_3, x_4, x_5\}</span>, and so the matrix of
interest in the first iteration was</p>
<p><span class="math display">
\mathbf{B}= \begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \\
\end{bmatrix}
</span>.</p>
<p>The vector of variables <span class="math inline">\mathbf{x}</span>
can similarly be segmented into the parts corresponding to basic
variables, which we’ll call <span
class="math inline">\mathbf{x}_B</span>, and non-basic variables <span
class="math inline">\mathbf{x}_N</span>. So for our example problem at
the first iteration we had:</p>
<p><span class="math display">
\mathbf{x}=\begin{bmatrix}x_1\\x_2\\x_3\\x_4\\x_5\end{bmatrix}\quad\mathbf{x}_B=\begin{bmatrix}x_3\\x_4\\x_5\end{bmatrix}\quad\mathbf{x}_N=\begin{bmatrix}x_1\\x_2\end{bmatrix}
</span></p>
<p>To solve the system of equations at any iteration, we applied
elementary row operations to create an identity matrix in the columns
corresponding to our basis. But since <span
class="math inline">\mathbf{B}</span> is non-singular, it has an inverse
<span class="math inline">\mathbf{B}^{-1}</span> such that <span
class="math inline">\mathbf{B}^{-1}\mathbf{B}=\mathbf{I}</span>, where
<span class="math inline">\mathbf{I}</span> is an identity matrix. So
really, all of our row operations amounted to pre-multiplying the system
of equations by <span class="math inline">\mathbf{B}^{-1}</span>.</p>
<p>Given this, watch what happens when we pre-multiply both sides of our
constraints by <span class="math inline">\mathbf{B}^{-1}</span>:</p>
<div class="mathSmall">
<p><span id="eq:basicVariableValues" class="eqnos"><span
class="math display">
\begin{align*}
\mathbf{A}\mathbf{x}= \mathbf{b}
&amp; \Leftrightarrow \mathbf{B}^{-1}\mathbf{A}\mathbf{x}=
\mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\text{pre-mult by
}\mathbf{B}^{-1}) \\
&amp; \Leftrightarrow
\mathbf{B}^{-1}\mathbf{A}\begin{bmatrix}\mathbf{x}_B\\\mathbf{x}_N\end{bmatrix}
= \mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\text{partition }x\text{
into basic/non-basic}) \\
&amp; \Leftrightarrow
\mathbf{B}^{-1}\mathbf{A}\begin{bmatrix}\mathbf{x}_B\\\mathbf{0}\end{bmatrix}
= \mathbf{B}^{-1}\mathbf{b}&amp;&amp;
\quad(\mathbf{x}_N=\mathbf{0}\text{ in basic solutions}) \\
&amp; \Leftrightarrow \mathbf{B}^{-1}\mathbf{B}\mathbf{x}_B =
\mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\mathbf{x}_N=\mathbf{0}\text{
takes out other columns of }\mathbf{A}) \\
&amp; \Leftrightarrow \mathbf{I}\mathbf{x}_B =
\mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\text{definition of inverse})
\\
&amp; \Leftrightarrow \mathbf{x}_B = \mathbf{B}^{-1}\mathbf{b}&amp;&amp;
\quad(\text{definition of identity})
\end{align*}
</span><span class="eqnos-number">(8)</span></span></p>
</div>
<p>So getting the variable values at a basic solution is as simple as
taking <span class="math inline">\mathbf{x}_N=\mathbf{0}</span> and
<span class="math inline">\mathbf{x}_B=\mathbf{B}^{-1}\mathbf{b}</span>.
If we similarly partition the objective vector <span
class="math inline">\mathbf{c}</span> into <span
class="math inline">\mathbf{c}_B</span> (corresponding to the basic
variables) and <span class="math inline">\mathbf{c}_N</span> (non-basic
variables) then the objective value at that solution is:</p>
<p><span class="math display">
\begin{align*}
\mathbf{c}\mathbf{x}&amp; = \mathbf{c}_B\mathbf{x}_B +
\mathbf{c}_N\mathbf{x}_N &amp;&amp; \\
&amp; = \mathbf{c}_B\mathbf{x}_B &amp;&amp;
\quad(\mathbf{x}_N=\mathbf{0}) \\
&amp; = \mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\text{sub
above value for }\mathbf{x}_B) \\
\end{align*}
</span></p>
<p>So we know how to find the solution for any given basis, but what
about determining entering and exiting variables? In section <a
href="#sec:simplexExample">4.6.4</a> we used the information from the
objective (top) row of our problem matrix, so let’s re-introduce that
here. We can summarize all of our problem information in the following
matrix formulation:</p>
<p><span id="eq:simplexMatrixAllInfo" class="eqnos"><span
class="math display">
\begin{bmatrix}
1 &amp; -\mathbf{c}\\
\mathbf{0}&amp; \mathbf{A}
\end{bmatrix}
\begin{bmatrix}
Z \\ \mathbf{x}
\end{bmatrix}
=
\begin{bmatrix}
0 \\ \mathbf{b}
\end{bmatrix}
</span><span class="eqnos-number">(9)</span></span></p>
<p>where once again <span class="math inline">Z</span> is a “variable”
representing the objective value. Note that this matches exactly with
eq. <a href="#eq:simplexExampleMatrix1">5</a> from section <a
href="#sec:simplexExample">4.6.4</a>.</p>
<h4>
The magic matrix
</h4>
<p>We know from linear algebra that any sequence of elementary matrix
operations can be performed simultaneously via matrix multiplication.
All we did during the iterations section <a
href="#sec:simplexExample">4.6.4</a> was apply elementary row operations
to the original matrix, so if we can find the correct matrix, recovering
all the relevant information is as simple as multiplying by that matrix.
With that in mind, let me present to you the following matrix<a
href="#fn35" class="footnote-ref" id="fnref35"
role="doc-noteref"><sup>35</sup></a>.</p>
<p><span id="eq:magicMatrix" class="eqnos"><span class="math display">
\begin{bmatrix}1 &amp; \mathbf{c}_B\mathbf{B}^{-1}\\ \mathbf{0}&amp;
\mathbf{B}^{-1}\end{bmatrix}
</span><span class="eqnos-number">(10)</span></span></p>
<p>Watch what happens when we pre-multiply this on the right-hand side
of eq. <a href="#eq:simplexMatrixAllInfo">9</a>:</p>
<p><span class="math display">
\begin{bmatrix}1 &amp; \mathbf{c}_B\mathbf{B}^{-1}\\ \mathbf{0}&amp;
\mathbf{B}^{-1}\end{bmatrix}
\begin{bmatrix}
0 \\ \mathbf{b}
\end{bmatrix}
=
\begin{bmatrix}
\mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}\\ \mathbf{B}^{-1}\mathbf{b}
\end{bmatrix}
</span></p>
<p>The top of the result is the objective value <span
class="math inline">Z</span> at the current basis solution, and the
bottom give the values of <span class="math inline">\mathbf{x}_B</span>.
So it looks like eq. <a href="#eq:magicMatrix">10</a> is precisely the
matrix we need to encapsulate all the operations we did during a simplex
iteration. Of course, any multiplication we apply on one side of an
equation must also be applied to the other side to keep the system
valid. So let’s apply pre-multiply eq. <a href="#eq:magicMatrix">10</a>
on the left-hand side of eq. <a href="#eq:simplexMatrixAllInfo">9</a> as
well:</p>
<p><span class="math display">
\begin{bmatrix}1 &amp; \mathbf{c}_B\mathbf{B}^{-1}\\ \mathbf{0}&amp;
\mathbf{B}^{-1}\end{bmatrix}
\begin{bmatrix}
1 &amp; -\mathbf{c}\\
\mathbf{0}&amp; \mathbf{A}
\end{bmatrix}
= \begin{bmatrix}1 &amp; \mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}\\ \mathbf{0}&amp; \mathbf{B}^{-1}\mathbf{A}\end{bmatrix}
</span></p>
<p>So for any given basis, the information we require for the simplex
method is all present in the following system:</p>
<p><span id="eq:simplexMatrixGeneralized" class="eqnos"><span
class="math display">
\begin{bmatrix}1 &amp; \mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}\\ \mathbf{0}&amp; \mathbf{B}^{-1}\mathbf{A}\end{bmatrix}
\begin{bmatrix}Z \\ \mathbf{x}\end{bmatrix}
=
\begin{bmatrix}
\mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}\\ \mathbf{B}^{-1}\mathbf{b}
\end{bmatrix}
</span><span class="eqnos-number">(11)</span></span></p>
<p>The top row coefficients <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}</span> are often called the <strong>reduced costs</strong> of
the variables at the current solution.</p>
<p>Maybe this looks a little messy when seeing it the first time, but
don’t let that scare you! Look at all the constituent elements of this
system. <span class="math inline">\mathbf{A}, \mathbf{b}</span>, and
<span class="math inline">\mathbf{c}</span> are all just
vectors/matrices from the problem definition. The only thing you need to
do from iteration to iteration is choose the basis, invert <span
class="math inline">\mathbf{B}</span> (which is just a sub-matrix of
<span class="math inline">\mathbf{A}</span>), then multiply!</p>
<p>To finish off this section, let’s use Python to verify that the
system we recover from eq. <a href="#eq:simplexMatrixGeneralized">11</a>
matches with what we got during the iterations in section <a
href="#sec:simplexExample">4.6.4</a>.</p>
<script src="https://gist.github.com/e5817bc5b1eb52dce2737969e0ee0c83.js"></script>
<h3 data-number="4.6.6"
id="presenting-finally-the-simplex-algorithm-mostly"><span
class="header-section-number">4.6.6</span> Presenting (finally) the
simplex algorithm (mostly)</h3>
<p>While we still have some edge cases and gotchas to discuss, we have
what we need to now succinctly specify the core of the simplex
algorithm. Remember, we assume any LP being solved by the simplex method
has been converted (by means of the techniques in section <a
href="#sec:lpForms">4.5</a>) to the equality-constrained form of eq. <a
href="#eq:augmentedFormLpMatrix">4</a>.</p>
<ul>
<li><em>Initialize</em>: Determine an initial BF solution (we’ll discuss
general methods for this in section <a
href="#sec:lpOtherConsiderations">4.6.7</a>).</li>
<li><em>Iterate</em>:
<ul>
<li><em>Test for optimality</em>: Examine the values of <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}</span> (i.e. the reduced costs, from the top row of eq. <a
href="#eq:simplexMatrixGeneralized">11</a>) corresponding to the
non-basic variables. If all coefficients are non-negative, terminate
with the optimal solution. Otherwise, continue with the iteration.</li>
<li><em>Determine the entering basic variable</em>: Select some variable
whose coefficient in <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}</span> is negative.</li>
<li><em>Determine the exiting basic variable</em>: Suppose the entering
variable from the last step corresponds to the <span
class="math inline">j</span>th column of the original constraint matrix
<span class="math inline">A</span>. Perform the <em>minimum ratio
test</em> from section <a href="#sec:simplexExample">4.6.4</a>, dividing
the entries of the vector <span
class="math inline">\mathbf{B}^{-1}\mathbf{b}</span> (the right-hand
side of the constraints portion of eq. <a
href="#eq:simplexMatrixGeneralized">11</a>) by the entries in the <span
class="math inline">j</span>th column of <span
class="math inline">\mathbf{B}^{-1}\mathbf{A}</span>. For the exiting
variable, select the basic variable corresponding to the row with the
smallest positive ratio.</li>
</ul></li>
</ul>
<p>And that’s it!</p>
<h3 data-number="4.6.7" id="sec:lpOtherConsiderations"><span
class="header-section-number">4.6.7</span> Other considerations</h3>
<div class="lectureVideoEmbed"
data-video-id="aa5bd6de00194e58bdfae5570433587c1d"
data-video-date="2023-09-11">
Finishing simplex, starting duality
</div>
<p>Let’s now discuss some implementation details that add slight
complications to the simplex algorithm, and would need to be taken care
of in any LP solving software.</p>
<h4>
Determining the initial BF solution
</h4>
<p>In our sample problem, determining an initial BF solution was simple
because of the slack variables we added to convert the problem to
equality form. But this won’t always be possible. By way of example,
suppose in our sample LP eq. <a href="#eq:prototypeLp">1</a> the problem
requires plant 3 to operate at full capacity. Then the third constraint
becomes an equality constraint, <span class="math inline">3x_1 + 2x_2 =
18</span>. Once slack variables are added to the other constraints, we
have the following formulation:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 + x_3 &amp; = \ \ 4 \\
&amp;&amp; 2x_2 + x_4 &amp; = 12 \\
&amp;&amp; 3x_1 + 2x_2 &amp; = 18 \\
&amp;&amp; x_1,x_2,x_3,x_4 &amp; \geq \ \ 0
\end{align*}
</span></p>
<p>There is no longer a nice identity matrix structure on which to base
our initial BF solution. In this case, a good trick is to add an extra,
so-called <strong>artificial variable</strong> to the formulation.
Additionally, we will add this variable to the objective function with a
<em>huge</em> negative coefficient denoted by <span
class="math inline">M</span>, a trick known as the <strong>Big M
method</strong>. For the above problem, the artificial variable
formulation will look like:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 - M\hat x_5&amp; \\
\text{s.t.}&amp;&amp; x_1 + x_3 &amp; = \ \ 4 \\
&amp;&amp; 2x_2 + x_4 &amp; = 12 \\
&amp;&amp; 3x_1 + 2x_2 + \hat x_5 &amp; = 18 \\
&amp;&amp; x_1,x_2,x_3,x_4,\hat x_5 &amp; \geq \ \ 0
\end{align*}
</span></p>
<p>Note that we require the artificial variable to be non-negative to
conform with eq. <a href="#eq:augmentedFormLpMatrix">4</a>, the form
required for simplex. It is further worth noting that the right-hand
side of the constraint needs to be non-negative to keep <span
class="math inline">\hat x_5\geq0</span> in the initial solution. This
is no big deal though, since if the right-hand side were negative we
could simply multiply both sides of the constraint by <span
class="math inline">-1</span> and use the resultant constraint in the
formulation instead.</p>
<p>What good will this do us? We can initialize simplex now with <span
class="math inline">x_3, x_4</span>, and <span class="math inline">\hat
x_5</span> as our original basis. Further, due to the massive penalty to
the objective for including <span class="math inline">\hat x_5</span> in
a solution, the artificial variable will eventually leave the basis if
possible. So we keep running simplex until either:</p>
<ul>
<li><span class="math inline">\hat x_5</span> drops out of the basis, at
which point we can remove it from the problem completely and continue
iterating simplex as usual.</li>
<li>We find an optimal solution to the artificial problem that includes
<span class="math inline">\hat x_5&gt;0</span>, in which case the
original problem was infeasible.</li>
</ul>
<p>Note that in this example we added only one artificial variable, but
it is possible that an artificial variable needs to be added for every
constraint. Either way the method is the same: make sure the right-hand
sides are non-negative, add the artificial variables, and keep iterating
through simplex until the artificial variables are gone.</p>
<h4>
Choosing the entering basic variable
</h4>
<p>We may choose the entering basic variable to be any non-basic
variable with a negative coefficient for <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}</span>. If there are multiple qualifying non-basic variables,
a common rule-of-thumb is to select the variable whose coefficient has
the largest absolute value. This is not guaranteed to be a
<em>better</em> choice than any of the others. But the thinking is,
might as well try the variable that gives you the most bang for your
buck as far as objective value change.</p>
<p>But what if there is a tie for the largest absolute value among
negative coefficients? You can just pick arbitrarily. As we mentioned,
simplex doesn’t really care that the largest absolute value is selected
anyway. So no special tie-breaking rule is required here.</p>
<h4>
Tie for the exiting basic variable
</h4>
<p>We determine the exiting variable based on <em>minimum ratio
test</em>. But what if the minimum ratio is shared between multiple
basic variables? Unlike in the case of the entering basic variable,
there actually <em>is</em> something to worry about in this case.</p>
<p>Let’s recall what the minimum ratio test was calculating. In each
row, we were determining how much we could increase the value of the
entering variable before the corresponding basic variable becomes zero.
A tie in the minimum ratio test would mean that multiple of the current
basic variables would take on a value of 0 when the entering variable
joins the basis. Thus in the next basic solution, at least one basic
variable will have a value of 0. Such a BF solution is called a
<strong>degenerate</strong> solution, and the 0-valued basic variables
are called degenerate variables.</p>
<p>Degeneracy can cause issues for the simplex method. In particular, if
a degenerate basic variable is the exiting variable in a subsequent
simplex iteration, then the entering variable cannot increase in value
from zero without making the degenerate variable take a negative value.
So even with the basis change, the solution stayed the same from one
iteration to the next. Even worse, this could continue in a cycle such
that simplex never stops iterating!</p>
<p>Luckily these looping conditions are exceedingly rare in practical
problems. Furthermore, there are rules for selecting the exiting basic
variable that are guaranteed to avoid this infinite looping scenario
(see e.g. <span class="citation" data-cites="simplexPivotNoLoops">Bland
(<a href="#ref-simplexPivotNoLoops"
role="doc-biblioref">1977</a>)</span>), though we won’t cover them in
this course.</p>
<h4>
No exiting basic variable
</h4>
<p>Recall that during the minimum ratio test for determining the exiting
basic variable, we only consider ratios in the rows where the
coefficient on the entering variable is strictly positive. This is
because a 0 or negative coefficient would imply that the entering
variable could be increased arbitrarily without violating either the
corresponding constraint or non-negativity for the corresponding basic
variable. If <em>every</em> such coefficient were <span
class="math inline">\leq 0</span>, this would imply that the entire
system remains feasible no matter how much the entering variable is
increased.</p>
<p>Recall that we selected an entering variable whose inclusion would
improve the objective value. But if the entering variable can be
increased indefinitely, then also the objective can be increased
indefinitely, so our problem is unbounded. So if at any point the
simplex method comes to an iteration where the entering variable’s
coefficients are all <span class="math inline">\leq0</span>, we
terminate and declare the problem unbounded.</p>
<h3 data-number="4.6.8" id="the-revised-simplex-method"><span
class="header-section-number">4.6.8</span> The revised simplex
method</h3>
<p>We’ll end this section on the simplex method with a note on the
so-called <strong>revised simplex method</strong>. Recall that every
iteration of the simplex method requires us to find <span
class="math inline">\mathbf{B}^{-1}</span>, the inverse of the columns
of <span class="math inline">\mathbf{A}</span> corresponding to the
basis variables. In practice, doing this inversion can be
computationally expensive. But it is possible to cut down on the
computation time by applying a nice trick to derive <span
class="math inline">\mathbf{B}^{-1}</span> for the current iteration
from the inverted matrix from the previous iteration. We won’t bother
with the details here, but you can read about it in <span
class="citation" data-cites="classText">Hillier and Lieberman (<a
href="#ref-classText" role="doc-biblioref">2021</a>)</span>, section
5.4.</p>
<h2 data-number="4.7" id="sec:lpDuality"><span
class="header-section-number">4.7</span> Duality</h2>
<p>In this section we’ll discuss the important concept of LP duality.
This neat bit of theory will allow us to prove the correctness of the
simplex method, and open up avenues to potentially solve LPs faster in
practice. We’ll also see its fingerprints when discussing
post-optimality analysis in section <a href="#sec:lpPostOpt">4.8</a>.
But before we get there, let’s start with some light fiction.</p>
<h3 data-number="4.7.1" id="sec:corporateTakeover"><span
class="header-section-number">4.7.1</span> The corporate takeover</h3>
<p>Suppose you really want to get into the glass manufacturing business.
You figure that Wyndor Glass Co. (the company from section <a
href="#sec:exampleLp">4.1</a>, where we derived our sample LP eq. <a
href="#eq:prototypeLp">1</a>) might be willing to sell you time in their
facilities. But you don’t just want <em>some</em> time, you have big
plans and could really use <em>all</em> their facility time for the next
week. You decide to propose to buy their facility time at a cost of
<span class="math inline">y_i</span> per hour in facility <span
class="math inline">i\in\{1, 2, 3\}</span>. How do you know what price
to propose?</p>
<p>You know a little bit about linear programming now, so you decide to
solve an LP to guide your decision. Naturally, you want to pay the least
amount possible for their facility time. Since the facilities are open
for 4, 12, and 18 hours per week respectively, your objective is to
minimize <span class="math inline">4y_1 + 12y_2 + 18y_3</span>.</p>
<p>But how do you know if Wyndor will accept your offer? At a minimum,
you know that they won’t accept anything less than $3,000 for an hour at
Plant 1 plus three hours at Plant 3. Why? You’ve done your homework.
With that time Wyndor can produce a full batch of Product 1 at a profit
of that same $3,000 figure. Similarly, you’ll need to at least $5,000
for two hours each at Plant 2 and Plant 3, to account for their profit
on batches of Product 2. And they certainly won’t be <em>paying</em> you
to take their valuable facility time, so for each Plant <span
class="math inline">i</span> you must have <span
class="math inline">y_i\geq 0</span>.</p>
<p>Brining it all together, you get this formulation:</p>
<p><span id="eq:prototypeLpDual" class="eqnos"><span
class="math display">
\begin{align*}
\text{min}&amp;&amp; 4y_1 + 12y_2 + 18y_3 &amp; \\
\text{s.t.}&amp;&amp;  y_1 +  3y_3 &amp; \geq 3 \\
     &amp;&amp; 2y_2 +  2y_3 &amp; \geq 5 \\
     &amp;&amp; y_1,y_2,y_3 &amp; \geq 0
\end{align*}
</span><span class="eqnos-number">(12)</span></span></p>
<p>You quickly throw together a Colab notebook to solve this problem.
You know that Wyndor can make $36,000 per week with their resources, so
the difference between that and the optimal solution solution to this LP
is pure profit for you. With visions of riches dancing through your
head, you run the notebook and find the optimal objective value is …</p>
<script src="https://gist.github.com/f5076b20215d0fb98009ba74b83bb930.js"></script>
<p>… that same $36,000? What an odd coincidence.</p>
<h3 data-number="4.7.2" id="defining-the-dual-lp"><span
class="header-section-number">4.7.2</span> Defining the dual LP</h3>
<div class="lectureVideoEmbed"
data-video-id="ef7be5c2f335464abb0d0b06c1796b761d"
data-video-date="2023-09-13">
Duality redux, plus some post-optimality analysis.
</div>
<p>Actually, this is no coincidence at all. It’s simply a consequence of
LP duality. For every LP, there is a second, associated LP that relates
to it in a special way. We call the second LP the <strong>dual</strong>
LP, and the original the <strong>primal</strong>. As it turns out, the
problem eq. <a href="#eq:prototypeLpDual">12</a> we just formulated is
the dual problem of our original sample LP eq. <a
href="#eq:prototypeLp">1</a>.</p>
<p>Let’s look a little closer at the relationship between eq. <a
href="#eq:prototypeLp">1</a> and eq. <a
href="#eq:prototypeLpDual">12</a>. To make things more obvious, let’s
write them out next to each other in matrix form. We’ll also rearrange
the order of the data and variable matrices in the dual problem:</p>
<div class="mathSmall">
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \begin{bmatrix}3 &amp;
5\end{bmatrix}\begin{bmatrix}x_1 \\ x_2\end{bmatrix} &amp;
&amp; \quad
\text{min}&amp;&amp; \begin{bmatrix}y_1 &amp; y_2 &amp;
y_3\end{bmatrix}\begin{bmatrix}4 \\ 12 \\ 18\end{bmatrix} &amp;
\\
\text{s.t.} &amp;&amp; \begin{bmatrix}1 &amp; 0 \\ 0 &amp; 2 \\ 3 &amp;
2\end{bmatrix}\begin{bmatrix}x_1 \\ x_2\end{bmatrix} &amp; \leq
\begin{bmatrix}4 \\ 12 \\ 18\end{bmatrix}
&amp; \quad
\text{s.t.} &amp;&amp; \begin{bmatrix}y_1 &amp; y_2 &amp;
y_3\end{bmatrix}\begin{bmatrix}1 &amp; 0 \\ 0 &amp; 2 \\ 3 &amp;
2\end{bmatrix} &amp; \geq \begin{bmatrix}3 &amp; 5\end{bmatrix}
\\
&amp;&amp; x_1,x_2 &amp; \geq 0
&amp; \quad
&amp;&amp; y_1,y_2,y_3 &amp; \geq 0
\end{align*}
</span></p>
</div>
<p>Side-by-side like this, it’s easy to see the connection. The
constraint matrix didn’t change at all, though we’re pre-multiplying the
variables in the dual as opposed to post-multiplying in the primal.
Further, the constraint right-hand side values from the primal became
the objective coefficients in the dual, and vice-versa. It’s kinda like
the whole problem fell on its side<a href="#fn36" class="footnote-ref"
id="fnref36" role="doc-noteref"><sup>36</sup></a>.</p>
<p>In general, the dual for the standard form LP is defined as
follows:</p>
<p><span id="eq:standardLpDual" class="eqnos"><span
class="math display">
\begin{align*}
&amp;\textbf{primal:}
&amp;&amp;&amp;&amp;&amp;&amp;\quad\textbf{dual:}&amp;&amp;&amp;\\
&amp;\text{max}&amp;&amp; \mathbf{c}\mathbf{x}&amp;
&amp;&amp;&amp;\quad
\text{min}&amp;&amp; \mathbf{y}\mathbf{b}&amp;
\\
&amp;\text{s.t.} &amp;&amp; \mathbf{A}\mathbf{x}\leq\mathbf{b}&amp;
&amp;&amp;&amp;\quad
\text{s.t.} &amp;&amp; \mathbf{y}\mathbf{A}\geq\mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{x}\geq0 &amp;
&amp;&amp;&amp;\quad
&amp;&amp; \mathbf{y}\geq0 &amp;
\end{align*}
</span><span class="eqnos-number">(13)</span></span></p>
<p>But what if your problem is in a different form? Can we still talk
about its dual in the same way? As you might have guessed, there is
indeed a dual problem for your LP no matter how it is stated. The
following gives another primal/dual pair (notice the lack of a
non-negativity requirement for the dual variables):</p>
<p><span id="eq:augmentedLpDual" class="eqnos"><span
class="math display">
\begin{align*}
&amp;\textbf{primal:}
&amp;&amp;&amp;&amp;&amp;&amp;\quad\textbf{dual:}&amp;&amp;&amp;\\
&amp;\text{max}&amp;&amp; \mathbf{c}\mathbf{x}&amp;
&amp;&amp;&amp;\quad
\text{min}&amp;&amp; \mathbf{y}\mathbf{b}&amp;
\\
&amp;\text{s.t.} &amp;&amp; \mathbf{A}\mathbf{x}=\mathbf{b}&amp;
&amp;&amp;&amp;\quad
\text{s.t.} &amp;&amp; \mathbf{y}\mathbf{A}\geq\mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{x}\geq0 &amp;
&amp;&amp;&amp;\quad
&amp;&amp;&amp;
\end{align*}
</span><span class="eqnos-number">(14)</span></span></p>
<div id="thm:dualEqualityForm" class="theorem">
<p>The systems in eq. <a href="#eq:augmentedLpDual">14</a> give a valid
primal/dual pair.</p>
</div>
<div class="proof" for="thm:dualEqualityForm" data-placement="appendix">
<p>The concept for this proof is to transform the primal problem from
eq. <a href="#eq:augmentedLpDual">14</a> into inequality form so that we
can use the definition of eq. <a href="#eq:standardLpDual">13</a> to get
the corresponding dual problem, then see what shakes out. To that end,
let’s use our trick from section <a
href="#sec:lpConstraintTransform">4.5.3</a> to convert to inequality
constraints by replacing each <span class="math inline">=</span>
constraint by one <span class="math inline">\leq</span> and one <span
class="math inline">\geq</span> constraint:</p>
<p><span class="math display">
\begin{align*}
&amp;\text{max}&amp;&amp; \mathbf{c}\mathbf{x}&amp;
&amp;&amp;&amp;\quad
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}&amp;
\\
&amp;\text{s.t.} &amp;&amp; \mathbf{A}\mathbf{x}=\mathbf{b}&amp;
&amp;&amp; = \qquad&amp;\quad
\text{s.t.} &amp;&amp;
\begin{bmatrix}\mathbf{A}\\-\mathbf{A}\end{bmatrix}\mathbf{x}\leq
\begin{bmatrix}\mathbf{b}\\-\mathbf{b}\end{bmatrix} &amp;
\\
&amp;&amp;&amp; \mathbf{x}\geq0 &amp;
&amp;&amp;&amp;\quad
&amp;&amp; \mathbf{x}\geq0&amp;
\end{align*}
</span></p>
<p>Now we can use eq. <a href="#eq:standardLpDual">13</a> to find the
dual. For reasons that will become clear later, we’ll replace the usual
<span class="math inline">\mathbf{y}</span> variable vector with two
separate vectors <span class="math inline">\mathbf{w}</span> and <span
class="math inline">\mathbf{z}</span>, corresponding to the positive and
negative constraint matrices.</p>
<p><span class="math display">
\begin{align*}
&amp;\text{min}&amp;&amp;
\begin{bmatrix}\mathbf{w}&amp;\mathbf{z}\end{bmatrix}\begin{bmatrix}\mathbf{b}\\-\mathbf{b}\end{bmatrix}
&amp;
\\
&amp;\text{s.t.} &amp;&amp;
\begin{bmatrix}\mathbf{w}&amp;\mathbf{z}\end{bmatrix}\begin{bmatrix}\mathbf{A}\\-\mathbf{A}\end{bmatrix}\geq
\mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{w},\mathbf{z}\geq0 &amp;
\end{align*}
</span></p>
<p>Now, watch what happens when we multiply out the objective: <span
class="math inline">\begin{bmatrix}\mathbf{w}&amp;\mathbf{z}\end{bmatrix}\begin{bmatrix}\mathbf{b}\\-\mathbf{b}\end{bmatrix}
= \mathbf{w}\mathbf{b}- \mathbf{z}\mathbf{b}</span>, and because of the
distributive property of matrix multiplication, we have <span
class="math inline">\mathbf{w}\mathbf{b}- \mathbf{z}\mathbf{b}=
(\mathbf{w}-\mathbf{z})\mathbf{b}</span>. Similar can be done with the
constraints, giving:</p>
<p><span class="math display">
\begin{align*}
&amp;\text{min}&amp;&amp;
\begin{bmatrix}\mathbf{w}&amp;\mathbf{z}\end{bmatrix}\begin{bmatrix}\mathbf{b}\\-\mathbf{b}\end{bmatrix}
&amp;
&amp;&amp;&amp;\quad
\text{min}&amp;&amp; (\mathbf{w}-\mathbf{z})\mathbf{b}&amp;
\\
&amp;\text{s.t.} &amp;&amp;
\begin{bmatrix}\mathbf{w}&amp;\mathbf{z}\end{bmatrix}\begin{bmatrix}\mathbf{A}\\-\mathbf{A}\end{bmatrix}\geq
\mathbf{c}&amp;
&amp;&amp; = \qquad&amp;\quad
\text{s.t.} &amp;&amp; (\mathbf{w}-\mathbf{z})\mathbf{A}\geq
\mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{w},\mathbf{z}\geq0 &amp;
&amp;&amp;&amp;\quad
&amp;&amp; \mathbf{w},\mathbf{z}\geq0 &amp;
\end{align*}
</span></p>
<p>Perhaps this looks familiar. This is exactly the trick we highlighted
in section <a href="#sec:lpVariableBoundTransform">4.5.4</a> for
transforming between non-negative variables and unrestricted variables.
We can consider <span class="math inline">\mathbf{w}</span> and <span
class="math inline">\mathbf{z}</span> as the respective “positive” and
“negative” parts of some other variable <span
class="math inline">\mathbf{y}</span>. Because <span
class="math inline">\mathbf{w}</span> and <span
class="math inline">\mathbf{z}</span> always appear together in the
formulation as <span class="math inline">\mathbf{w}-\mathbf{z}</span>,
we can replace <span class="math inline">\mathbf{w}-\mathbf{z}</span> by
the unrestricted <span class="math inline">\mathbf{y}</span> and get an
equivalent formulation. So the dual turns into</p>
<p><span class="math display">
\begin{align*}
&amp;\text{min}&amp;&amp; (\mathbf{w}-\mathbf{z})\mathbf{b}&amp;
&amp;&amp;&amp;\quad
\text{min}&amp;&amp; \mathbf{y}\mathbf{b}&amp;
\\
&amp;\text{s.t.} &amp;&amp;
(\mathbf{w}-\mathbf{z})\mathbf{A}\geq\mathbf{c}&amp;
&amp;&amp; = \qquad&amp;\quad
\text{s.t.} &amp;&amp; \mathbf{y}\mathbf{A}\geq \mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{w},\mathbf{z}\geq0 &amp;
&amp;&amp;&amp;\quad
&amp;&amp; &amp;
\end{align*}
</span></p>
<p>which is precisely the dual form from eq. <a
href="#eq:augmentedLpDual">14</a>.</p>
</div>
<h3 data-number="4.7.3" id="properties-of-the-dual-lp"><span
class="header-section-number">4.7.3</span> Properties of the dual
LP</h3>
<p>A nice fact about duality is that the primal-dual relationship is
symmetric, i.e.</p>
<div id="thm:dualOfDual" class="theorem">
<p>The dual of the dual problem is equivalent to the primal problem.</p>
</div>
<div class="proof" for="thm:dualOfDual" data-placement="appendix">
<p>The steps required for his proof are encapsulated in the following
diagram:</p>
<div class="mathSmall">
<p><span class="math display">
\begin{align*}
&amp;\text{min}&amp;&amp; \mathbf{y}\mathbf{b}&amp;
&amp;&amp;&amp;
\text{max}&amp;&amp; -\mathbf{y}\mathbf{b}&amp;
\\
&amp;\text{s.t.} &amp;&amp; \mathbf{y}\mathbf{A}\leq\mathbf{c}&amp;
&amp;&amp;\Rightarrow\qquad&amp;
\text{s.t.} &amp;&amp; -\mathbf{y}\mathbf{A}\geq-\mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{y}\geq0 &amp;
&amp;&amp;(\times -1)\quad&amp;
&amp;&amp; \mathbf{y}\geq0 &amp;
\\
\\
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;\Downarrow\text{(dual)}&amp;\\
\\
&amp;\text{max}&amp;&amp; \mathbf{c}\mathbf{x}&amp;
&amp;&amp;&amp;
\text{min}&amp;&amp; -\mathbf{c}\mathbf{x}&amp;
\\
&amp;\text{s.t.} &amp;&amp; \mathbf{A}\mathbf{x}\geq\mathbf{b}&amp;
&amp;&amp;\Leftarrow\qquad&amp;
\text{s.t.} &amp;&amp; -\mathbf{A}\mathbf{x}\leq-\mathbf{b}&amp;
\\
&amp;&amp;&amp; \mathbf{x}\geq0 &amp;
&amp;&amp;(\times -1)\quad&amp;
&amp;&amp; \mathbf{x}\geq0 &amp;
\end{align*}
</span></p>
</div>
<p>The top-left problem is the dual of the standard form LP. We don’t
know how to take its dual correctly, so we should put it in the form of
eq. <a href="#eq:standardFormLpMatrix">3</a> since we know what that
dual looks like (eq. <a href="#eq:standardLpDual">13</a>). Using our
tricks from section <a href="#sec:lpForms">4.5</a>, we multiply the
objective by -1 to convert from minimization to maximization, and we
multiply both sides of the inequalities by <span
class="math inline">-\mathbf{I}</span> to change from <span
class="math inline">\geq</span> constraints to <span
class="math inline">\leq</span> constraints, obtaining the top-right
problem.</p>
<p>We move from the top-right to the bottom-right simply by taking the
dual from eq. <a href="#eq:standardLpDual">13</a>. So we switch the
objective function coefficients with the constraint right-hand side,
change from maximization to minimization, and multiply the variables on
the other side of the constraint matrix.</p>
<p>The move from bottom-right to bottom-left is the same as the move
from top-left to top-right, i.e. multiplying the objective by -1 and the
constraints by <span class="math inline">-\mathbf{I}</span>. What we end
up with is precisely the original standard-form problem eq. <a
href="#eq:standardFormLpMatrix">3</a>.</p>
</div>
<p>The solutions to the primal and dual problems hold a special
relationship too, in that the objective value from one always bounds the
possible objective values for the other:</p>
<div id="thm:weakDuality" class="theorem"
data-display-name="weak duality">
<p>If <span class="math inline">\mathbf{x}</span> is a feasible solution
for the primal problem and <span class="math inline">\mathbf{y}</span>
is a feasible solution for the dual problem, then</p>
<p><span class="math display">
\mathbf{c}\mathbf{x}\leq\mathbf{y}\mathbf{b}.
</span></p>
</div>
<div class="proof" for="thm:weakDuality">
<p>The proof for this is just some simple linear algebra. <span
class="math inline">\mathbf{x}</span> being feasible for the primal
problem means <span
class="math inline">\mathbf{A}\mathbf{x}\leq\mathbf{b}</span>.
Pre-multiplying both sides by <span
class="math inline">\mathbf{y}</span> will give us: <span
class="math display">
\mathbf{A}\mathbf{x}\leq\mathbf{b}
\Leftrightarrow
\mathbf{y}\mathbf{A}\mathbf{x}\leq\mathbf{y}\mathbf{b}.
</span> Note the above wouldn’t necessarily hold if some values of <span
class="math inline">\mathbf{y}</span> were negative, but since <span
class="math inline">\mathbf{y}</span> is feasible for the dual we must
have <span class="math inline">\mathbf{y}\geq0</span>, by definition of
the dual problem.</p>
<p>Similarly, with <span class="math inline">\mathbf{y}</span> being
feasible to the dual, we have <span
class="math inline">\mathbf{y}\mathbf{A}\geq\mathbf{c}</span>.
Post-multiplying both sides by <span
class="math inline">\mathbf{x}</span> (which similarly must be
non-negative) gives: <span class="math display">
\mathbf{y}\mathbf{A}\geq\mathbf{c}
\Leftrightarrow
\mathbf{y}\mathbf{A}\mathbf{x}\geq\mathbf{c}\mathbf{x}.
</span></p>
<p>Combining the two resultant inequalities gives us what we need: <span
class="math display">
\mathbf{c}\mathbf{x}\leq\mathbf{y}\mathbf{A}\mathbf{x}\leq\mathbf{y}\mathbf{b}.
</span></p>
</div>
<p>An immediate corollary<a href="#fn37" class="footnote-ref"
id="fnref37" role="doc-noteref"><sup>37</sup></a> of <span
class="thmRef" for="thm:weakDuality"></span> is the following:</p>
<div id="thm:dualSameValueThenOptimal" class="theorem"
data-thm-type="corollary">
<p>If <span class="math inline">\mathbf{x}</span> is a solution to the
primal problem and <span class="math inline">\mathbf{y}</span> is a
solution to the dual problem such that <span
class="math inline">\mathbf{c}\mathbf{x}=\mathbf{y}\mathbf{b}</span>,
then <span class="math inline">\mathbf{x}</span> and <span
class="math inline">\mathbf{y}</span> are optimal solutions to the
primal and dual problems, respectively.</p>
</div>
<div class="proof" for="thm:dualSameValueThenOptimal">
<p>Since <span class="math inline">\mathbf{y}</span> is feasible for the
dual problem, <span class="thmRef" for="thm:weakDuality"></span> tells
us that no primal solution can have a value higher than <span
class="math inline">\mathbf{y}\mathbf{b}</span>. Then since <span
class="math inline">\mathbf{c}\mathbf{x}=\mathbf{y}\mathbf{b}</span>,
<span class="math inline">\mathbf{x}</span> attains this highest
possible value, thus it is optimal. A similar argument gives that <span
class="math inline">\mathbf{y}</span> is optimal for the dual.</p>
</div>
<p>Among other things, <span class="thmRef"
for="thm:weakDuality"></span> tells us that the problem eq. <a
href="#eq:prototypeLpDual">12</a> we formulated in section <a
href="#sec:corporateTakeover">4.7.1</a> had no hopes of attaining an
objective value higher than the optimal for eq. <a
href="#eq:prototypeLp">1</a>. So 36 was the highest value we could have
hoped for. And it turns out we were actually able to attain that value
in the dual problem. Was this just luck? No, as it turns out, thanks to
the following theorem.</p>
<div id="thm:strongDuality" class="theorem"
data-display-name="strong duality">
<p>If <span class="math inline">\mathbf{x}^*</span> is an optimal
solution for the primal problem and <span
class="math inline">\mathbf{y}^*</span> is an optimal solution for the
dual problem, then</p>
<p><span class="math display">
\mathbf{c}\mathbf{x}^*=\mathbf{y}^*\mathbf{b}.
</span></p>
</div>
<div class="proof" for="thm:strongDuality">
<p>For this proof we’ll make use of the alternate primal/dual
formulation of eq. <a href="#eq:augmentedLpDual">14</a> and our
knowledge of the simplex method. By assumption, the primal problem has
an optimal solution <span class="math inline">x^*</span>. Thus in the
final simplex iteration the reduced costs are all non-negative. That is,
for the optimal basis we have <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}\geq0</span> (you may want to check eq. <a
href="#eq:simplexMatrixGeneralized">11</a> to refresh your memory on
what the system of equations looks like for a given simplex basis).</p>
<p>Let’s take the vector <span class="math inline">\mathbf{y}</span>
defined as <span
class="math inline">\mathbf{y}=\mathbf{c}_B\mathbf{B}^{-1}</span>.
Subbing that into the above inequality, we have <span
class="math display">
\mathbf{y}\mathbf{A}- \mathbf{c}\geq0 \Leftrightarrow
\mathbf{y}\mathbf{A}\geq\mathbf{c}
</span> which implies that <span class="math inline">\mathbf{y}</span>
is a feasible solution for the dual. Furthermore, noting that <span
class="math inline">\mathbf{x}_B^*=\mathbf{B}^{-1}\mathbf{b}</span> (by
eq. <a href="#eq:basicVariableValues">8</a>), we have <span
class="math display">
\begin{align*}
\mathbf{y}\mathbf{b}&amp;=
\mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\text{definition
of }\mathbf{y}) \\
     &amp;= \mathbf{c}_B\mathbf{x}^*_B &amp;&amp; \quad(\text{above
note}) \\
     &amp;= \mathbf{c}\mathbf{x}^* &amp;&amp; \quad(\mathbf{x}_N =
\mathbf{0}) \\
\end{align*}
</span></p>
<p>So not only is <span class="math inline">\mathbf{y}</span> feasible
for the dual, its objective value in the dual is equivalent to the
objective value for <span class="math inline">\mathbf{x}^*</span> in the
primal. So by <span class="thmRef"
for="thm:dualSameValueThenOptimal"></span> <span
class="math inline">\mathbf{y}^*</span> is an optimal solution for the
dual, and <span class="math inline">\mathbf{x}^*,\mathbf{y}^*</span>
satisfy the condition of the theorem.</p>
</div>
<h3 data-number="4.7.4" id="simplex-and-the-dual-problem"><span
class="header-section-number">4.7.4</span> Simplex and the dual
problem</h3>
<p>Hold on a second - do you see what we did in that last proof? We
proved the theorem, sure, but there’s more. This proof was constructive,
meaning that we didn’t just prove that the primal and dual optimal
values are equal, we showed how to find <span
class="math inline">\mathbf{y}^*</span> from <span
class="math inline">\mathbf{x}^*</span>. Not only that, but we showed
how to derive <span class="math inline">\mathbf{y}^*</span> <em>using
the simplex method</em>! Simplex gives its own proof of optimality! All
that time setting up the simplex method in section <a
href="#sec:simplex">4.6</a> we only gestured at why it works. But now we
have the proof of correctness sitting right in front of us!</p>
<div id="thm:simplexWorks" class="theorem">
<p>Given a linear program with a bounded objective, the simplex method
will terminate at an optimal solution. Moreover, an optimal solution to
the dual problem may be retrieved from the optimal basis via <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}</span>.</p>
</div>
<div class="proof" for="thm:simplexWorks">
<p>We’ll first note that technically we need to bypass the cycling issue
from degenerate solutions discussed in section <a
href="#sec:lpOtherConsiderations">4.6.7</a>. But assuming that is taken
care of, the simplex method terminates at some solution <span
class="math inline">\mathbf{x}^*</span>. Taking the associated basis and
following the steps of the proof to <span class="thmRef"
for="thm:strongDuality"></span>, we obtain a solution <span
class="math inline">\mathbf{y}^*=\mathbf{c}_B\mathbf{B}^{-1}</span> such
that <span class="math inline">\mathbf{y}^*\mathbf{b}=
\mathbf{c}\mathbf{x}^*</span>. Thus by <span class="thmRef"
for="thm:dualSameValueThenOptimal"></span> <span
class="math inline">x^*</span> and <span class="math inline">y^*</span>
are both optimal for their respective problems.</p>
</div>
<p>Also implied by the proof of <span class="thmRef"
for="thm:strongDuality"></span>: Taking <span
class="math inline">\mathbf{y}=\mathbf{c}_B\mathbf{B}^{-1}</span> for
the any basis gives us a solution <span
class="math inline">\mathbf{y}</span> to the dual problem such that
<span class="math inline">\mathbf{y}^*\mathbf{b}=
\mathbf{c}_B\mathbf{x}_B^*</span>. However, due to <span class="thmRef"
for="thm:strongDuality"></span>, we know that no <em>feasible</em>
solution to <span class="math inline">\mathbf{y}</span> can have any
value lower than the optimal <span
class="math inline">\mathbf{c}\mathbf{x}^*</span>. So the <span
class="math inline">\mathbf{y}</span> generated is feasible if and only
if the basis generating it is optimal for the primal problem.</p>
<p>We now know that the simplex method will generate optimal solutions
for <em>both</em> the primal problem <em>and</em> the dual problem. This
gives us an opportunity: what if for some reason we believe simplex will
run faster on the dual problem than it would on the primal problem. As
an example, the number of constraints in a problem is often related to
the number of simplex iterations required to solve it. Since the
constraints in the primal correspond directly to variables in the dual
(and vice-versa) if you have a problem with many more constraints than
variables, it stands to reason that simplex may solve the dual problem
faster than the primal. Since simplex gives solutions to both the primal
and dual problems (and the dual of the dual is the primal), running
simplex on the dual may get us an optimal solution faster.</p>
<p>Another notion worth mentioning is the <strong>dual simplex</strong>
method. We will not discuss it in any detail here,<a href="#fn38"
class="footnote-ref" id="fnref38" role="doc-noteref"><sup>38</sup></a>
but it is an algorithm applied to the primal problem whose steps look as
if it were regular simplex being applied to the dual problem. It can be
useful to have both methods (primal and dual simplex) available when
solving an LP, and most solvers do exactly this.</p>
<h3 data-number="4.7.5"
id="primaldual-feasibilityboundedness-relationships"><span
class="header-section-number">4.7.5</span> Primal/dual
feasibility/boundedness relationships</h3>
<p>To wrap up the duality section, let’s discuss how the feasibility and
boundedness of the primal and dual problems relate to one another. The
possibilities are summarized in the following result:</p>
<div id="thm:primalDualRelations" class="theorem">
<p>The following relationships always hold between the primal LP and its
associated dual:</p>
<ol type="1">
<li>If the primal problem is feasible with a bounded objective, then so
is the dual.</li>
<li>If the primal problem is feasible but with an unbounded objective,
then the dual is infeasible.</li>
<li>If the primal problem is infeasible, then the dual has either no
feasible solutions or an unbounded objective function.</li>
</ol>
</div>
<div class="proof" for="thm:primalDualRelations">
<p>Case 1 follows directly from <span class="thmRef"
for="thm:simplexWorks"></span>. Case 2 is a corollary of weak duality
(<span class="thmRef" for="thm:weakDuality"></span>), since the
existence of a dual solution would immediately bound the primal
objective.</p>
<p>Case 3 can be proven by contradiction using <span class="thmRef"
for="thm:simplexWorks"></span> (and <span class="thmRef"
for="thm:dualOfDual"></span>): Suppose that the dual is neither
infeasible nor unbounded. Then it must be feasible with a bounded
objective, which by <span class="thmRef" for="thm:simplexWorks"></span>
means that applying simplex to this problem will yield an optimal, and
therefore feasible, solution to the primal as well, a contradiction.</p>
</div>
<h2 data-number="4.8" id="sec:lpPostOpt"><span
class="header-section-number">4.8</span> Post-optimality analysis</h2>
<p>After a linear program has been solved, it is often the case that
you’d like to consider separate, but similar scenarios for you problem
of interest. In the case of our example LP eq. <a
href="#eq:prototypeLp">1</a>, the company might like to know how much
the solution would change if they could add another hour of production
time to one of their facilities. Additionally, often when a problem is
formulated, the exact data (<span class="math inline">\mathbf{A},
\mathbf{b}, \mathbf{c}</span>) that is used is only an estimate, or
subject to decisions made by upper management. In these cases we might
like to know something about how the objective could change with small
updates to these values. These activities all fall under the heading of
<strong>post-optimality analysis</strong>, and LP theory gives us some
tools for dealing with them.</p>
<h3 data-number="4.8.1" id="sec:lpReopt"><span
class="header-section-number">4.8.1</span> Re-optimization</h3>
<p>In the simplest and most general case, say that we’ve already solved
a very large LP, and for whatever reason we need to make a few tweaks to
the problem and see how the solution changes. One approach to this could
be to re-run simplex from scratch on the new problem. But for very large
LPs, a better approach may be <strong>re-optimization</strong>, which is
essentially a way to “start where you left off” on the previous problem.
The idea is to start from the previous optimal basis and deduce how
changes in the data affect the simplex information from eq. <a
href="#eq:simplexMatrixGeneralized">11</a>.</p>
<p>The advantage here is that since the original problem is very similar
to the one being solved now, the new optimal solution is likely to be
“nearby” to the old optimal solution, and thus we can hope that fewer
simplex iterations are needed to complete the re-optimization process
when compared to re-solving the problem from scratch. It is very
possible that, even with the changes, the previous optimal solution is
still optimal for the new problem, which you could know by checking the
newly-calculated reduced costs. Even if the old solution is no longer
optimal, it may still be feasible, allowing you to continue the simplex
algorithm from there. Lastly, even if the old solution is no longer
feasible for the new problem, a few iterations of the <em>dual</em>
simplex algorithm may take you to an optimal solution.</p>
<h3 data-number="4.8.2" id="sec:shadowPrices"><span
class="header-section-number">4.8.2</span> Shadow Prices</h3>
<p>Consider a resource allocation problem, like e.g. our sample LP
eq. <a href="#eq:prototypeLp">1</a>, where the problem is of the form
eq. <a href="#eq:standardFormLpMatrix">3</a> and the constraints denote
how much of each resource is needed for each possible activity. In these
cases, at the optimal basis the reduced costs <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}-\mathbf{c}</span>
corresponding to the slack variable for each constraint denote the
so-called <strong>shadow price</strong> of the associated resource.</p>
<p>Let’s look again eq. <a href="#eq:simplexExampleFinalMatrix">7</a>,
which was how our system looked after we completed the simplex method
while solving the sample LP in section <a
href="#sec:simplexExample">4.6.4</a>. The final three coefficients in
the top row are the shadow prices of the three resources, i.e. an hour
of production capacities at Plants 1, 2, and 3, respectively. Looking at
the system, we see a shadow price of 0 for Plant 1, a price of <span
class="math inline">\frac{3}{2}</span> for Plant 2, and a price of <span
class="math inline">1</span> for Plant 3.</p>
<p>How do we interpret these shadow prices? Let’s consider Plant 3,
whose shadow price is 1. In the context of the final simplex iteration,
that same value 1 was the reduced cost on <span
class="math inline">x_5</span>, the slack variable for the Plant 3
constraint. We interpret that to mean that a small increase in <span
class="math inline">x_5</span> would decrease the objective value by
$1,000 per unit, which is why we decided not to bring <span
class="math inline">x_5</span> into the basis. Since <span
class="math inline">x_5</span> is the <em>slack</em> in the Plant 3
constraint, we can interpret an increase in <span
class="math inline">x_5</span> as <em>taking away</em> capacity from
Plant 3. So we could also interpret that reduced cost as telling us that
taking away capacity from Plant 3 would cost us $1,000 per hour. On the
flip side, this should also mean that <em>increasing</em> capacity at
Plant 3 would be worth and extra $1,000 per hour to us.</p>
<p>This insight is the key to interpreting the shadow price. It is the
amount we would expect the objective to increase if we could gain a
<em>little more</em><a href="#fn39" class="footnote-ref" id="fnref39"
role="doc-noteref"><sup>39</sup></a> of a given resource, and hence also
the maximum <em>price</em> we’d be willing to pay in order to secure
this increase.</p>
<p>So in our sample problem, we should be willing to pay $1,500 for an
extra hour of capacity at Plant 2, and $1,000 for an extra hour at Plant
3. But the shadow price for Plant 1 is 0. Why is that? Well, in the
optimal solution to the sample problem, we only use 2 of the available 4
hours at Plant 1. We already have 2 hours of capacity there that we
aren’t using, so why would we pay anybody for even more?</p>
<p>Another nice interpretation for the shadow price comes from the dual
problem. Recall in section <a href="#sec:corporateTakeover">4.7.1</a>
when we formulated our “corporate takeover” problem eq. <a
href="#eq:prototypeLpDual">12</a>, which we later found was actually the
dual to our sample LP. In that formulation, the variables <span
class="math inline">y_1, y_2, y_3</span> represented how much we’d be
willing to pay for time at Wyndor’s three facilities, and when we ran
the notebook in section <a href="#sec:corporateTakeover">4.7.1</a> the
optimal values for these variables were again those same values from
above, <span class="math inline">0, \frac{3}{2}</span>, and <span
class="math inline">1</span>. Of course, it should be no surprise that
these are exactly equal to the shadow prices, as we’ve already seen the
connection between the two in the proof to <span class="thmRef"
for="thm:simplexWorks"></span>.</p>
<h3 data-number="4.8.3" id="sec:sensitivityAnalysis"><span
class="header-section-number">4.8.3</span> Sensitivity Analysis</h3>
<div class="lectureVideoEmbed"
data-video-id="02852e5c6cf44834912154ba1636a5851d"
data-video-date="2023-09-15">
Wrapping up sensitivity analysis and LP. Discussed HW2, particularly
question 5. Video cuts off, but you don’t really miss anything.
</div>
<p><strong>Sensitivity analysis</strong> is the process of determining
how small changes in problem data can alter the optimal solution. As
explained in <span class="citation" data-cites="classText">Hillier and
Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span>, section 7.2,</p>
<blockquote>
<p>one assumption of linear programming is that all the parameters of
the model (<span class="math inline">a_{ij}</span>, <span
class="math inline">b_i</span>, and <span
class="math inline">c_j</span>) are known constants. Actually, the
parameter values used in the model normally are just estimates based on
a prediction of future conditions. The data obtained to develop these
estimates often are rather crude or nonexistent, so that the parameters
in the original formulation may represent little more than quick rules
of thumb provided by busy line personnel. The data may even represent
deliberate overestimates or underestimates to protect the interests of
the estimators.</p>
</blockquote>
<p>Thus it is valuable to know if changes in problem data will have
outsized effects on the optimal solution. In this section, we’ll discuss
ways to determine the so-called <em>allowable range</em> for different
values, meaning the values a particular coefficient can take without
changing the optimal solution.</p>
<p>For the sake of brevity, we’ll only carry out this analysis for the
right-hand side values <span class="math inline">b_i</span>. Changes in
other problem data are covered in section 7.2 of <span class="citation"
data-cites="classText">Hillier and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span>.</p>
<h4>
Changing a single rhs value
</h4>
<p>Suppose after running simplex you would like to consider changes to
the right-hand side values, from <span
class="math inline">\mathbf{b}</span> to <span
class="math inline">\mathbf{\hat b}</span>. From eq. <a
href="#eq:simplexMatrixGeneralized">11</a>, we know that the values of
<span class="math inline">\mathbf{b}</span> affect only the right-hand
side of the final matrix system. So, in particular, the reduced costs on
all variables will stay the same. Thus if the new right-hand side values
<span class="math inline">\mathbf{B}^{-1}\mathbf{\hat b}</span> are all
non-negative, we’re still at the optimal solution.</p>
<p>Let’s take our the Wyndor Glass problem as an example. sample LP
eq. <a href="#eq:prototypeLp">1</a>. <span class="citation"
data-cites="classText">Hillier and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span> gives the following
exposition:</p>
<blockquote>
<p>Sensitivity analysis is begun for the original Wyndor Glass
Co. problem by examining the optimal values of the <span
class="math inline">y_i</span> dual variables <span
class="math inline">( y_1^* = 0, y_2^* = \frac{3}{2}, y_3^*=1)</span>.
These shadow prices give the marginal value of each resource <span
class="math inline">i</span> (the available production capacity of Plant
<span class="math inline">i</span>) for the activities (two new
products) under consideration, where marginal value is expressed in the
units of <span class="math inline">Z</span> (thousands of dollars of
profit per week). As discussed previously, the total profit from these
activities can be increased $1,500 per week (<span
class="math inline">y_2^*</span> times $1,000 per week) for each
additional unit of resource 2 (hour of production time per week in Plant
2) that is made available. This increase in profit holds for relatively
small changes that do not affect the feasibility of the current basic
solution (and so do not affect the <span
class="math inline">y_i^*</span> values). Consequently, the OR team has
investigated the marginal profitability from the other current uses of
this resource to determine if any are less than $1,500 per week. This
investigation reveals that one old product is far less profitable. The
production rate for this product already has been reduced to the minimum
amount that would justify its marketing expenses. However, it can be
discontinued altogether, which would provide an additional 12 units of
resource 2 for the new products. Thus, the next step is to determine the
profit that could be obtained from the new products if this shift were
made. This shift changes <span class="math inline">b_2</span> from 12 to
24 in the linear programming model.</p>
</blockquote>
<p>So we’d like to know what happens when we change <span
class="math inline">b_2</span> from 12 to 24. As a first step, let’s
take a look at the plot for this problem with the modified
constraint:</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;chooseObjVals&quot;: true, &quot;yMax&quot;: 14.99, &quot;removeConstraints&quot;: [2], &quot;addConstraints&quot;: [[[0, 2, 24, &quot;l&quot;], [6, 13.1]]]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Compared to our first plot of this problem from section <a
href="#sec:lpVisualized">4.3</a>, we see that the bounding line for the
constraint on <span class="math inline">x_2</span> has been moved way
up, such that this constraint does not even touch the feasible region
anymore<a href="#fn40" class="footnote-ref" id="fnref40"
role="doc-noteref"><sup>40</sup></a>. How might this affect the
solution?</p>
<p>Let’s go ahead and calculate the altered right-hand side according to
eq. <a href="#eq:simplexMatrixGeneralized">11</a>. Following the
formulas, we’ll get <span class="math display">
Z = \mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}= 54,\qquad \begin{bmatrix}x_3
\\ x_2 \\ x_1\end{bmatrix} = \mathbf{x}_B = \mathbf{B}^{-1}\mathbf{b}=
\begin{bmatrix}6 \\ 12 \\ -2\end{bmatrix}
</span> at our previous optimal basis. For simplex, a negative
right-hand side means a negative value for a basic variable, and thus an
infeasible solution. So our old optimal basis is no longer feasible.</p>
<p>What happened here? In terms of the plots, the original basic
solution came at the intersection of the constraints <span
class="math inline">3x_1 + 2x_2 \leq 18</span> and <span
class="math inline">2x_2 \leq 12</span>. That intersection used to be in
the feasible region, but when the second constraint was changed to <span
class="math inline">2x_2 \leq 24</span> the intersection changed to
somewhere off the plot entirely.</p>
<p>So finding the optimal solution to our new problem requires a change
of basis. Starting from a primal-infeasible basis, the best way to
proceed is an application of the dual simplex method to regain
feasibility<a href="#fn41" class="footnote-ref" id="fnref41"
role="doc-noteref"><sup>41</sup></a>. Doing so would bring us to a new
basis of <span class="math inline">(x_4, x_2, x_3)</span> and a new
optimal solution of <span class="math inline">(x_1, x_2, x_3, x_4, x_5)
= (0, 9, 4, 6, 0)</span>, which has a corresponding objective value of
<span class="math inline">Z=45</span>.</p>
<h4>
Determining the allowable range
</h4>
<p>Let’s recap what we’ve done here. We were considering a change to the
right-hand side values of our LP. Our analysis involved changing the
right-hand side then re-optimizing. We found that increasing <span
class="math inline">b_2</span> by 12 changed our optimal basis and
increased the objective value by 9, from 36 to 45. But wait, the shadow
price on <span class="math inline">b_2</span> in the original model was
<span class="math inline">\frac{3}{2}</span>, so why didn’t we get an
increase of <span class="math inline">9\times\frac{3}{2}=13.5</span>?
And we’re already past the re-optimization section, so why did we run
simplex again?</p>
<p>On the shadow price issue: We mentioned when introducing shadow
prices in section <a href="#sec:shadowPrices">4.8.2</a> that they are
only valid <em>locally</em>, i.e. they hold from “small” changes in the
resource, but if changes become too big then all bets are off. But how
big is too big? We’ll explore that next, and we won’t even (fully) run
simplex to do it!</p>
<p>Let’s first set some notation. We’ll use the capital greek letter
<span class="math inline">\Delta</span> to denote the “change in” some
value, so that <span class="math inline">\Delta b_2</span> is the amount
we change <span class="math inline">b_2</span> for the analysis. So in
our previous example, we had <span class="math inline">\Delta b_2 = 24 -
12 = 12</span>. We’d like to find the range of values for <span
class="math inline">\Delta b_2</span> such that our previous basis is
still optimal.</p>
<p>Let’s first consider feasibility. Recall that a basic solution is
feasible if and only if all the variable values are non-negative, which
from eq. <a href="#eq:simplexMatrixGeneralized">11</a> gives us <span
class="math inline">\mathbf{B}^{-1}\mathbf{b}\geq0</span>. At the
optimal solution to our sample problem, we have</p>
<p><span class="math display">
\mathbf{B}^{-1}= \begin{bmatrix}
1 &amp; \frac{1}{3} &amp; -\frac{1}{3} \\
0 &amp; \frac{1}{2} &amp; 0 \\
0 &amp; -\frac{1}{3} &amp; \frac{1}{3}
\end{bmatrix}
</span></p>
<p>Changing <span class="math inline">b_2</span> to <span
class="math inline">b_2 + \Delta b_2</span> turns the requirement
into:</p>
<p><span class="math display">
\begin{align*}
&amp;&amp;
\begin{bmatrix}
1 &amp; \frac{1}{3} &amp; -\frac{1}{3} \\
0 &amp; \frac{1}{2} &amp; 0 \\
0 &amp; -\frac{1}{3} &amp; \frac{1}{3}
\end{bmatrix}
\begin{bmatrix}
4 \\ 12 + \Delta b_2 \\ 18
\end{bmatrix}
&amp;\geq\mathbf{0}\\
\Leftrightarrow &amp;&amp;
\begin{bmatrix}
2 + \frac{1}{3}\Delta b_2 \\
6 + \frac{1}{2}\Delta b_2 \\
2 - \frac{1}{3}\Delta b_2 \\
\end{bmatrix}
&amp;\geq\mathbf{0}
\end{align*}
</span></p>
<p>The first inequality implies <span class="math inline">\Delta
b_2\geq-6</span>, the second implies <span class="math inline">\Delta
b_2\geq-12</span>, and the third implies <span
class="math inline">\Delta b_2\leq 6</span>. So to satisfy all three
simultaneously, we need to keep <span class="math inline">-6\leq\Delta
b_2\leq6</span>, the equivalent of saying <span
class="math inline">6\leq b_2\leq 18</span>.</p>
<p>So keeping <span class="math inline">6\leq b_2\leq 18</span> gives a
feasible solution, but is the old basis still optimal? It turns out that
we can answer that very simply, by noticing that changes to <span
class="math inline">\mathbf{b}</span> have no effect on the reduced cost
vector <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-\mathbf{c}</span>.
Since this basis was optimal for the original, those same reduced costs
must still be non-negative, so the old optimal basis is still optimal
whenever <span class="math inline">\Delta b_2</span> is in the
acceptable range.</p>
<p>As for how much the objective changes, let’s recall (again from
eq. <a href="#eq:simplexMatrixGeneralized">11</a>) that the objective
value at a basic solution is given by <span
class="math inline">Z=\mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}</span>.
We’ve already calculated <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}= \begin{bmatrix}0 &amp;
\frac{3}{2} &amp; 1\end{bmatrix}</span> at the optimal basis, and thus
altering <span class="math inline">b_2</span> gives us</p>
<p><span class="math display">
Z = \begin{bmatrix}0 &amp; \frac{3}{2} &amp;
1\end{bmatrix}\begin{bmatrix}4 \\ 12 + \Delta b_2 \\ 18\end{bmatrix}
  = 36 + \frac{3}{2}\Delta b_2.
</span></p>
<p>So our interpretation of the shadow price holds over this range as
well.</p>
<p>Lastly, let’s take a look at the plots of the problem when we take
<span class="math inline">b_2</span> at the limits of its allowable
range. First, for <span class="math inline">b_2=6</span>:</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;chooseObjVals&quot;: true, &quot;removeConstraints&quot;: [2], &quot;addConstraints&quot;: [[[0, 2, 6, &quot;l&quot;], [6, 4.1]]]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>And for <span class="math inline">b_2=18</span>.</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;chooseObjVals&quot;: true, &quot;removeConstraints&quot;: [2], &quot;addConstraints&quot;: [[[0, 2, 18, &quot;l&quot;], [6, 10.1]]]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>We won’t spend much time dwelling on this, but notice how the
original optimal solution came at the intersection of the second and
third constraints of eq. <a href="#eq:prototypeLp">1</a>. Now on these
two plots, the optimal is still at that intersection, while also adding
a third intersecting constraint<a href="#fn42" class="footnote-ref"
id="fnref42" role="doc-noteref"><sup>42</sup></a>. Moving any further
would make that intersection infeasible, which is why the allowable
range stops there.</p>
<h2 data-number="4.9" id="notes-and-further-reading"><span
class="header-section-number">4.9</span> Notes and further reading</h2>
<p>The presentation in this section followed very closely to various
sections in chapters 3-7 in <span class="citation"
data-cites="classText">Hillier and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span>. Many of the proofs in section <a
href="#sec:lpDuality">4.7</a> were adapted from <span class="citation"
data-cites="bertsimas-LPbook">Bertsimas and Tsitsiklis (<a
href="#ref-bertsimas-LPbook" role="doc-biblioref">1997</a>)</span>. Some
other topics for the interested reader to follow up on:</p>
<ul>
<li>We briefly mentioned <em>dual simplex</em> and some of its uses in
these notes. <span class="citation" data-cites="classText">Hillier and
Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span> section 8.1 covers it in more
detail.</li>
<li>When covering sensitivity analysis (section <a
href="#sec:sensitivityAnalysis">4.8.3</a>) we only considered changes to
a single rhs value. <span class="citation"
data-cites="classText">Hillier and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span> (section 7.2) covers further
cases, like analyzing changes in other problem data, or simultaneous
changes in multiple rhs values.</li>
<li>Section 7.4 in <span class="citation" data-cites="classText">Hillier
and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span> briefly discusses <em>robust
optimization</em>, where the setup includes ranges of potential values
of model data, and the goal is to find solutions that will be feasible
and close to optimal for the entire set of potential problem data.</li>
<li>Simplex is not the only algorithm for solving LPs. Sections 4.9 and
8.4 of <span class="citation" data-cites="classText">Hillier and
Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span> study so-called <em>interior
point</em> algorithms for linear programs. These algorithms have an
interesting role in the history of LP. Most notably, many of these
methods have been proven to terminate in a number of steps
<em>polynomial</em> in the size of the LP considered, a feat that has
not been duplicated for the simplex method. But even with this
theoretical advantage, the interior point methods are not usually faster
than simplex in practice. Even so, most solvers will include an interior
point method that will be called upon in certain circumstances.</li>
</ul>
<p>The K-State IMSE department offers <a
href="https://catalog.k-state.edu/preview_course_nopop.php?catoid=54&amp;coid=375882">IMSE
881</a>, a full semester course devoted to linear programming
theory.</p>
<h1 data-number="5" id="integer-programming"><span
class="header-section-number">5</span> Integer programming</h1>
<div class="lectureVideoEmbed"
data-video-id="82e9cb1ddf1b4cbbaa625d040d42b0891d"
data-video-date="2023-09-18">
Integer programming definitions, intro to modeling IPs. I forgot to turn
on my lapel mic at the beginning of class (about the first 7 minutes),
though the room mic was on and seemed to pick up most everything ok.
</div>
<p>In this section we will introduce integer programming (IP), which is
an of extension of linear programming that includes restrictions that
some (or all) of the decision variables must take integer values. While
this may initially seem like a small tweak, the addition of these
integrality<a href="#fn43" class="footnote-ref" id="fnref43"
role="doc-noteref"><sup>43</sup></a> constraints is actually quite
powerful, and will allow us to model all types of interesting problems
that linear programming could not handle. The added expressiveness comes
with a tradeoff, though, as integer programs generally take much more
effort to solve than their linear counterparts.</p>
<p>For this course, we will discuss some preliminaries before moving on
to IP modeling techniques. We’ll spend more time on modeling here than
in the LP section, in order to explore the flexibility integer programs
provide and discuss some of the tricks that can be used to set up
problems of all types. We’ll finish our practical discussion with a
section on solving IPs with Python. On the theoretical side, we’ll touch
a bit on the theory that helps explain what makes solving IPs so
difficult. We’ll then get into solution techniques, including
branch-and-bound and cutting plane procedures.</p>
<h2 data-number="5.1" id="definitions"><span
class="header-section-number">5.1</span> Definitions</h2>
<p>We’ll consider a few forms of integer programs in this course. A
<strong>(pure) integer (linear) program</strong><a href="#fn44"
class="footnote-ref" id="fnref44" role="doc-noteref"><sup>44</sup></a>
(<strong>IP</strong>)<a href="#fn45" class="footnote-ref" id="fnref45"
role="doc-noteref"><sup>45</sup></a> is a linear program where
<em>all</em> the decision variables are required to be integer, i.e. it
is a problem of the form<a href="#fn46" class="footnote-ref"
id="fnref46" role="doc-noteref"><sup>46</sup></a>:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}\\
\text{s.t.}&amp;&amp; \mathbf{A}\mathbf{x}&amp;\leq\mathbf{b}\\
     &amp;&amp; \mathbf{x}&amp;\in\mathbb{I}^n_+
\end{align*}
</span></p>
<p>In contrast, a <strong>mixed integer (linear) program</strong>
(<strong>MIP</strong>) is a linear program where some, but not
necessarily all, of the decision variables are required to be integer,
i.e.</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}+ \mathbf{h}\mathbf{y}\\
\text{s.t.}&amp;&amp; \mathbf{A}\mathbf{x}+
\mathbf{G}\mathbf{y}&amp;\leq\mathbf{b}\\
     &amp;&amp; \mathbf{x}&amp;\in\mathbb{I}^n_+ \\
     &amp;&amp; \mathbf{y}&amp;\geq\mathbf{0}
\end{align*}
</span></p>
<p>A MIP is more flexible that a pure IP, but much of the theory we
cover will be easier to talk about for IPs. When we present results for
IPs, know that they can likely be extended to MIPs as well, but with
some minor modifications.</p>
<p>A <strong>binary integer (linear) program</strong>
(<strong>BIP</strong>) is a subclass of IPs where the variables are
restricted not just to integers, but to either one of the values <span
class="math inline">0</span> or <span class="math inline">1</span>. Thus
we can define a BIP as having the form:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}\\
\text{s.t.}&amp;&amp; \mathbf{A}\mathbf{x}&amp;\leq\mathbf{b}\\
     &amp;&amp; \mathbf{x}&amp;\in\{0,1\}^n
\end{align*}
</span></p>
<p>A BIP is sometimes also called a <strong>0-1 integer (linear)
program</strong>.</p>
<p>As you can see, every IP by definition has an associated LP
underlying it, obtained from the IP by removing the integrality
constraints. This underlying LP is very important in the study of
integer programs, and is known as the IP’s <strong>LP
relaxation</strong> or <strong>linear relaxation</strong><a href="#fn47"
class="footnote-ref" id="fnref47"
role="doc-noteref"><sup>47</sup></a>.</p>
<h2 data-number="5.2" id="sec:ipRoundingNotEnough"><span
class="header-section-number">5.2</span> Rounding is not enough</h2>
<p>Right about now, you may be wondering how important IP’s integer
restriction really is. Can’t we just solve the related LP, round the
solution to the nearest integer, then be done with it?</p>
<p>Theoretically, the answer is a resounding no. Practically, the answer
may change depending on your requirements. But let’s try to illustrate
why the rounding method could be problematic. Consider the following
integer program:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 12x_1 + 10x_2 &amp; \\
\text{s.t.}&amp;&amp; -7x_1 + 5x_2 &amp; \leq 5 \\
     &amp;&amp;  9x_1 +  7x_2 &amp; \leq 54 \\
     &amp;&amp; x_1,x_2 &amp; \in\mathbb{I}_+
\end{align*}
</span></p>
<p>We’ve shown this 2-dimensional IP in a plot below. Shaded in gray is
the feasible region to the problem’s LP relaxation. The plotted points
are all the feasible solutions to the IP, i.e. the points inside the LP
relaxation’s feasible region which are also integer. In this case, you
can verify graphically that the optimal solution to the LP relaxation is
<span class="math inline">(x_1, x_2)=(2.5, 4.5)</span> with an objective
value of 75.</p>
<svg width="350" height="350" class="lpDraw" base="roundingIp" altArgs="{&quot;chooseObjVals&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Say we’d like to find our integer solution by simply rounding the
optimal LP relaxation solution. The first difficulty would be
determining which way (up vs. down) to round the numbers. But another,
more fundamental difficulty is that there is no guarantee that
<em>any</em> rounded solution will be feasible. Indeed, that is the case
we find ourselves in here, as each of the rounded solutions <span
class="math inline">(2, 4), (2, 5), (3, 4)</span>, and <span
class="math inline">(3, 5)</span> are infeasible<a href="#fn48"
class="footnote-ref" id="fnref48"
role="doc-noteref"><sup>48</sup></a>.</p>
<p>Ok, so say instead you just want to find the feasible integer
solution that is closest to the LP relaxation solution. Putting aside
the question of how to do that, there is no guarantee that even that
solution will be the optimal integer solution. Indeed, in this example
the closest feasible integer solutions are <span class="math inline">(2,
3)</span> and <span class="math inline">(3, 3)</span>, of which <span
class="math inline">(3, 3)</span> has the best objective value at 66.
But in fact the best integer solution is <span
class="math inline">(6,0)</span> with an objective value of 72, a 9%
increase!</p>
<p>Even worse still, we’ll often formulate BIPs such that the
interpretation of the 0-1 variable is whether or not to take some
action. For some types of problems, it’s not at all uncommon for the LP
relaxation solution to a BIP to be every variable taking the value <span
class="math inline">0.5</span>! Such a solution would leave you no clue
as to which direction you should round the solutions. In these cases,
considering only the LP relaxation gives you no hint whatsoever about
how to proceed.</p>
<h2 data-number="5.3" id="ip-modeling"><span
class="header-section-number">5.3</span> IP modeling</h2>
<p>Hopefully the preceding section gave you some appreciation for why
integrality constraints can be useful. The aim for this section is to
give you a broader idea of what situations can be modeled with IPs. Of
particular interest is the use of binary variables to encode different
types of logic in our models.</p>
<h3 data-number="5.3.1" id="general-integer-variables"><span
class="header-section-number">5.3.1</span> General integer
variables</h3>
<p>The most straightforward application if IPs is modeling an LP where
the decision variables can’t be fractional. For example, say you’re
building an optimization model to decide how many washing machines to
buy for your fleet of laundromats. There is no way to meaningfully buy,
say, half of a washing machine to deploy in your stores. This is a case
where integer-valued decisions are required.</p>
<p>As far as writing out the model, it is as simple as adding a <span
class="math inline">\mathbf{x}\in\mathbb{I}^n</span> line to your
formulation. For example, suppose in the Wyndor Glass sample LP (eq. <a
href="#eq:prototypeLp">1</a>) we can only make whole batches of each
product. A new formulation would look like:</p>
<p><span id="eq:wyndorIp" class="eqnos"><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq \ \ 4  \\
     &amp;&amp; 2x_2 &amp; \leq 12 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+
\end{align*}
</span><span class="eqnos-number">(15)</span></span></p>
<p>We’ve seen in section <a href="#sec:ipRoundingNotEnough">5.2</a> that
the optimal solution can change quite a bit when moving from real-valued
variables to integral ones, motivating the IP solution techniques we’ll
be exploring later.</p>
<h3 data-number="5.3.2" id="sec:binVarTricks"><span
class="header-section-number">5.3.2</span> Binary variable tricks</h3>
<p>Finding solutions with general integer values is great. But in my
opinion the real power in integer programming comes from using binary
variables to encode new kinds of logic that you can’t replicate in a
linear program. In this section, we will explore some of these binary
variable tricks. We’ll consider eq. <a href="#eq:wyndorIp">15</a>, our
new integer version of the Wyndor glass problem, as a jumping-off point
for our examples.</p>
<h4>
Either/or constraints
</h4>
<p>For our first example, let’s consider a scenario where exactly one
out of two constraints needs to be satisfied, and we get to decide which
one to enforce as part of the problem. For example, let’s consider a
modification to the Wyndor glass IP eq. <a href="#eq:wyndorIp">15</a>
where we have the potential to build a new facility to replace Plant 3.
This new facility would be available for only 13 hours per week.
However, due to updated technology, producing batches of each product
will take less time: Product 1 will require 2 hours at the new Plant 3,
while Product 2 will require only 1 hour. In effect, we’d like to
replace the old Plant 3 constraint with something like:</p>
<p><span class="math display">
\begin{align*}
\text{either}&amp;&amp;3x_1 + 2x_2 \leq 18 \\
\text{or}    &amp;&amp;2x_1 + x_2 \leq 13
\end{align*}
</span></p>
<p>There is no “native” facility for this type of constraint in IP,
we’re still stuck with only linear functions of our decision variables.
But we can implement this “either/or” logic by adding an auxiliary,
binary variable <span class="math inline">y</span> to the problem in a
certain fashion<a href="#fn49" class="footnote-ref" id="fnref49"
role="doc-noteref"><sup>49</sup></a>. Consider the following IP:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq \ \ 4  \\
     &amp;&amp; 2x_2 &amp; \leq 12 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18 + My \\
     &amp;&amp; 2x_1 + x_2 &amp; \leq 13 + M(1 - y)\\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+ \\
     &amp;&amp; y &amp; \in \ \{0, 1\}
\end{align*}
</span></p>
<p>Here, <span class="math inline">M</span><a href="#fn50"
class="footnote-ref" id="fnref50" role="doc-noteref"><sup>50</sup></a>
is some sufficiently large constant (something like 100 would be more
than sufficient in this case).</p>
<p>What did we accomplish by adding <span class="math inline">y</span>
and <span class="math inline">M</span> in this manner? First, let’s
notice that the new constraints are still linear functions of the
variables. (Remember, <span class="math inline">M</span> is a constant
and not a variable.) Now, think what it would mean if <span
class="math inline">y=1</span>. In that case, the constraint</p>
<p><span class="math display">
3x_1 + 2x_2 \leq 18 + My
</span></p>
<p>becomes</p>
<p><span class="math display">
3x_1 + 2x_2 \leq \textit{some very large number}
</span></p>
<p>so that any reasonable setting of the <span
class="math inline">\mathbf{x}</span> variables will satisfy it.
Meanwhile, the constraint</p>
<p><span class="math display">
2x_1 + x_2 \leq 13 + M(1 - y)
</span></p>
<p>becomes just</p>
<p><span class="math display">
2x_1 + x_2 \leq 13
</span></p>
<p>So if we choose <span class="math inline">y=1</span>, then only the
constraint <span class="math inline">2x_1 + x_2 \leq 13</span> will
matter, i.e. we’re using the new facility. Similarly, if we set <span
class="math inline">y=0</span>, then the only constraint that matters is
<span class="math inline">3x_1 + 2x_2 \leq 18</span>, i.e. we’re not
using the new facility and making due with the old one. Thus we’ve
successfully recreated the either/or logic using linear constraints and
binary variables!</p>
<h4>
Functions taking one of <span class="math inline">n</span> possible
values
</h4>
<p>Sometimes the right-hand side of your linear constraints might be
able to take one of several distinct values. As an example, let’s say
that Wyndor’s Plant 3 may be open for additional hours at some extra
cost. It may remain open for 3 extra hours at a cost of $2,000, or it
may remain open for 6 extra hours at a cost of $4,500. How could eq. <a
href="#eq:wyndorIp">15</a> be modified to take this into account? Take a
look at this formulation:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 - 2y_1 - 4.5y_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq \ \ 4  \\
     &amp;&amp; 2x_2 &amp; \leq 12 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18 + 3y_1 + 6y_2 \\
     &amp;&amp; y_1 + y_2 &amp; \leq \ \ 1 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+ \\
     &amp;&amp; y_1,y_2 &amp; \in \ \{0, 1\}
\end{align*}
</span></p>
<p>By constraining <span class="math inline">y_1 + y_2 \leq 1</span>, we
allow only <span class="math inline">(y_1, y_2)\in\{(0, 0),(1, 0),(0,
1)\}</span>. If <span class="math inline">(y_1,y_2)=(0,0)</span> this
would reduce back to the original problem. If <span
class="math inline">(y_1,y_2)=(1,0)</span> then we’d have the situation
where the plant is open for 3 extra hours, and we’ve reduced our profits
by $2,000 to account for the extra cost. Similarly, if <span
class="math inline">(y_1,y_2)=(0,1)</span> then we’ll have an extra 6
hours of use in the plant, but at the required cost of $4,500.</p>
<h4>
Setup costs
</h4>
<p>A common occurrence in OR problems is a setup cost involved in
participating in some activity. Suppose in the Wyndor problem that the
three facilities did not exist yet, so they need to decide which
facilities to build as well as the ultimate product mix. Say that in
order to build any of the plants, they’d need to take out a loan that
they plan to pay back with their weekly profits for the foreseeable
future. If the weekly payback for any given facility is $6,000, how can
we model this with an integer program? Take a look at the following
formulation:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 - 6y_1 - 6y_2 -6y_3&amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq \ \ 4y_1  \\
     &amp;&amp; 2x_2 &amp; \leq 12y_2 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18y_3 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+ \\
     &amp;&amp; y_1,y_2,y_3 &amp; \in \{0, 1\}
\end{align*}
</span></p>
<p>We’ve added new binary variables, <span class="math inline">y_1,
y_2</span>, and <span class="math inline">y_3</span>, which we’d like to
interpret as a value of <span class="math inline">1</span> for <span
class="math inline">y_i</span> means that facility <span
class="math inline">i</span> will be built, and a value of <span
class="math inline">0</span> means it won’t be built. How does that
alter the formulation? We know that building a facility will cost us
$6,000 weekly over the loan term, so we’ll subtract $6,000 from our
weekly profits for any facility via the term <span
class="math inline">-6y_i</span> in the objective. Furthermore, we can
only use the time in each facility if it is built. So the constants on
right-hand sides of the original formulation are all now multiplied by
the corresponding <span class="math inline">y_i</span> variable. This
way, if we decide not to build the facility by setting <span
class="math inline">y_i=0</span>, there is no time available at the
(non-existent) facility. Otherwise, its time is available as usual.</p>
<h4>
Boolean algebra
</h4>
<div class="lectureVideoEmbed"
data-video-id="c73d5c4374034d25b0f305548fd8ddc41d"
data-video-date="2023-09-20">
A quick recap of HW3, then more IP modeling.
</div>
<p>Given binary variables <span class="math inline">x_1, x_2</span> we
can mimic the basic operations from <a
href="https://en.wikipedia.org/wiki/Boolean_algebra">Boolean algebra</a>
(AND, OR, XOR) in integer programs. In each case, we’ll do this with an
auxiliary binary variable <span class="math inline">y</span>. For each
operation, I’ll show the associated truth table (telling the values of
<span class="math inline">y</span> that should correspond to each
possible value of <span class="math inline">x_1, x_2</span>) and the
corresponding set of linear constraints. It’s a good exercise to go
through each row of the table and verify that the constraints do indeed
enforce the relation.</p>
<ul>
<li>AND: <span class="math inline">y=1</span> if and only if <span
class="math inline">x_1=x_2=1</span>:
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
   \begin{align*}
   y&amp;\leq x_1 \\
   y&amp;\leq x_2 \\
   y&amp;\geq x_1 + x_2 - 1 \\
   x_1, x_2, y &amp; \in \{0,1\}
   \end{align*}
   </span>
</div>
</div></li>
<li>OR: <span class="math inline">y=1</span> if and only if <em>at
least</em> one of <span class="math inline">x_1</span> or <span
class="math inline">x_2</span> equals <span
class="math inline">1</span>:
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
   \begin{align*}
   y&amp;\leq x_1 + x_2 \\
   y&amp;\geq x_1 \\
   y&amp;\geq x_2 \\
   x_1, x_2, y &amp; \in \{0,1\}
   \end{align*}
   </span>
</div>
</div></li>
<li>XOR: <span class="math inline">y=1</span> if and only if
<em>exactly</em> one of <span class="math inline">x_1</span> or <span
class="math inline">x_2</span> equals <span
class="math inline">1</span>:
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
   \begin{align*}
   y&amp;\leq x_1 + x_2 \\
   y&amp;\geq x_1 - x_2 \\
   y&amp;\geq x_2 - x_1 \\
   y&amp;\leq 2 - x_1 - x_2 \\
   x_1, x_2, y &amp; \in \{0,1\}
   \end{align*}
   </span>
</div>
</div></li>
</ul>
<p>(It occurred to me while presenting this that maybe it would be
helpful to provide some <em>incorrect</em> formulations for these
concepts, in order to illustrate what might go wrong while modeling. You
can find this in the appendix, section <a
href="#sec:badIpModels">7.4</a>)</p>
<p>Note that these constraint sets wouldn’t normally constitute an IP on
their own, but instead they would be just a subset of the constraints
you’d find inside a larger, more complex problem. Let’s consider the
following addition to the Wyndor IP: The company realizes that they
cannot use the full 18 hours available at Plant 3 if they produce
<em>both</em> Product 1 and Product 2 during a given week, since they’ll
require some down time in order to set up the line for a change in
product. They anticipate this setup to take 2 hours away from their
production time.</p>
<p>We’ll alter eq. <a href="#eq:wyndorIp">15</a> by including three
additional, binary variables <span class="math inline">y_1, y_2</span>,
and <span class="math inline">z</span>. We’ll set up the <span
class="math inline">y_i</span> variables so that <span
class="math inline">y_i=1</span> if we plan to produce any of Product
<span class="math inline">i</span> (i.e. <span
class="math inline">x_i&gt;0</span>), and we’ll let <span
class="math inline">z=1</span> if and only if <span
class="math inline">y_1=y_2=1</span>. The formulation follows:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; y_1 &amp; \leq x_1 \\
     &amp;&amp; My_1 &amp; \geq x_1 \\
     &amp;&amp; y_2 &amp; \leq x_2 \\
     &amp;&amp; My_2 &amp; \geq x_2 \\
     &amp;&amp; z&amp;\leq y_1 \\
     &amp;&amp; z&amp;\leq y_2 \\
     &amp;&amp; z&amp;\geq y_1 + y_2 - 1\\
     &amp;&amp; x_1 &amp; \leq \ \ 4  \\
     &amp;&amp; 2x_2 &amp; \leq 12 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18 - 2z \\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+ \\
     &amp;&amp; y_1,y_2,z &amp; \in \ \{0, 1\}
\end{align*}
</span></p>
<p>The constraints</p>
<p><span class="math display">
\begin{align*}
y_i &amp; \leq x_i \\
My_i &amp; \geq x_i \\
\end{align*}
</span></p>
<p>(with sufficiently large <span class="math inline">M</span>) serve to
ensure that <span class="math inline">y_i=1</span> if and only if <span
class="math inline">x_i&gt;0</span> (which, since we have <span
class="math inline">x_i\in\mathbb{I}</span>, also means <span
class="math inline">x_i\geq1</span>)<a href="#fn51" class="footnote-ref"
id="fnref51" role="doc-noteref"><sup>51</sup></a>. The next constraints
involving <span class="math inline">y_1, y_2</span>, and <span
class="math inline">z</span> are exactly the AND logical constraints
from above, ensuring that <span class="math inline">z=1</span> if and
only if both <span class="math inline">y_1</span> and <span
class="math inline">y_2</span> are 1 (and hence <span
class="math inline">x_1,x_2&gt;0</span>). The final modification comes
in the Plant 3 resource constraint</p>
<p><span class="math display">
3x_1 + 2x_2 \leq 18 - 2z
</span></p>
<p>which serves to reduce the available production time when both
products are being produced.</p>
<h3 data-number="5.3.3" id="sec:ipWordProblems"><span
class="header-section-number">5.3.3</span> Example word problems</h3>
<div class="lectureVideoEmbed"
data-video-id="f24c71ae75c74c6ab8fe1f1146ccea831d"
data-video-date="2023-09-22">
Even more IP modeling. Tried to address the confusion from last lecture,
then modeled a few more word problems.
</div>
<p>Here we present the sample scenarios in section 12.4 of <span
class="citation" data-cites="classText">Hillier and Lieberman (<a
href="#ref-classText" role="doc-biblioref">2021</a>)</span>, and talk
about how to model each scenario. Each formulation will require some
tricks with binary variables.</p>
<h4>
Resource allocation with extra restrictions
</h4>
<blockquote>
<p>The Research and Development Division of the GOOD PRODUCTS COMPANY
has developed three possible new products. However, to avoid undue
diversification of the company’s product line, management has imposed
the following restriction:</p>
<p>Restriction 1: From the three possible new products, at most two
should be chosen to be produced.</p>
<p>Each of these products can be produced in either of two plants. For
administrative reasons, management has imposed a second restriction in
this regard.</p>
<p>Restriction 2: Just one of the two plants should be chosen to be the
sole producer of the new products.</p>
<p>The production cost per unit of each product would be essentially the
same in the two plants. However, because of differences in their
production facilities, the number of hours of production time needed per
unit of each product might differ between the two plants. These data are
given in Table 12.2, along with other relevant information, including
marketing estimates of the number of units of each product that could be
sold per week if it is produced. The objective is to choose the
products, the plant, and the production rates of the chosen products so
as to maximize total profit.</p>
</blockquote>
<figure>
<img src="images/ip-example-1-data.png"
alt="Data for the Good Products Company problem (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Data for the Good Products Company
problem <span class="citation" data-cites="classText">(<a
href="#ref-classText" role="doc-biblioref">Hillier and Lieberman
2021</a>)</span></figcaption>
</figure>
<p>This feels a lot like the Wyndor Glass problem, but there are several
extra restrictions put in. First of all, we have a bound on the number
of items sold per week, but this is something that we could handle in
plain old linear programming. More interesting are Restriction 1 and
Restriction 2, which will require us to add some binary variables to the
formulation and carefully set up the constraints to enforce the desired
logic. To that end, let’s examine the following model<a href="#fn52"
class="footnote-ref" id="fnref52"
role="doc-noteref"><sup>52</sup></a>:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 5x_1 + 7x_2 + 3x_3&amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq 7y_1  \\
     &amp;&amp; x_2 &amp; \leq 5y_2 \\
     &amp;&amp; x_3 &amp; \leq 9y_3 \\
     &amp;&amp; y_1 + y_2 + y_3 &amp; \leq 2 \\
     &amp;&amp; 3x_1 + 4x_2 + 2x_3 &amp; \leq 30 + My_4 \\
     &amp;&amp; 4x_1 + 6x_2 + 2x_3 &amp; \leq 40 + M(1 - y_4) \\
     &amp;&amp; x_1,x_2,x_3 &amp; \in \ \mathbb{I}_+ \\
     &amp;&amp; y_1,y_2,y_3,y_4 &amp; \in \{0, 1\}
\end{align*}
</span></p>
<p>Without the <span class="math inline">y_i</span> variables, this is
essentially just another resource allocation problem like the integer
version of the Wyndor problem eq. <a href="#eq:wyndorIp">15</a>. But now
we have variables <span class="math inline">y_1, y_2, y_3</span> to
account for the problem’s Restriction 1, and <span
class="math inline">y_4</span> accounts for Restriction 2.</p>
<p>How does it work? Well, <span class="math inline">y_4</span> is
applying the either/or constraint trick we saw earlier in section <a
href="#sec:binVarTricks">5.3.2</a>. Notice that if <span
class="math inline">y_4=1</span> (and <span class="math inline">M</span>
is selected large enough) then the constraint on production in Plant 1
has so much slack that any reasonable settings of the <span
class="math inline">x_i</span> variables will not violate it. Thus the
only constraint in effect is the Plant 2 resource constraint. So the
interpretation is that <span class="math inline">y_4=1</span> means that
Plant 2 is the plant chosen to satisfy Restriction 2. Similarly, <span
class="math inline">y_4=0</span> means that Plant 1 is the one selected
plant that handles the production.</p>
<p>How about the other <span class="math inline">y_i</span> variables?
Notice that if <span class="math inline">y_i=0</span> for any <span
class="math inline">i</span>, then the corresponding constraint on <span
class="math inline">x_i</span> becomes <span
class="math inline">x_i\leq0</span>, meaning that Product <span
class="math inline">i</span> cannot be produced. Otherwise, if <span
class="math inline">y_i=1</span>, then <span
class="math inline">x_i</span> is only bounded by the weekly sales
potential from the table, and thus Product <span
class="math inline">i</span> <em>is</em> allowed to be produced. Then
adding the constraint <span class="math inline">y_1 + y_2 + y_3 \leq
2</span> codifies the requirement that at most 2 of the products may be
produced.</p>
<h4>
Violating proportionality
</h4>
<blockquote>
<p>The SUPERSUDS CORPORATION is developing its marketing plans for next
year’s new products. For three of these products, the decision has been
made to purchase a total of five TV spots for commercials on national
television networks. The problem we will focus on is how to allocate the
five spots to these three products, with a maximum of three spots (and a
minimum of zero) for each product.</p>
<p>The following table shows the estimated impact of allocating zero,
one, two, or three spots to each product. This impact is measured in
terms of the profit (in units of millions of dollars) from the
additional sales that would result from the spots, considering also the
cost of producing the commercial and purchasing the spots. The objective
is to allocate five spots to the products so as to maximize the total
profit.</p>
</blockquote>
<figure>
<img src="images/ip-example-2-data.png"
alt="Data for the Supersuds Corporation problem (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Data for the Supersuds Corporation
problem <span class="citation" data-cites="classText">(<a
href="#ref-classText" role="doc-biblioref">Hillier and Lieberman
2021</a>)</span></figcaption>
</figure>
<p>Your first thought for modeling this may be to have integer variables
<span class="math inline">x_1, x_2, x_3</span>, with the value of <span
class="math inline">x_i</span> denoting the number of TV spots allocated
to product <span class="math inline">i</span>. But this won’t work,
because the objective violates the so-called <em>proportionality
assumption</em> for linear functions, i.e. that each extra unit of a
variable affects the value of the function by the same amount. That is
not true here, e.g. for product 1 doubling from 1 spot to 2 does not
double the profit.</p>
<p>Instead, let’s define a separate binary variable for each product and
each possible selection of TV spots for the product. So we’ll have a
binary variables <span class="math inline">y_{ij}</span> such that <span
class="math inline">y_{ij}=1</span> if and only if we decide on <span
class="math inline">j</span> TV spots for product <span
class="math inline">i</span>, and otherwise <span
class="math inline">y_{ij}=0</span>. With this setup, our model would
look like:</p>
<div class="mathSmall">
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; y_{11} + 3y_{12} + 3y_{13} + 2y_{22} + 3y_{23} -
y_{31} + 2y_{32} + 4y_{33}&amp; \\
\text{s.t.}&amp;&amp; y_{11} + y_{12} + y_{13} &amp; \leq 1 \\
     &amp;&amp; y_{21} + y_{22} + y_{23} &amp; \leq 1 \\
     &amp;&amp; y_{31} + y_{32} + y_{33} &amp; \leq 1 \\
     &amp;&amp; y_{11} + 2y_{12} + 3y_{13} + y_{21} + 2y_{22} + 3y_{23}
+ y_{31} + 2y_{32} + 3y_{33} &amp; \leq 5 \\
     &amp;&amp; y_{ij} &amp; \in \{0,1\} \ \ \forall\ i,j
\end{align*}
</span></p>
</div>
<p>The objective is straightforward, coming directly from the numbers in
the table. As for the constraints, lets start with the first three. We
shouldn’t have something like, say, both <span
class="math inline">y_{11}=1</span> and <span
class="math inline">y_{12}=1</span>, since it doesn’t make sense to
allocate both <span class="math inline">1</span> and <span
class="math inline">2</span> spots for the same product. At most one of
<span class="math inline">y_{i1}, y_{i2}</span>, or <span
class="math inline">y_{i3}</span> can be chosen which is why we’ve
included the</p>
<p><span class="math display">
y_{i1} + y_{i2} + y_{i3} \leq 1
</span></p>
<p>constraints.</p>
<p>What about the final (functional) constraint? The left-hand side of
the constraint sums up the total number of TV spots that are allocated.
So the reason that, for example, we see the term <span
class="math inline">3y_{13}</span> is that selecting <span
class="math inline">y_{13}=1</span> allocates 3 spots to product 1, thus
making use of 3 of the available 5 slots. Then the 5 on the right-hand
side enforces that at most 5 TV spots are allocated overall.</p>
<h4>
Covering all characteristics
</h4>
<blockquote>
<p>SOUTHWESTERN AIRWAYS needs to assign its crews to cover all its
upcoming flights. We will focus on the problem of assigning three crews
based in San Francisco to the flights listed in the first column of the
following table. The other 12 columns show the 12 feasible sequences of
flights for a crew. (The numbers in each column indicate the order of
the flights.) Exactly three of the sequences need to be chosen (one per
crew) in such a way that every flight is covered. (It is permissible to
have more than one crew on a flight, where the extra crews would fly as
passengers, but union contracts require that the extra crews would still
need to be paid for their time as if they were working.) The cost of
assigning a crew to a particular sequence of flights is given (in
thousands of dollars) in the bottom row of the table. The objective is
to minimize the total cost of the three crew assignments that cover all
the flights.</p>
</blockquote>
<figure>
<img src="images/ip-example-3-data.png"
alt="Data for the Southwestern Airways problem (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Data for the Southwestern Airways problem
<span class="citation" data-cites="classText">(<a href="#ref-classText"
role="doc-biblioref">Hillier and Lieberman 2021</a>)</span></figcaption>
</figure>
<p>We can model this problem in the following way, with the binary
variable <span class="math inline">x_i=1</span> if we assign sequence
<span class="math inline">i</span> to some crew, and otherwise <span
class="math inline">x_i=0</span>:</p>
<div class="mathSmall">
<p><span class="math display">
\begin{align*}
\text{min}&amp;&amp; 2x_1 + 3x_2 + 4x_3 + 6x_4 + 7x_5 + 5x_6 &amp; \\
     &amp;&amp; + 7x_7 + 8x_8 + 9x_9 + 9x_{10} + 8x_{11} + 9x_{12}&amp;
\\
\text{s.t.}&amp;&amp; x_1 + x_4 + x_7 + x_{10} &amp; \geq 1
\qquad  \text{(SF to LA)} \\
     &amp;&amp; x_2 + x_5 + x_8 + x_{11} &amp; \geq 1 \qquad \text{(SF
to Den)} \\
     &amp;&amp; x_3 + x_6 + x_9 + x_{12} &amp; \geq 1 \qquad \text{(SF
to Sea)} \\
     &amp;&amp; x_4 + x_7 + x_9 + x_{10} + x_{12} &amp; \geq 1 \qquad
\text{(LA to Chi)} \\
     &amp;&amp; x_1 + x_6 + x_{10} + x_{11} &amp; \geq 1 \qquad
\text{(LA to SF)} \\
     &amp;&amp; x_4 + x_5 + x_9 &amp; \geq 1 \qquad \text{(Chi to Den)}
\\
     &amp;&amp; x_7 + x_8 + x_{10} + x_{11} + x_{12} &amp; \geq 1 \qquad
\text{(Chi to Sea)} \\
     &amp;&amp; x_2 + x_4 + x_5 + x_9 &amp; \geq 1 \qquad \text{(Den to
SF)} \\
     &amp;&amp; x_5 + x_8 + x_{11} &amp; \geq 1 \qquad \text{(Den to
Chi)} \\
     &amp;&amp; x_3 + x_7 + x_8 + x_{12} &amp; \geq 1 \qquad \text{(Sea
to SF)} \\
     &amp;&amp; x_6 + x_9 + x_{10} + x_{11} + x_{12} &amp; \geq 1 \qquad
\text{(Sea to LA)} \\
     &amp;&amp; \sum_{j=1}^{12} x_j &amp; = 3 \qquad \text{(3 crews)} \\
     &amp;&amp; x_j &amp; \in \{0,1\} \ \ \ \forall\ j
\end{align*}
</span></p>
</div>
<p>The objective function is straightforward: if we assign one of the
sequences to some crew, then we must pay the costs according to the
bottom row of the table. Our constraints are that we are required to
cover every flight. Take the first constraint for example. This is the
constraint that enforces that we must have some crew flying from SF to
LA. Which sequences contain that flight? From the first row in the
table, we see this leg is included in sequences 1, 4, 7, and 10. So we
are required to select at least one of those sequences to make sure
there is a crew flying from SF to LA, hence we have the constraint <span
class="math inline">x_1 + x_4 + x_7 + x_{10} \geq 1</span>.</p>
<p>In the final formulation, we follow this logic for every flight in
the table. Lastly, we are required to make an assignment for three
crews, which we encode with the <span
class="math inline">\sum_{j=1}^{12} x_j = 3</span> constraint.</p>
<h3 data-number="5.3.4" id="sec:ipModelDataSep"><span
class="header-section-number">5.3.4</span> Model/data separation</h3>
<div class="lectureVideoEmbed"
data-video-id="ca5c6f5b711b4646ac87678cf72beac21d"
data-video-date="2023-09-25">
Even more IP modeling, this time with model/data separation.
</div>
<p>The above ad-hoc modeling is useful, but in real applications we
often have to solve different, but similarly structured models on some
regular schedule. We’d prefer not to write a new model from scratch
every time we need to solve one. As we discussed in section <a
href="#sec:lpModelDataSep">4.4.4</a>, the best practice is to write<a
href="#fn53" class="footnote-ref" id="fnref53"
role="doc-noteref"><sup>53</sup></a> a base, general model which encodes
all the logic for the problem, then inject the relevant problem data
when an instance needs to be solved.</p>
<p>To that end, in this section we’ll present some generalized IP
formulations for common OR problems.</p>
<h4>
Knapsack
</h4>
<p>We’ll start with a simple one, the <a
href="https://en.wikipedia.org/wiki/Knapsack_problem">knapsack
problem</a>. The classical framing is something like this: you’re going
on a camping trip. The weight you can carry in your backpack is limited
to <span class="math inline">W\in\mathbb{R}</span>. There are <span
class="math inline">n</span> items you can take with you, and for each
<span class="math inline">j\in\{1,2,\dots,n\}</span>, item <span
class="math inline">j</span> has some weight <span
class="math inline">w_j</span> and some value to you <span
class="math inline">v_j</span>. The goal is to select which items to
take with you, subject to the weight constraint, such that the total
value of the items taken is maximized.</p>
<p>We can model this problem with binary variables <span
class="math inline">x_j</span>, <span
class="math inline">j\in\{1,2,\dots,n\}</span> so that <span
class="math inline">x_j=1</span> if we choose to take item <span
class="math inline">j</span>, and otherwise <span
class="math inline">x_j=0</span>. The formulation looks like:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \sum_{j=1}^n v_jx_j&amp; \\
\text{s.t.}&amp;&amp; \sum_{j=1}^n w_jx_j&amp;\leq W \\
&amp;&amp;x_j&amp;\in\{0, 1\} \ \ \forall \ j\in\{1,2,\dots,n\}
\end{align*}
</span></p>
<h4>
Set covering
</h4>
<p>The <a href="https://en.wikipedia.org/wiki/Set_cover_problem">set
covering problem</a> is another classic OR problem with several
applications (the Southwestern Airlines crew scheduling problem in
section <a href="#sec:ipWordProblems">5.3.3</a> was one example). In
abstract terms, the idea is that there is some set of items <span
class="math inline">S</span>, and some number of <span
class="math inline">n</span> subsets<a href="#fn54" class="footnote-ref"
id="fnref54" role="doc-noteref"><sup>54</sup></a> <span
class="math inline">S_j\subseteq S</span>, <span
class="math inline">j\in\{1,2,\dots,n\}</span>. The idea is to choose
some collection of the subsets so that every member of <span
class="math inline">S</span> is also present in at least one subset.</p>
<p>Ok, that was a mouthful, let’s try to explain with an example.
Remember the airline crew scheduling problem referenced above? In that
case, the base set <span class="math inline">S</span> was the set of
flight segments that the airline needed to fly (SF to LA, Chicago to
Denver, etc.). The <span class="math inline">S_j</span> subsets were the
feasible flight sequences, like sequence 6 from the table that consisted
of flying from SF to Seattle, then Seattle to LA, and finally LA to SF.
Our job was to select the flight sequences such that every flight
segment was flown at least once<a href="#fn55" class="footnote-ref"
id="fnref55" role="doc-noteref"><sup>55</sup></a>.</p>
<p>Let’s give one more example to motivate our formulation. Say a new
city is deciding where to place their fire stations. They require that
every neighborhood in the city can be reached in under 5 minutes by at
least one fire station. There are <span class="math inline">n</span>
potential building sites for the new stations, and <span
class="math inline">m</span> different neighborhoods in the city (so
<span class="math inline">S=\{1,2,\dots,m\}</span>). For each potential
building site <span class="math inline">j\in\{1,2,\dots,n\}</span>,
there is a set <span class="math inline">S_j\subseteq S</span> of
neighborhoods that can be reached from that site in under 5 minutes.
There is also a cost <span class="math inline">c_j\in\mathbb{R}</span>
associated with building a station at site <span
class="math inline">j</span>. How can the city minimize building costs
while still meeting the requirements?</p>
<p>Our formulation will include binary variables <span
class="math inline">x_j</span> with the interpretation that a station
will be built at site <span class="math inline">j</span> if and only if
<span class="math inline">x_j=1</span>. The formulation follows<a
href="#fn56" class="footnote-ref" id="fnref56"
role="doc-noteref"><sup>56</sup></a>:</p>
<p><span class="math display">
\begin{align*}
\text{min}&amp;&amp; \sum_{j=1}^n c_jx_j&amp; \\
\text{s.t.}&amp;&amp; \sum_{j:i\in S_j} x_j&amp;\geq 1 &amp; \forall
i\in\{1,2,\dots,m\}\\
&amp;&amp;x_j&amp;\in\{0, 1\} &amp; \forall \ j\in\{1,2,\dots,n\}
\end{align*}
</span></p>
<h4>
Traveling salesman
</h4>
<p>We’ve touched on the traveling salesman problem (TSP) already, way
back in section <a href="#sec:tsp">2.2.1</a>. This is the famous problem
where a salesman has a list of cities to visit and needs to find the
shortest possible path that leads him through every city before
returning to the starting point.</p>
<p>To formalize things a bit, say the salesman needs to visit a list of
<span class="math inline">n</span> cities, and the distances between any
two cities <span class="math inline">i,j\in\{1,\dots,n\}, i\neq j</span>
is known and denoted as <span class="math inline">d_{ij}</span><a
href="#fn57" class="footnote-ref" id="fnref57"
role="doc-noteref"><sup>57</sup></a>. We’ll use binary variables <span
class="math inline">x_{ij}</span> for each <span
class="math inline">i,j\in\{1,\dots,n\}, i\neq j</span>, with the
interpretation that <span class="math inline">x_{ij}=1</span> if and
only if the salesman chooses to travel directly from city <span
class="math inline">i</span> to city <span class="math inline">j</span>
as part of his path. A first attempt at this model might look like
this:</p>
<p><span class="math display">
\begin{align*}
\text{min}&amp;&amp;
\sum_{i\in\{1,\dots,n\}}\sum_{j\in\{1,\dots,n\}:j\neq i}
d_{ij}x_{ij}&amp; \\
\text{s.t.}&amp;&amp; \sum_{j\in\{1,\dots,n\}:j\neq i} x_{ij} &amp;=
1&amp;&amp; \forall \ i\in\{1,\dots,n\}\\
&amp;&amp; \sum_{i\in\{1,\dots,n\}:i\neq j} x_{ij} &amp;= 1&amp;&amp;
\forall \ j\in\{1,\dots,n\}\\
&amp;&amp;x_{ij}&amp;\in\{0, 1\} &amp;&amp; \forall \ i\neq j
\end{align*}
</span></p>
<p>On first inspection, this <em>looks like</em> it’s a correct
formulation. There are two groups of constraints above. In the first
group you set some <span class="math inline">i</span>, then amongst all
<span class="math inline">j\neq i</span> you ensure that exactly one
<span class="math inline">x_{ij}</span> equals <span
class="math inline">1</span>. This has the effect of enforcing that the
salesman leaves every town exactly once. The second group of constraints
does something similar, enforcing that the salesman arrives in every
town exactly once.</p>
<p>So, what’s the problem? It might not be evident initially<a
href="#fn58" class="footnote-ref" id="fnref58"
role="doc-noteref"><sup>58</sup></a>, but this formulation does nothing
to eliminate so-called <em>subtours</em> in the formulation. That is to
say, the feasible solutions to the above model include a solution where
the salesman visits, say, the first half of the cities in one tour and
the second half of the cities in a second, separate tour, with no links
between the two. A solution including subtours is illustrated below.</p>
<figure>
<img src="images/subtours.png" alt="TSP subtours (Wolsey 2020)" />
<figcaption aria-hidden="true">TSP subtours <span class="citation"
data-cites="wolsey2020">(<a href="#ref-wolsey2020"
role="doc-biblioref">Wolsey 2020</a>)</span></figcaption>
</figure>
<p>To recover a valid formulation, we’ll need to include constraints
that make these subtours impossible. How might we do that? Consider the
above image, where we see a subtour among cities 3, 8, and 9. We can
keep this from happening by way of a constraint that ensures that the
salesman travels at least once between some city in the set <span
class="math inline">\{3, 8, 9\}</span> and another city not in that set,
i.e. a city in the complement set <span class="math inline">\{1, 2, 4,
5, 6, 7, 10\}</span>. That is, we can add the constraint:</p>
<p><span class="math display">
\sum_{i\in\{3, 8, 9\}}\sum_{j\in\{1, 2, 4, 5, 6, 7, 10\}}x_{ij} \geq 1
</span></p>
<p>Alternatively, we could write the constraint in terms of just the
original set <span class="math inline">\{3, 8, 9\}</span> by restricting
the number of edges between set members to less than 3 (the size of the
set).</p>
<p><span class="math display">
\sum_{i\in\{3, 8, 9\}}\sum_{j\in\{3, 8, 9\}}x_{ij} \leq 2
</span></p>
<p>Of course, this constraint will only eliminate the possibility of
that one subtour (and its complement). There are plenty of other
subtours possible, one for essentially every subset of <span
class="math inline">\{1,\dots,n\}</span>. So a truly valid formulation
for the TSP must include one of these <strong>subtour elimination
constraints</strong> for every<a href="#fn59" class="footnote-ref"
id="fnref59" role="doc-noteref"><sup>59</sup></a> subset <span
class="math inline">S\subseteq\{1,\dots,n\}</span><a href="#fn60"
class="footnote-ref" id="fnref60" role="doc-noteref"><sup>60</sup></a>.
Such a formulation including these constraints<a href="#fn61"
class="footnote-ref" id="fnref61" role="doc-noteref"><sup>61</sup></a>
could look like<a href="#fn62" class="footnote-ref" id="fnref62"
role="doc-noteref"><sup>62</sup></a>:</p>
<div class="mathSmall">
<p><span class="math display">
\begin{align*}
\text{min}&amp;&amp;
\sum_{i\in\{1,\dots,n\}}\sum_{j\in\{1,\dots,n\}:j\neq i}
d_{ij}x_{ij}&amp; \\
\text{s.t.}&amp;&amp; \sum_{j\in\{1,\dots,n\}:j\neq i} x_{ij} &amp;=
1&amp;&amp; \forall \ i\in\{1,\dots,n\}\\
&amp;&amp; \sum_{i\in\{1,\dots,n\}:i\neq j} x_{ij} &amp;= 1&amp;&amp;
\forall \ j\in\{1,\dots,n\}\\
&amp;&amp; \sum_{i\in S}\sum_{j\in S:i\neq j}x_{ij} &amp;\leq |S|-1
&amp;&amp; \forall \ S\subseteq \{1,\dots,n\}, S\neq\emptyset\\
&amp;&amp;x_{ij}&amp;\in\{0, 1\} &amp;&amp; \forall \ i\neq j
\end{align*}
</span></p>
</div>
<h2 data-number="5.4" id="solving-ips-with-software"><span
class="header-section-number">5.4</span> Solving IPs with software</h2>
<div class="lectureVideoEmbed"
data-video-id="ef4eb455a3e9454c84cd09e5658306c21d"
data-video-date="2023-09-27">
HW4 review and IP software.
</div>
<p>Let’s now talk a bit about using software to solve integer
programming problems. This discussion is an extension to the one we
already had in section <a href="#sec:lpSoftware">4.4</a>, where we spoke
about solvers in the context of linear programs. Much of what we said
there applies here as well, and there is significant overlap between the
best LP solvers and best IP solvers.</p>
<h3 data-number="5.4.1" id="solvers-1"><span
class="header-section-number">5.4.1</span> Solvers</h3>
<p>Speaking of, let’s talk a bit more about IP solvers. In my opinion,
integer programs sit in something of a sweet spot where the types of
problems you can model are broad and useful, while at the same time
software has improved to a point that the models are viable to be solved
within reasonable time frames. To illustrate the effects of recent
software improvements, let’s consider the case of Gurobi. The company
was founded 2008. As of their latest major version release (10.0) in
November 2022, <a
href="https://www.gurobi.com/features/gurobi-optimizer-delivers-unmatched-performance/">they
reported a 75x speedup</a> in solve times over the 1.1 version. Note
that this includes just the software improvements, not taking into
account the hardware advances in that period as well.</p>
<p>As mentioned earlier, there are basically two classes of solvers
available: the free, open source ones (<a
href="https://www.coin-or.org/">CBC</a>, <a
href="https://scipopt.org/">SCIP</a>, <a
href="https://highs.dev/">HiGHS</a>), and the commercial (paid) ones (<a
href="https://www.gurobi.com/">Gurobi</a>, <a
href="https://www.ibm.com/products/ilog-cplex-optimization-studio/cplex-optimizer">CPLEX</a>,
<a
href="https://www.fico.com/en/products/fico-xpress-optimization">Xpress</a>,
<a href="https://www.shanshu.ai/copt/">COPT</a>). As far as performance,
you generally get what you pay for. For the last couple decades,
regularly updated performance benchmarks for these solvers have been
published <span class="citation" data-cites="solverBenchmarks">(<a
href="#ref-solverBenchmarks" role="doc-biblioref"><span>“Mittelmann
Benchmarks,”</span> n.d.</a>)</span>. The <a
href="https://plato.asu.edu/ftp/milp.html">latest MIP benchmarks</a><a
href="#fn63" class="footnote-ref" id="fnref63"
role="doc-noteref"><sup>63</sup></a> are indicative of the usual trend,
that the commercial offerings can solve far more of the test instances
within the specified time limit, and the solve times are generally 5-10x
faster<a href="#fn64" class="footnote-ref" id="fnref64"
role="doc-noteref"><sup>64</sup></a>.</p>
<p>License costs for this software can be expensive, but you don’t
always need to pay a lot to use them. You can usually download and use
the big commercial solvers on smaller problems in non-commercial
contexts, with limits on the number of variables and constraints in your
models. But the limits are such that they would generally not be
offering a large benefit over the free solvers anyway. More useful for
you, the commercial solvers do offer free licenses to students and
academics for non-commercial use, and these licenses do not come with
any size limitations<a href="#fn65" class="footnote-ref" id="fnref65"
role="doc-noteref"><sup>65</sup></a>. Lastly, even commercial users can
request free (but temporary) trial licenses for development purposes,
letting you “try before you buy” when you have a new use case in
mind.</p>
<h3 data-number="5.4.2" id="sec:solvingIpsWithPython"><span
class="header-section-number">5.4.2</span> Solving IPs with Python</h3>
<div class="lectureVideoEmbed"
data-video-id="10f182354fe7429ab62d9d1887008ac11d"
data-video-date="2023-09-29">
Finish Python IPs, begin complexity theory.
</div>
<p>Now that we’ve got some modeling down, let’s see how we can implement
the models using Python code. In the following notebook, we illustrate
how to set up several of the models explored above, with special
attentions paid to the generalized models of section <a
href="#sec:ipModelDataSep">5.3.4</a>.</p>
<script src="https://gist.github.com/73f227dfef3ba217c11fe80db18d6b5f.js"></script>
<h2 data-number="5.5" id="sec:complexityIntro"><span
class="header-section-number">5.5</span> Intro to complexity</h2>
<p>I’ve mentioned already that IPs are much harder to solve than LPs,
and in playing with some of the last notebooks you may have seen how
solve times can increase with relatively small increases in the size of
the random instances we solve. It turns out there is some deep theory
that goes toward explaining why we have such difficulties. This theory
is known as <strong>computational complexity theory</strong>, which is
concerned with how much effort is required to solve problems of
different types. We won’t be able to do much more than scratch the
surface of it here, but I thought it was important enough to explain a
bit of the basics<a href="#fn66" class="footnote-ref" id="fnref66"
role="doc-noteref"><sup>66</sup></a>.</p>
<h3 data-number="5.5.1" id="combinatorial-explosion"><span
class="header-section-number">5.5.1</span> Combinatorial explosion</h3>
<p>Let’s consider again that notebook we just saw in section <a
href="#sec:solvingIpsWithPython">5.4.2</a>. Scroll down to the end where
we solve some randomly-generated TSP instances. Let’s solve some more
instances, starting with 5 cities. When you run the cell, you’ll see the
logs provided by the Gurobi solver. One of the first lines should read
“Optimize a model with 20 rows, 20 columns, and 60 nonzeros.” What does
this mean? Well, there is a matrix underlying every IP or LP we solve,
and these stats tell you about the size of this matrix. Just like when
we set up problems to solve simplex, the rows correspond to the model
constraints, and the columns correspond to the variables. The number of
non-zeros refers to the numerical values inside the matrix,
corresponding to each time a variable has a non-zero coefficient in some
constraint.</p>
<p>What we’re interested in is how the problem size grows as we increase
the number of cities. Changing to 6 cities, we see “47 rows, 30 columns
and 210 nonzeros”. For 7 cities it is “70 rows, 42 columns and 756
nonzeros”. The following table shows the story for different numbers of
cities:</p>
<table>
<tr>
<th>
Cities
</th>
<th>
Rows
</th>
<th>
Columns
</th>
<th>
Nonzeros
</th>
</tr>
<tr>
<td>
5
</td>
<td>
20
</td>
<td>
20
</td>
<td>
60
</td>
</tr>
<tr>
<td>
6
</td>
<td>
47
</td>
<td>
30
</td>
<td>
210
</td>
</tr>
<tr>
<td>
7
</td>
<td>
70
</td>
<td>
42
</td>
<td>
756
</td>
</tr>
<tr>
<td>
8
</td>
<td>
170
</td>
<td>
56
</td>
<td>
1344
</td>
</tr>
<tr>
<td>
9
</td>
<td>
264
</td>
<td>
72
</td>
<td>
2232
</td>
</tr>
<tr>
<td>
10
</td>
<td>
647
</td>
<td>
90
</td>
<td>
8550
</td>
</tr>
<tr>
<td>
11
</td>
<td>
1034
</td>
<td>
110
</td>
<td>
28380
</td>
</tr>
</table>
<p>Immediately we see that the number of variables grow pretty quickly,
but it’s nothing compared to the numbers of constraints and nonzeros.
And there is a good reason I stopped the table at 11 cities: choosing 12
cities or more takes us beyond the size limit of the Gurobi trial
license. But by altering the code (not actually adding constraints, just
counting how often we would have done so) we can continue counting the
number of variables and constraints that would be added for larger
problem (I’m ignoring nonzeros now). I went ahead and did that for a few
more numbers of cities, and I’ll show these extended results in the
following plot:</p>
<div class="plotlyLineChart" data-plot-data="[
    {
        &quot;x&quot;: [5,6,7,8,9,10,11,12,13,14,15],
        &quot;y&quot;: [20,47,70,170,264,647,1034,2521,4108,9921,16398],
        &quot;type&quot;: &quot;scatter&quot;,
        &quot;name&quot;: &quot;Rows&quot;
    }, {
        &quot;x&quot;: [5,6,7,8,9,10,11,12,13,14,15],
        &quot;y&quot;: [20,30,42,56,72,90,110,132,156,182,210],
        &quot;type&quot;: &quot;scatter&quot;,
        &quot;name&quot;: &quot;Columns&quot;
    }
]"
data-plot-layout="{&quot;xaxis&quot;: {&quot;title&quot;: &quot;Cities&quot;}}">

</div>
<p>The plot for the number of columns just looks like a straight line,
but it’s really not. You can toggle lines on or off in the plot by
clicking on the corresponding legend text, go ahead and do that to see
the columns line by itself. It has an upward curve as well. In fact, we
can easily characterize the number of columns in the model in terms of
the number of cities. The variables are simply pairs of cities, so if
there are <span class="math inline">n</span> cities then there are <span
class="math inline">n(n-1)\approx n^2</span> city pairs<a href="#fn67"
class="footnote-ref" id="fnref67" role="doc-noteref"><sup>67</sup></a>.
But the number of rows in the model is largely determined by the number
of subtour elimination constraints, and we have one of those for every
<em>subset</em> of the <span class="math inline">n</span> cities<a
href="#fn68" class="footnote-ref" id="fnref68"
role="doc-noteref"><sup>68</sup></a>. For a set with <span
class="math inline">n</span> elements, there are <span
class="math inline">2^n</span> possible subsets<a href="#fn69"
class="footnote-ref" id="fnref69"
role="doc-noteref"><sup>69</sup></a>.</p>
<p>So even though the <span class="math inline">n^2</span> columns grows
markedly faster than linear, in the face of the truly exponential growth
of <span class="math inline">2^n</span> constraints the plot might as
well be a straight line. The difference between polynomial (e.g. <span
class="math inline">n^2</span>) and exponential growth is at the center
of the theory we will now explore. Unfortunately, for most integer
programs, an exponential growth rate like this is difficult (perhaps
impossible) to avoid.</p>
<h3 data-number="5.5.2" id="complexity-definitions"><span
class="header-section-number">5.5.2</span> Complexity “definitions”</h3>
<p>We’d now like to formalize the type of discussion we had above, where
we tried to tie the <em>size</em> of a problem (e.g., the number of
cities in a TSP) to the <em>number of steps</em> required to solve the
problem (e.g., the number of constraints we need to generate). But since
complexity isn’t a main focus of this course, we won’t be very formal
with our definitions. For the purposes of this class, we’ll define the
<strong>size</strong> of an instance of a given problem to be the size
of a file on your computer that saves all the problem data. Of course,
there could be several different ways to save the same problem data,
some being more efficient than others. So let’s say, again very
informally, that the file is “close to” as efficient as possible at
saving the data.</p>
<p>For a TSP with <span class="math inline">n</span> cities, how big of
a file will we need? At a minimum, we’ll need to save the distances
between each pair of cities, and there are <span
class="math inline">\approx n^2</span> of these pairs to consider.
Furthermore, the actual distance numbers being saved also make a
difference, since it takes less disk space to save a file with the
number 1 in it than a file with the number 1,000,000,000,000,000<a
href="#fn70" class="footnote-ref" id="fnref70"
role="doc-noteref"><sup>70</sup></a>. But it is important to note that
the amount of space needed to store a number is not proportional to the
number itself, but rather its logarithm, in the same way that it doesn’t
take twice as many digits to write 300 than it does to write 150 even
though the first number is twice the second. They both take three digits
to write, because <span class="math inline">2 &lt;
\log_{10}(150)\approx\log_{10}(300) &lt; 3</span><a href="#fn71"
class="footnote-ref" id="fnref71"
role="doc-noteref"><sup>71</sup></a>.</p>
<p>Now, say you have an algorithm that solves a given problem type.
We’re interested in the number of “elementary calculations” (think
addition, multiplication, etc.) required to solve any instance of a
problem with size <span class="math inline">s</span>. That number of
steps, written as a function of <span class="math inline">s</span>, is
called the <strong>running time</strong> of the algorithm. We’ll say
that an algorithm is <strong>polynomial</strong> (or
<strong>polynomial-time</strong>) if the number of steps required is
<span class="math inline">&lt; s^r</span> for some <span
class="math inline">r\in\mathbb{R}</span>.</p>
<p>Although we’re ultimately working with optimization problems, the
questions we’ll be focusing on here relate to <strong>decision
problems</strong>, i.e. questions for which the answer is either yes or
no. But the two notions are related, in that given any optimization
problem we can form a “decision version” of the problem. For example,
the TSP asks you to find a minimum length tour that visits every city.
The decision version would be something like “is there a tour that
visits every city with length at most <span
class="math inline">k</span>” for some number <span
class="math inline">k</span><a href="#fn72" class="footnote-ref"
id="fnref72" role="doc-noteref"><sup>72</sup></a>.</p>
<p>Finally, I should note that while it may look like I’m being lazy in
approximating e.g. <span class="math inline">n(n-1)\approx n^2</span>
(for the number of variables in our TSP model), it is actually a defacto
rule in the theory to “not sweat the small stuff”<a href="#fn73"
class="footnote-ref" id="fnref73" role="doc-noteref"><sup>73</sup></a>.
The important thing is how the function grows as <span
class="math inline">n</span> grows, and for <span
class="math inline">n(n-1) = n^2 - n</span> and <span
class="math inline">n</span> very large, that <span
class="math inline">-n</span> term adds very little. Similarly, in the
TSP model we only added a constraint for about half of the possible
subsets, so there were more like <span class="math inline">2^n/2</span>
constraints. But we’re comfortable approximating that by <span
class="math inline">2^n</span> because what matters is more the
<em>shape</em> of the curve than the magnitude.<a href="#fn74"
class="footnote-ref" id="fnref74"
role="doc-noteref"><sup>74</sup></a></p>
<h3 data-number="5.5.3" id="the-classes-mathcalp-and-mathcalnp"><span
class="header-section-number">5.5.3</span> The classes <span
class="math inline">\mathcal{P}</span> and <span
class="math inline">\mathcal{NP}</span></h3>
<p>With these loose definitions in hand, we’re now ready to discuss the
two most famous complexity classes, and a way to win a million
dollars.</p>
<p>The first of these famous classes is <span
class="math inline">\mathcal{NP}</span><a href="#fn75"
class="footnote-ref" id="fnref75" role="doc-noteref"><sup>75</sup></a>.
For a problem to be in <span class="math inline">\mathcal{NP}</span>, it
must be true that given any instance for which the answer is “yes”,
there is a polynomial-time algorithm verifying the “yes” answer.
Importantly, this algorithm is allowed to take a “small” (polynomial in
the instance size) “hint” as input as well as the instance. The idea is
that if someone found out the answer, they could prove it to you
easily.</p>
<p>Taking TSP as an example, if I claim for some instance that there
<em>is</em><a href="#fn76" class="footnote-ref" id="fnref76"
role="doc-noteref"><sup>76</sup></a> a tour with length at most <span
class="math inline">k</span>, I can just provide you with a conforming
tour (ordering of the cities), then you can verify it yourself in
polynomial time by checking the length of that tour. So TSP is in the
class <span class="math inline">\mathcal{NP}</span>, as are (the
decision versions of) LP, IP, and all the optimization problems we’ll
encounter in this class.</p>
<p>The next important class is <span
class="math inline">\mathcal{P}</span>, which is the class of decision
problems in <span class="math inline">\mathcal{NP}</span> for which
there exists a polynomial-time algorithm to solve it (i.e. determine
whether the answer is “yes” or “no”). This would include simple problems
like determining if a list of numbers is in numerical order. It also
includes some perhaps surprising problems, like determining whether a
given number is prime. In fact, the decision version of our old friend
linear programming is also in the class <span
class="math inline">\mathcal{P}</span><a href="#fn77"
class="footnote-ref" id="fnref77"
role="doc-noteref"><sup>77</sup></a>.</p>
<p>By way of the above definition, we know that <span
class="math inline">\mathcal{P}\subseteq\mathcal{NP}</span>, i.e. every
problem that is polynomial-time solvable is polynomial-time verifiable.
A reasonable question, then, is whether there are problems in <span
class="math inline">\mathcal{NP}</span> that are not in <span
class="math inline">\mathcal{P}</span> (i.e. problems that are easy to
verify but difficult to solve). Or is that not the case, so that <span
class="math inline">\mathcal{P}=\mathcal{NP}</span>? The answer is…
well, we actually don’t know the answer! People have been working at
this since the 1970s when these classes were first formalized, but a
proof either way has still remained elusive. There would be interesting
consequences to a proof in either direction<a href="#fn78"
class="footnote-ref" id="fnref78" role="doc-noteref"><sup>78</sup></a>.
The interest is so high that in the year 2000 the Clay Mathematics
Institute named the <span class="math inline">\mathcal{P}</span>
vs. <span class="math inline">\mathcal{NP}</span> problem among its 7 <a
href="https://www.claymath.org/millennium-problems/">Millennium Prize
Problems</a>, a list of important unsolved problems in a wide array of
mathematical fields. The institute will award $1 million to anyone who
resolves a problem from the list<a href="#fn79" class="footnote-ref"
id="fnref79" role="doc-noteref"><sup>79</sup></a>.</p>
<h3 data-number="5.5.4"
id="mathcalnp-complete-and-mathcalnp-hard-problems"><span
class="header-section-number">5.5.4</span> <span
class="math inline">\mathcal{NP}</span>-complete and <span
class="math inline">\mathcal{NP}</span>-hard problems</h3>
<div class="lectureVideoEmbed"
data-video-id="d36704377e374854b910f55e6caf11721d"
data-video-date="2023-10-02">
Wrap up complexity, begin branch and bound
</div>
<p>While the main question in the field, <span
class="math inline">\mathcal{P}\stackrel{?}{=}\mathcal{NP}</span>,
remains unsolved, there are still interesting things to be said about
problems inside <span class="math inline">\mathcal{NP}</span>. One of
the most important notions is that of <span
class="math inline">\mathcal{NP}</span>-completeness. Central to this
theory is the notion of a <strong>problem reduction</strong>, which is a
way of taking an instance of one problem, applying some “small”
(polynomially many) number of tweaks to it, then recovering an instance
of a new problem. A problem is said to be <strong><span
class="math inline">\mathcal{NP}</span>-complete</strong> if it is in
<span class="math inline">\mathcal{NP}</span> and additionally there
exists a way to reduce any other <span
class="math inline">\mathcal{NP}</span> problem to it<a href="#fn80"
class="footnote-ref" id="fnref80"
role="doc-noteref"><sup>80</sup></a>.</p>
<p>Because of this property, one can think of the class of <span
class="math inline">\mathcal{NP}</span>-complete problems as the set of
the “hardest” problems in <span class="math inline">\mathcal{NP}</span>.
This is because a polynomial-time algorithm for an <span
class="math inline">\mathcal{NP}</span>-complete problem would
automatically imply a polynomial-time algorithm for any other <span
class="math inline">\mathcal{NP}</span>-complete problem (by first
applying the polynomial-time reduction, then running the polynomial-time
solution algorithm). It turns out that (the decision version of) IP, as
well as TSP, knapsack, set covering, and several other interesting
problems we can model with IPs, are all <span
class="math inline">\mathcal{NP}</span>-complete.</p>
<p>There is also a related notion called <span
class="math inline">\mathcal{NP}</span>-hardness. A problem is
considered <strong><span
class="math inline">\mathcal{NP}</span>-hard</strong> if, once again,
there exists a polynomial-time reduction from any <span
class="math inline">\mathcal{NP}</span> problem to it. But unlike with
<span class="math inline">\mathcal{NP}</span>-completeness, an <span
class="math inline">\mathcal{NP}</span>-hard problem does not need to be
a member of <span class="math inline">\mathcal{NP}</span> itself. This
allows us to talk about problems of interest that are not decision
problems, e.g. optimization problems like integer programming.</p>
<h3 data-number="5.5.5" id="what-makes-ips-hard"><span
class="header-section-number">5.5.5</span> What makes IPs hard</h3>
<p>It is this theory that lies at the heart of why IPs are so hard to
solve in practice. Since nobody has proven <span
class="math inline">\mathcal{P}\neq\mathcal{NP}</span> we cannot say
with <em>absolute certainty</em> that no efficient method for solving
IPs exists. But the fact remains that IP is an <span
class="math inline">\mathcal{NP}</span>-hard problem, and after decades
of research, nobody has been able to reduce theoretical run times down
below something exponential in the input size. And this is true not just
for IPs, but for <em>any</em> of the <a
href="https://en.wikipedia.org/wiki/List_of_NP-complete_problems">myriad
<span class="math inline">\mathcal{NP}</span>-complete</a> and <span
class="math inline">\mathcal{NP}</span>-hard problems. Even beyond the
“nobody has done it yet” argument, there are other interesting reasons
why most would conjecture <span
class="math inline">\mathcal{P}\neq\mathcal{NP}</span> over <span
class="math inline">\mathcal{P}=\mathcal{NP}</span> (see e.g. <a
href="https://scottaaronson.blog/?p=1720">this blog post</a> from a
well-known theoretical computer scientist). Given the state of things,
what we’ll see in this chapter is that the solution methods currently
used for IPs can all induce exponentially<a href="#fn81"
class="footnote-ref" id="fnref81" role="doc-noteref"><sup>81</sup></a>
growing run-times.</p>
<p>But I’d like to point out, it’s the run times that matter here, and
not the number of possible solutions. Let’s take TSP as an example, for
which there are indeed exponentially many possible solutions, <span
class="math inline">2^n</span> potential tours for an <span
class="math inline">n</span>-city instance. But the number of potential
solutions is not the factor that determines complexity. After all, if I
gave you a list of <span class="math inline">n</span> cities and asked
you to put it in alphabetical order, you wouldn’t lament the <span
class="math inline">2^n</span> potential orderings of the cities and
declare it impossible to find the correct one (the best <a
href="https://en.wikipedia.org/wiki/Sorting_algorithm">sorting
algorithm</a> run times scale like <span class="math inline">n\log
n</span>). And linear programs have <em>infinitely many</em> feasible
solutions, but as we’ve discussed LPs are solvable in polynomial time<a
href="#fn82" class="footnote-ref" id="fnref82"
role="doc-noteref"><sup>82</sup></a>.</p>
<h3 data-number="5.5.6" id="all-hope-is-not-lost"><span
class="header-section-number">5.5.6</span> All hope is not lost</h3>
<p>Given the above, it seems there’s ample reason to be pessimistic
about the quest to find sub-exponential algorithms for integer programs.
Does that mean that, given some integer program of more than modest
size, we should simply bow our heads and wallow in misery, knowing an
optimal solution will forever elude us? Of course not!</p>
<p>First off, there is still a possibility for a proof that <span
class="math inline">\mathcal{P}=\mathcal{NP}</span>! But even in a world
where <span class="math inline">\mathcal{P}\neq\mathcal{NP}</span>, we
still have a chance. The theory is all about how run times grow as the
size goes to infinity, but there is nothing in the theory that says at
what size the problems become intractable. It’s entirely possible that
the size of the problems you’re working on are small enough to solve in
reasonable time.</p>
<p>For example, TSPs have been solved where the number of cities is in
the 10,000s, and problems with hundreds of cities can often be solved
within seconds<a href="#fn83" class="footnote-ref" id="fnref83"
role="doc-noteref"><sup>83</sup></a>. Further, the knapsack problem is
<span class="math inline">\mathcal{NP}</span>-hard, but algorithms exist
for it where the run time is exponential only in the size of the largest
value coefficient, not the number of items considered. So if you’re
dealing with knapsack problems where the objective value coefficients
are guaranteed to not be too large, solving the problem is suddenly
efficient.</p>
<p>Another note is that we’re talking about optimization problems where
we want to provably find the best answer. But in practice, maybe you
don’t need the absolute best answer. Perhaps it is possible to run a
heuristic that finds a “good enough” answer in a reasonable amount of
time. (Although there is a whole section of complexity theory dedicated
to approximation algorithms as well, and sometimes finding decent
approximations is just as hard as finding actual optimal solutions).</p>
<p>All this to say - IPs are hard in general, and some are just too big
to solve in a reasonable amount of time. But the gap between <span
class="math inline">0</span> and “too big” can be substantial, and the
number of useful instances within that gap is immense. Furthermore, a
good knowledge of the usual solution techniques can help you model your
problem in a way that is more likely to be solvable.</p>
<h2 data-number="5.6" id="branch-and-bound"><span
class="header-section-number">5.6</span> Branch and bound</h2>
<p>In this section, we’ll cover the common IP solution technique of
branch and bound. This is a powerful tool deployed in all IP solvers,
but the ideas behind are very simple.</p>
<h3 data-number="5.6.1" id="sec:divideAndConquer"><span
class="header-section-number">5.6.1</span> Divide and Conquer</h3>
<p>Consider the following IP:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 10x_1 + 12x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 + x_2 &amp; \leq \ \ 5  \\
     &amp;&amp; 2x_1 + 4x_2 &amp; \leq 15 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \ \mathbb{I}_+
\end{align*}
</span></p>
<p>We’ve plotted this problem below. As we’ve seen before, the plotted
points are the feasible integer solutions, while the gray-shaded area
corresponds to the feasible region of the problem’s LP relaxation. We’d
like to solve this problem, and while we don’t know how to solve IPs
yet, we <em>can</em> solve the underlying LP relaxation. Furthermore, we
know the following must hold<a href="#fn84" class="footnote-ref"
id="fnref84" role="doc-noteref"><sup>84</sup></a>:</p>
<div id="thm:integerLpOptimalSolution" class="theorem"
data-thm-type="proposition">
<p>Suppose <span class="math inline">P</span> is an integer program, and
further suppose that <span class="math inline">P</span>’s LP relaxation
has an optimal solution <span class="math inline">\mathbf{x}</span> that
is also integer. Then <span class="math inline">\mathbf{x}</span> is an
optimal solution to <span class="math inline">P</span> as well.</p>
</div>
<p>The proof for this one is pretty simple, following easily from the
fact that any feasible (integer) solutions to <span
class="math inline">P</span> are also feasible for <span
class="math inline">P</span>’s LP relaxation.</p>
<p>So let’s just use what we know, solve the LP relaxation, and maybe we
can get lucky and the LP optimal solution will happen to be integer.
Unfortunately, you can verify graphically that the optimal LP solution
comes at <span class="math inline">(x_1, x_2) = (2.5, 2.5)</span> with
an objective value of 55.</p>
<svg width="350" height="350" class="lpDraw" base="bbExample1" altArgs="{&quot;chooseObjVals&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>That didn’t work to find us an integer solution, so what can we do?
We still only know how to solve LPs, so we’d like to keep using that
knowledge. Suppose we do the following: Let’s create two different IPs
by “branching” off our first IP. Let’s call the original IP <span
class="math inline">P</span> and the two new IPs <span
class="math inline">P^1</span> and <span class="math inline">P^2</span>.
We’ll keep the new problems identical to <span
class="math inline">P</span> except with the addition of one new
constraint each. Consider these two formulations:</p>
<p><span class="math display">
\begin{align*}
P^1: &amp;&amp;&amp;                        &amp;\quad  P^2: \\
\text{max}&amp;&amp; 10x_1 + 12x_2
&amp;         &amp;\quad  \text{max}&amp;&amp; 10x_1 + 12x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 + x_2 &amp; \leq \ \
5  &amp;\quad  \text{s.t.}&amp;&amp; x_1 + x_2 &amp; \leq \ \ 5  \\
     &amp;&amp; 2x_1 + 4x_2 &amp; \leq 15   &amp;\quad       &amp;&amp;
2x_1 + 4x_2 &amp; \leq 15 \\
     &amp;&amp; x_1 &amp; \leq \ \ 2        &amp;\quad       &amp;&amp;
x_1 &amp; \geq \ \ 3 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \
\mathbb{I}_+  &amp;\quad       &amp;&amp; x_1,x_2 &amp; \in \ \
\mathbb{I}_+
\end{align*}
</span></p>
<p>What have we done here? Let’s look at the image below, where we’ve
plotted the LP relaxations and feasible integer points for both <span
class="math inline">P^1</span> and <span class="math inline">P^2</span>.
If you hit the “Toggle Plots” button, you can look back at the original
problem <span class="math inline">P</span> and the optimal solution for
that LP relaxation.</p>
<div>
<script>
     bbExampleClickFunc = () => {
          for (plotNum of [1, 2]){
               plotEl = document.getElementById('bbExamplePlot' + plotNum);
               plotEl.style.display = plotEl.style.display === 'none' ? 'block' : 'none';
          }
     }
</script>
<div id="bbExamplePlot1" style="display:block">
<svg width="350" height="350" class="lpDraw" base="bbExample2">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<div id="bbExamplePlot2" style="display:none">
<svg width="350" height="350" class="lpDraw" base="bbExample1" altArgs="{&quot;extraMathText&quot;: [[&quot;P&quot;, 130, 230]], &quot;extraPoints&quot;: [[2.5, 2.5, {&quot;fill&quot;: &quot;blue&quot;, &quot;r&quot;: 5}]], &quot;extraText&quot;: [[&quot;LP optimal&quot;, 160, 190, {&quot;font-size&quot;: &quot;0.7rem&quot;}]]}">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<button class="basicCenter" onClick="bbExampleClickFunc()" style="padding: 0.5rem">
Toggle Plots
</button>
</div>
<p>There are a few important items to note about this decomposition:</p>
<ol type="1">
<li>All the integer feasible solutions for <span
class="math inline">P</span> are also feasible for either <span
class="math inline">P^1</span> or <span
class="math inline">P^2</span>.</li>
<li>Conversely, any integer feasible solution for <span
class="math inline">P^1</span> or <span class="math inline">P^2</span>
is also feasible for <span class="math inline">P</span>.</li>
<li>The optimal solution to <span class="math inline">P</span>’s LP
relaxation is <em>not</em> feasible for either <span
class="math inline">P^1</span> or <span
class="math inline">P^2</span>.</li>
</ol>
<p>The first two items imply that we’re still dealing with the same set
of integer feasible solutions when we go from <span
class="math inline">P</span> to <span class="math inline">P^1</span> and
<span class="math inline">P^2</span>. From the third item, we know that
we’ll come up with a different solution if we solve either <span
class="math inline">P^1</span> or <span class="math inline">P^2</span>’s
LP relaxation, so we have hope again that we can solve an LP and return
an integer feasible solution. This action of splitting the initial
problem into two (or more) sub-problems, while also satisfying the above
three conditions, is known as <strong>branching</strong>. Importantly,
we have the following result relating to sub-problems of <span
class="math inline">P</span> that satisfy conditions 1 and 2:</p>
<div id="thm:subproblemsContainOpt" class="theorem"
data-thm-type="proposition">
<p>Suppose <span class="math inline">P</span>, <span
class="math inline">P^1</span>, and <span class="math inline">P^2</span>
are integer programs with identical objective functions satisfying
conditions 1 and 2 from above. If <span
class="math inline">\mathbf{x}^1</span>, <span
class="math inline">\mathbf{x}^2</span> are optimal solutions to <span
class="math inline">P^1</span> and <span class="math inline">P^2</span>
respectively, then at least one of <span
class="math inline">\mathbf{x}^1</span> or <span
class="math inline">\mathbf{x}^2</span> is optimal for <span
class="math inline">P</span>.</p>
</div>
<div class="proof" for="thm:subproblemsContainOpt">
<p>Suppose for contradiction that neither <span
class="math inline">\mathbf{x}^1</span> nor <span
class="math inline">\mathbf{x}^2</span> are optimal for <span
class="math inline">P</span>. By condition 2 we know both <span
class="math inline">\mathbf{x}^1</span> and <span
class="math inline">\mathbf{x}^2</span> are feasible for <span
class="math inline">P</span>, so there must exist some <span
class="math inline">\mathbf{x}</span> feasible for <span
class="math inline">P</span> such that <span
class="math inline">\mathbf{c}\mathbf{x}&gt;
\mathbf{c}\mathbf{x}^1</span> and <span
class="math inline">\mathbf{c}\mathbf{x}&gt;
\mathbf{c}\mathbf{x}^2</span>. But by condition 1 <span
class="math inline">\mathbf{x}</span> must be feasible for <span
class="math inline">P^i</span> for some <span
class="math inline">i</span>, and <span
class="math inline">\mathbf{c}\mathbf{x}&gt;
\mathbf{c}\mathbf{x}^i</span> contradicts the optimality of <span
class="math inline">\mathbf{x}^i</span> for <span
class="math inline">P^i</span>.</p>
</div>
<p>So by branching, we’ve reduced the process of solving <span
class="math inline">P</span> (which didn’t work for us directly) to
solving <span class="math inline">P^1</span> and <span
class="math inline">P^2</span>.</p>
<h3 data-number="5.6.2" id="dropping-dead-weight"><span
class="header-section-number">5.6.2</span> Dropping dead weight</h3>
<p>Let’s now go ahead and solve the LP relaxations of our two new
sub-problems <span class="math inline">P^1</span> and <span
class="math inline">P^2</span>. You can quickly verify that the for
<span class="math inline">P^1</span> the LP optimal solution is <span
class="math inline">(2, 2.75)</span> with and objective value of 53, and
for <span class="math inline">P^2</span> the LP optimal solution is
<span class="math inline">(3, 2)</span> with an objective value of 54.
And hey, would you look at that! The LP optimal solution to <span
class="math inline">P^2</span> was integer, so by <span class="thmRef"
for="thm:integerLpOptimalSolution"></span> it must <span
class="math inline">P^2</span>’s best integer solution as well!</p>
<p>So <span class="math inline">P^2</span> is now solved, but
unfortunately <span class="math inline">P^2</span> was only half of our
original problem <span class="math inline">P</span>. When we subdivided
<span class="math inline">P</span> we had no way of telling whether
<span class="math inline">P</span>’s optimal solution lay on the <span
class="math inline">P^1</span> side or the <span
class="math inline">P^2</span> side. So we need to return our attention
to <span class="math inline">P^1</span>. Its optimal solution was not
integral, so we’ll need to branch again and create two new sub-problems
for the already-a-sub-problem problem <span
class="math inline">P^1</span>. Right?</p>
<p>Actually, let’s think again about all the information we have. <span
class="math inline">P^2</span> has an optimal integer solution with an
objective value of 54, and by the construction of <span
class="math inline">P^2</span> that same integer solution is feasible
for <span class="math inline">P</span>. Thus we have a
<strong>bound</strong> on an optimal solution to <span
class="math inline">P</span>: it will have a value no lower than that
same 54. We also know that the optimal solution to <span
class="math inline">P^1</span>’s LP relaxation was only 53, so in
particular no integer solutions to <span class="math inline">P^1</span>
can have a value better then 53. So whatever solution we’d get by
eventually solving <span class="math inline">P^1</span>, we know it
won’t have a better objective value than the integer solution we’ve
already found for <span class="math inline">P</span> (via <span
class="math inline">P^2</span>).</p>
<p>All this to say, there is no need to actually solve <span
class="math inline">P^1</span>! The information we’ve already gained
from the LP relaxation tells us that we can just ignore it now (a
process that we will call <strong>pruning</strong> or
<strong>fathoming</strong>), and the optimal solution to <span
class="math inline">P</span> is also the optimal solution to <span
class="math inline">P^2</span>: <span class="math inline">(x_1, x_2) =
(3, 2)</span> with an objective value of 54.</p>
<h3 data-number="5.6.3" id="algorithm-basics"><span
class="header-section-number">5.6.3</span> Algorithm basics</h3>
<div class="lectureVideoEmbed"
data-video-id="98e6e074dd1e406b97eb870ce68ba08d1d"
data-video-date="2023-10-04">
HW 5 review, branch and bound
</div>
<p>The preceding sections displayed the essence of the branch and bound
algorithm for solving integer programs. You initially solve the
underlying LP relaxation. If the optimal solution <span
class="math inline">\mathbf{x}^*</span> is not integer, you
<em>branch</em> by selecting some variable <span
class="math inline">x_i</span> such that <span
class="math inline">x_i^*\not\in\mathbb{I}</span>, then creating two new
IPs that are identical to the original, except to one problem you add a
constraint <span class="math inline">x_i\leq\lfloor x^*_i \rfloor</span>
and to the other you add <span class="math inline">x_i\geq\lceil x^*_i
\rceil</span><a href="#fn85" class="footnote-ref" id="fnref85"
role="doc-noteref"><sup>85</sup></a>. These new problems are called the
<strong>child problems</strong> of the original problem, and any
subsequent children of the child problems are called <strong>descendant
problems</strong>.</p>
<p>You keep recursively branching and solving sub-problems, making use
of the <em>bounding</em> information available from the LP relaxations
and any integer solutions you’ve already found. The optimal value of a
problem’s LP relaxation is an <em>upper bound</em> on both its own
optimal integer solution value and the values of its descendants. Any
integer solutions found are a <em>lower bound</em> on the original
problem’s optimal integer value. This bound information is used
continually to decide which (if any) sub-problems cannot lead to an
optimal solution for the original problem, and thus may be pruned.</p>
<h3 data-number="5.6.4" id="sec:bnbExample"><span
class="header-section-number">5.6.4</span> A branch and bound
example</h3>
<p>Let’s walk through a more involved branch and bound example (from
<span class="citation" data-cites="wolsey2020">Wolsey (<a
href="#ref-wolsey2020" role="doc-biblioref">2020</a>)</span>). It is a
small example, but it will still highlight all the relevant decisions
that need to be made, as well as make use of all possible node pruning
criteria. Consider the following integer program, which we’ll name <span
class="math inline">P</span>:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 4x_1 - x_2 &amp; \\
\text{s.t.}&amp;&amp; 7x_1 - 2x_2 &amp; \leq 14  \\
     &amp;&amp; x_2 &amp; \leq 3 \\
     &amp;&amp; 2x_1 - 2x_2 &amp; \leq 3 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+
\end{align*}
</span></p>
<p>Our first step is the solve the LP relaxation. Doing so leads to a
non-integer optimal solution <span class="math inline">(\frac{20}{7},
3)</span> with objective value <span
class="math inline">\frac{59}{7}</span>. Since this solution is not
integral, we need to branch. While there are multiple ways one could
create the branching sub-problems, for this class we’ll be creating them
as we did in section <a href="#sec:divideAndConquer">5.6.1</a>:
Considering the optimal LP relaxation solution <span
class="math inline">x^*</span>, choose a variable whose value is
fractional then create two sub-problems by adding the constraint <span
class="math inline">x_i^*\leq\lfloor x_i^* \rfloor</span> to one problem
and the constraint <span class="math inline">x_i^*\geq\lceil x_i^*
\rceil</span> to the other. In this case, the only variable with a
fractional value in the LP optimal solution is <span
class="math inline">x_1</span><a href="#fn86" class="footnote-ref"
id="fnref86" role="doc-noteref"><sup>86</sup></a>. So our new problems
are <span class="math inline">P^1</span>, to which we add <span
class="math inline">x_1\leq2</span>, and <span
class="math inline">P^2</span>, to which we’ll add <span
class="math inline">x_1\geq3</span>.</p>
<p>As we continue to branch and add sub-problems, we’ll find it
convenient to have a graphic to reference to help us keep our place. The
below image displays our <strong>branch-and-bound tree</strong> for the
problem so far.</p>
<svg width="450" height="210" class="bbTreeDraw" base="bbTree1">
Sorry, your browser does not support inline SVG.
</svg>
<p>In this graph, each node represents a sub-problem. The gray-colored
nodes are sub-problems that have not yet been <strong>explored</strong>,
meaning that we haven’t attempted to solve the sub-problem yet. If we’ve
already branched on a sub-problem, then its node in the tree is colored
blue. Branches are represented by edges emanating down from the node,
with the text next to the edge describing the inequality added to
achieve each child problem.</p>
<p>If a node has already been explored, we display the sub-problem’s
optimal LP relaxation value next to it. Additionally, next to the root
(top) node, we also keep track of the value of the best <em>integer</em>
solution found so far in the tree. This currently-best integer solution
is known as the <strong>incumbent</strong> solution, and we’ll see how
its objective value can be used to prune nodes whose LP relaxation value
is low. For now we haven’t yet found any integer solutions, so we’ll use
the value <span class="math inline">-\infty</span>.</p>
<p>At this point we’ve explored one node and created two new, unexplored
nodes. We must now choose which unexplored node to examine next. We’ll
discuss later in section <a href="#sec:choosingBNBNodes">5.6.6</a> how
this selection might be made in practice, but ultimately the selection
does not make a difference in the correctness of the algorithm<a
href="#fn87" class="footnote-ref" id="fnref87"
role="doc-noteref"><sup>87</sup></a>. So let’s arbitrarily select <span
class="math inline">P^1</span>.</p>
<p>Now we must solve the LP relaxation for <span
class="math inline">P^1</span><a href="#fn88" class="footnote-ref"
id="fnref88" role="doc-noteref"><sup>88</sup></a>. Doing so gives us an
optimal solution of <span class="math inline">(2, \frac{1}{2})</span>
with an optimal value of <span class="math inline">\frac{15}{2}</span>.
Since the solution is not integer, and we have no global lower bound to
compare against, we must now branch again. Since <span
class="math inline">x_2</span> is the only fractional variable, we will
branch on it to create new sub-problems <span
class="math inline">P^3</span> and <span
class="math inline">P^4</span>.</p>
<svg width="450" height="330" class="bbTreeDraw" base="bbTree2">
Sorry, your browser does not support inline SVG.
</svg>
<p>Let’s continue on. Say we select <span class="math inline">P^2</span>
as the next sub-problem to explore. We attempt to solve its LP
relaxation but instead find that the problem is infeasible. This implies
that the optimal solution to <span class="math inline">P</span> does not
lie on this branch, so we no longer need to explore it. In this case, we
say that <span class="math inline">P^2</span> was <strong>pruned by
infeasibility</strong>. In our graph, we’ll color a node red if we prune
it in this way. Hence our branch and bound tree now looks like:</p>
<svg width="450" height="330" class="bbTreeDraw" base="bbTree3">
Sorry, your browser does not support inline SVG.
</svg>
<p>Let’s make our next node selection. Say we arbitrarily choose <span
class="math inline">P^4</span>. The LP relaxation is solved and returns
an optimal solution <span class="math inline">(2, 1)</span> with
objective value <span class="math inline">7</span>. Since the optimal
solution is also an integer solution, we no longer need to explore this
portion of the graph, and so we will prune <span
class="math inline">P^4</span>. The act of pruning a node after finding
an integer solution is called <strong>pruning by optimality</strong>,
but note that the word “optimality” here is local, as in we’ve found the
optimal integer solution for <span class="math inline">P^4</span>. We do
not know yet if this integer solution is also optimal for <span
class="math inline">P</span>. Furthermore, since this is the first
integer solution we’ve found, it’s also the new incumbent solution for
the problem.</p>
<p>Let’s have the color purple represent a node that is pruned by
optimality, and to further distinguish the node as having an integer
optimal solution, we’ll add an asterisk to the optimal relaxation value.
Our latest version of the branch and bound tree looks like this:</p>
<svg width="450" height="330" class="bbTreeDraw" base="bbTree4">
Sorry, your browser does not support inline SVG.
</svg>
<p>The only remaining unexplored node is <span
class="math inline">P^3</span>. If we solve its LP relaxation, we obtain
a solution <span class="math inline">(\frac{3}{2}, 0)</span> with
objective value <span class="math inline">6</span>. Since the optimal LP
value is 6, the best integer solution for <span
class="math inline">P^3</span> is also no higher than 6. But since the
incumbent solution has an objective value <span
class="math inline">7\geq 6</span>, we have no hope of finding an
improved solution for <span class="math inline">P</span> in this portion
of the tree. So instead of branching on a fractional variable, we
immediately prune <span class="math inline">P^3</span>. Pruning by this
logic is termed <strong>pruning by bound</strong>. In our graph, we’ll
use the color orange for nodes pruned by bound.</p>
<p>Speaking of the graph, we have pruned every single node now with no
remaining nodes to explore. You can see the final tree below, and can
use the buttons under the plot to cycle through each iteration we
completed.</p>
<div>
<script>
     bbTreesClickFunc = (x) => {
          for (plotNum of [1, 2, 3, 4, 5]){
               plotEl = document.getElementById('bbTreePlot' + plotNum);
               if (plotEl.style.display === 'block') {
                    displayed = plotNum;
               }
          }
          newDisplayed = displayed + parseInt(x);
          newDisplayed = newDisplayed === 6 ? 1 : newDisplayed === 0 ? 5 : newDisplayed;
          document.getElementById('bbTreePlot' + displayed).style.display = 'none';
          document.getElementById('bbTreePlot' + newDisplayed).style.display = 'block';
          document.getElementById('bbTreePlotLabel').textContent = 'Iteration ' + newDisplayed;
     }
</script>
<div id="bbTreePlot5" style="display:block">
<svg width="450" height="330" class="bbTreeDraw" base="bbTree5">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<div id="bbTreePlot1" style="display:none">
<svg width="450" height="330" class="bbTreeDraw" base="bbTree1">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<div id="bbTreePlot2" style="display:none">
<svg width="450" height="330" class="bbTreeDraw" base="bbTree2">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<div id="bbTreePlot3" style="display:none">
<svg width="450" height="330" class="bbTreeDraw" base="bbTree3">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<div id="bbTreePlot4" style="display:none">
<svg width="450" height="330" class="bbTreeDraw" base="bbTree4">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<div id="bbTreePlotLabel" style="text-align: center">
Iteration 5
</div>
<div style="display: flex; justify-content: center">
<button class="forwardBackwardButton" id="bbTreePlotBackButton" onClick="bbTreesClickFunc(&quot;-1&quot;)">
</button>
<button class="forwardBackwardButton" id="bbTreePlotForwardButton" onClick="bbTreesClickFunc(&quot;1&quot;)">
</button>
</div>
<script>
     document.getElementById('bbTreePlotBackButton').textContent = '<<';
     document.getElementById('bbTreePlotForwardButton').textContent = '>>';
</script>
</div>
<p>With no further portions of the tree to explore, the incumbent
solution <span class="math inline">(2, 1)</span> from sub-problem <span
class="math inline">P^3</span> must be our optimal solution.</p>
<h3 data-number="5.6.5" id="the-branch-and-bound-algorithm"><span
class="header-section-number">5.6.5</span> The branch and bound
algorithm</h3>
<p>Let’s now write out a full treatment of the branch and bound
algorithm. There are still several details missing from this treatment
(e.g. selection of unexplored nodes, as discussed in section <a
href="#sec:choosingBNBNodes">5.6.6</a>), and there are definitely
alterations and improvements that could be made. The purpose of this
exercise is merely to lay out the bulk of a fully-functional
algorithm.</p>
<p>The notation in what follows mostly mirrors what we’ve seen in our
discussions above. We’ll let <span class="math inline">P=P^0</span>
denote the original IP to be solved. <span
class="math inline">x^*</span> is the current incumbent solution
(i.e. the best-known integer solution). The bound and <span
class="math inline">\underline Z</span> is the best-known lower bound on
the optimal solution value for <span class="math inline">P</span>
(i.e. the value of the incumbent solution), while <span
class="math inline">\overline Z^i</span> is the optimal value of the LP
relaxation of some sub-problem <span class="math inline">P^i</span>.
We’ll let <span class="math inline">L</span> represent the list of
unexplored sub-problems. The act of pruning a sub-problem includes
removing it (and any of its descendants) from <span
class="math inline">L</span>.</p>
<ul>
<li><em>Initialize</em>: Set <span class="math inline">\underline
Z=-\infty</span>, <span class="math inline">L=[P^0]</span>, and <span
class="math inline">x^*</span> undefined.</li>
<li><em>Iterate</em>:
<ul>
<li>If <span class="math inline">L</span> is not empty:
<ul>
<li>Select some sub-problem <span class="math inline">P^i</span> in
<span class="math inline">L</span>.</li>
<li>Solve LP relaxation of <span class="math inline">P^i</span> to
obtain optimal solution <span class="math inline">x^i</span>. Set <span
class="math inline">\overline Z^i</span> to optimal value (or <span
class="math inline">-\infty</span> if infeasible).</li>
<li>If <span class="math inline">\overline Z^i=-\infty</span>:
<ul>
<li>Prune <span class="math inline">P^i</span> by infeasibility.</li>
</ul></li>
<li>Else if <span class="math inline">\overline Z^i\leq\underline
Z</span>:
<ul>
<li>Prune <span class="math inline">P^i</span> by bound.</li>
</ul></li>
<li>Else if <span class="math inline">x^i</span> is integer:
<ul>
<li>Update <span class="math inline">\underline Z=\overline Z^i</span>
and <span class="math inline">x^*=x^i</span>. Prune <span
class="math inline">P^i</span> by optimality.</li>
</ul></li>
<li>Else:
<ul>
<li>Branch on a fractional value in <span class="math inline">x^i</span>
and add the two new sub-problems to <span
class="math inline">L</span>.</li>
</ul></li>
</ul></li>
<li>Else:
<ul>
<li>If <span class="math inline">x^*</span> is undefined, <span
class="math inline">P</span> is infeasible.</li>
<li>Else, return <span class="math inline">x^*</span> as optimal
solution.</li>
</ul></li>
</ul></li>
</ul>
<h3 data-number="5.6.6" id="sec:choosingBNBNodes"><span
class="header-section-number">5.6.6</span> Next nodes and branching
variables</h3>
<p>While working through our branch and bound examples, there were two
places where we had to make decisions on how to proceed:</p>
<ul>
<li>When an LP relaxation solution is fractional, which variable do we
select to create the next branching sub-problems?</li>
<li>When we’ve finished processing a node in the branch and bound tree,
which node do we select to process next?</li>
</ul>
<p>In each case, we made our decision arbitrarily among the available
options. In this section we will talk about some strategies used in
practice and arguments for using them.</p>
<h4>
Choosing the branching variable
</h4>
<p>When a sub-problem’s LP relaxation solution has fractional
components, we must choose one of the fractional variables to branch on.
One common tactic is to select the variable that is “most fractional”,
i.e. the variable whose fractional part (i.e. <span
class="math inline">x_i - \lfloor x_i \rfloor</span>) in the LP
relaxation solution is closest to <span
class="math inline">\frac{1}{2}</span>. The justification for this
selection is that values closer to integer values are perhaps more
likely to take the value they are closest to in an optimal solution,
while values whose integer parts are close to <span
class="math inline">\frac{1}{2}</span> could go either way. But this is
really just a rule of thumb. The logic behind that justification is not
guaranteed to hold true, and selecting variables in this way will not
necessarily lead to faster algorithm run times.</p>
<p>UPDATE: Just after presenting this in class, I happened upon the
following podcast where the guest is the creator of the solver SCIP and
currently heads R&amp;D for Gurobi. According to him, the “most
fractional” rule is (maybe worse than?) useless.</p>
<iframe class="basicCenter" width="560" height="315" src="https://www.youtube.com/embed/8bhIW27vCUQ?si=uVfwGTgca0xboEaT&amp;start=3378" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
<p>Another technique, which we will not cover in detail here, is called
<strong>strong branching</strong>. The idea is to take each
fractional-valued variable and see how much the LP relaxation’s
objective will change if <span class="math inline">x_i</span> is rounded
down versus if <span class="math inline">x_i</span> is rounded up. The
idea is that choosing a branching variable that induces larger
variations in bounds is more likely to lead to quicker pruning, and thus
help to minimize the size of the branch and bound tree. The downside is
that this determination requires solving (or at least running several
simplex iterations on) a different LP for each fractional variable,
which can take significant amounts of time. Most solvers will use some
strong branching, but only apply it selectively when they think the
extra work up front will be rewarded by significantly smaller search
trees later.</p>
<h4>
Choosing the next sub-problem
</h4>
<p>If you’ve just finished processing some node in your branch and bound
tree, and there are multiple unexplored nodes still in the tree, how do
you choose which node to move to next? Two common approaches are the
<strong>depth-first</strong> strategy and the <strong>best node</strong>
strategy.</p>
<p>In a depth-first strategy, you continually work on children of the
last completed node until an integer solution is found. The hope is that
this strategy has the best chance to quickly lead you to an integer
feasible solution, and thus you’ll be able to start pruning other nodes
with this bound. It may also potentially make the sub-problems easier to
solve, since moving from one node to another involves only adding a
single constraint at each point. You would have just computed the
previous optimal basis at the last node, so re-optimization may be
faster. A tree developed while executing a depth-first strategy might
look like this:</p>
<svg width="650" height="380" class="bbTreeDraw" base="depthFirstTree">
Sorry, your browser does not support inline SVG.
</svg>
<p>In a best node strategy, you select the unexplored node with the
highest upper bound, i.e. the a node whose parent had the highest LP
relaxation value. Taking the following tree as an example, we would
select one of <span class="math inline">P^5</span> or <span
class="math inline">P^6</span> before <span
class="math inline">P^3</span> or <span class="math inline">P^4</span>
because the LP relaxation value for <span class="math inline">P^2</span>
is higher than the LP relaxation value for <span
class="math inline">P^3</span>.</p>
<svg width="450" height="330" class="bbTreeDraw" base="bestNodeTree">
Sorry, your browser does not support inline SVG.
</svg>
<p>The intuition here is to stay in the area of the tree with the best
chance of having good integer feasible solutions. For the above tree
(and using the bound information we have from the parent LP relaxations)
<span class="math inline">P^3</span> and <span
class="math inline">P^4</span>’s optimal integer solution can have a
value of at most 19, whereas <span class="math inline">P^5</span> and
<span class="math inline">P^6</span> have a <em>chance</em> for a value
up to 20. This is far from a guarantee of where the best solution will
be, but it’s nonetheless a defensible choice given the information
available. Furthermore, attacking the highest-bounded problems lets you
reduce the upper bounds quicker, potentially helping to prove the
optimality of an incumbent solution.</p>
<p>In practice, a mix of these two strategies is often used. Depth-first
is a popular choice at the beginning of a solve in order to identify a
feasible solution quickly. After that, a mix of the two notions can be
deployed, in an attempt to balance out the need for better feasible
solutions versus reduced upper bounds.</p>
<h3 data-number="5.6.7" id="correctness-and-complexity"><span
class="header-section-number">5.6.7</span> Correctness and
complexity</h3>
<p>So now you have your first IP solving algorithm, but is it guaranteed
to work? The answer is yes, and the key to proving so doesn’t lie in any
interesting theory like we saw for the simplex method.</p>
<p>To start, let’s consider only binary integer programs. In a BIP, all
variables must take a value of 0 or 1, so our branches will always set
some <span class="math inline">x_i=0</span> or <span
class="math inline">x_i=1</span>. In a worst case, the tree for a BIP
with three variables might look like this:</p>
<svg width="650" height="330" class="bbTreeDraw" base="fullTree3d">
Sorry, your browser does not support inline SVG.
</svg>
<p>The tree cannot grow beyond this, because in the bottom row every
variable has been fixed to some value or another<a href="#fn89"
class="footnote-ref" id="fnref89" role="doc-noteref"><sup>89</sup></a>!
For an IP with general integer variables (i.e. not just binary), we can
argue something similar so long as the feasible region of the IP is
bounded. A slightly more subtle argument is needed if the feasible
region is not bounded, but we won’t bother with that here.</p>
<p>But even if the algorithm is valid, another important question is how
many nodes we might need to explore before finishing. And we’ve already
outlined an answer to that above: That worst-case tree for the
3-variable case had 15 nodes in it, and depending on the objective
function and branching/node selection procedures it’s entirely possible
that we’d need to visit each and every one of them before finding the
optimal solution. In general, a BIP with <span
class="math inline">n</span> variables will in the worst case generate a
tree with <span class="math inline">2^n</span> nodes in the final row
(<span class="math inline">n</span> variables, each with 2 choices of
the value taken), and <span class="math inline">2^{n + 1} - 1</span>
nodes in total. A general IP can have even more.</p>
<p>So the number of nodes visited during branch and bound may be
exponential in the number of variables in the problem. This is
unfortunate, but we should have expected it after what we learned in
section <a href="#sec:complexityIntro">5.5</a>. Integer programming is
an <span class="math inline">\mathcal{NP}</span>-hard problem, so we
don’t know any polynomial-time algorithms for it.</p>
<h2 data-number="5.7" id="cutting-planes"><span
class="header-section-number">5.7</span> Cutting planes</h2>
<div class="lectureVideoEmbed"
data-video-id="45565f4e661842a7b84de225dd8ed0a01d"
data-video-date="2023-10-09">
Branch and bound wrap up, begin cutting planes.
</div>
<p>We now turn our attention to cutting planes, another concept that is
often used in conjunction with branch and bound in integer programming
solvers.</p>
<h3 data-number="5.7.1" id="sec:integerHull"><span
class="header-section-number">5.7.1</span> The integer hull</h3>
<p>Consider again our first sample IP in the branch and bound section,
whose formulation I’ve provided again below:</p>
<p><span id="eq:cuttingPlaneExample" class="eqnos"><span
class="math display">
\begin{align*}
\text{max}&amp;&amp; 10x_1 + 12x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 + x_2 &amp; \leq \ \ 5  \\
     &amp;&amp; 2x_1 + 4x_2 &amp; \leq 15 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \ \mathbb{I}_+
\end{align*}
</span><span class="eqnos-number">(16)</span></span></p>
<p>When plotted out, the result is:</p>
<svg width="350" height="350" class="lpDraw" base="bbExample1">
Sorry, your browser does not support inline SVG.
</svg>
<p>Once again, the feasible region to the problem’s LP relaxation is
presented as the gray-shaded area, while the plotted points are the
integer feasible solutions. Now suppose we were to re-formulate the
problem, adding two new constraints like so:</p>
<p><span id="eq:integerHullExample" class="eqnos"><span
class="math display">
\begin{align*}
\text{max}&amp;&amp; 10x_1 + 12x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 + x_2 &amp; \leq \ \ 5  \\
     &amp;&amp; 2x_1 + 4x_2 &amp; \leq 15 \\
     &amp;&amp; x_1 + 2x_2 &amp; \leq 7 \\
     &amp;&amp; x_2 &amp; \leq 3 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \ \mathbb{I}_+
\end{align*}
</span><span class="eqnos-number">(17)</span></span></p>
<p>Let’s take a look at this new problem in the below plot. Using the
“Toggle Plots” button allows you to switch back and forth between this
new formulation eq. <a href="#eq:integerHullExample">17</a> and the
previous one eq. <a href="#eq:cuttingPlaneExample">16</a>.</p>
<div>
<script>
     cpExampleClickFunc = () => {
          for (plotNum of [1, 2]){
               plotEl = document.getElementById('cutPlaneExamplePlot' + plotNum);
               plotEl.style.display = plotEl.style.display === 'none' ? 'block' : 'none';
          }
     }
</script>
<div id="cutPlaneExamplePlot1" style="display:block">
<svg width="350" height="350" class="lpDraw" base="bbExample1" altArgs="{&quot;addConstraints&quot;: [[[1, 2, 7, &quot;l&quot;], [4.5, 1.25]],[[0, 1, 3, &quot;l&quot;], [3, 3.6]]]}">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<div id="cutPlaneExamplePlot2" style="display:none">
<svg width="350" height="350" class="lpDraw" base="bbExample1">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<button class="basicCenter" onClick="cpExampleClickFunc()" style="padding: 0.5rem">
Toggle Plots
</button>
</div>
<p>What do you see when comparing these plots? When moving from eq. <a
href="#eq:cuttingPlaneExample">16</a> to eq. <a
href="#eq:integerHullExample">17</a> the feasible region for the LP
relaxation has shrunk. But notice that the set of feasible integer
points has stayed exactly the same! In fact, eq. <a
href="#eq:integerHullExample">17</a> is in some sense the “tightest”
formulation for an integer program with those points as its feasible
solutions.</p>
<p>To properly describe what’s going on here, we need a few definitions.
Given two points <span
class="math inline">\mathbf{x}^1,\mathbf{x}^2\in\mathbb{R}^n</span>, a
<strong>convex combination</strong> of the two points is any point <span
class="math inline">\mathbf{y}</span> of the form <span
class="math inline">\mathbf{y}= \lambda \mathbf{x}^1 + (1 - \lambda)
\mathbf{x}^2</span> for some <span
class="math inline">0\leq\lambda\leq1</span>. That definition may seem a
little complicated, but it’s really just saying that <span
class="math inline">\mathbf{y}</span> falls on the line segment between
<span class="math inline">\mathbf{x}</span> and <span
class="math inline">\mathbf{y}</span>.</p>
<p>Now let’s extend that definition a bit. Given a collection of points
<span
class="math inline">\mathbf{x}^1,\mathbf{x}^2,\dots,\mathbf{x}^m\in\mathbb{R}^n</span>
the <strong>convex hull</strong> of these points is any point <span
class="math inline">\mathbf{y}</span> of the form <span
class="math inline">\lambda_1\mathbf{x}^1+\lambda_2\mathbf{x}^2+\cdots+\lambda_m\mathbf{x}^m</span>
where <span class="math inline">\sum_i\lambda_i=1</span>. Again, this
seems a little complicated on first inspection, but the idea is pretty
simple. For example take any three points <span
class="math inline">\mathbf{x}^1,\mathbf{x}^2,\mathbf{x}^3</span> that
don’t lie on the same line. The convex hull of those three points is any
point inside the triangle that has <span
class="math inline">\mathbf{x}^1,\mathbf{x}^2</span>, and <span
class="math inline">\mathbf{x}^3</span> as its corner points. Extending
to larger sets <span
class="math inline">\mathbf{x}^1,\dots,\mathbf{x}^m</span>, the convex
hull is the set of points with corners coming from <span
class="math inline">\mathbf{x}^1,\dots,\mathbf{x}^m</span> and including
anything “in the middle” of them.</p>
<p>Of particular importance to an integer program is the so-called
<em>integer hull</em> of the formulation. Given an IP, its
<strong>integer hull</strong> is the convex hull of all its integer
feasible solutions. Looking back now to our previous plots, we can see
that eq. <a href="#eq:integerHullExample">17</a> actually defines the
integer hull of eq. <a href="#eq:cuttingPlaneExample">16</a>!</p>
<p>Why do we care about the integer hull? It is the convex hull of all
the integer feasible solutions, so in particular all of the corner
points are integer points. This means that if we have some set of linear
inequalities (like in eq. <a href="#eq:integerHullExample">17</a>) whose
feasible region is exactly its integer hull, then solving the associated
IP becomes very easy. Why? Because <span class="thmRef"
for="thm:cornerPointOpt"></span> told us that every linear program has
an optimal corner point solution, and in particular the simplex method
always returns a corner point solution. So running simplex on such a
formulation is guaranteed to return an optimal integer point!</p>
<h3 data-number="5.7.2" id="network-flows---ip-for-free"><span
class="header-section-number">5.7.2</span> Network flows - IP for
free!</h3>
<p>Of course, when we need to model an integer program, we’re usually
not so lucky that our formulation just so happens to yield the problem’s
integer hull. But there are some classes of problems for which we
<em>do</em> know the formulation of the integer hull, turning a
seemingly difficult integer programming problem into an easily-solved
linear program.</p>
<p>The most famous such example is the <strong>minimum cost network
flow</strong> problem, and the setup is this: You’re given a directed
graph (in the <a href="https://en.wikipedia.org/wiki/Graph_theory">graph
theory</a> sense) with vertices <span
class="math inline">1,2,\dots,n</span> and edges <span
class="math inline">(i,j), i,j\in\{1,\dots,n\}</span>. You need to move
some supply of items along this network. Each vertex <span
class="math inline">i</span> has a demand <span
class="math inline">d_i</span> (which can be negative, with negative
demand being interpreted as a supply). An example network is displayed
below, with the external edges entering a vertex representing a supply
for the vertex, while and external edge leaving the vertex represents a
demand.</p>
<figure>
<img src="images/network-flow.png"
alt="Network flow example (Wolsey 2020)" />
<figcaption aria-hidden="true">Network flow example <span
class="citation" data-cites="wolsey2020">(<a href="#ref-wolsey2020"
role="doc-biblioref">Wolsey 2020</a>)</span></figcaption>
</figure>
<p>Items may be transported through the network via the arcs, with each
edge <span class="math inline">(i,j)</span> having a per-unit cost <span
class="math inline">c_{ij}</span> associated with using it, as well as a
capacity <span class="math inline">h_{ij}</span> giving the maximum
amount of product that may be moved along the edge. The minimum cost
network flow problem is a natural way to model an inventory distribution
network, or even literal flows (say of oil through a pipeline).</p>
<p>To model this problem, we’ll use variables <span
class="math inline">x_{ij}</span> to denote the amount of each product
to transport down each edge. Also, as a convenience, let denote by <span
class="math inline">V</span> and <span class="math inline">E</span> the
sets of vertices and edges, respectively. For any vertex <span
class="math inline">i</span> let’s denote by <span
class="math inline">V^+(i)</span> the set of edges that <em>exit</em>
<span class="math inline">i</span> and by <span
class="math inline">V^-(i)</span> the set of edges the <em>enter</em>
<span class="math inline">i</span> (so for the above example, we have
<span class="math inline">V^+(1)=\{2, 4\}</span> and <span
class="math inline">V^-(1)=\{3, 5\}</span>). Then a model for this
problem could look like:</p>
<p><span id="eq:networkFlow" class="eqnos"><span class="math display">
\begin{align*}
\text{min}&amp;&amp; \sum_{(i,j)\in E}c_{ij}x_{ij} &amp; \\
\text{s.t.}&amp;&amp; \sum_{k\in V^-(i)}x_{ki} - \sum_{k\in
V^+(i)}x_{ik} &amp; = b_i &amp;&amp; \forall\ i\in V \\
     &amp;&amp; x_{ij} &amp; \geq 0 &amp;&amp; \forall\ (i,j) \in E \\
     &amp;&amp; x_{ij} &amp; \leq h_{ij} &amp;&amp; \forall\ (i,j) \in E
\\
\end{align*}
</span><span class="eqnos-number">(18)</span></span></p>
<p>Note that the first group of constraints just say that the net amount
leaving each vertex has to be equal to the demand of the vertex. Also
note that I did not specify that the <span
class="math inline">x_{ij}</span> variables are required to be integers.
There are two reasons for this: first, you could imagine a scenario
(say, where <span class="math inline">x_{ij}</span> represents gallons
of water flowing through a pipe) where you are ok with non-integer
solutions. But the more fundamental reason is due to the following
theorem (a proof to which is beyond the scope of the class):</p>
<div id="thm:networkFlowInteger" class="theorem">
<p>If the demands <span class="math inline">b_i</span> and capacities
<span class="math inline">h_{ij}</span> are all integral, then every
corner-point solution to eq. <a href="#eq:networkFlow">18</a> is
integral.</p>
</div>
<p>In other words, the inequality system of eq. <a
href="#eq:networkFlow">18</a> describes its own integer hull. That’s
pretty remarkable, right? On the face of it, this problem doesn’t appear
(at least to me) to be any easier than any of the various <span
class="math inline">\mathcal{NP}</span>-complete problems we’ve seen in
class. And yet if we use this formulation, we can use linear programming
techniques to recover an optimal integer solution in polynomial time!<a
href="#fn90" class="footnote-ref" id="fnref90"
role="doc-noteref"><sup>90</sup></a> There are also several
purpose-built algorithms for min-cost network flows that are known to
run in polynomial time. The practical knowledge to take away from this -
any time you can formulate a problem as a network flow, it is usually a
good idea to do so!</p>
<h3 data-number="5.7.3" id="valid-inequalities"><span
class="header-section-number">5.7.3</span> Valid inequalities</h3>
<p>Unfortunately, we’re not always so lucky as we were with the network
flow problem. Most IPs we formulate will not coincide with their integer
hulls, meaning the LP relaxation is unlikely to give us an integer
solution directly. But it turns out one can (eventually) recover a
description of the integer hull from any IP via the addition of
<strong>cutting planes</strong>, which are basically extra inequalities
that are valid for the integer program but violate some of the
non-integer region of the IP’s LP relaxation.</p>
<p>A definition: An inequality <span
class="math inline">\mathbb{\pi}\mathbf{x}\leq\pi_0</span> (for some
vector <span class="math inline">\mathbb{\pi}</span> and number <span
class="math inline">\pi_0</span>) is a <strong>valid inequality</strong>
for an IP if every integer feasible solution to the IP satisfies it. For
example, in section <a href="#sec:integerHull">5.7.1</a> we took the
formulation eq. <a href="#eq:cuttingPlaneExample">16</a> and added two
valid inequalities <span class="math inline">x_1 + 2x_2 \leq 7</span>
and <span class="math inline">x_2 \leq 3</span> to turn it into a new
formulation eq. <a href="#eq:integerHullExample">17</a>. We can tell the
inequalities were valid from the subsequent plot, which we’ll show again
here:</p>
<svg width="350" height="350" class="lpDraw" base="bbExample1" altArgs="{&quot;addConstraints&quot;: [[[1, 2, 7, &quot;l&quot;], [4.5, 1.25]],[[0, 1, 3, &quot;l&quot;], [3, 3.6]]]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Neither of the added inequalities violate any of the <em>integer</em>
feasible points for the original formulation. They do violate some
<em>non-integer</em> feasible points for the original problem’s LP
relaxation, but this is a fine and in fact desirable thing for a cutting
plane to do.</p>
<p>Let’s now point out a few more valid inequalities for some IP
formulations, taken from <span class="citation"
data-cites="wolsey2020">Wolsey (<a href="#ref-wolsey2020"
role="doc-biblioref">2020</a>)</span>.</p>
<p>Suppose the constraint<a href="#fn91" class="footnote-ref"
id="fnref91" role="doc-noteref"><sup>91</sup></a> for a <span
class="math inline">\{0,1\}</span> knapsack problem is given by:</p>
<p><span class="math display">
3x_1 - 4x_2 + 2x_3 - 3x_4 + 5x_5 \leq -2.
</span></p>
<p>If <span class="math inline">x_2=x_4=0</span>, then every remaining
coefficient on the left-hand side of the constraint is positive. Since
each variable is binary, it would then be impossible to get the
left-hand side value <span class="math inline">\leq -2</span> as
required. So the inequality <span class="math inline">x_2 + x_4 \geq
1</span> is valid.</p>
<p>Now, let’s consider the following set of inequalities:</p>
<p><span class="math display">
\begin{align*}
y&amp;\leq9999x \\
y&amp;\geq0 \\
y&amp;\leq5 \\
x&amp;\in\{0,1\}
\end{align*}
</span></p>
<p>Due to the upper bound on <span class="math inline">y</span> and
since <span class="math inline">x</span> is binary, the inequality <span
class="math inline">y\leq 5x</span> is valid.</p>
<p>Lastly, lets consider an integer program with a single functional
constraint:</p>
<p><span class="math display">
\begin{align*}
13x_1 + 20x_2 + 11x_3 + 6x_4 &amp;\geq 72 \\
x_1,x_2,x_3,x_4 &amp;\in\mathbb{I}_+
\end{align*}
</span></p>
<p>Let’s divide both sides by 11, which will result in the (clearly
valid) inequality:</p>
<p><span class="math display">
\frac{13}{11}x_1+\frac{20}{11}x_2+x_3+\frac{6}{11}x_4\geq 6\frac{6}{11}
</span></p>
<p>Since every <span class="math inline">x_i</span> has been constrained
non-negative and the constraint is of <span
class="math inline">\geq</span> type, we can increase coefficients on
the left-hand side and still end up with a valid inequality. For
example, the fact that <span
class="math inline">2x_1\geq\frac{13}{11}x_1</span> combined with the
above inequality means that the following is valid:</p>
<p><span class="math display">
2x_1+\frac{20}{11}x_2+x_3+\frac{6}{11}x_4\geq 6\frac{6}{11}
</span></p>
<p>Similarly, if we round up <em>all</em> the coefficients on the
left-hand side we will still have a valid (but slightly weaker)
inequality that every (even non-integer) solution to the original
problem will satisfy:</p>
<p><span class="math display">
2x_1+2x_2+x_3+x_4\geq 6\frac{6}{11}
</span></p>
<p>But we can do one more thing: Every integer solution with have all of
the <span class="math inline">x_i</span> values integer, and since all
the coefficients on the left-hand side of the latest inequality are
integer, the <em>entire</em> left-hand side will be an integer. So we
can round up the right-hand side without violating any integer solutions
to the original problem, hence:</p>
<p><span class="math display">
2x_1+2x_2+x_3+x_4\geq 7
</span></p>
<p>is a valid inequality for the original IP.</p>
<h3 data-number="5.7.4"
id="a-general-procedure-for-generating-cuts"><span
class="header-section-number">5.7.4</span> A general procedure for
generating cuts</h3>
<div class="lectureVideoEmbed"
data-video-id="5e94b1371d02464ebe8ff7e41dad70201d"
data-video-date="2023-10-11">
HW 6 review, finish cutting planes.
</div>
<p>By reasoning through the examples, hopefully you can see why each of
the preceding inequalities were valid for their respective problems. But
if we’re looking for a general way to solve integer programs, this kind
of ad-hoc searching is not going to take us very far. Although maybe
there was something to that last one…</p>
<p>Suppose we have in integer program defined by some set of linear
constraints. We know from linear algebra that multiplying inequalities
by a constant will yield valid inequalities, as will adding inequalities
together (assuming the inequalities have the same sign). Indeed, any
sequence of those operations will yield a valid inequality for the
original linear system.</p>
<p>Let’s take an example. Suppose we have an integer program with the
following set of constraints:</p>
<p><span class="math display">
\begin{align*}
7x_1 + 2x_2 &amp;\leq 14 \\
x_2 &amp;\leq 3 \\
2x_1 - 2x_2 &amp;\leq 3 \\
x_1,x_2,x_3&amp;\in\mathbb{I}_+
\end{align*}
</span></p>
<p>If we multiply the first inequality by <span
class="math inline">\frac{2}{7}</span>, the second by <span
class="math inline">\frac{37}{63}</span>, the third by <span
class="math inline">0</span>, and add the results together, we get:</p>
<p><span class="math display">
2x_1 + \frac{1}{63}x_2\leq\frac{121}{21}
</span></p>
<p>We know this is valid for the linear programming relaxation. From
here, we can repeat the process of our previous example: Since it is a
<span class="math inline">\leq</span> constraint and each <span
class="math inline">x_i</span> is non-negative, we may round down the
coefficients on the left-hand side to get:</p>
<p><span class="math display">
2x_1 \leq\frac{121}{21}
</span></p>
<p>Then, since everything on the left-hand side is integral, rounding
down the right-hand side will leave us an inequality that is still valid
for all of the IP’s <em>integer</em> solutions. So</p>
<p><span class="math display">
2x_1\leq5
</span></p>
<p>is valid for the integer program.</p>
<h3 data-number="5.7.5" id="the-chvátalgomory-procedure"><span
class="header-section-number">5.7.5</span> The Chvátal–Gomory
procedure</h3>
<p>It will turn out that, from a theory perspective, the procedure from
that preceding section is kind of all we need to know. Let’s formalize
what we did above by presenting the <strong>Chvátal–Gomory (CG)</strong>
procedure for generating valid inequalities.</p>
<p>Let <span class="math inline">P=\{\mathbf{x}:\mathbf{A}\mathbf{x}\leq
\mathbf{b}\}</span>, with <span class="math inline">\mathbf{A}</span> an
<span class="math inline">m\times n</span> matrix with columns <span
class="math inline">(\mathbf{a}_1,\mathbf{a}_2,\dots,\mathbf{a}_n)</span>,
be the set of feasible solutions to a system of linear inequalities, and
let <span class="math inline">\mathbf{u}\in\mathbb{R}_+^m</span> be a
non-negative vector. Then the inequality</p>
<p><span class="math display">
\sum_{j=1}^n\lfloor \mathbf{u}\mathbf{a}_j
\rfloor\mathbf{x}_j\leq\lfloor \mathbf{u}\mathbf{b} \rfloor
</span></p>
<p>is called a <strong>CG inequality</strong> for <span
class="math inline">P</span>. Furthermore, this inequality is valid for
the set of integer solutions to <span class="math inline">P</span> (due
to the same reasoning we went through in the preceding section).</p>
<p>Basically, building a CG inequality consists of creating linear
combinations of the constraints defining <span
class="math inline">P</span>, then rounding down each coefficient. The
<strong>CG procedure</strong> is the process of generating GC
inequalities and adding them to the formulation for <span
class="math inline">P</span>. From there, you could build new cutting
planes by taking linear combinations of the newly-added inequalities,
which could also be added to the formulation for <span
class="math inline">P</span>. And it turns out that you can generate
<em>any</em> valid inequality by repeating this procedure (though once
again, the proof is beyond the scope of this course):</p>
<div id="thm:CGFinite" class="theorem">
<p>Every valid inequality for <span class="math inline">P</span>’s
integer hull can be obtained by applying the CG procedure a finite
number of times.</p>
</div>
<p>This is a neat result, but how practical is it? While any inequality
can be generated with finitely many rounds of the CG procedure, that
finite number can sometimes be (as you might have guessed) exponentially
large in <span class="math inline">n</span> (the dimension of <span
class="math inline">P</span>). You may also require exponentially many
of these inequalities to define the integer hull.</p>
<p>Furthermore, the definition isn’t very prescriptive. Sure, there is
some sequence of multiplier vectors <span class="math inline">u</span>
that will yield any inequality that you want, but we don’t have a very
practical way of determining this sequence.</p>
<h3 data-number="5.7.6"
id="gomorys-fractional-cutting-plane-algorithm"><span
class="header-section-number">5.7.6</span> Gomory’s fractional cutting
plane algorithm</h3>
<p>With that final critique in mind, let’s see if we can do a little
better and define an actual algorithm for solving IPs with cutting
planes. As per usual, we’ll start by solving the LP relaxation to our IP
of interest. If the solution is not integral, we’d like to be able to
add an inequality that is valid for the IP but also removes the previous
LP optimal solution. Let’s take the following IP as an example:</p>
<p><span id="eq:gomoryExampleInequalities" class="eqnos"><span
class="math display">
\begin{align*}
\text{max}&amp;&amp; 4x_1 -  x_2 \\
\text{s.t.}&amp;&amp; 7x_1 - 2x_2 &amp; \leq 14 \\
     &amp;&amp;         x_2 &amp; \leq 3 \\
     &amp;&amp; 2x_1 - 2x_2 &amp; \leq 3 \\
     &amp;&amp;  x_1,   x_2 &amp;  \in \mathbb{I}_+
\end{align*}
</span><span class="eqnos-number">(19)</span></span></p>
<p>Let’s add slack variables (which, since <span
class="math inline">x_1,x_2</span> are integer and all the data is
integer, will be integer at an optimal solution as well) and re-write
the problem in matrix form suitable for the simplex method:</p>
<p><span class="math display">
\begin{bmatrix}
1 &amp; -4 &amp;  1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp;  7 &amp; -2 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp;  0 &amp;  1 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp;  2 &amp; -2 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 14 \\ 3 \\ 3
\end{bmatrix}
</span></p>
<p>If we solve this with the simplex method, the system at the optimal
basis would look like:</p>
<p><span class="math display">
\begin{bmatrix}
1 &amp; 0 &amp;  0 &amp;  4/7 &amp;  1/7 &amp; 0 \\
0 &amp; 1 &amp;  0 &amp;  1/7 &amp;  2/7 &amp; 0 \\
0 &amp; 0 &amp;  1 &amp;    0 &amp;    1 &amp; 0 \\
0 &amp; 0 &amp;  0 &amp; -2/7 &amp; 10/7 &amp; 1
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
59/7 \\ 20/7 \\ 3 \\ 23/7
\end{bmatrix}
</span></p>
<p>We see that the optimal basic solution is not integral. How can we
add a cut that will be feasible for the IP but eliminate this basic
solution? Let’s take a look at the second row of the matrix, where <span
class="math inline">x_1</span> is basic with a fractional value. That
equation</p>
<p><span id="eq:gomoryEx1" class="eqnos"><span class="math display">
x_1 + \frac{1}{7}x_3 + \frac{2}{7}x_4 = \frac{20}{7}
</span><span class="eqnos-number">(20)</span></span></p>
<p>is valid for the LP relaxation. We will continue to use the trick of
rounding down coefficients to get new valid inequalities. Rounding down
the left-hand side coefficients will give us an inequality that is valid
for the LP relaxation:</p>
<p><span class="math display">
x_1 + 0x_3 + 0x_4 \leq \frac{20}{7}
</span></p>
<p>then (as before) since the entire left-hand side is integral, any
integer solution to the IP will have to satisfy</p>
<p><span class="math display">
x_1 + 0x_3 + 0x_4 \leq 2
</span></p>
<p>or equivalently</p>
<p><span id="eq:gomoryEx2" class="eqnos"><span class="math display">
-x_1 \geq -2.
</span><span class="eqnos-number">(21)</span></span></p>
<p>So with eq. <a href="#eq:gomoryEx2">21</a> valid for the IP and
eq. <a href="#eq:gomoryEx1">20</a> valid for the LP relaxation (and thus
also the IP), adding them together yields the following inequality which
must also be valid for the IP:</p>
<p><span class="math display">
\frac{1}{7}x_3 + \frac{2}{7}x_4 \geq \frac{6}{7}.
</span></p>
<p>Not only is this valid, it is also violated by the prior basic
solution, since the only variables remaining on the left-hand side are
non-basic and thus take a value of 0 at the basic solution. We can even
verify this graphically. The first step will be to write the new
inequality in terms of the original variables, which we know how to do
since <span class="math inline">x_3</span> and <span
class="math inline">x_4</span> are the slack variables for the first and
second constraints, respectively, of eq. <a
href="#eq:gomoryExampleInequalities">19</a>. So we can substitute <span
class="math inline">x_3=14-7x_1+2x_2</span> and <span
class="math inline">x_4=3-x_2</span> and cancel out terms to see that
the inequality is equivalent to <span
class="math inline">x_1\leq2</span>. Below, you can see the plot of the
original LP eq. <a href="#eq:gomoryExampleInequalities">19</a> with the
new cut <span class="math inline">x_1\leq2</span> added. Hit the “Toggle
Plots” button to see the original formulation with the LP optimal point
included. Notice how the new valid inequality cuts away the old LP
solution while leaving all the integer points intact.</p>
<div>
<script>
     gomoryExampleClickFunc = () => {
          for (plotNum of [1, 2]){
               plotEl = document.getElementById('gomoryExamplePlot' + plotNum);
               plotEl.style.display = plotEl.style.display === 'none' ? 'block' : 'none';
          }
     }
</script>
<div id="gomoryExamplePlot1" style="display:block">
<svg width="350" height="350" class="lpDraw" base="gomoryExample1" altArgs="{&quot;addConstraints&quot;: [[[1, 0, 2, &quot;l&quot;],[0.75, 4]]]}">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<div id="gomoryExamplePlot2" style="display:none">
<svg width="350" height="350" class="lpDraw" base="gomoryExample1" altArgs="{&quot;extraPoints&quot;: [[2.85714285714, 3, {&quot;fill&quot;: &quot;blue&quot;, &quot;r&quot;: 5}]], &quot;extraText&quot;: [[&quot;LP optimal&quot;, 240, 100, {&quot;font-size&quot;: &quot;0.7rem&quot;}]]}">
Sorry, your browser does not support inline SVG.
</svg>
</div>
<button class="basicCenter" onClick="gomoryExampleClickFunc()" style="padding: 0.5rem">
Toggle Plots
</button>
</div>
<p>To continue solving, we can add this new inequality to the problem
formulation and re-solve with simplex. If the optimal basis has a
fractional variable, we can add a new constraint in the way we just did
above. Then we continue on like this until solving simplex yields an
integral basic solution.</p>
<p>The process we just outlined is called <strong>Gomory’s fractional
cutting plane algorithm</strong>. In general, the new inequalities are
drawn from any row in the simplex system at the optimal basis with a
fractional right-hand side value. We can write that row as</p>
<p><span class="math display">
x_{b} + \sum_{j\in N}a_jx_j = r
</span></p>
<p>where <span class="math inline">N</span> is the set of non-basic
variables, and <span class="math inline">b</span> is the index of the
basic variable in that row. Then the cut we add is given by:</p>
<p><span class="math display">
\sum_{j\in N}(a_j-\lfloor a_j \rfloor)x_j\geq r-\lfloor r \rfloor
</span></p>
<p>Gomory’s algorithm is guaranteed to terminate at an optimal solution
in a finite number of steps. But once again, that finite number can
still grow exponentially with respect to the size of the problem
instance. In practice, it has not been found to be competitive with
branch and bound.</p>
<h3 data-number="5.7.7" id="branch-and-cut"><span
class="header-section-number">5.7.7</span> Branch and cut</h3>
<p>So far it sounds like cutting planes are not the way forward for
solving integer programs in practice. But that is not quite true. Even
if no solver uses cutting plane algorithms exclusively to solve IPs,
they still have a role to play. The state of the art in IP solvers is a
style of algorithm known as <strong>branch and cut</strong>. We won’t
cover it any detail, but we have given the main ideas already. There is
a branch and bound tree governing the search, but at various times
during the algorithm cutting planes are derived and added to either the
base problems or any of the sub-problems. Other techniques come into
play as well, such as several pre-solve steps that take the original
problem and attempt to reformulate it in some way to make it easier to
solve, as well as running heuristics to find/improve integer feasible
solutions.</p>
<h2 data-number="5.8" id="practical-miscellany"><span
class="header-section-number">5.8</span> Practical miscellany</h2>
<div class="lectureVideoEmbed"
data-video-id="745f23d1d9e74db6935c23634b3ddb671d"
data-video-date="2023-10-06">
Some miscellaneous items you may want to know about when solving IPs
with software.
</div>
<p>I’d like to conclude our tour of integer programming with a few
miscellaneous notes on using solvers on practical problems. We’ll
discuss how to understand solver logs, plus demonstrate some more
advanced tools you can use while solving tough problems.</p>
<script src="https://gist.github.com/0ff0c39f9eb4573e878330ff46465d94.js"></script>
<h2 data-number="5.9" id="notes-and-further-reading-1"><span
class="header-section-number">5.9</span> Notes and further reading</h2>
<div class="lectureVideoEmbed"
data-video-id="754dad0e4ec244709ca99fc8dc1b956b1d"
data-video-date="2023-10-13">
IP wrap, exam review.
</div>
<p>While I’ve taken many of this section’s modeling examples from
chapter 12 in <span class="citation" data-cites="classText">Hillier and
Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span>, for the theory and algorithms I
prefer the presentation in <span class="citation"
data-cites="wolsey2020">Wolsey (<a href="#ref-wolsey2020"
role="doc-biblioref">2020</a>)</span>. Much of the content here is due
to that book’s chapters 3, 6, 7, and 8.</p>
<p>In fact, there’s even more from <span class="citation"
data-cites="wolsey2020">Wolsey (<a href="#ref-wolsey2020"
role="doc-biblioref">2020</a>)</span> that I would have liked to cover
if I had the time:</p>
<ul>
<li>More classes of cutting planes (that are used by solvers) are
covered in later sections of chapter 8.</li>
<li>There is some interesting theory behind when an integer program is
easy to solve (as is the case with network flows) covered in chapter 3.
The concepts to look for are total unimodularity and matroids.</li>
<li>Column generation (chapter 11) is an nifty technique for tackling
certain integer programs with large numbers of variables.</li>
<li>Chapter 13 covers several different kinds of heuristics that a MIP
solver might use to find good integer solutions or improve existing
ones, which can help to fathom branch and bound nodes and keep the tree
from growing too large.</li>
<li>Sections 7.5 and 7.6 cover several aspects of the types of branch
and cut algorithms that are used in the best integer programming
solvers.</li>
</ul>
<p>I could always say more about complexity theory. Since we didn’t get
too technical in our presentation here, I thought I could point out <a
href="https://www.quantamagazine.org/complexity-theorys-50-year-journey-to-the-limits-of-knowledge-20230817/">a
recent article</a> I read talking about the history of complexity
research and current trends. It also is non-technical and written for a
general audience, so I think it is actually pretty approachable. Anyone
interested by what we covered in class should certainly check it
out.</p>
<p>Lastly, I’ll note that the K-State IMSE department offers <a
href="https://catalog.k-state.edu/content.php?catoid=58&amp;navoid=11444">IMSE
884</a>, a full semester course devoted to integer programming and
combinatorial optimization. Additionally, <a
href="https://catalog.k-state.edu/content.php?catoid=58&amp;navoid=11444">IMSE
882</a> covers network flows and graph theory and has some intersection
with the topics we covered here as well.</p>
<h1 data-number="6" id="nonlinear-programming"><span
class="header-section-number">6</span> Nonlinear programming</h1>
<div class="lectureVideoEmbed"
data-video-id="a1bace97c5f1459bb76588dfdba3d4c11d"
data-video-date="2023-10-16">
Discussed the class project, then jumped into nonlinear programming and
calculus background.
</div>
<p>We will now spend some time discussing the broad topic of nonlinear
programming. This will mark a bit of a shift in the class, as up to this
point our discussions have mostly been building upon previous topics. As
we’ll see, the functional forms we deal with for nonlinear programs
break fairly distinctly from what we’ve already seen in the
linear/integer programming domains.</p>
<p>Stated most generally, a <strong>nonlinear programming</strong>
problem is an optimization problem of the form</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; f(\mathbf{x}) \\
\text{s.t.}&amp;&amp; g_i(\mathbf{x}) &amp; \leq b_i &amp; \forall \
i\in\{1,\dots,m\} \\
     &amp;&amp; \mathbf{x}&amp; \in \mathbb{R}^n
\end{align*}
</span></p>
<p>for some <span class="math inline">n</span> (the number of variables)
and <span class="math inline">m</span> (number of constraints). In this
class we will generally assume that <span class="math inline">f</span>
and <span class="math inline">g_i</span> are differentiable (and often
twice differentiable) everywhere, but otherwise this is a fairly general
formulation. We will split our exploration into several sections, with
problem classes generally differing over the following specs:</p>
<ul>
<li>Number of variables</li>
<li>Existence of constraints</li>
<li>Qualities of the objective function <span
class="math inline">f</span></li>
<li>Qualities of the constraint functions <span
class="math inline">g_i</span></li>
</ul>
<h2 data-number="6.1" id="example-nonlinear-programs"><span
class="header-section-number">6.1</span> Example nonlinear programs</h2>
<p>Turning away from the world of linear constraints and objectives, it
is intuitively clear that the class of problems we can deal with now is
much more broad. Here we give a few samples of where nonlinearities may
naturally arise in optimization problems.</p>
<h3 data-number="6.1.1" id="price-elasticity"><span
class="header-section-number">6.1.1</span> Price elasticity</h3>
<p>When we first modeled the Wyndor LP in section <a
href="#sec:exampleLp">4.1</a>, we made an important assumption with
regards to the revenue generated from the products. We assumed that we
could sell as much as we could produce at one fixed cost. This is
necessary for a linear objective function, and may be a fine assumption
in some scenarios. But it’s not always going to match reality.</p>
<p>If you’ve taken an economics class you’re probably familiar with the
relationship between the supply of an item and the price people are
willing to pay for it. In practice, a store might set a certain price
for an item and sell some number of them at that price, but not sell out
of everything until the last remaining items go on sale. The effect is
that each marginal unit produced is expected to command a slightly lower
price than the previous units, and the only way to model this
relationship in a mathematical program is with nonlinear functions.</p>
<h3 data-number="6.1.2" id="investment-risk"><span
class="header-section-number">6.1.2</span> Investment risk</h3>
<p>One application where nonlinear programming is often used is in
portfolio management. Usually portfolio managers are worried about both
the expected returns and the risk associated with their investments. As
we’ll see, this risk factor is best modeled via nonlinear functions.</p>
<p>Suppose that <span class="math inline">n</span> stocks are being
considered for inclusion into some portfolio, with decision variables
<span class="math inline">x_j</span>, <span
class="math inline">j\in\{1,\dots,n\}</span> being the number of shares
of stock <span class="math inline">j</span> to be included. Following
the usual notation, we’ll let <span class="math inline">\mu_j</span>
denote the expected return for investing in stock <span
class="math inline">j</span> over some time horizon, and let <span
class="math inline">\sigma_{jj}</span> represent the associated
variance. Furthermore, there may be correlations between the risks of
certain stocks, so it’s important to also consider the <a
href="https://en.wikipedia.org/wiki/Covariance">covariance</a> <span
class="math inline">\sigma_{ij}</span> of pairs of stocks <span
class="math inline">i</span> and <span class="math inline">j</span>.</p>
<p>If we let <span class="math inline">R(\mathbf{x})</span> denote the
expected return of the portfolio defined by <span
class="math inline">\mathbf{x}</span>, and let <span
class="math inline">V(\mathbf{x})</span> denote the variance, then we
have</p>
<p><span class="math display">
R(\mathbf{x}) = \sum_{j=1}^n\mu_jx_j \qquad\text{and}\qquad
V(\mathbf{x}) = \sum_{i=1}^n\sum_{j=1}^n\sigma_{ij}x_ix_j.
</span></p>
<p>Now, <span class="math inline">R(\mathbf{x})</span> is a linear
function in <span class="math inline">\mathbf{x}</span>, but <span
class="math inline">V(\mathbf{x})</span> is nonlinear due to the
quadratic terms <span class="math inline">x_ix_j</span>. One might
select <span class="math inline">V(\mathbf{x})</span> to be the
objective to be minimized while constraining that <span
class="math inline">R(\mathbf{x})</span> is above some threshold, or
perhaps <span class="math inline">R(\mathbf{x})</span> is the objective
to be maximized while <span class="math inline">V(\mathbf{x})</span> is
constrained. Either way, the nonlinearity introduced by <span
class="math inline">V(\mathbf{x})</span> means that we need new
approaches to find an optimal solution.</p>
<h2 data-number="6.2"
id="single-variable-unconstrained-optimization"><span
class="header-section-number">6.2</span> Single-variable unconstrained
optimization</h2>
<p>Let’s now jump into our first class of nonlinear optimization
problems. Naturally, we’ll start with a simple case, and one you already
know something about from your calculus class: optimizing a function
<span class="math inline">f(x)</span> with a single variable and no
constraints.</p>
<h3 data-number="6.2.1" id="calculus-review"><span
class="header-section-number">6.2.1</span> Calculus review</h3>
<p>Recall that for this course we’re assuming <span
class="math inline">f</span> to be differentiable everywhere. That being
the case, a necessary condition for some <span
class="math inline">x&#39;</span> to be optimal for <span
class="math inline">f</span> is that the derivative is equal to 0 at
<span class="math inline">x&#39;</span>, i.e.:</p>
<p><span class="math display">
f&#39;(x&#39;) = 0.
</span></p>
<p>These points <span class="math inline">x&#39;</span> with <span
class="math inline">f&#39;(x&#39;)=0</span> are called the
<strong>critical points</strong> of <span class="math inline">f</span>.
You probably remember this condition from calculus, but do you remember
why it’s necessary? Let’s take a moment to recall the definition of a
derivative:</p>
<p><span class="math display">
f&#39;(x) = \lim_{h\rightarrow0}\frac{f(x + h) - f(x)}{h}.
</span></p>
<p>Suppose now that we’d like minimize some function <span
class="math inline">f</span>, and we know at some point <span
class="math inline">x&#39;</span> that <span
class="math inline">f&#39;(x&#39;)&lt;0</span>. Then by the above
definition, there must be some <span class="math inline">h&gt;0</span>
such that</p>
<p><span class="math display">
\begin{align*}
\frac{f(x&#39; + h) - f(x&#39;)}{h} &lt; 0 &amp;\Leftrightarrow f(x&#39;
+ h) - f(x&#39;) &lt; 0 \\
&amp;\Leftrightarrow f(x&#39; + h) &lt; f(x&#39;)
\end{align*}
</span></p>
<p>and thus <span class="math inline">x&#39;</span> cannot minimize
<span class="math inline">f</span>. Similar arguments hold for each
combination of minimization/maximization and <span
class="math inline">f&#39;(x&#39;)&gt;0</span> or <span
class="math inline">f&#39;(x&#39;)&lt;0</span>.</p>
<p>So <span class="math inline">f&#39;(x&#39;)=0</span> is a necessary
condition for <span class="math inline">x&#39;</span> to be optimal, but
as you’ll recall it is not sufficient. A common example is the function
<span class="math inline">f(x)=x^3</span> (plotted below), where we have
<span class="math inline">f&#39;(0)=0</span> but <span
class="math inline">x&#39;=0</span> is not any kind of maximum or
minimum for the function. For any <span
class="math inline">h&gt;0</span>, no matter how small, you’ll have
<span class="math inline">f(h) &gt; f(0)</span> and <span
class="math inline">f(-h) &lt; f(0)</span>.</p>
<div class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px" data-expression="x^3"
data-xrange="[-1.5, 1.5]" data-extrapoints="[[0, 0]]">

</div>
<p>However, if <span class="math inline">f</span> has a second
derivative there is more we can say. Suppose again we’d like to minimize
<span class="math inline">f</span> and we have some point <span
class="math inline">x&#39;</span> such that <span
class="math inline">f&#39;(x&#39;)=0</span> and also <span
class="math inline">f&#39;&#39;(x&#39;)&gt;0</span>. By definition of
the derivative, we have:</p>
<p><span class="math display">
f&#39;&#39;(x&#39;)=\lim_{h\rightarrow0}\frac{f&#39;(x&#39; + h) -
f&#39;(x&#39;)}{h}
</span></p>
<p>Since <span class="math inline">f&#39;(x&#39;) = 0</span>, we simply
have</p>
<p><span class="math display">
f&#39;&#39;(x&#39;)=\lim_{h\rightarrow0}\frac{f&#39;(x&#39; + h)}{h}
</span></p>
<p>Since we’ve said that <span class="math inline">f&#39;&#39;(x&#39;)
&gt; 0</span>, we must have</p>
<p><span class="math display">
\frac{f&#39;(x&#39; + h)}{h} &gt; 0
</span></p>
<p>for sufficiently small <span class="math inline">h</span><a
href="#fn92" class="footnote-ref" id="fnref92"
role="doc-noteref"><sup>92</sup></a>. When <span
class="math inline">h</span> is sufficiently small and positive, we
multiply each side by <span class="math inline">h</span> to see that</p>
<p><span class="math display">
f&#39;(x&#39; + h) &gt; 0
</span></p>
<p>i.e. <span class="math inline">f</span> is increasing in some small
neighborhood to the right of <span class="math inline">x&#39;</span>.
Similarly, if <span class="math inline">h</span> is sufficiently small
and negative, multiplying by <span class="math inline">h</span> flips
the sign and we get</p>
<p><span class="math display">
f&#39;(x&#39; + h) &lt; 0
</span></p>
<p>i.e. <span class="math inline">f</span> is decreasing in the small
neighborhood to the left of <span class="math inline">x&#39;</span>.
Putting it all together (and staying within a sufficiently small
neighborhood of <span class="math inline">x&#39;</span>), as we approach
<span class="math inline">x&#39;</span> from the left <span
class="math inline">f</span> continues to decrease. Then we hit <span
class="math inline">x&#39;</span>, and as we continue on to the right
<span class="math inline">f</span> will start increasing. Thus <span
class="math inline">x&#39;</span> must be the minimum of <span
class="math inline">f</span> within that neighborhood.</p>
<p>What we’ve described here is just the familiar <em>second derivative
test</em> from calculus. Namely, if <span
class="math inline">x&#39;</span> is a critical point of <span
class="math inline">f</span> and <span
class="math inline">f&#39;&#39;(x&#39;)&gt;0</span> then <span
class="math inline">x&#39;</span> is a <strong>local minimum</strong> of
<span class="math inline">f</span>. Similarly, if <span
class="math inline">f&#39;&#39;(x&#39;)&lt;0</span> then <span
class="math inline">x&#39;</span> is a <strong>local maximum</strong> of
<span class="math inline">f</span>.</p>
<p>Of course, the difficulty is in the word <em>local</em>. Being a
local optimum means that you are the optimal solution within some
portion of <span class="math inline">f</span>, but not necessarily
optimal when looking at the entire domain of <span
class="math inline">f</span>. As an example, the function <span
class="math inline">f(x)=x^3 - x</span> (plotted below) has a local
maximum at <span class="math inline">x=\frac{-1}{\sqrt{3}}</span> and a
local minimum at <span class="math inline">x=\frac{1}{\sqrt{3}}</span>.
But neither point is a true optimum. Indeed, there is no optimal value
for this function at all, as the plot goes off to <span
class="math inline">\infty</span> to the right and <span
class="math inline">-\infty</span> to the left.</p>
<div class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px" data-expression="x^3 - x"
data-xrange="[-1.5, 1.5]"
data-extrapoints="[[&quot;1 / sqrt(3)&quot;, &quot;eval&quot;], [&quot;-1 / sqrt(3)&quot;, &quot;eval&quot;]]">

</div>
<p>What we’d usually like to find is a <strong>global minimum</strong>
(or <strong>global maximum</strong>) of the function, i.e. the point
<span class="math inline">x^*</span> at which <span
class="math inline">f(x^*) \leq f(x)</span> (or <span
class="math inline">f(x^*) \geq f(x)</span> for a maximum) for
<em>any</em> <span class="math inline">x</span> in the domain of <span
class="math inline">f</span>. For an arbitrary function <span
class="math inline">f</span> it can be difficult to ascertain whether a
given local optimum is also globally optimal. But there are certain
types of functions for which we can make this determination easily.</p>
<h3 data-number="6.2.2" id="convexity-and-concavity"><span
class="header-section-number">6.2.2</span> Convexity and concavity</h3>
<p>Nonlinear programming can be challenging. Tell an OR practitioner to
solve a nonlinear optimization problem and they may get a little
nervous. But if you tell them the objective function is convex, they’ll
breathe a sigh of relief. Convexity makes everything better in OR
land.</p>
<p>A function of a single variable <span class="math inline">f</span> is
said to be a <strong>convex function</strong> if, for each pair of
values <span class="math inline">x&#39;,x&#39;&#39;</span> and any <span
class="math inline">\lambda</span> with <span
class="math inline">0&lt;\lambda&lt;1</span>, we have</p>
<p><span id="eq:convexDefinition1d" class="eqnos"><span
class="math display">
f(\lambda x&#39;&#39; + (1-\lambda)x&#39;)\leq \lambda f(x&#39;&#39;) +
(1 - \lambda)f(x&#39;)
</span><span class="eqnos-number">(22)</span></span></p>
<p>If the <span class="math inline">\leq</span> can be replaced by a
<span class="math inline">&lt;</span>, then the we say that function is
a <strong>strictly convex function</strong>.</p>
<p>That is an admittedly symbol-heavy definition, so let’s try to unpack
it. On the left-hand side we’ve taken a combination of <span
class="math inline">x&#39;</span> and <span
class="math inline">x&#39;&#39;</span> then evaluated <span
class="math inline">f</span> at that combination. On the right-hand side
we evaluated <span class="math inline">f</span> at each point <span
class="math inline">x&#39;</span> and <span
class="math inline">x&#39;&#39;</span> and then taken a combination of
those values. So the difference is only in the order in which we apply
the function and the combination.</p>
<p>But it’s easier to see on a plot, so let’s look at some. Below, I’ve
plotted three functions: <span class="math inline">f(x)=x^2 -
\frac{1}{2}</span> on the left, <span class="math inline">f(x)=x^3 -
x</span> in the middle, and <span class="math inline">f(x)=-x^2 +
\frac{1}{2}</span> on the right. For each one let’s consider <span
class="math inline">x&#39;=-1</span> and <span
class="math inline">x&#39;&#39;=1</span>. The red dots represent the
points <span class="math inline">(x&#39;, f(x&#39;))</span> and <span
class="math inline">(x&#39;&#39;, f(x&#39;&#39;))</span>.</p>
<div style="display:flex;justify-content:space-around">
<div class="plotlyFunctionPlot" style="width:200px;height:200px"
data-expression="x^2 - 0.5" data-xrange="[-1.5, 1.5]"
data-extrapoints="[[-1, &quot;eval&quot;, &quot;red&quot;, 8], [1, &quot;eval&quot;, &quot;red&quot;, 8]]"
data-linebetweenpoints="true">

</div>
<div class="plotlyFunctionPlot" style="width:200px;height:200px"
data-expression="x^3 - x" data-xrange="[-1.5, 1.5]"
data-extrapoints="[[-1, &quot;eval&quot;, &quot;red&quot;, 8], [1, &quot;eval&quot;, &quot;red&quot;, 8]]"
data-linebetweenpoints="true">

</div>
<div class="plotlyFunctionPlot" style="width:200px;height:200px"
data-expression="-x^2 + 0.5" data-xrange="[-1.5, 1.5]"
data-extrapoints="[[-1, &quot;eval&quot;, &quot;red&quot;, 8], [1, &quot;eval&quot;, &quot;red&quot;, 8]]"
data-linebetweenpoints="true">

</div>
</div>
<p>For any <span class="math inline">\lambda</span>, the right-hand side
of eq. <a href="#eq:convexDefinition1d">22</a> <span
class="math inline">\lambda f(x&#39;&#39;) + (1 -
\lambda)f(x&#39;)</span> will equate to some point on the red line
segment. Meanwhile, the left-hand <span class="math inline">f(\lambda
x&#39;&#39; + (1-\lambda)x&#39;)</span> side refers to a value on the
function curve in the same vertical line. Hence the eq. <a
href="#eq:convexDefinition1d">22</a> will be satisfied for every lambda
exactly when the red line segment is always above the corresponding
segment of the curve. Given this, the second and third of our plots
clearly do not correspond to convex functions.</p>
<p>What about the first plot? Unfortunately we can’t prove convexity
with just one line segment. The definition stipulates that <em>any</em>
such line segment is always above the curve <em>no matter where you put
the end points</em>. But I think you can imagine that this is true for
the first plot. Indeed, the first function <span
class="math inline">f(x)=x^2 + \frac{1}{2}</span> <em>is</em>
convex.</p>
<p>The appeal of working with convex functions is due to the following
result:</p>
<div id="thm:convexLocalOptIsGlobalOpt" class="theorem">
<p>Suppose <span class="math inline">f</span> is a convex function and
<span class="math inline">x^*</span> is a local minimum for <span
class="math inline">f</span>. Then <span class="math inline">x^*</span>
is also a global minimum for <span class="math inline">f</span>.</p>
</div>
<div class="proof" for="thm:convexLocalOptIsGlobalOpt"
data-placement="appendix">
<p>For this proof we’ll assume that <span class="math inline">f</span>
is a function of a single variable, but you should know that both the
definition for convexity and this theorem are still valid when <span
class="math inline">f</span> is a multivariate function.</p>
<p>Since <span class="math inline">x^*</span> is a local minimum, there
exists some number <span class="math inline">p\in \mathbb{R}</span> such
that for any <span class="math inline">y</span> with <span
class="math inline">|x^* - y| &lt; p</span> (i.e. any point within a
distance of <span class="math inline">p</span> from <span
class="math inline">x^*</span>) we have <span class="math inline">f(y)
\geq f(x^*)</span>. Our proof will go by contradiction, so for
contradiction assume that <span class="math inline">x^*</span> is not a
global minimum and hence there exists some <span
class="math inline">x&#39;</span> that satisfies <span
class="math inline">f(x&#39;) &lt; f(x^*)</span>.</p>
<p>However, by the definition of convexity, for any <span
class="math inline">0&lt;\lambda&lt;1</span> we have</p>
<p><span class="math display">
\begin{align*}
f(\lambda x&#39; + (1-\lambda)x^*)&amp;\leq\lambda f(x&#39;) +
(1-\lambda)f(x^*) \\
&amp;&lt;\lambda f(x^*) + (1-\lambda)f(x^*) \\
&amp;=f(x^*)
\end{align*}
</span></p>
<p>But if we choose <span class="math inline">\lambda</span> small
enough then we will have <span class="math inline">|x^*-(\lambda x&#39;
+ (1-\lambda)x^*)|&lt;p</span>, contradicting that <span
class="math inline">x^*</span> was a local minimum.</p>
</div>
<p>Luckily, we do not need to go about drawing graphs and line segments
whenever we want to prove convexity, so long as <span
class="math inline">f</span> has a second derivative. If this is the
case, then <span class="math inline">f</span> is convex if and only if
<span class="math inline">f&#39;&#39;(x)\geq0</span> for every <span
class="math inline">x</span>. Similarly, <span
class="math inline">f</span> is strictly convex if and only if <span
class="math inline">f&#39;&#39;(x)&gt;0</span> for every <span
class="math inline">x</span>. In your calculus class, you may have
called this a “concave up” function. Geometrically, this is interpreted
as a function that is always “curving upward”, which meshes well with
our “curve below the line segment” definition above.</p>
<p>Furthermore, as you might suspect, there is a similar notion for
maximization problem, which we obtain by flipping all the related
inequalities. This time, we use the term <strong>concave
function</strong> for any function <span class="math inline">f</span>
that satisfies</p>
<p><span class="math display">
f(\lambda x&#39;&#39; + (1-\lambda)x&#39;)\geq \lambda f(x&#39;&#39;) +
(1 - \lambda)f(x&#39;)
</span></p>
<p>If the above is satisfied when replacing <span
class="math inline">\geq</span> with <span
class="math inline">&gt;</span> then we have a <strong>strictly concave
function</strong>. This time the interpretation is flipped, so that the
line segment must lie <em>below</em> the the function plot, as in the
third plot in our above figure. Functions with a second derivative are
concave if and only if <span class="math inline">f&#39;&#39;(x)\leq
0</span> for every <span class="math inline">x</span>, with strictness
achieved if <span class="math inline">f&#39;&#39;(x)&lt;0</span>. This
type of function is also described as being “concave down”<a
href="#fn93" class="footnote-ref" id="fnref93"
role="doc-noteref"><sup>93</sup></a>, and is characterized by its
“curving downward” nature.</p>
<p>Regardless if we’re working on a minimization problem over a convex
function or a maximization problem over a concave function, we know that
once we’ve found a critical point we have what we’re looking for (no
need to worry about the point only being a local optimum).</p>
<h3 data-number="6.2.3" id="analytical-vs.-numerical-methods"><span
class="header-section-number">6.2.3</span> Analytical vs. numerical
methods</h3>
<p>At this point, it may seem that we’ve covered everything we need to
know about minimizing/maximizing convex/concave functions of single
variables. For example, the previous section tells us that in order to
find the maximum of <span class="math inline">f(x)=-x^2</span> it
suffices to show</p>
<p><span class="math display">
f&#39;(x) = 0 \Leftrightarrow -2x = 0 \Leftrightarrow x=0
</span></p>
<p>This is true, but sometimes we are not so lucky that we can
analytically solve for <span class="math inline">f&#39;(x)=0</span> as
we did here, and in fact it comes up often in practice that an
analytical solution is not practical. This motivates the need for
<strong>numerical methods</strong> for solving such problems. In the
next few sections, we’ll show examples of <strong>search
procedures</strong> for finding the optimal points for univariate
functions. In each case, the approach will be to find a sequence of
<strong>trial solutions</strong>. Each iteration begins at the current
trial solution, then via some systematic search leads to a new and
improved trial solution. The procedure continues until the trial
solutions have converged to an optimal solution, should one exist.</p>
<h3 data-number="6.2.4" id="bisection-method"><span
class="header-section-number">6.2.4</span> Bisection method</h3>
<p>Our first search procedure is the bisection method. While no one
would suggest you implement this technique to solve problems in
practice, it is a relatively intuitive algorithm that is great for
learning the tenor of these search techniques in general. For what
follows, we will assume that we are trying to maximize some concave
function.</p>
<p>Actually, concavity is not strictly required for this method.
Technically, using <span class="math inline">x^*</span> to denote the
maximum of <span class="math inline">f</span>, the only requirements for
the method to work are:</p>
<p><span class="math display">
\begin{align*}
f&#39;(x^*) &amp; = 0 \\
f&#39;(x) &amp; &gt; 0 &amp; \forall \ x&lt;x^* \\
f&#39;(x) &amp; &lt; 0 &amp; \forall \ x&gt;x^*
\end{align*}
</span></p>
<p>Of course, concavity is the most natural condition for which these
criteria hold.</p>
<p>As with most numerical optimization procedures, we will not be
guaranteed to find the true optimal solution. Instead, before we begin
we’ll need to select our <strong>error tolerance</strong>, which is how
close we’ll need to get to an optimal solution before we decide our
answer is “good enough” and we terminate the algorithm. We’ll denote
this term by <span class="math inline">\epsilon</span>.</p>
<p>To begin the algorithm, we’ll need to know both an upper bound and a
lower bound on <span class="math inline">x^*</span>. One could write out
a principled algorithm for finding these bounds, but for the purposes of
this class we’ll just find these by inspection. We’ll denote these upper
and lower bounds as <span class="math inline">\overline x</span> and
<span class="math inline">\underline x</span>, respectively.</p>
<p>At each iteration, these upper and lower bounds will essentially give
the edges of our search space, since we know by concavity that the
optimal solution must be between them. The purpose of each iteration is
to select our next trial solution <span
class="math inline">x&#39;</span> such that we can reduce the size of
our search space at the next iteration. One could go about determining
this next trial solution in several different ways, but our selection in
the bisection method is (fittingly for the name) to select the midpoint
between <span class="math inline">\underline x</span> and <span
class="math inline">\overline x</span>. So we set <span
class="math inline">x&#39;=\frac{\underline x + \overline
x}{2}</span>.</p>
<p>At this point, we may have gotten lucky and have <span
class="math inline">f&#39;(x&#39;)=0</span>. In that case, we would have
found the optimal solution (due to concavity of <span
class="math inline">f</span>). But otherwise we can use the sign of
<span class="math inline">f&#39;(x&#39;)</span> to tighten our bounds.
In particular, if <span class="math inline">f&#39;(x&#39;)&lt;0</span>
then we must have <span class="math inline">x^*&lt;x&#39;</span> and so
<span class="math inline">x&#39;</span> can be the upper bound in our
next iteration. Otherwise, <span
class="math inline">f&#39;(x&#39;)&gt;0</span> and so <span
class="math inline">x^*&gt;x&#39;</span> and <span
class="math inline">x&#39;</span> is the lower bound in the next
iteration.</p>
<p>Brining it all together, the bisection method works like this:</p>
<ul>
<li><em>Initialize</em>: Select error tolerance <span
class="math inline">\epsilon</span> and find initial bounds <span
class="math inline">\underline x</span>, <span
class="math inline">\overline x</span> by inspection. Select the initial
trial solution as <span class="math inline">x&#39;=\frac{\underline x +
\overline x}{2}</span>.</li>
<li><em>Iterate</em>:
<ul>
<li>Evaluate (the sign of) <span
class="math inline">f&#39;(x&#39;)</span>:</li>
<li>If <span class="math inline">f&#39;(x&#39;)\geq 0</span>:
<ul>
<li>Set <span class="math inline">\underline x=x&#39;</span>.</li>
</ul></li>
<li>Else:
<ul>
<li>Set <span class="math inline">\overline x=x&#39;</span>.</li>
</ul></li>
<li>Set <span class="math inline">x&#39;=\frac{\underline x + \overline
x}{2}</span>.</li>
<li>If <span class="math inline">\overline x - \underline x &lt;=
2\epsilon</span>:
<ul>
<li><span class="math inline">x&#39;</span> must be within <span
class="math inline">\epsilon</span> of <span
class="math inline">x^*</span>, so terminate and return <span
class="math inline">x&#39;</span> as optimal within tolerance.</li>
</ul></li>
</ul></li>
</ul>
<h4>
Example
</h4>
<p>Let’s run the bisection method now using the function <span
class="math inline">f(x) = 12x - 3x^4 - 2x^6</span>, which we’ve plotted
below. We can verify that <span class="math inline">f&#39;&#39;(x) = -
36x^2 - 60 x^4</span>, and so <span
class="math inline">f&#39;&#39;(x)\leq0</span> for all <span
class="math inline">x</span> meaning <span class="math inline">f</span>
is concave and hence suitable for the method.</p>
<div class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px" data-expression="12x - 3x^4 - 2x^6"
data-xrange="[-0.22, 1.3]">

</div>
<p>We’ll let <span class="math inline">\epsilon = 0.01</span>, and by
inspection we can find that <span class="math inline">0</span> and <span
class="math inline">2</span> are respectively lower and upper bounds on
the maximum. So for our first iteration we’ll have <span
class="math inline">\underline x=0</span>, <span
class="math inline">\overline x=2</span>, and <span
class="math inline">x&#39;=\frac{0 + 2}{2}=1</span>.</p>
<p>The following table illustrates the how the values of <span
class="math inline">\underline x, \overline x</span>, and <span
class="math inline">x&#39;</span> change as we iterate through the
bisection method.</p>
<figure>
<img src="images/bisection-example-table.png"
alt="Applying the bisection method on f(x)=12x - 3x^4 - 2x^6 (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Applying the bisection method on <span
class="math inline">f(x)=12x - 3x^4 - 2x^6</span> <span class="citation"
data-cites="classText">(<a href="#ref-classText"
role="doc-biblioref">Hillier and Lieberman 2021</a>)</span></figcaption>
</figure>
<p>As another visual aid, consider the below plots that illustrate how
<span class="math inline">x&#39;</span> is updated from iteration to
iteration.</p>
<div>
<script>
     bisectExClickFunc = (x) => {
          const plotNums = [1, 2, 3, 4, 5, 6, 7];
          for (plotNum of plotNums){
               plotEl = document.getElementById('bisectEx' + plotNum);
               if (plotEl.style.display === 'block') {
                    displayed = plotNum;
               }
          }
          newDisplayed = displayed + parseInt(x);
          newDisplayed = newDisplayed === (plotNums.length + 1) ? 1 : newDisplayed === 0 ? plotNums.length : newDisplayed;
          document.getElementById('bisectEx' + displayed).style.display = 'none';
          document.getElementById('bisectEx' + newDisplayed).style.display = 'block';
          document.getElementById('bisectExPlotLabel').textContent = 'Iteration ' + newDisplayed;
     }
</script>
<div id="bisectEx1" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:block"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[1, &quot;eval&quot;, &quot;blue&quot;, 5], [0.5, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="bisectEx2" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:none"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[0.5, &quot;eval&quot;, &quot;blue&quot;, 5], [0.75, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="bisectEx3" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:none"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[0.75, &quot;eval&quot;, &quot;blue&quot;, 5], [0.875, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="bisectEx4" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:none"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[0.875, &quot;eval&quot;, &quot;blue&quot;, 5], [0.8125, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="bisectEx5" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:none"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[0.8125, &quot;eval&quot;, &quot;blue&quot;, 5], [0.84375, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="bisectEx6" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:none"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[0.84375, &quot;eval&quot;, &quot;blue&quot;, 5], [0.828125, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="bisectEx7" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:none"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[0.828125, &quot;eval&quot;, &quot;blue&quot;, 5], [0.8359375, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="bisectExPlotLabel" style="text-align: center">
Iteration 1
</div>
<div style="display: flex; justify-content: center">
<button class="forwardBackwardButton" id="bisectExPlotBackButton" onClick="bisectExClickFunc(&quot;-1&quot;)">
</button>
<button class="forwardBackwardButton" id="bisectExPlotForwardButton" onClick="bisectExClickFunc(&quot;1&quot;)">
</button>
</div>
<script>
     document.getElementById('bisectExPlotBackButton').textContent = '<<';
     document.getElementById('bisectExPlotForwardButton').textContent = '>>';
</script>
</div>
<h3 data-number="6.2.5" id="newtons-method"><span
class="header-section-number">6.2.5</span> Newton’s method</h3>
<p>The bisection method is certainly a valid optimization algorithm and
its simplicity makes it a good choice for an introduction to search
procedures. But its main drawback is that it is relatively slow to
converge. Recall that we started the algorithm with 0 and 2 as our lower
and upper bounds and a trial solution of 1, so the distance from our
trial solution to the true optimal solution was at most 1. Each
iteration reduces the gap by a factor <span
class="math inline">\frac{1}{2}</span>, so to reduce it below our chosen
tolerance of <span class="math inline">\epsilon=0.01</span> we are
required to complete <span class="math inline">\lceil \log_2(1) -
\log_2(0.01) \rceil=7</span> iterations of the algorithm.</p>
<p>Without another method to compare to, it is hard to say whether or
not this is good. But we will find that our next method, known as
<strong>Newton’s method</strong><a href="#fn94" class="footnote-ref"
id="fnref94" role="doc-noteref"><sup>94</sup></a>, will usually converge
in fewer iterations. A key to the quicker convergence is that Newton’s
method will use more information about the function than the bisection
method did. Namely, instead of considering just (the sign of) the first
derivative of <span class="math inline">f</span>, Newton’s method
considers both first and second derivative information in determining
the next trial solution.</p>
<p>The motivation for how the derivative information is used comes from
the Taylor series you learned about in calculus class. Assuming that
<span class="math inline">f</span> is infinitely differentiable, the
<strong>Taylor series</strong> of <span class="math inline">f</span> at
some number <span class="math inline">a\in\mathbb{R}</span> is given
by:</p>
<p><span class="math display">
f(a) + \frac{f&#39;(a)}{1!}(x - a) + \frac{f&#39;&#39;(a)}{2!}(x - a)^2
+ \frac{f&#39;&#39;&#39;(a)}{3!}(x - a)^3 + \dots
</span></p>
<p>The nice thing about the Taylor series is that it gives us a way to
approximate <em>any</em> function by a polynomial, by evaluating at
least the first few terms of the series. Indeed, for any <span
class="math inline">x</span> that is “close to” <span
class="math inline">a</span>, the second-degree Taylor polynomial
approximates the value of <span class="math inline">f(x)</span> quite
well, i.e. we have</p>
<p><span class="math display">
f(x) \approx f(a) + \frac{f&#39;(a)}{1!}(x - a) +
\frac{f&#39;&#39;(a)}{2!}(x - a)^2
</span></p>
<p>This is precisely what Newton’s method uses to determine its next
trial solution. Essentially, we will use the second-degree Taylor
polynomial as a quadratic approximation to <span
class="math inline">f</span> and quickly solve for <span
class="math inline">x</span> that maximizes the approximation.</p>
<p>How do we do this? Recall that <span class="math inline">a</span> is
just some real number (in our algorithm, it will be the current trial
solution), so that <span class="math inline">f(a), f&#39;(a)</span>, and
<span class="math inline">f&#39;&#39;(a)</span> are just constants. So
the polynomial is really just a quadratic function of <span
class="math inline">x</span>, for which can we can easily take a
derivative and say</p>
<p><span class="math display">
f&#39;(x)\approx f&#39;(a) + f&#39;&#39;(a)(x - a)
</span></p>
<p>If we set that right-hand side to 0 and solve for <span
class="math inline">x</span>, we end up with:</p>
<p><span class="math display">
x = a - \frac{f&#39;(a)}{f&#39;&#39;(a)}.
</span></p>
<p>We won’t prove it, but it is true that since we’ve assumed <span
class="math inline">f</span> is concave, it is also true that the
second-degree Taylor polynomial is concave. So that critical point <span
class="math inline">a - \frac{f&#39;(a)}{f&#39;&#39;(a)}</span> we just
found is a global maximum for the polynomial. Since the polynomial is a
good estimate for <span class="math inline">f</span> (at least when near
<span class="math inline">a</span>) we might as well take that value as
our next trial solution.</p>
<p>This is precisely what we’ll do in Newton’s method. Let’s use the
notation <span class="math inline">x_i</span> for the trial solution in
the <span class="math inline">i</span>th iteration of the method. Then
the trial solutions follow the relation:</p>
<p><span class="math display">
x_{i + 1} = x_i - \frac{f&#39;(x_i)}{f&#39;&#39;(x_i)}.
</span></p>
<p>We’ve determined how to update the trial solution, but how do we know
when to stop? Two common stopping criteria are to stop either when two
consecutive trial solutions are sufficiently close, i.e. <span
class="math inline">|x_{i + 1} - x_i|&lt;\epsilon</span> for some small
<span class="math inline">\epsilon&gt;0</span>, or for the derivative at
the trial solution to be sufficiently close to zero, i.e. <span
class="math inline">f&#39;(x_i)&lt;\epsilon</span>. For our presentation
below, we’ll adopt the first standard.</p>
<p>Lastly, how should we determine the first trial solution? It
ultimately does not matter - one could just start at <span
class="math inline">x=0</span> or anywhere else you like. If you can
plot out the function to find a good initial spot, or otherwise have a
good idea where the optimum might be, you can just go with that as
well.</p>
<p>Bringing it all together, here are the steps for executing Newton’s
method:</p>
<ul>
<li><em>Initialize</em>: Select error tolerance <span
class="math inline">\epsilon</span>. Set <span
class="math inline">i=1</span> and choose initial trial solution <span
class="math inline">x_1</span>.</li>
<li><em>Iterate</em>:
<ul>
<li>Set <span class="math inline">x_{i+1}=x_i -
\frac{f&#39;(x_i)}{f&#39;&#39;(x_i)}</span>.</li>
<li>If <span class="math inline">|x_{i+1}-x_i|&lt;\epsilon</span>:
<ul>
<li>Terminate and return <span class="math inline">x_{i+1}</span> as
optimal within tolerance.</li>
</ul></li>
<li>Else:
<ul>
<li>Set <span class="math inline">i=i+1</span>.</li>
</ul></li>
</ul></li>
</ul>
<h4>
Example
</h4>
<p>Let’s go ahead and run Newton’s method on the same example from last
section, <span class="math inline">f(x)=12x - 3x^4 - 2x^6</span>. We’ll
start from the same initial trial solution <span
class="math inline">x_1=1</span>, and decrease the error tolerance to
<span class="math inline">\epsilon=0.00001</span>. From here, the only
information we need to complete the first iteration is <span
class="math inline">f&#39;(1)</span> and <span
class="math inline">f&#39;&#39;(1)</span>. We have</p>
<p><span class="math display">
f&#39;(x) = 12 - 12x^3 - 12x^5 = 12(1 - x^3 - x^5)
</span></p>
<p>and</p>
<p><span class="math display">
f&#39;&#39;(x) = -12(3x^2 + 5x^4)
</span></p>
<p>meaning that the next trial solution should be</p>
<p><span class="math display">
x_2 = x_1 - \frac{12(1 - x_1^3 - x_1^5)}{-12(3x_1^2 + 5x_1^4)} = 1 -
\frac{1}{8} = \frac{7}{8}.
</span></p>
<p>Since <span class="math inline">|x_2-x_1|&gt;\epsilon</span> we must
continue with another iteration. The results of subsequent iterations
are given in the following table:</p>
<figure>
<img src="images/newton-example-table.png"
alt="Applying Newton’s method on f(x)=12x - 3x^4 - 2x^6 (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Applying Newton’s method on <span
class="math inline">f(x)=12x - 3x^4 - 2x^6</span> <span class="citation"
data-cites="classText">(<a href="#ref-classText"
role="doc-biblioref">Hillier and Lieberman 2021</a>)</span></figcaption>
</figure>
<p>Since <span class="math inline">|x_4-x_3|\leq\epsilon</span> we
terminate after iteration 4 with <span
class="math inline">0.83762</span> as our optimal (within tolerance)
solution.</p>
<p>Analogous to last section, here’s a group of plots illustrating how
the trial solution changes from iteration to iteration:</p>
<div>
<script>
     newtonExClickFunc = (x) => {
          const plotNums = [1, 2, 3, 4];
          for (plotNum of plotNums){
               plotEl = document.getElementById('newtonEx' + plotNum);
               if (plotEl.style.display === 'block') {
                    displayed = plotNum;
               }
          }
          newDisplayed = displayed + parseInt(x);
          newDisplayed = newDisplayed === (plotNums.length + 1) ? 1 : newDisplayed === 0 ? plotNums.length : newDisplayed;
          document.getElementById('newtonEx' + displayed).style.display = 'none';
          document.getElementById('newtonEx' + newDisplayed).style.display = 'block';
          document.getElementById('newtonExPlotLabel').textContent = 'Iteration ' + newDisplayed;
     }
</script>
<div id="newtonEx1" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:block"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[1, &quot;eval&quot;, &quot;blue&quot;, 5], [0.875, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="newtonEx2" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:none"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[0.875, &quot;eval&quot;, &quot;blue&quot;, 5], [0.84003, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="newtonEx3" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:none"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[0.84003, &quot;eval&quot;, &quot;blue&quot;, 5], [0.83763, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="newtonEx4" class="plotlyFunctionPlot basicCenter"
style="width:350px;height:350px;display:none"
data-expression="12x - 3x^4 - 2x^6" data-xrange="[0.4, 1.1]"
data-extrapoints="[[0.83763, &quot;eval&quot;, &quot;blue&quot;, 5], [0.83762, &quot;eval&quot;, &quot;blue&quot;, 5]]"
data-linebetweenpoints="true" data-arrowsonlines="true"
data-layoutextra="{&quot;yaxis&quot;: {&quot;range&quot;: [null, 8]}}">

</div>
<div id="newtonExPlotLabel" style="text-align: center">
Iteration 1
</div>
<div style="display: flex; justify-content: center">
<button class="forwardBackwardButton" id="newtonExPlotBackButton" onClick="newtonExClickFunc(&quot;-1&quot;)">
</button>
<button class="forwardBackwardButton" id="newtonExPlotForwardButton" onClick="newtonExClickFunc(&quot;1&quot;)">
</button>
</div>
<script>
     document.getElementById('newtonExPlotBackButton').textContent = '<<';
     document.getElementById('newtonExPlotForwardButton').textContent = '>>';
</script>
</div>
<p>It’s only a single sample, but it’s still pretty impressive to see
the difference in convergence speed between Newton’s method and the
bisection method. It only took 4 iterations for Newton’s method while
bisection took 7 iterations, and that’s even with the more forgiving
error tolerance <span class="math inline">\epsilon=0.01</span> instead
of <span class="math inline">\epsilon=0.00001</span>. If we were to run
the bisection method with the more stringent error tolerance we would
have required <span class="math inline">\lceil \log_2(1) -
\log_2(0.00001) \rceil=17</span> iterations!</p>
<!-- {insertSection:sections/nonlinear_programming/multivariate_unconstrained.md} -->
<!-- {insertSection:sections/nonlinear_programming/notes.md} -->
<h1 data-number="7" id="appendix"><span
class="header-section-number">7</span> Appendix</h1>
<h2 data-number="7.1" id="sec:symbols"><span
class="header-section-number">7.1</span> Special symbols</h2>
<ul>
<li><span class="math inline">\mathbb{R}</span>: The set of real
numbers, i.e. anything on the number line between (though not
including!) <span class="math inline">-\infty</span> and <span
class="math inline">\infty</span>.</li>
<li><span class="math inline">\mathbb{R}_+</span>: The set of
non-negative real numbers, i.e. anything in <span
class="math inline">\mathbb{R}</span> that is greater than or equal to
0.</li>
<li><span class="math inline">\mathbb{I}</span>: The set of integer
numbers, i.e. whole numbers from the set <span
class="math inline">\mathbb{R}</span>.</li>
<li><span class="math inline">\mathbb{I}_+</span>: The set of
non-negative integer numbers, i.e. anything in <span
class="math inline">\mathbb{I}</span> that is greater than or equal to
0.</li>
<li><span class="math inline">\{\cdots\}</span>: Set notation. Items
inside the curly brackets are the elements of the set, so <span
class="math inline">\{0,1\}</span> is the 2-element set consisting of
just the numbers 0 and 1.</li>
<li><span class="math inline">\in</span>: Set inclusion. When we write
<span class="math inline">x\in S</span>, we mean that <span
class="math inline">x</span> is an element of the set <span
class="math inline">S</span>. For example, we could write <span
class="math inline">\pi\in\mathbb{R}</span>, meaning the number <span
class="math inline">\pi</span> is a real number.</li>
<li><span class="math inline">\subseteq</span>: Subset. For two sets
<span class="math inline">S, S&#39;</span>, we say <span
class="math inline">S&#39;\subseteq S</span> (said “<span
class="math inline">S&#39;</span> is a subset of <span
class="math inline">S</span>”) if every element of <span
class="math inline">S&#39;</span> is also an element of <span
class="math inline">S</span>.</li>
<li><span class="math inline">|S|</span>: Size of a set. This denotes
the number of elements in a set, so e.g. <span
class="math inline">|\{1,5,7,12\}|=4</span>.</li>
<li><span class="math inline">\emptyset</span>: Empty set. A set with no
elements.</li>
<li><span class="math inline">\forall</span>: For all. We use this
symbol when we want to specify that something should be done for all
elements in some set. So if we’re writing out the constraints for some
model and we say <span class="math inline">x_j\geq 0\ \forall\ j\in\{1,
2, \cdots, n\}</span> we’re just saying that each of <span
class="math inline">x_1, x_2, \cdots, x_n</span> should be
non-negative.</li>
<li><span class="math inline">\{x: x\textit{ satisfies some
condition}\}</span>: Conditional set. This represents the set of all
<span class="math inline">x</span> such that <span
class="math inline">x</span> satisfies the condition to the right of the
colon (:). For example, <span class="math inline">\{n\in\mathbb{I}:5\leq
n\leq 10\}</span> is the set of all integers between 5 and 10,
i.e. <span class="math inline">\{5,6,7,8,9,10\}</span></li>
<li><span class="math inline">S^m</span>: The set of vectors with <span
class="math inline">m</span> elements, all of which are from some set
<span class="math inline">S</span>. For example, <span
class="math inline">\mathbb{R}^3</span> is the set of 3-element, real
number vectors. So we could say <span class="math display">
    \begin{bmatrix}1 \\ 2.64 \\ -3\end{bmatrix}\in\mathbb{R}^3.
</span></li>
<li><span class="math inline">S^{m\times n}</span>: The set of matrices
with <span class="math inline">m</span> rows and <span
class="math inline">n</span> columns, whose elements are from some set
<span class="math inline">S</span>. For example, <span
class="math inline">\mathbb{I}^{m\times n}</span> is the set of <span
class="math inline">m\times n</span> matrices whose entries are all
integers. So we could say <span class="math display">
\begin{bmatrix}4 &amp; 3 &amp; 9 &amp; 6\\ 0 &amp; 4 &amp; 8 &amp; 5\\ 7
&amp; 7 &amp; 2 &amp; 1\end{bmatrix} \in \mathbb{I}^{3\times 4}.
</span></li>
<li><span class="math inline">\mathbf{0}</span>: A matrix (or vector)
with all entries equal to 0 (the size of the matrix is usually clear by
context).</li>
<li><span class="math inline">\mathbf{I}</span>: A square matrix with
all entries equal to 0, except the diagonal where all entries equal 1
(the size of the matrix is usually clear by context). This looks like:
<span class="math display">\begin{bmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 1 \\
\end{bmatrix}</span></li>
<li><span class="math inline">\Leftrightarrow</span>: If and only if. It
indicates the the statement to the left is logically equivalent to the
statement on the right, e.g. <span class="math inline">a &gt; b
\Leftrightarrow -a &lt; -b</span>.</li>
<li><span class="math inline">\lfloor x \rfloor</span>: The “floor” of
the number <span class="math inline">x\in\mathbb{R}</span>, i.e. the
value resulting from rounding <span class="math inline">x</span> down to
the nearest integer. So <span class="math inline">\lfloor 1.3
\rfloor=1</span>.</li>
<li><span class="math inline">\lceil x \rceil</span>: The “ceiling” of
the number <span class="math inline">x\in\mathbb{R}</span>, i.e. the
value resulting from rounding <span class="math inline">x</span> up to
the nearest integer. So <span class="math inline">\lceil 1.3
\rceil=2</span>.</li>
</ul>
<h2 data-number="7.2" id="sec:linearAlgebra"><span
class="header-section-number">7.2</span> Linear algebra review</h2>
<p>Linear algebra is the study of math involving matrices, vectors, and
linear transformations. A <strong>matrix</strong> (the basic object of
linear algebra) is a rectangular array of numbers. For example,</p>
<p><span class="math display">
\mathbf{A}=\begin{bmatrix} 2 &amp; 4 \\ 7 &amp; 0 \\ 6 &amp; 3
\end{bmatrix}
</span></p>
<p>is a <span class="math inline">3\times 2</span> matrix. A matrix is
said to be <strong>square</strong> if it has the same number of rows and
columns.</p>
<p>In these notes, we will usually denote matrices with boldface,
uppercase letters.</p>
<h3 data-number="7.2.1" id="sec:matrixMath"><span
class="header-section-number">7.2.1</span> Matrix math</h3>
<p>We say Matrices <span class="math inline">\mathbf{A}</span>, <span
class="math inline">\mathbf{B}</span> are <strong>equal</strong> if
<em>all</em> of their elements are equal. First off, that means <span
class="math inline">\mathbf{A}</span> and <span
class="math inline">\mathbf{B}</span> must have the same number of rows
<span class="math inline">m</span> and columns <span
class="math inline">n</span>. Additionally, if we write notate the
entries of the matrices like:</p>
<p><span id="eq:matrixDef" class="eqnos"><span class="math display">
\mathbf{A} = \begin{bmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn} \\
\end{bmatrix}
</span><span class="eqnos-number">(23)</span></span></p>
<p>and</p>
<p><span class="math display">
\mathbf{B} = \begin{bmatrix}
b_{11} &amp; b_{12} &amp; \cdots &amp; b_{1n} \\
b_{21} &amp; b_{22} &amp; \cdots &amp; b_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
b_{m1} &amp; b_{m2} &amp; \cdots &amp; b_{mn} \\
\end{bmatrix}.
</span></p>
<p>Then we say <span class="math inline">\mathbf{A}=\mathbf{B}\ </span>
if and only if <span class="math inline">\ a_{11}=b_{11}</span>, <span
class="math inline">a_{12}=b_{12}</span>, … and so on.</p>
<p><strong>Addition</strong> is only defined for two matrices of the
same size. For two <span class="math inline">m\times n</span> matrices
<span class="math inline">\mathbf{A}</span> and <span
class="math inline">\mathbf{B}</span>, we have</p>
<p><span class="math display">
\mathbf{A} + \mathbf{B} = \begin{bmatrix}
a_{11} + b_{11} &amp; a_{12} + b_{12} &amp; \cdots &amp; a_{1n} + b_{1n}
\\
a_{21} + a_{21} &amp; a_{22} + a_{22} &amp; \cdots &amp; a_{2n} + a_{2n}
\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{m1} + a_{m1} &amp; a_{m2} + a_{m2} &amp; \cdots &amp; a_{mn} + a_{mn}
\\
\end{bmatrix}
</span></p>
<p>For matrices, <strong>multiplication</strong> <span
class="math inline">\mathbf{A}\mathbf{B}</span> is only defined when the
the second dimension of <span class="math inline">\mathbf{A}</span>
equals the first dimension of <span
class="math inline">\mathbf{B}</span>. So, if <span
class="math inline">\mathbf{A}</span> is an <span
class="math inline">m\times n</span> matrix (for some <span
class="math inline">m, n</span>), we need <span
class="math inline">B</span> to be an <span class="math inline">n\times
s</span> matrix (for some <span class="math inline">s</span>). In this
case, we define their product as the matrix <span
class="math inline">\mathbf{C}</span> having entries</p>
<p><span class="math display">
c_{ij} = \sum_{k=1}^n a_{ik}b_{kj}.
</span></p>
<p>Here is a small example to see it in action:</p>
<p><span class="math display">
\begin{align*}
\begin{bmatrix}0&amp;1\\2&amp;3\\4&amp;5\end{bmatrix}
\begin{bmatrix}6&amp;7\\8&amp;9\end{bmatrix}
&amp;=
\begin{bmatrix}
0\cdot6 + 1\cdot8 &amp; 0\cdot7 + 1\cdot9 \\
2\cdot6 + 3\cdot8 &amp; 2\cdot7 + 3\cdot9 \\
4\cdot6 + 5\cdot8 &amp; 4\cdot7 + 5\cdot9 \\
\end{bmatrix}\\
&amp;=
\begin{bmatrix}8&amp;9\\36&amp;41\\64&amp;73\end{bmatrix}
\end{align*}
</span></p>
<p>There is a simpler form of multiplication available between a matrix
<span class="math inline">\mathbf{A}</span> and a scalar (a single
number) <span class="math inline">s</span>, where each element of the
product is simply the corresponding element of <span
class="math inline">\mathbf{A}</span> multiplied by <span
class="math inline">s</span>, i.e.</p>
<p><span class="math display">
s\mathbf{A}= \begin{bmatrix}
sa_{11} &amp; sa_{12} &amp; \cdots &amp; sa_{1n} \\
sa_{21} &amp; sa_{22} &amp; \cdots &amp; sa_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
sa_{m1} &amp; sa_{m2} &amp; \cdots &amp; sa_{mn} \\
\end{bmatrix}
</span></p>
<h3 data-number="7.2.2" id="properties-of-matrix-operations"><span
class="header-section-number">7.2.2</span> Properties of matrix
operations</h3>
<p>The above matrix operations satisfy the following properties:</p>
<ul>
<li>Associativity of addition:<span class="math display">(\mathbf{A}+
\mathbf{B}) + \mathbf{C} = \mathbf{A}+ (\mathbf{B} +
\mathbf{C})</span></li>
<li>Associativity of multiplication:<span
class="math display">\mathbf{A}(\mathbf{B}\mathbf{C}) =
(\mathbf{A}\mathbf{B})\mathbf{C}</span></li>
<li>Commutativity of addition:<span class="math display">\mathbf{A}+
\mathbf{B} = \mathbf{B} + \mathbf{A}</span></li>
<li>Distributivity:<span class="math display">\mathbf{A}(\mathbf{B} +
\mathbf{C}) = \mathbf{A}\mathbf{B} + \mathbf{A}\mathbf{C}</span></li>
</ul>
<p>You may notice that multiplication does not commute, i.e. <span
class="math inline">\mathbf{A}\mathbf{B} \neq
\mathbf{B}\mathbf{A}</span>. Indeed, in the general case where <span
class="math inline">\mathbf{A}</span> is an <span
class="math inline">m\times n</span> matrix and <span
class="math inline">\mathbf{B}</span> is an <span
class="math inline">n\times s</span> matrix, the product <span
class="math inline">\mathbf{B}\mathbf{A}</span> is not even defined if
<span class="math inline">m\neq s</span>. Even if <span
class="math inline">m=s</span> and the product is defined, the result
needs not be the same.</p>
<h3 data-number="7.2.3" id="special-matrices"><span
class="header-section-number">7.2.3</span> Special matrices</h3>
<p>A <strong>vector</strong> is a special type of matrix with either a
single column or a single row, e.g.</p>
<p><span class="math display">
\mathbf{x}=\begin{bmatrix} 1 \\ 9 \\ 3 \end{bmatrix}
</span></p>
<p>is a <strong>column vector</strong> and <span
class="math display">\mathbf{x}=\begin{bmatrix} 1 &amp; 9 &amp; 3
\end{bmatrix}</span> is a <strong>row vector</strong>. In these notes,
vectors will usually be denoted with with boldface, lowercase letters. A
convention in some texts, which we will not follow here, is for vectors
to be assumed as column vectors unless explicitly transposed. For these
notes, we will let context dictate whether a vector is a row vector or a
column vector (it is usually clear).</p>
<p>An <strong>identity matrix</strong>, denoted by <span
class="math inline">\mathbf{I}</span>, is a square vector whose elements
are all 0s expect for 1s along the diagonal, i.e.</p>
<p><span class="math display">
\mathbf{I}= \begin{bmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 1 \\
\end{bmatrix}
</span></p>
<p>The main property of identity matrices is that multiplying another
(properly sizes) matrix does not alter it, i.e. we have</p>
<p><span class="math display">
\mathbf{I}\mathbf{A}= \mathbf{A},\quad \mathbf{A}\mathbf{I}= \mathbf{A}.
</span></p>
<p>Note that we usually don’t explicitly specify the size of <span
class="math inline">\mathbf{I}</span>, since it is usually clear from
the context.</p>
<p>The <strong>null matrix</strong> or <strong>zero matrix</strong>,
denoted by <span class="math inline">\mathbf{0}</span> is a matrix (or
vector) with all entries equal to 0. Again, we will usually not
explicitly specify its size since it will be clear from context. The
zero matrix satisfies:</p>
<p><span class="math display">
\mathbf{A}+ \mathbf{0}= \mathbf{A},\quad \mathbf{0}\mathbf{A}=
\mathbf{0},\quad \mathbf{A}\mathbf{0}= \mathbf{A}.
</span></p>
<p>Note that <span class="math inline">\mathbf{I}</span> and <span
class="math inline">\mathbf{0}</span> play roles in matrix operations
similar to the roles of 1 and 0 (respectively) in arithmetic.</p>
<h3 data-number="7.2.4" id="rank-and-inverse"><span
class="header-section-number">7.2.4</span> Rank and inverse</h3>
<p>A set of vectors <span class="math inline">\mathbf{x}_1,
\mathbf{x}_2, \dots, \mathbf{x}_m</span> is said to be <strong>linearly
dependent</strong> if there exists <span class="math inline">m</span>
numbers <span class="math inline">c_1, c_2, \dots, c_m</span>, some of
which are not zeros, such that</p>
<p><span class="math display">
c_1\mathbf{x}_1 + c_2\mathbf{x}_2 + \cdots + c_m\mathbf{x}_m =
\mathbf{0}.
</span></p>
<p>Otherwise, the vectors are said to be <strong>linearly
independent</strong>. For example, the vectors</p>
<p><span class="math display">
\mathbf{x}_1 = [1, 1, 1],\quad \mathbf{x}_2 = [0, 1, 1],\quad
\mathbf{x}_3 = [2, 5, 5],
</span></p>
<p>if we take <span class="math inline">c_1 = 2</span>, <span
class="math inline">c_2 = 3</span>, and <span class="math inline">c_3 =
-1</span> then we have</p>
<p><span class="math display">
\begin{align*}
2\mathbf{x}_1 + 3\mathbf{x}_2 - x_3 &amp; = [2, 2, 2] + [0, 3, 3] - [2,
5, 5]\\
                    &amp; = [0, 0, 0]
\end{align*}
</span></p>
<p>so the vectors are linearly dependent.</p>
<p>The <strong>rank</strong> of a set of vectors is the largest number
of linearly independent vectors that can be chosen from the space. So
e.g. the rank of <span class="math inline">\{\mathbf{x}_1, \mathbf{x}_2,
\mathbf{x}_3\}</span> from above is 2.</p>
<p>Matrices also have a notion of rank. The <strong>row rank</strong> of
a matrix is the rank of its set of row vectors, while the <strong>column
rank</strong> of the matrix is the rank of its set of column vectors. An
important result in linear algebra is that, for any matrix, the row rank
and column rank are the same. Thus we can talk about the
<strong>rank</strong> of a matrix, being equal to either the row rank or
the column rank.</p>
<p>Suppose <span class="math inline">\mathbf{A}</span> is an <span
class="math inline">n\times n</span> (square) matrix. We say <span
class="math inline">\mathbf{A}</span> is <strong>non-singular</strong>
if it has rank <span class="math inline">n</span>. Otherwise, if the
rank is less than <span class="math inline">n</span>, we way it is
<strong>singular</strong>. Importantly, if <span
class="math inline">\mathbf{A}</span> is non-singular, there is a unique
non-singular matrix <span class="math inline">\mathbf{A}^{-1}</span>
such that</p>
<p><span class="math display">
\mathbf{A}\mathbf{A}^{-1}= \mathbf{I}= \mathbf{A}^{-1}\mathbf{A}.
</span></p>
<p>We call the matrix <span class="math inline">\mathbf{A}^{-1}</span>
the <strong>inverse</strong> of <span
class="math inline">\mathbf{A}</span>. Furthermore, singular matrices do
not have inverses.</p>
<h3 data-number="7.2.5" id="systems-of-equations"><span
class="header-section-number">7.2.5</span> Systems of equations</h3>
<p>Matrices are great for concisely stating systems of linear equations,
linear equations in some set of variables you’d like to hold true
simultaneously. For example, the set of equations</p>
<p><span class="math display">
2x_1 + 3x_2 = 7\\
5x_1 - 4x_2 = 6
</span></p>
<p>can alternatively be stated as:</p>
<p><span class="math display">
\begin{bmatrix}
2 &amp; 3 \\
5 &amp; -4
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
7 \\ 6
\end{bmatrix}
</span></p>
<h3 data-number="7.2.6" id="sec:elementaryRowOperations"><span
class="header-section-number">7.2.6</span> Elementary operations</h3>
<p>There are certain elementary operations one can perform on a system
of linear equations that don’t have an effect on the solution of the
system. I’ll state these operations in terms of rows, but similar
operations exist for columns as well:</p>
<ul>
<li>Interchange two rows: <span class="math display">
\begin{bmatrix}
2 &amp; 3 \\
5 &amp; -4
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
7 \\ 6
\end{bmatrix}
\Leftrightarrow
\begin{bmatrix}
5 &amp; -4 \\
2 &amp; 3
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
6 \\ 7
\end{bmatrix}
</span></li>
<li>Multiply a row by a non-zero number, e.g. multiplying the top row by
two: <span class="math display">
\begin{bmatrix}
2 &amp; 3 \\
5 &amp; -4
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
7 \\ 6
\end{bmatrix}
\Leftrightarrow
\begin{bmatrix}
4 &amp; 6 \\
5 &amp; -4
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
14 \\ 6
\end{bmatrix}
</span></li>
<li>Adding a multiple of one row to another row, e.g. multiplying the
first row by 2 and adding it to the second: <span class="math display">
\begin{bmatrix}
2 &amp; 3 \\
5 &amp; -4
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
7 \\ 6
\end{bmatrix}
\Leftrightarrow
\begin{bmatrix}
2 &amp; 3 \\
9 &amp; 2
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
7 \\ 20
\end{bmatrix}
</span></li>
</ul>
<h2 data-number="7.3" id="writing-mathematics-in-a-colab-notebook"><span
class="header-section-number">7.3</span> Writing mathematics in a Colab
notebook</h2>
<p>Besides writing Python code, another useful feature of a Colab
notebook is the ability to use “text” cells to write Markdown. <a
href="https://en.wikipedia.org/wiki/Markdown">Markdown</a> provides a
convenient way to render formatted text, and in fact the notes you are
reading now were written using it. The flavor of Markdown implemented in
Colab allows for the addition of <a
href="https://en.wikipedia.org/wiki/LaTeX">LaTeX</a> syntax for
rendering mathematical symbols. Colab is far from the only place where
you can use Markdown, but as usual it is simple to set up and use right
out of the box.</p>
<p>In the following notebook, I’ve included examples of how to render
mathematical symbols inside Colab. This is far from a comprehensive
guide, sticking to items I think might be useful for the class. I came
across a more extensive guide you may want to check out <a
href="https://ashki23.github.io/markdown-latex.html">here</a>.</p>
<script src="https://gist.github.com/eea93b3fac7b6040bcb074e95b4e5076.js"></script>
<h2 data-number="7.4" id="sec:badIpModels"><span
class="header-section-number">7.4</span> Examples of bad IP
modeling</h2>
<p>When modeling problems as integer programs, and especially when using
binary variables to encode some type of logic, it can be very easy to
<em>think</em> you’ve come up with a valid formulation, only to solve
the problem and get an answer that you weren’t expecting due to some bad
constraints. In this section, I’ll give some sample “bad” IP models that
do not properly enforce the logic they were meant to, and discuss how
things went wrong.</p>
<h3 data-number="7.4.1" id="boolean-algebra"><span
class="header-section-number">7.4.1</span> Boolean algebra</h3>
<p>Let’s consider the Boolean algebra operations we modeled in
section <a href="#sec:binVarTricks">5.3.2</a>. We’ll show wrong ways to
model each of AND, OR, and XOR, and explain why they don’t work as
required. In each model, we want the binary variable <span
class="math inline">y</span> to equal the output of the specified
Boolean function applied to binary variables <span
class="math inline">x_1</span> and <span
class="math inline">x_2</span>.</p>
<ul>
<li><p>AND: Here’s the truth table and an example
<strong>incorrect</strong> formulation:</p>
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
\begin{align*}
y&amp;\leq x_1 \\
y&amp;\leq x_2 \\
y&amp;\geq \frac{1}{2}(x_1 + x_2) \\
  x_1, x_2, y &amp; \in \{0,1\}
\end{align*}
</span>
</div>
</div>
<p>It is easy to look at this and say something like: “when <span
class="math inline">x_1=x_2=1</span> then the third constraint makes
<span class="math inline">y=1</span>, and otherwise one of <span
class="math inline">y\leq x_1</span> or <span class="math inline">y\leq
x_2</span> will force <span class="math inline">y=0</span>”. And while
that statement is true, it fails to account for the fact that all
constraints are active in an integer program, and we don’t get to pick
and choose which ones to enforce based on the situation.</p>
<p>Once we start considering every constraint, we see that if only one
of <span class="math inline">x_1</span> or <span
class="math inline">x_2</span> equal 1 then there is no feasible value
for <span class="math inline">y</span>. For example, suppose that we
have <span class="math inline">x_1=1</span> and <span
class="math inline">x_2=0</span>. Then the second constraint will say
<span class="math inline">y\leq0</span>, while the third constraint will
say <span class="math inline">y\geq1/2</span>, and these two clearly
can’t be satisfied simultaneously. As a result, any model with this as
part of the constraints will not be able to return a solution where
<span class="math inline">x_1+x_2=1</span>, which is probably not what
you wanted.</p></li>
<li><p>OR: Once again, here’s the truth table and a <strong>bad</strong>
formulation:</p>
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
  \begin{align*}
  y&amp;\geq x_1 \\
  y&amp;\geq x_2 \\
  x_1, x_2, y &amp; \in \{0,1\}
  \end{align*}
  </span>
</div>
</div>
<p>This will correctly force <span class="math inline">y=1</span> in
situations where either <span class="math inline">x_1</span> or <span
class="math inline">x_2</span> (or both) are <span
class="math inline">1</span>, but it fails to properly account for the
converse, i.e. the top row of the truth table when <span
class="math inline">x_1=x_2=0</span>. These constraints will allow
either <span class="math inline">y=0</span> or <span
class="math inline">y=1</span> in that case, instead of enforcing <span
class="math inline">y=0</span> like we want.</p></li>
<li><p>XOR: The truth table and <strong>improper</strong>
formulation:</p>
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
  \begin{align*}
  y&amp;\leq x_1 + x_2 \\
  y&amp;\geq x_1 \\
  y&amp;\geq x_2 \\
  y&amp;\leq x_1 - x_2 \\
   x_1, x_2, y &amp; \in \{0,1\}
  \end{align*}
  </span>
</div>
</div>
<p>We could once again be tricked by this formulation if we only
consider certain constraints for certain scenarios. We could say:</p>
<ul>
<li>Constraint 1 forces <span class="math inline">y=0</span> when <span
class="math inline">x_1=0,x_2=0</span></li>
<li>Constraint 2 forces <span class="math inline">y=1</span> when <span
class="math inline">x_1=1,x_2=0</span></li>
<li>Constraint 3 forces <span class="math inline">y=1</span> when <span
class="math inline">x_1=0,x_2=1</span></li>
<li>Constraint 4 forces <span class="math inline">y=0</span> when <span
class="math inline">x_1=1,x_2=1</span></li>
</ul>
<p>and think that we’ve satisfied all of our requirements. The catch, as
with our AND formulation, is that these constraints must be considered
<em>simultaneously</em> in <em>every</em> situation. So for example, in
the situation <span class="math inline">x_1=0,x_2=1</span> we would
indeed get the third constraint forcing <span
class="math inline">y=1</span>. But we’d also have the fourth constraint
forcing <span class="math inline">y\leq-1</span>, meaning that the
constraints can not all be satisfied in this case. Thus a model with
this as part of the constraint set could never return a solution with
<span class="math inline">x_1=0, x_2=1</span>, incorrectly cutting off
an entire segment of the problem’s feasible region.</p></li>
</ul>
<h2 data-number="7.5" id="sec:appendixSelectedProofs"><span
class="header-section-number">7.5</span> Selected proofs</h2>
<p>This section contains proofs to selected statements in the main
text.</p>
<h1 id="References">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="doc-bibliography">
<div id="ref-bertsimas-LPbook" class="csl-entry" role="doc-biblioentry">
Bertsimas, D., and J. N. Tsitsiklis. 1997. <em>Introduction to Linear
Optimization</em>. Athena Scientific.
</div>
<div id="ref-simplexPivotNoLoops" class="csl-entry"
role="doc-biblioentry">
Bland, Robert G. 1977. <span>“New Finite Pivoting Rules for the Simplex
Method.”</span> <em>Mathematics of Operations Research</em> 2 (2):
103–7. <a
href="http://www.jstor.org/stable/3689647">http://www.jstor.org/stable/3689647</a>.
</div>
<div id="ref-tspPursuit" class="csl-entry" role="doc-biblioentry">
Cook, William J. 2012. <em>In Pursuit of the Traveling Salesman:
Mathematics at the Limits of Computation</em>. Princeton University
Press. <a
href="http://www.jstor.org/stable/j.ctt7t8kc">http://www.jstor.org/stable/j.ctt7t8kc</a>.
</div>
<div id="ref-classText" class="csl-entry" role="doc-biblioentry">
Hillier, F. S., and G. J. Lieberman. 2021. <em>Introduction to
Operations Research</em>. McGraw-Hill Education. <a
href="https://books.google.com/books?id=gnhSzQEACAAJ">https://books.google.com/books?id=gnhSzQEACAAJ</a>.
</div>
<div id="ref-kleeMinty" class="csl-entry" role="doc-biblioentry">
Klee, Victor, and George J. Minty. 1970. <span>“HOW GOOD IS THE SIMPLEX
ALGORITHM.”</span> In. <a
href="https://api.semanticscholar.org/CorpusID:117965841">https://api.semanticscholar.org/CorpusID:117965841</a>.
</div>
<div id="ref-solverBenchmarks" class="csl-entry" role="doc-biblioentry">
<span>“Mittelmann Benchmarks.”</span> n.d. <a
href="https://plato.asu.edu/bench.html">https://plato.asu.edu/bench.html</a>.
</div>
<div id="ref-spivakCalculus" class="csl-entry" role="doc-biblioentry">
Spivak, M. 2006. <em>Calculus</em>. Calculus. Cambridge University
Press. <a
href="https://books.google.com/books?id=7JKVu_9InRUC">https://books.google.com/books?id=7JKVu_9InRUC</a>.
</div>
<div id="ref-tspPic" class="csl-entry" role="doc-biblioentry">
<span>“Waterloo TSP.”</span> n.d. <a
href="https://www.math.uwaterloo.ca/tsp/"
class="uri">https://www.math.uwaterloo.ca/tsp/</a>.
</div>
<div id="ref-wolsey2020" class="csl-entry" role="doc-biblioentry">
Wolsey, L. A. 2020. <em>Integer Programming</em>. Wiley. <a
href="https://books.google.com/books?id=3yhPwwEACAAJ">https://books.google.com/books?id=3yhPwwEACAAJ</a>.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The most recent version of this textbook is the 11th
edition, which came out in 2021. But much of the content quoted here
comes from the 10th edition from 2015. Nothing about the course will
require you to have a certain edition, or any book at all. But I think
it’s a very useful reference.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The pedant in me wants to point out that this word
“optimal” is horribly misused in conversation fairly regularly, in the
form of the misguided phrase “more optimal”. As I mentioned, “optimal”
really just means “best”, and “best” is not on a sliding scale; either
you have the best answer or you don’t. One choice can’t be “more best”
than another, just as one solution can’t be “more optimal” than another.
I think I’m fighting a losing battle on this, but maybe for the sake of
this course we can all agree to never put the words “more” and “optimal”
next to each other? Thanks.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>There’s a neat book all about the TSP, <span
class="citation" data-cites="tspPursuit">Cook (<a href="#ref-tspPursuit"
role="doc-biblioref">2012</a>)</span>, written by a great professor that
I took a course from while getting my PhD. It’s more popularly focused
than technical, so it’s a surprisingly smooth read. Highly
recommended!<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>You can tell from the image that this map is pretty old.
<a href="https://www.math.uwaterloo.ca/tsp/usa50/">The site from which
it came</a> tells a neat story about how this instance was solved, by
hand, way back in 1954! There are some other interesting bits there too,
well worth a read in my opinion.<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>If you <em>are</em> looking for a deep dive, I’d suggest
checking out the other classes in our Masters of Operations Research
program.<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>It’s not exactly like Jupyter, but the same in spirit.
Also, don’t worry if you don’t know about Jupyter or coding notebooks
yet.<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>This shouldn’t be a huge hurdle. If you don’t have one
already you can always create a burner account for the sake of the
class.<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>You can check out <a
href="https://www.python.org/downloads/">Python’s downloads page</a> or
go with <a href="https://www.anaconda.com/">Anaconda</a> for an expanded
built-in toolset.<a href="#fnref8" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>I’m listing lots of Google Cloud products because that’s
the cloud platform I’ve used most, but the other big providers have
similar offerings.<a href="#fnref9" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>You might look at this and think “that just means <span
class="math inline">x_2 \leq 6</span>.” You would be correct, and it
would be completely valid to use that constraint instead.<a
href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>The “s.t.” is an abbreviation for “subject to” and is
used in formulations leading into the constraints section.<a
href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>So long as we’re talking about real numbers, of course.
Something like <span class="math inline">x_1=\text{blue}</span>, <span
class="math inline">x_2=\text{elephant}</span> is just nonsense and
isn’t a solution to our problem.<a href="#fnref12" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>The smallest value if we have a minimization problem,
or the largest value for a maximization problem.<a href="#fnref13"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>I couldn’t think of a good way to do this with touch
events, so this part doesn’t work as well on a mobile device. Sorry.<a
href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>Actually, my little widget here is not perfect.
Depending how small of a decimal you add, you may get it to tell you
there are optimal solutions at a slightly higher objective value. This
is due to choosing a precision that this setup really can’t handle. It
is worth mentioning that even the most sophisticated solvers can have
issues with rounding errors and numerical stability, but they’re
generally very good. As long as you are careful with your formulations
you usually won’t run into issues.<a href="#fnref15"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>Truth be told, this isn’t a rigorous proof of
optimality, at least in the strict sense of mathematical proofs. But the
solution methods we’ll study later do give such proofs.<a
href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>In most practical applications, infeasiblity is a good
indicator that you modeled something incorrectly. Like in this example,
it doesn’t make sense that we could make arbitrarily many of some
product. So if you find a problem you’re working on is infeasible, it’s
a good idea to double-check your formulation.<a href="#fnref17"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>There are similar packages available in other popular
programming languages as well.<a href="#fnref18" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p>Most come with limited licenses for noncommercial uses,
and also offer free unrestricted licenses for students and academics.<a
href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p>A quick example: <span class="math inline">x \leq
10</span> means the exact same thing as <span class="math inline">-x
\geq -10</span>.<a href="#fnref20" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p>You can think of <span class="math inline">y_j</span>
as the “positive part” and <span class="math inline">z_j</span> as the
“negative part” of <span class="math inline">x_j</span>. Note that we
haven’t done anything to enforce that only one of <span
class="math inline">y_j</span> and <span class="math inline">z_j</span>
are nonzero at a time. So for example if some solution to the original
formulation had <span class="math inline">x_j=2</span> then in the new
formulation we could have <span class="math inline">y_j=2</span> and
<span class="math inline">z_j=0</span>, or we could just as easily have
something like <span class="math inline">y_j=12, z_j=10</span> or <span
class="math inline">y_j=106.7, z_j=104.7</span>.<a href="#fnref21"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p>I’m not mentioning a lot of people by name in these
notes, but I couldn’t skip Dantzig. Mostly I wanted to bring up this
famous story: A student comes late to class one day, sees two problems
written on the board, and assumes they are the day’s assigned homework.
The problems are more difficult than usual, but he solves them. When he
turns them in, the professor is elated - these weren’t homework problems
at all, but rather famous unsolved problems in the field! You can find
several versions of this story out there, citing several different
people as the supposed student. Turns out <a
href="https://www.snopes.com/fact-check/the-unsolvable-math-problem/#6oJOtz9WKFQUHhbw.99">this
actually happened, and the student was Dantzig</a>.<a href="#fnref22"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p>There’s a neat story, quoting from <span
class="citation" data-cites="tspPursuit">Cook (<a href="#ref-tspPursuit"
role="doc-biblioref">2012</a>)</span>, in <a
href="https://punkrockor.com/2014/04/29/happiness-is-assuming-the-world-is-linear/">this
blog post</a> (yes, OR blogs are a thing). It’s specifically about
Dantzig first introducing the simplex method during a talk in 1948, and
more generally about understanding your assumptions 😀.<a
href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p>Interestingly, several other linear programming
algorithms have been devised whose theoretical properties seem to
suggest they would be more efficient. But in practice that hasn’t been
the case. Simplex continues to be the best algorithm in practice for the
widest array of problems.<a href="#fnref24" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p>There are corner-point infeasible solutions as well,
which sit at intersections outside the feasible region<a href="#fnref25"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26"><p>I’m used to calling them vertices, but the textbook
tends to call them corner-point solutions, which I like as a more
helpful, descriptive term. I’ll try to stick to corner-point solution
for the notes, but I expect to slip up a few times, especially during
lectures.<a href="#fnref26" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn27"><p>For those that are not aware, a
<strong>theorem</strong> is a mathematical statement that has been
proven to be true, based on some set of standard axioms. Anything I cite
as a theorem in these notes, you can be confident it holds true, even if
we don’t work through a rigorous proof.<a href="#fnref27"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28"><p>At least not generally - for common variants of the
simplex method, there exist examples where every CPF solution is visited
during execution (<span class="citation" data-cites="kleeMinty">(<a
href="#ref-kleeMinty" role="doc-biblioref">Klee and Minty
1970</a>)</span> is the first, most famous example). But this isn’t
usually an issue in practice.<a href="#fnref28" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn29"><p>This is really the key takeaway from our whole
discussion in this section, and if this is the only thing you remember
about the simplex method 10 years from now I’ll still be satisfied. This
is the key insight, you can always re-learn the details later.<a
href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30"><p>The greek capital letter <span
class="math inline">\Delta</span> is commonly used to denote an amount
of change, and in these context is often read as “change in.”<a
href="#fnref30" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn31"><p>Note that having the highest per-unit change doesn’t
necessarily make it the “best” choice in any particular way. It may be
that choosing a different (but still improving) direction will mean that
we finish the algorithm faster. But in general we can’t tell beforehand,
so we often just choose the direction with the highest change as
convenient rule-of-thumb.<a href="#fnref31" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn32"><p>It is also possible to have a tie in the minimum ratio
test. This is another special case that we’ll cover later.<a
href="#fnref32" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn33"><p>Now might be a good time to check out the simplex
visualization in section <a href="#sec:simplexVisualized">4.6.2</a> and
see if you understand the interpretation of the slack variable values in
the solutions we’ve found.<a href="#fnref33" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn34"><p>Note also that if you came to the equality-constrained
problem (<span
class="math inline">\mathbf{A}\mathbf{x}=\mathbf{b}</span>) via a
transformation from the inequality form (<span
class="math inline">\mathbf{A}\mathbf{x}\leq\mathbf{b}</span>) by adding
slack variables, the slack variables themselves guarantee full row
rank.<a href="#fnref34" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn35"><p>Sorry to just present this to you as if it’s a mystical
gift from the gods. We could have totally derived it ourselves, but I
didn’t think it was worth the class time.<a href="#fnref35"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn36">This “fell on its side” thing is easier to see if you
post-multiply the dual variables instead:
<div class='mathSmall'>
<p>$$ <span class="math display">\begin{align*}
\text{min}&amp;&amp; \begin{bmatrix}4 &amp; 12 &amp;
18\end{bmatrix}\begin{bmatrix}y_1 \\ y_2 \\ y_3\end{bmatrix} &amp; \\
\text{s.t.} &amp;&amp; \begin{bmatrix}1 &amp; 0 &amp; 3 \\ 0 &amp; 2
&amp; 2\end{bmatrix}\begin{bmatrix}y_1 \\ y_2 \\ y_3\end{bmatrix} &amp;
\geq \begin{bmatrix}3 \\ 5\end{bmatrix} \\
&amp;&amp; y_1,y_2,y_3 &amp; \geq 0
\end{align*}</span></p>
<p><span class="math display">
&lt;/div&gt;
</span><a href="#fnref36" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn37"><p>A <em>corollary</em> is like a theorem, and we could
just as easily have called this a theorem as well. But generally we use
the word corollary when the result follows almost directly from a result
presented previously.<a href="#fnref37" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn38"><p>Interested readers can check <span class="citation"
data-cites="classText">Hillier and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span>, section 8.1.<a href="#fnref38"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn39"><p>If you increase it too much, interactions from other
constraints may change the effect. How much is too much? We’ll explore
this question in section <a href="#sec:sensitivityAnalysis">4.8.3</a><a
href="#fnref39" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn40"><p>This might be a first hint that our problem has changed
significantly.<a href="#fnref40" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn41"><p>We aren’t covering dual simplex in this course, but I
think it’s good for you to know that it exists, and in particular that
it has a role to play in sensitivity analysis or re-optimization.<a
href="#fnref41" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn42"><p>This also introduces potential degeneracy issues, but
we’ll ignore that for the purposes of this class.<a href="#fnref42"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn43"><p>In this context, we use the word <em>integral</em> to
mean “of or denoted by an integer” (which, as of the time of writing, is
the second definition provided by Google when searching the word). I
agree it’s somewhat confusing since the word has a separate common
meaning when used in casual conversation, and even a separate meaning in
mathematics that you’re familiar with from calculus.<a href="#fnref43"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn44"><p>Of course, you could also talk about non-linear
optimization problems with integer variable restrictions. Still, the
terminology <em>integer programming</em> is usually restricted to
integer extensions to LPs.<a href="#fnref44" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn45"><p>Some sources will include an “L” (for “linear”) in the
initialism as well. So if you see things like ILP, MILP, or BILP in
other texts, know that these are likely the same as what we’re calling
IP, MIP, and BIP.<a href="#fnref45" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn46"><p>New notation alert: as mentioned in section <a
href="#sec:symbols">7.1</a>, the symbol <span
class="math inline">\mathbb{I}</span> stands for the set of integer
numbers. The <span class="math inline">+</span> in the subscript means
that we are considering non-negative integers (though this is just a
convention, as we saw with linear programs in section <a
href="#sec:lpForms">4.5</a> we can bypass non-negativity with certain
formulation tricks). The <span class="math inline">n</span> in the
superscript is just from the dimension of the vector <span
class="math inline">\mathbf{x}</span>, in this case meaning that a valid
selection for <span class="math inline">\mathbf{x}</span> must consist
of <span class="math inline">n</span> such integers.<a href="#fnref46"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn47"><p>The notion of a <em>relaxation</em> shows up in other
places in optimization theory as well. In general, a relaxation <span
class="math inline">R</span> of some minimization problem <span
class="math inline">P</span> is another optimization problem such that
the set of feasible solutions to <span class="math inline">P</span> is a
subset of the feasible solutions to <span class="math inline">R</span>.
Further, for any solution <span class="math inline">x</span> to <span
class="math inline">P</span>, the objective value at <span
class="math inline">x</span> in <span class="math inline">R</span> is
less than or equal to the objective value at <span
class="math inline">x</span> in <span class="math inline">P</span> (in
the case of the LP relaxation to an IP, the objective values are equal).
Relaxations are usually easier to solve than the original problem and
can be useful as approximations or in bounding <span
class="math inline">P</span>’s possible objective values.<a
href="#fnref47" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn48"><p>I should point out that, in a practical application,
there is often some wiggle room in the (sometimes shoddily estimated)
problem data such that you could fudge a little and make one of these
rounded solutions work. This may or may not be an option depending on
your scenario.<a href="#fnref48" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn49"><p>Another way to approach this particular problem may be
to just solve two different IPs, one with the first constraint and one
with the second, then compare the resultant solutions. But it’s not too
hard to imagine a scenario where perhaps a new build is considered for
each facility, and with enough facilities you wouldn’t want to do a new
model for each possible combination of new/old facilities.<a
href="#fnref49" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn50"><p>This is the second time we’ve seen <span
class="math inline">M</span> represent some very large number - it’s a
recurring theme in OR.<a href="#fnref50" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn51"><p>Verify this by seeing what the constraints reduce to
when <span class="math inline">x_i=0</span> versus when <span
class="math inline">x_i&gt;0</span>.<a href="#fnref51"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn52"><p>For some reason, the presentation of this problem in
the textbook leaves the <span class="math inline">x_i</span> variables
are real-valued instead of integers. I figure integers are more
realistic, and since we’re in the IP portion of the notes, why not do it
that way?<a href="#fnref52" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn53"><p>Ideally in computer code.<a href="#fnref53"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn54"><p>New notation: when we write <span
class="math inline">S&#39;\subseteq S</span>, we mean to say that <span
class="math inline">S&#39;</span> is a subset of <span
class="math inline">S</span>. That is, <span
class="math inline">S</span> and <span class="math inline">S&#39;</span>
are both sets, and every element of <span
class="math inline">S&#39;</span> is also an element of <span
class="math inline">S</span>.<a href="#fnref54" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn55"><p>Plus an extra constraint on the number of flight
segments to choose - this constraint is not included in the classical
set covering problem.<a href="#fnref55" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn56"><p>Note the new notation in the second summation, <span
class="math inline">\{j:i\in S_j\}</span>. We call this the “conditional
set” notation in section <a href="#sec:symbols">7.1</a>. It means the
set of all <span class="math inline">j</span> such that the condition
<span class="math inline">i\in S_j</span> is true.<a href="#fnref56"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn57"><p>If <span class="math inline">d_{ij}=d_{ji}</span> for
all <span class="math inline">i,j</span> then we call it a <em>symmetric
TSP</em>. But this doesn’t need to hold for our formulations to work.<a
href="#fnref57" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn58"><p>I can’t tell you how many times I’ve come up with what
I thought was a valid formulation for a problem, only to solve the model
and get some invalid result because I overlooked some subtle case my
model didn’t cover. Modeling a given IP is not always as straightforward
as it might initially appear.<a href="#fnref58" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn59"><p>Technically we don’t need <em>every</em> subset, since
the same constraint will cover both the selected subset and its
complement (e.g. the constraint above will eliminate the possibility of
subtours in both sets <span class="math inline">\{3, 8, 0\}</span> and
<span class="math inline">\{1, 2, 4, 5, 6, 7, 10\}</span>). Further,
subsets of size 1 are technically covered by the basic “leave every city
once” constraints.<a href="#fnref59" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn60"><p>If you’re thinking “that could be a lot of
constraints”, you’re right. It can be a problem. We’ll be coming back to
this observation later.<a href="#fnref60" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn61"><p>In fact, you could make due with <em>only</em> the
subtour elimination constraints, since the original functional
constraints are essentially just subtour elimination constraints for the
subtours of size <span class="math inline">n-1</span>.<a href="#fnref61"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn62"><p>Two bits of new notation here. First, <span
class="math inline">\emptyset</span> represents an empty set, i.e. a set
with no elements. Technically, <span
class="math inline">\emptyset</span> is a subset of all other sets, but
we don’t want to consider it in our formulation so we’ll explicitly
exclude it. Second, <span class="math inline">|S|</span> denotes the
size of a set, i.e. the number of elements in it.<a href="#fnref62"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn63"><p>You’ll notice some of the big names (specifically CPLEX
and Xpress) are missing from these benchmarks. They used to be included
as well, but there was some bit of drama from a few years back that led
to the big commercial solvers asking to be excluded from these public
benchmarks. Gurobi has since returned.<a href="#fnref63"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn64"><p>Note that, due to the nature of the benchmarks, the
reported speed differences underestimate the differences on larger
problems that are more likely to be of interest in industry
applications.<a href="#fnref64" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn65"><p>You may want to take advantage of this for your class
project.<a href="#fnref65" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn66"><p>Actually, I think I alluded to complexity earlier in
class and told you we wouldn’t cover it. But I just couldn’t help
myself, so here we are.<a href="#fnref66" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn67"><p>Note that the order matters here, i.e. traveling from
New York to DC is not the same as traveling from DC to New York. If
order didn’t matter, we could divide the number by 2.<a href="#fnref67"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn68"><p>Actually, the way we modeled it in the notebook, we
only used about half of the subsets, since the subtour elimination
constraints suffice for both the subset they are built on and the
complement set.<a href="#fnref68" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn69"><p>Why? Think about it like this: to create a subset one
has to decide, for each element of the set, whether to include it or
not. This gives you 2 choices <span class="math inline">n</span>
independent times, or <span class="math inline">2^n</span> total
choices.<a href="#fnref69" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn70"><p>We can also talk about, say, dividing all the numbers
by their greatest common denominator in order to save space, but we
won’t worry about that here.<a href="#fnref70" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn71"><p>If we’re talking about saving files on a computer that
uses bits instead of digits, we’d take the logarithm with a base of 2
instead of 10.<a href="#fnref71" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn72"><p>There is in fact a deeper link between decision and
optimization problems. It is a little beyond the scope of this course to
formalize, but I’ll mention here: If the associated decision problem is
solvable in polynomial time, then so is the optimization problem (one
can solve the decision problem over and over again, and if you use a
so-called bisection search on the objective function to guide which
decision problems you solve, you’ll only have to do so polynomially many
times).<a href="#fnref72" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn73"><p>Formally, we would use what’s known as “<a
href="https://en.wikipedia.org/wiki/Big_O_notation">big O notation</a>”,
which works like this: For two functions <span
class="math inline">f</span> and <span class="math inline">g</span>, we
say that <span class="math inline">f(n)\in O(g(n))</span> if there are
some numbers <span class="math inline">c\in\mathbb{R}_+,
n&#39;\in\mathbb{R}</span> such that <span
class="math inline">|f(n)|\leq c\cdot g(n)</span> for all <span
class="math inline">n &gt; n&#39;</span>. Essentially, <span
class="math inline">g</span> dominates <span
class="math inline">f</span> in the limit (subject to some constant
factor). From the definition, it is clear that <span
class="math inline">n(n-1)\in O(n^2)</span>.<a href="#fnref73"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn74"><p>This may seem unintuitive at first, and is the main
point of conflict between the theory and the real world. Indeed, in any
practical application, it would make a great deal of difference if your
algorithm required <span class="math inline">2n^2</span> steps versus
<span class="math inline">10^{1000}n^2</span> steps. If it’s any
consolation, in practice humongous constants like this do not tend to
occur. It’s also common for constants to start out higher when an
algorithm is first introduced, only to be reduced as more research is
put into the problem.<a href="#fnref74" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn75"><p>The name <span class="math inline">\mathcal{NP}</span>
stands for “non-deterministic polynomial time” and is a leftover from
the very first formalization of this notion, which came from so-called
<a
href="https://en.wikipedia.org/wiki/Nondeterministic_Turing_machine">non-deterministic
Turing machines</a>. I wish the name were more indicative of the “easily
verifiable” notion we present here, but the nomenclature is well
entrenched now and we’re well past the point of no return.<a
href="#fnref75" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn76"><p>Crucially, the ability to prove is one-sided. The
definition said we need only be able to verify instances for which the
answer is “yes”. We need not be able to do anything for “no”
instances.<a href="#fnref76" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn77"><p>This result is due to analysis on various
interior-point methods for LP, and interestingly not for the simplex
method. As we’ve hinted at, there are various implementation details you
need to hash out to run simplex in practice, and nobody has ever proven
that any version of simplex is guaranteed to finish in polynomial
time.<a href="#fnref77" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn78"><p>For instance, if <span
class="math inline">\mathcal{P}\neq\mathcal{NP}</span> then we’d know
definitively that scalable algorithms for solving integer programs
cannot exist. Meanwhile, if <span
class="math inline">\mathcal{P}=\mathcal{NP}</span>, then many of the
algorithms we use today for cryptography (to, for example, keep your
bank credentials safe while shopping online) are unsafe in principal and
potentially vulnerable to attack. People also like to get philosophical
when discussing the implications of <span
class="math inline">\mathcal{P}=\mathcal{NP}</span>, making provocative
claims like “there is no difference between someone whe can appreciate
art and an artist” or “anyone who can recognize good music is as
talented as Mozart”. There’s truth in these statements as metaphors, but
sometimes I find it hard to tell if these people actually mean them
literally. As far as I’m concerned, these sweeping metaphysical claims
don’t follow from the theory.<a href="#fnref78" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn79"><p>Interestingly, the (so far) <a
href="https://en.wikipedia.org/wiki/Grigori_Perelman">only person to
solve one of these problems</a> turned down the money.<a href="#fnref79"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn80"><p>This may feel like a high bar to clear, since there are
many different <span class="math inline">\mathcal{NP}</span> problems,
so proving that <em>any</em> of them can be reduced to a given problem
of interest feels like an impossible amount of work. In practice,
researchers identified a problem called <a
href="https://en.wikipedia.org/wiki/Boolean_satisfiability_problem"><em>satisfiability</em>
(or <em>SAT</em>)</a> which encapsulates exactly this notion of <span
class="math inline">\mathcal{NP}</span>-completeness. Then, once you
have <em>some</em> <span
class="math inline">\mathcal{NP}</span>-complete problem, proving
another is <span class="math inline">\mathcal{NP}</span>-complete
requires just reducing a known <span
class="math inline">\mathcal{NP}</span>-complete problem to your problem
of interest.<a href="#fnref80" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn81"><p>Like I did with “more optimal” before, I can’t help but
point out another of my linguistic pet peeves here. You’ll often here
people talk about something “growing exponentially” in plain English,
but it almost never fits the mathematical definition, i.e. the growth
rate with respect to some factor <span class="math inline">n</span> is
proportional to <span class="math inline">p^n</span> for some <span
class="math inline">p\in\mathbb{R}</span>. People will say it when the
growth rate is only quadratic (grows like <span
class="math inline">n^2</span>). I’ve seen people label literal
<em>linear growth</em> as exponential, and I want to tear my hair out.
But the most egregious thing is when people say something grows
exponentially when they only have two data points, like “total sales
this year grew exponentially over last year’s total sales.” Umm, you
only have two data points. You can draw literally any kind of curve
between two data points, so I guess you <em>could</em> draw an
exponential curve too, but come on. What justifies you calling it
exponential over quadratic or linear or <em>literally anything
else</em>?<a href="#fnref81" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn82"><p>You might object that there only finitely many
corner-point solutions, and these are the only ones that matter. That’s
fair, but I’ll point out that the number of corner points still grows
exponentially, and there are other optimization problems with infinitely
many solutions that are still polynomial-time solvable.<a
href="#fnref82" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn83"><p>That’s not to say that the IP formulation we coded for
the TSP can solve instances of this size. The best TSP solvers use IP
techniques, but they don’t use the full model as we formulated. Later in
class, I plan to show an example where we solve a TSP with Gurobi but
without adding every subtour elimination constraint up front.<a
href="#fnref83" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn84"><p>For the uninitiated, A <em>proposition</em> is again
like a theorem, and the below statement could have been called a theorem
just a well. But we tend to use the work “proposition” instead when the
result is a little more obvious.<a href="#fnref84" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn85"><p>In case you haven’t seen this notation before, <span
class="math inline">\lfloor x \rfloor</span> (said “floor of <span
class="math inline">x</span>”) is value resulting from rounding <span
class="math inline">x</span> <em>down</em> to the closest integer, while
<span class="math inline">\lceil x \rceil</span> (“ceiling of <span
class="math inline">x</span>”) is the value resulting from rounding
<span class="math inline">x</span> <em>up</em> to the closest integer.
For example, <span class="math inline">\lfloor 1.3 \rfloor=1</span> and
<span class="math inline">\lceil 1.3 \rceil=2</span>.<a href="#fnref85"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn86"><p>If multiple variables had fractional values you could
just select one of them arbitrarily and the algorithm will still work.
We’ll talk about other ways to choose between multiple fractional
variables in section <a href="#sec:choosingBNBNodes">5.6.6</a>.<a
href="#fnref86" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn87"><p>While algorithm correctness is not affected by the
selection criteria, the number of nodes explored by the end of the
algorithm, and thus ultimately algorithm run time, certainly can be.<a
href="#fnref87" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn88"><p>Note that the only difference between <span
class="math inline">P^1</span>’s LP relaxation and that of the problem
<span class="math inline">P</span> we just solved is the addition of a
single constraint. So instead of solving <span
class="math inline">P^1</span>’s LP relaxation from scratch, a
well-written algorithm could use solution information from <span
class="math inline">P</span> and use a re-optimization procedure as
discussed in section <a href="#sec:lpReopt">4.8.1</a>.<a href="#fnref88"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn89"><p>For example, at <span class="math inline">P^{12}</span>
we see by following the edges that we’ve fixed the three variables to
<span class="math inline">x_1=1, x_2=0, x_3=1</span>.<a href="#fnref89"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn90"><p>We know that the simplex method always returns a
corner-point solution, but we also don’t have a version of simplex that
is guaranteed to run in polynomial time. But don’t worry, we won’t cover
it but there are other ways to recover an optimal corner-point solution
to an LP in polynomial time.<a href="#fnref90" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn91"><p>Remember, the natural IP formulation for the knapsack
problem has only one constraint aside from setting the variables to be
binary.<a href="#fnref91" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn92"><p>This is the usual trick when working with limits. When
some condition is true in the limit, it just means that there is
<em>some</em> area (perhaps incredibly small) around the point of
interest where the condition is always true.<a href="#fnref92"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn93"><p>Yes, I agree it’s confusing that a concave function in
our new sense only corresponds to a “concave down” function, while a
“concave up” function is convex and not at all concave. Sorry.<a
href="#fnref93" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn94"><p>Yes, the method is named for Sir Isaac Newton, pioneer
of calculus and gravitation.<a href="#fnref94" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<script>
    printerFunc = () => {
        header = document.getElementsByClassName('navbar')[0];
        footer = document.getElementsByTagName('footer')[0];
        header.style.visibility = 'hidden';
        footer.style.visibility = 'hidden';
        window.print();
        setTimeout(() => {})
    }
    window.onafterprint = function(){
        header.style.visibility = 'visible';
        footer.style.visibility = 'visible';
    }
</script>
</div>
<div id="classModeDiv"></div>
<footer>
    <div style="width:3rem"></div>
    <small>&copy; Copyright 2023, Jeffrey Pavelka</small>
    <div style='cursor:pointer;margin:0 1rem' onclick="printerFunc()">&#128438;</div>
</footer>
</body>
</html>
