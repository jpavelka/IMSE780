<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>IMSE780</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <script>
      const drawBBTrees = () => {
          for (svg of document.getElementsByClassName('bbTreeDraw')) {
              graphInfo = JSON.parse(JSON.stringify(BBGraphData[svg.getAttribute('base')]));
              textsToAdd = [];
              for (n of Object.keys(graphInfo['nodes'])) {
                  graphInfo['nodes'][n]['level'] = 0;
                  graphInfo['nodes'][n]['children'] = [];
              }
              for (e of graphInfo['edges']) {
                  graphInfo['nodes'][e[1]]['level'] = graphInfo['nodes'][e[0]]['level'] + 1;
                  graphInfo['nodes'][e[1]]['parent'] = e[0];
              }
              r = 25
              const drawNode = (x, y, attrs) => {
                  circ = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
                  circ.setAttribute('cx', x);
                  circ.setAttribute('cy', y);
                  circ.setAttribute('r', r);
                  circ.setAttribute('fill', 'lightgray');
                  circ.setAttribute('stroke-width', '2pt');
                  circ.setAttribute('stroke', 'gray');
                  for (const [k, v] of Object.entries(attrs || {})) {
                      circ.setAttribute(k, v);
                  }
                  svg.appendChild(circ);
              }
              const addMathText = (math, x, y, attrs) => {
                  attrs = attrs || {};
                  forObj = document.createElementNS('http://www.w3.org/2000/svg', 'foreignObject');
                  mathEl = document.createElement('span');
                  katex.render(math, mathEl, {
                      throwOnError: false
                  });
                  if (attrs['coordToPix'] || false) {
                      [x, y] = coordToPix(x, y)
                  }
                  forObj.setAttribute('x', x);
                  forObj.setAttribute('y', y);
                  attrs['height'] = attrs['height'] || '1.2rem';
                  attrs['width'] = attrs['width'] || '15rem';
                  attrs['font-size'] = attrs['font-size'] || '12pt';
                  attrs['font-family'] = attrs['font-family'] || 'KaTeX_Main,Times New Roman,serif';
                  for (const [k, v] of Object.entries(attrs || {})) {
                      forObj.setAttribute(k, v);
                  }
                  forObj.appendChild(mathEl);
                  textsToAdd.push(forObj);
              }
              const drawLine = (x1, y1, x2, y2, attrs) => {
                  el = document.createElementNS('http://www.w3.org/2000/svg', 'line');
                  el.setAttribute('x1', x1);
                  el.setAttribute('y1', y1);
                  el.setAttribute('x2', x2);
                  el.setAttribute('y2', y2);
                  attrs = attrs || {}
                  attrs['style'] = attrs['style'] || 'stroke:gray';
                  for (const [k, v] of Object.entries(attrs)) {
                      el.setAttribute(k, v);
                  }
                  svg.appendChild(el);
              }
              incumbentVal = undefined;
              for ([n, d] of Object.entries(graphInfo.nodes)) {
                  x = parseFloat(svg.getAttribute('width')) / 2;
                  if (d.parent) {
                      parentInfo = graphInfo.nodes[d['parent']];
                      d.childNum = parentInfo.children.length;
                      side = d.childNum === 0 ? -1 : 1;
                      dist = 2 * (3 - d.level) * r;
                      x = parentInfo.x + side * dist;
                      parentInfo.children.push(n);
                  }
                  y = (2 + 5 * d.level) * r;
                  graphInfo['nodes'][n]['level'] = d.level;
                  graphInfo['nodes'][n]['x'] = x;
                  graphInfo['nodes'][n]['y'] = y;
                  addMathText(n, x - 8, y - 10);
                  if (d.state === 'integer') {
                      incumbentVal = incumbentVal === undefined ? d.lp : Math.max(incumbentVal, d.lp);
                      d.lp += '^*';
                  }
                  if (!!d.lp) {
                      addMathText(d.lp, x + 25, y - 30);
                  }
              }
              for (e of graphInfo.edges) {
                  coords = []
                  for (i of [0, 1]) {
                      for (j of ['x', 'y']) {
                          coords.push(graphInfo.nodes[e[i]][j]);
                      }
                  }
                  drawLine(...coords);
                  textX = (coords[0] + coords[2]) / 2;
                  textY = (coords[1] + coords[3]) / 2 - 20;
                  if (graphInfo.nodes[e[1]].childNum === 0) {
                      textX -= 55;
                  } else {
                      textX += 0;
                  }
                  addMathText(e[2], textX, textY);
              }
              for (d of Object.values(graphInfo.nodes)) {
                  if (d.level === 0) {
                      incumbentText = incumbentVal === undefined ? '-\\infty' : `${incumbentVal}`
                      addMathText(incumbentText, d.x + 28, d.y + 5);
                  }
                  attrs = {}
                  if (d.state === 'branched') {
                      attrs.stroke = 'blue';
                      attrs.fill = 'lightblue';
                  }
                  if (d.state === 'infeasible') {
                      attrs.stroke = 'red';
                      attrs.fill = 'lightpink';
                  }
                  if (d.state === 'integer') {
                      attrs.stroke = 'purple';
                      attrs.fill = 'plum';
                  }
                  if (d.state === 'bounded') {
                      attrs.stroke = 'darkorange';
                      attrs.fill = 'peachpuff';
                  }
                  drawNode(d.x, d.y, attrs);
              }
              for (textObj of textsToAdd) {
                  svg.appendChild(textObj);
              }
          }
      }
  </script>
  <style>   
      #classModeDiv {
          position: fixed;
          width: min(max(80%, calc(100% - min(50%, 300px) - 1rem)), 700px);
          padding: 30pt;
          top: 200px;
          left: 50%;
          transform: translateX(-50%);
          background-color: white;
          border: 2pt solid;
          border-radius: 10pt;
          padding: 10px;
          box-shadow: 5px 5px rgb(200, 200, 200);
          visibility: hidden;
      }
  </style>
  <script>
      const classModeSetup = () => {
          const classMode = document.getElementById('classModeDiv');
          let noClassModeHref = window.location.href.split('#')[0];
          if (noClassModeHref[noClassModeHref.length - 1] !== '/') {
              noClassModeHref += '/';
          }
          noClassModeHref += '?classmode=false';
          classMode.onclick = closeClassMode;
          classMode.innerHTML = `
              <div>
                  Welcome to class mode! This is your friendly reminder to check that:
                  <ul>
                      <li>The mics are on.</li>
                      <li>The camera is pointed at the whiteboard.</li>
                      <li>PIP is off.</li>
                  </ul>
                  Click anywhere to close this window.
                  <div>To turn off class mode, click <a href=${noClassModeHref}>here</a>.</div>
              </div>
          `
      }
      const closeClassMode = () => {
          const classMode = document.getElementById('classModeDiv');
          const noClassModeHref = window.location.href.split('?')[0] + '/?classmode=false';
          const minutesBetweenReminders = 30;
          if (classMode.style.visibility === "visible") {
              classMode.style.visibility = "hidden";
              classMode.innerHTML = `
                  <div>
                      <div style='padding: 0.5rem;'>Hi! This is your periodic class mode reminder to:</div>
                      <div style='text-align:center;font-size:1.2rem;'><b>Check the microphone!</b></div>
                      <div style='padding: 0.5rem;'>Click anywhere to close this window.</div>
                      <div style='padding: 0.5rem;'>To turn off class mode, click <a href=${noClassModeHref}>here</a>.</div>
                  </div>
              `
              setTimeout(() => classMode.style.visibility = "visible", 1000 * 60 * minutesBetweenReminders);
          }
      }
  </script>
  <!-- TOC styling adapted from https://www.w3schools.com/howto/howto_js_sidenav.asp -->
  <style>
      nav#TOC:nth-child(2) {
          margin-top: 0.6rem;
          box-shadow: rgba(0, 0, 0, 0.2) 2px 0px 10px 1px;
      }
      nav#TOC li {
          list-style-type: none;
      }
      nav#TOC > ul {
          margin-bottom: 1.5rem;
          margin-top: 2rem;
          line-height: 1.9rem;
      }
      #TOC ul {
          padding-left: 0;
      }
      nav#TOC {
          height: 100%;
          width: 0;
          position: fixed;
          z-index: 1;
          top: 0;
          left: 0;
          background-color: #ebebeb;
          overflow-x: hidden;
          padding-top: 1rem;
          transition: 0.5s;
          overflow-y: scroll;
      }
      nav#TOC a {
          text-decoration: none;
          font-size: max(1rem, min(calc(0.9rem + 0.4vw), 22pt));;
          color: #000;
          display: block;
          transition: 0.3s;
          padding-top: 0.2rem;
          padding-bottom: 0.3rem;
          border-bottom: 1pt solid lightgray;
      }
      nav#TOC a:hover {
          color: #888;
      }
      #TOC .toc-section-number::after {
          content: ':\00a0'
      }
      #tocTop {
          height: 1.5em;
          display: flex;
          justify-content: space-between;
          padding-top: 0.5rem;
          padding-bottom: 0.65rem;
          position: fixed;
          top: 0;
          visibility: hidden;
          background-color: #ebebeb;
          z-index: 1;
          border-bottom: 1pt solid gray;
      }
      .tocHidden {
          display: none     
      }
      .tocExpand {
          margin-left: auto;
          font-size: 30pt !important;
          font-family: 'Courier New', Courier, monospace;
      }
      .navbar {
          position: fixed;
          top: 0;
          left: 0;
          right: 0;
          font-size: 1.1rem;
          background-color: #ebebeb;
          width: 100%;
          border-bottom: 1pt solid gray;
          padding-top: 0.5rem;
          padding-bottom: 0.5rem;
          display: flex;
          justify-content: space-between;
          z-index: 2;
      }
      @media screen and (max-height: 450px) {
          .sidenav {
              padding-top: 15px;
          }

          .sidenav a {
              font-size: 18px;
          }
      }
  </style>
  <script>
      function openCloseNav() {
          const tocTop = document.getElementById("tocTop")
          if (tocTop.style.visibility == "visible") {
              closeNav();
              return
          }
          const screenWidth = window.innerWidth;
          const tocWidth = Math.min(0.75 * screenWidth, 350);
          const leftoverWidth = screenWidth - tocWidth;
          const main = document.getElementById("main");
          const mainWidth = main.offsetWidth;
          document.getElementById("TOC").style.width = tocWidth + 'px';
          tocTop.style.width = tocWidth + 'px';
          tocTop.style.visibility = "visible";
          if (leftoverWidth >= mainWidth) {
              main.style.marginLeft = tocWidth / 2 + 'px';
          }
      }
      function closeNav() {
          document.getElementById("TOC").style.width = "0";
          document.getElementById("main").style.marginLeft = null;
          document.getElementById("tocTop").style.visibility = "hidden";
      }
      function closeNavIfSmall() {
          if (document.getElementById("tocTop").style.visibility == "visible" && document.getElementById("main").style.marginLeft == 0){
              closeNav()
          }
      }
  </script>
  <script>
      const theoremHelpers = () => {
          let theoremObj = {};
          for (thm of document.getElementsByClassName('theorem')) {
              ((thm) => {
                  let headerEl = thm.previousSibling;
                  while ( !['H1', 'H2', 'H3'].includes(headerEl.tagName)) {
                      headerEl = headerEl.previousSibling;
                  }
                  section = headerEl.getAttribute('data-number').split('.')[0];
                  theoremObj[thm.id] = {
                      'theorem': thm,
                      'proof': undefined,
                      'section': section
                  };
              })(thm)
          }
          for (prf of document.getElementsByClassName('proof')) {
              ((prf) => {
                  theoremObj[prf.getAttribute('for')].proof = prf;
                  firstP = prf.getElementsByTagName('p')[0];
                  firstP.innerHTML = '<b>Proof: </b>' + firstP.innerHTML;
              })(prf)
          }
          secNumThms = {};
          for ([thmId, thmObj] of Object.entries(theoremObj)) {
              ((thmId, thmObj) => {
                  thm = document.getElementById(thmId);
                  sec = thmObj.section;
                  el = thmObj.theorem;
                  proof = thmObj.proof;
                  if (!Object.keys(secNumThms).includes(sec)) {
                      secNumThms[sec] = 0;
                  }
                  secNumThms[sec] += 1;
                  thmTypeStr = thm.getAttribute('data-thm-type') || 'theorem';
                  thmTypeStr = thmTypeStr[0].toUpperCase() + thmTypeStr.slice(1);
                  el.setAttribute('refStr', `${thmTypeStr} ${sec}.${secNumThms[sec]}`)
                  labelSpan = document.createElement('span');
                  labelSpan.classList = ['theoremLabel'];
                  let preTheoremStr = `${thmTypeStr} ${sec}.${secNumThms[sec]}`
                  if (!!thm.getAttribute('data-display-name')) {
                      preTheoremStr += ` (${thm.getAttribute('data-display-name')})`
                  }
                  labelSpan.textContent = preTheoremStr + ': ';
                  el.insertBefore(labelSpan, el.firstChild);
                  const main = document.getElementById('main');
                  if (!!proof) {
                      if (proof.getAttribute('data-placement') === 'appendix') {
                          const appLink = document.createElement('p');
                          const thmClone = thm.cloneNode(true);
                          thmClone.id = thm.id + 'AppendixVersionWithProof';
                          thmCloneLabel = thmClone.firstChild;
                          thmCloneLabel.innerHTML = `<a href="#${thm.id}">${thmCloneLabel.textContent.trim()}</a>&nbsp;`
                          appLink.innerHTML = `(<a href="#${thmClone.id}">Proof</a> in the appendix.)`;
                          main.insertBefore(appLink, thm.nextSibling);
                          const refs = document.getElementById('References');
                          main.insertBefore(thmClone, refs);
                          main.insertBefore(proof, refs);
                      }
                  }
              })(thmId, thmObj)
          }
          const refEls = document.getElementsByClassName('thmRef');
          for (ref of refEls) {
              ((ref) => {
                  thm = document.getElementById(ref.getAttribute('for'));
                  ref.innerHTML = `<a href="#${thm.id}">${thm.getAttribute('refStr')}</a>`
              })(ref)
          }
          addTooltips([...refEls].map(el => el.firstChild), true);
      }
  </script>
  <script>
      document.onreadystatechange = () => {
          if (document.readyState !== "complete") {
              document.querySelector("#main").style.display = "none";
              document.querySelector(".navbar").style.display = "none";
              document.querySelector("#loader").style.visibility = "visible";
              document.querySelector("#classModeDiv").style.visibility = "hidden";
          } else {
              document.querySelector("#loader").style.display = "none";
              document.querySelector(".navbar").style.display = "flex";
              document.querySelector("#main").style.display = "block";
              if (getUrlParameter('classmode') !== 'false') {
                  document.querySelector("#classModeDiv").style.visibility = "visible";
              }
          }
      };
      window.onload = () => {
          appendixSecNo = renumberAppendix();
          addMathContainers();
          theoremHelpers();
          addRefsToToc();
          eqRefExpandLinksAndAddTooltips();
          citeRefExpandLinksAndAddTooltips();
          secRefExpandLinksAndAddBackArrow(appendixSecNo);
          addFootnoteTooltips();
          addCodeCopyButtons();
          tocHelpers();
          drawAllSvgPlots();
          classModeSetup();
          videoEmbeds();
          document.onclick = closeClassMode;
          document.getElementById('main').onclick = closeNavIfSmall;
          makeAssignmentLink();
          drawPlotlyCharts();
          drawBBTrees();
      }
      drawPlotlyCharts = () => {
          for ([ind, el] of [...document.getElementsByClassName('plotlyLineChart')].entries()) {
              chartId = 'plotyChart' + ind;
              el.id = chartId;
              plotData = JSON.parse(el.getAttribute('data-plot-data'));
              plotLayout = JSON.parse(el.getAttribute('data-plot-layout') || '{}');
              Plotly.newPlot(chartId, plotData, plotLayout)
          }
      }
      makeAssignmentLink = () => {
          toAssignmentsEl = document.getElementById('toAssignments');
          if (!!toAssignmentsEl){
              toAssignmentsEl.setAttribute('href',
                  window.location.href.split('#')[0].split('?')[0] + 'assignments.html'
              )
          }
      }
      videoEmbeds = () => {
          for (el of document.getElementsByClassName('lectureVideoEmbed')) {
              ((el) => {
                  const descHTML = el.innerHTML;
                  const dt = el.getAttribute('data-video-date');
                  const dtStr = `${parseInt(dt.slice(5, 7))}/${parseInt(dt.slice(8, 10))}`
                  el.innerHTML = `&#127909;<small class="tinyText">Lecture video ${dtStr}</small>`;
                  el.style.cursor = 'pointer';
                  const embedIndentDiv = document.createElement('div');
                  embedIndentDiv.classList = ['embedIndent'];
                  el.appendChild(embedIndentDiv);
                  el.onclick = () => {
                      embedIndentDiv.style.display = embedIndentDiv.style.display == 'block' ? 'none' : 'block';
                  }
                  const textDiv = document.createElement('div');
                  textDiv.innerHTML = `<b>Class lecture ${dtStr}: </b>` + descHTML;
                  embedIndentDiv.appendChild(textDiv);
                  const vidIframe = document.createElement('iframe');
                  vidIframe.classList = ['lectureEmbedIframe'];
                  vidIframe.setAttribute('src', `https://mediasite.k-state.edu/mediasite/Play/${el.getAttribute('data-video-id')}?player=NextGenSystemPlayer&amp;cover=true&amp;lockControls=false&amp;coverTitle=false&amp;autoStart=false&amp;useExtensions=false&amp;disableXR=false&amp;quizzes=false&amp;hotspots=false&amp;clickToPlay=true&amp;playfrom=0`);
                  embedIndentDiv.appendChild(vidIframe);
              })(el)
          }
      }
      getUrlParameter = (name) => {
          name = name.replace(/[\[]/, '\\[').replace(/[\]]/, '\\]');
          var regex = new RegExp('[\\?&]' + name + '=([^&#]*)');
          var results = regex.exec(location.search);
          return results === null ? '' : decodeURIComponent(results[1].replace(/\+/g, ' '));
      };
      addMathContainers = () => {
          for (el of document.querySelectorAll('.math.display')) {
              katexContainer = document.createElement('div');
              katexContainer.classList = ['katexContainer'];
              el.parentNode.insertBefore(katexContainer, el);
              katexContainer.appendChild(el);
          }
      }
      renumberAppendix = () => {
          const appendixEl = document.getElementById('appendix') || document.getElementById('sec:appendix');
          const appendixSecNo = appendixEl.getAttribute('data-number');
          appendixEl.setAttribute('data-number', 'A');
          appendixEl.firstChild.remove();
          const appendixSections = [...document.getElementsByTagName('*')].filter(el => {
              return (el.getAttribute('data-number') || 'a').split('.')[0] === appendixSecNo;
          })
          for (apSec of appendixSections) {
              const numSplit = apSec.getAttribute('data-number').split('.');
              const secNo = 'A.' + numSplit.slice(1).join('.');
              apSec.setAttribute('data-number', secNo);
              apSec.firstChild.textContent = secNo;
          }
          const tocEls = [...document.getElementsByClassName('toc-section-number')].filter(el => {
              return (el.textContent).split('.')[0] === appendixSecNo;
          })
          for (tocEl of tocEls) {
              if (tocEl.textContent == appendixSecNo) {
                  tocEl.remove();
              } else {
                  const numSplit = tocEl.textContent.split('.');
                  const secNo = 'A.' + numSplit.slice(1).join('.');
                  tocEl.textContent = secNo;
              }
          }
          return appendixSecNo
      }
      tocHelpers = () => {
          for (el of document.querySelectorAll('#TOC a')) {
              const hrefId = el.getAttribute('href').slice(1);
              let parentEl = el.parentNode;
              let numUlsNested = 0;
              while (!!parentEl) {
                  numUlsNested += (parentEl.tagName == 'UL') ? 1 : 0
                  parentEl = parentEl.parentNode
              }
              innerHTML = el.innerHTML;
              el.innerHTML = '';
              newEl = document.createElement('div');
              newEl.innerHTML = innerHTML;
              newEl.style.marginLeft = numUlsNested * 0.4 + 'rem';
              newEl.style.display = 'flex';
              newEl.innerHTML = innerHTML;
              if (numUlsNested > 1) {
                  el.parentNode.classList.add('tocHideable');
                  el.parentNode.classList.add('tocHidden');
              }
              liParent = el.parentNode;
              if (liParent.getElementsByTagName('UL').length > 0) {
                  expandEl = document.createElement('span');
                  expandEl.innerHTML = '&nbsp;+&nbsp;';
                  expandEl.classList = ['tocExpand'];
                  newEl.appendChild(expandEl);
                  ((expandEl, liParent) => {
                      expandEl.onclick = (e) => {
                          for (hideable of [...liParent.getElementsByClassName('tocHideable')]) {
                              let hideableParent = hideable.parentNode;
                              while (hideableParent.tagName !== 'LI') {
                                  hideableParent = hideableParent.parentNode
                              }
                              if (hideableParent !== liParent) {
                                  continue
                              }
                              if ([...hideable.classList].includes('tocHidden')) {
                                  hideable.classList.remove('tocHidden');
                                  expandEl.innerHTML = '&nbsp;-&nbsp;';
                              } else {
                                  hideable.classList.add('tocHidden');
                                  expandEl.innerHTML = '&nbsp;+&nbsp;';
                              }
                          };
                          e.preventDefault();
                      }
                  })(expandEl, liParent)
              }
              el.appendChild(newEl);
          }
      }
      addCodeCopyButtons = () => {
          buttonAddFunc = () => {
              copyButtons = document.querySelectorAll('.copyButton');
              wide = 700;
              if (copyButtons.length > 0) {
                  if (window.innerWidth < wide) {
                      for (cb of copyButtons) {
                          cb.remove();
                      }
                  }
              } else {
                  if (window.innerWidth >= wide) {
                      for (el of document.querySelectorAll('div.sourceCode')) {
                          copyEl = document.createElement('span');
                          el.insertBefore(copyEl, el.firstChild);
                          copyEl.innerHTML = 'ðŸ“‹';
                          copyEl.classList = ['copyButton'];
                          ((el, copyEl) => {
                              copyEl.onclick = () => {
                                  text = el.getElementsByTagName('pre')[0].textContent;
                                  navigator.clipboard.writeText(text);
                                  infoEl = document.createElement('div');
                                  infoEl.textContent = 'Copied!';
                                  infoEl.classList = ['copyMessage']
                                  copyEl.appendChild(infoEl);
                                  setTimeout(() => infoEl.remove(), 2000);
                              };
                          })(el, copyEl)
                      }
                  }
              }
          }
          buttonAddFunc();
          window.addEventListener("resize", buttonAddFunc);
      }
      addRefsToToc = () => {
          liEl = document.createElement('li');
          aEl = document.createElement('a');
          aEl.href = '#References';
          aEl.innerHTML = 'References';
          ulEl = document.getElementById('TOC').getElementsByTagName('ul')[0];
          liEl.appendChild(aEl);
          ulEl.appendChild(liEl);
      }
      addTooltips = (els, includeLinkBacks, arrowFloat = false) => {
          for ([i, el] of els.entries()) {
              ((el, i) => {
                  refId = el.getAttribute('href');
                  refEl = document.getElementById(refId.slice(1));
                  el.setAttribute('href', '#');
                  el.classList = ['eqnRef'];
                  nextEl = document.createElement('span');
                  el.parentNode.insertBefore(nextEl, el.nextSibling);
                  popupId = refId + 'popup' + i;
                  elId = popupId + 'Ref';
                  nextEl.id = elId;
                  ((a, b, c, d, e) => {
                      a.onclick = () => {
                          footnoteOnTooltipClick(b, c, d, e);
                          return false
                      };
                  })(el, popupId, refEl.innerHTML, elId, includeLinkBacks ? refId.slice(1) : null)
                  if (includeLinkBacks) {
                      backId = 'back' + refId;
                      backEl = document.getElementById(backId);
                      if (!!!backEl) {
                          backEl = document.createElement('div');
                          backEl.id = backId;
                          backEl.classList = ['backRefElement'];
                          backArrowEl = document.createElement('a');
                          backArrowEl.id = backId + 'Arrow';
                          backArrowEl.innerHTML = "â†©ï¸Ž";
                          backArrowEl.style.display = 'none';
                          backEl.onclick = () => backEl.style.display = 'none';
                          backEl.appendChild(backArrowEl);
                          refEl.appendChild(backEl);
                      }
                  }
              })(el, i)
          }
      }
      expandLinks = (els, prevWordInclude) => {
          for (const el of els) {
              sib = el.previousSibling;
              sibTextSplit = sib.textContent.split(/\s+/).filter(s => s !== '');
              prevWord = sibTextSplit[sibTextSplit.length - 1].replace('(', '');
              if (prevWordInclude.includes(prevWord)) {
                  repS = RegExp(`${prevWord}[^a-zA-Z]$`);
                  el.innerHTML = prevWord + ' ' + el.innerHTML;
                  sib.textContent = sib.textContent.replace(repS, '');
              }
          }
      }
      eqRefExpandLinksAndAddTooltips = () => {
          els = document.querySelectorAll('[href^="\#eq:"]');
          expandLinks(els, ['eq.', 'Equation']);
          addTooltips(els, true);
      }
      secRefExpandLinksAndAddBackArrow = (appendixSecNo) => {
          els = [...document.querySelectorAll('[href^="\#sec:"]')].filter(el => {
              return el.parentNode.tagName !== 'LI'
          });
          const appendixStr = 'the appendix';
          for (el of els) {
              if (el.textContent == appendixSecNo) {
                  sib = el.previousSibling;
                  sib.remove();
                  el.textContent = appendixStr;
              } else {
                  el.textContent = document.getElementById(el.getAttribute('href').slice(1)).getAttribute('data-number');
              }
          }
          expandLinks(els.filter(el => el.textContent !== appendixStr), ['section']);
          for ([i, el] of els.entries()) {
              const secId = el.getAttribute('href').slice(1);
              const elId = 'linkToSec' + secId + i;
              el.id = elId;
              const toSec = document.getElementById(secId);
              el.onclick = () => {
                  backArrowId = secId + 'ReturnLink';
                  let backArrowEl = document.getElementById(backArrowId);
                  if (!!backArrowEl) {
                      backArrowEl.remove();
                  }
                  backArrowEl = document.createElement('a');
                  backArrowEl.id = backArrowId
                  backArrowEl.setAttribute('href', '#' + elId);
                  backArrowEl.style.float = 'right';
                  backArrowEl.innerHTML = "â†©ï¸Ž";
                  backArrowEl.onclick = () => backArrowEl.remove();
                  toSec.appendChild(backArrowEl);
              }
          }
      }
      citeRefExpandLinksAndAddTooltips = () => {
          els = document.getElementById('main').getElementsByClassName('citation');
          addTooltips([...els].map(el => el.getElementsByTagName('a')[0]), false);
          for (el of els) {
              textContent = el.textContent;
              el.getElementsByTagName('a')[0].textContent = textContent;
              for (childEl of el.childNodes) {
                  if (!!!childEl.tagName) {
                      childEl.textContent = '';
                  }
              }
          }
      }
      addFootnoteTooltips = () => {
          for (fnBack of [...document.getElementById('main').getElementsByClassName('footnote-back')]) {
              fnBack.remove();
          }
          els = document.getElementById('main').getElementsByClassName('footnote-ref');
          addTooltips([...els], false);
          footnotesEl = document.getElementById('footnotes');
          if (!!footnotesEl) {
              footnotesEl.remove();
          }
          for (el of document.getElementsByClassName('eqnRef')) {
              const childEl = el.firstChild;
              if (childEl.tagName === 'SUP') {
                  childEl.textContent = 'note';
                  childEl.style.fontSize = '0.5rem';
              }
          }
      }
  </script>
  <style>
      .lpDraw {
          position: relative;
          left: 50%;
          transform: translateX(-50%);
      }
      .bbTreeDraw {
          position: relative;
          left: 50%;
          transform: translateX(-50%);
      }
      .pointChooseDiv {
          text-align: center;
      }
      .pointChooseInput {
          border: solid 1pt black;
          border-radius: 2pt;
          width: 2rem;
          height: 1.1rem;
      }
      .pointChooseLabel {
          font-size: 14pt;
          padding-left: 5pt;
          padding-right: 5pt;
      }
      .pointChooseText {
          text-align: center;
          font-size: max(12pt, 1rem);
      }
      .underPlot {
          margin-top: -10pt;
      }
      @keyframes append-animate {
          0% {
              stroke-width: 0;
          }
          25% {
              stroke-width: 4;
          }
          50% {
              stroke-width: 0;
          }
      }
      .violatedIneq {
          animation: append-animate 4s infinite;
      }
      @keyframes simplex-arrow-flash {
          0% {
              stroke-width: 3;
          }
          5% {
              stroke-width: 4;
          }
          10% {
              stroke-width: 3;
          }
          100% {
              stroke-width: 3;
          }
      }
      .simplexArrowChosen {
          animation: simplex-arrow-flash 12s infinite;
      }
      .simplexDirectionTable {
          margin: 0;
          margin-left: auto;
          margin-right: auto;
          width: 350px;
      }
      .pointChooseText button {
          font-size: 0.8rem;
          padding: 0.5rem;
          margin: 0 0.1rem;
      }
  </style>
  <style>
      .eqnos {
          display: flex;
          align-items: center;
          width: 100%;
          overflow-x: auto;
      }
      .eqnos br {
          display: none;
      }
      .eqnos-number {
          margin-left: auto;
          padding-left: 1rem;
      }
      .katexContainer {
          flex-grow: 1;
          overflow-x: auto;
      }
  </style>
  <script>
      let baseLps = {
          prototypeLp: {
              xMin: -1,
              xMax: 8.99,
              yMin: -1,
              yMax: 10.99,
              obj: [3, 5],
              ineqs: [[3, 2, 18, "l"], [1, 0, 4, "l"], [0, 2, 12, "l"]],
              ineqTextPlaces: [[5, 2.5], [2.25, 8], [6, 6.9]]
          },
          roundingIp: {
              xMin: -1,
              xMax: 7.99,
              yMin: -1,
              yMax: 5.99,
              obj: [12, 10],
              ineqs: [[-7, 5, 5, "l"], [9, 7, 54, "l"]],
              ineqTextPlaces: [[3, 5.25], [4.25, 3]],
              plotIntegerFeasible: true,
              addFeasibleRegionText: false
          },
          bbExample1: {
              xMin: -1,
              xMax: 6.99,
              yMin: -1,
              yMax: 6.99,
              obj: [10, 12],
              ineqs: [[1, 1, 5, "l"], [2, 4, 15, "l"]],
              ineqTextPlaces: [[0.5, 5], [4, 2.25]],
              plotIntegerFeasible: true,
              addFeasibleRegionText: false
          },
          bbExample2: {
              xMin: -1,
              xMax: 6.99,
              yMin: -1,
              yMax: 6.99,
              obj: [10, 12],
              ineqs: [[1, 1, 5, "l"], [2, 4, 15, "l"], [1, 0, 2, "l", [1]], [1, 0, 3, "g", [2]]],
              ineqTextPlaces: [[0.5, 5], [4, 2.25], [0.625, 6.5], [3.125, 4]],
              plotIntegerFeasible: true,
              addFeasibleRegionText: false,
              extraMathText: [["P^1", 80, 230], ["P^2", 190, 265]]
          }
      }
      const drawPlot = (svg, svgId) => {
          // parameters
          svg.id = svgId;
          const parentDiv = document.createElement('div');
          svg.parentNode.insertBefore(parentDiv, svg);
          parentDiv.appendChild(svg);
          svgDefs = document.createElementNS('http://www.w3.org/2000/svg', 'defs');
          svg.appendChild(svgDefs);
          goodDirColor = 'blue';
          badDirColor = 'red';
          goodArrowheadMarker = document.createElementNS('http://www.w3.org/2000/svg', 'marker');
          goodArrowheadMarker.id = goodDirColor + 'ArrowMarker';
          goodArrowheadMarker.setAttribute('markerWidth', 5);
          goodArrowheadMarker.setAttribute('markerHeight', 3);
          goodArrowheadMarker.setAttribute('refX', 0);
          goodArrowheadMarker.setAttribute('refY', 1.5);
          goodArrowheadMarker.setAttribute('orient', 'auto');
          arrowPoly = document.createElementNS('http://www.w3.org/2000/svg', 'polygon');
          arrowPoly.setAttribute('points', "0 0, 5 1.5, 0 3");
          arrowPoly.setAttribute('fill', goodDirColor);
          goodArrowheadMarker.appendChild(arrowPoly);
          badArrowheadMarker = goodArrowheadMarker.cloneNode(true);
          badArrowheadMarker.id = badDirColor + 'ArrowMarker'
          badArrowheadMarker.firstChild.setAttribute('fill', badDirColor);
          arrowheadMarker = goodArrowheadMarker.cloneNode(true);
          arrowheadMarker.id = 'blackArrowMarker'
          arrowheadMarker.firstChild.setAttribute('fill', 'black');
          svgDefs.appendChild(goodArrowheadMarker);
          svgDefs.appendChild(badArrowheadMarker);
          svgDefs.appendChild(arrowheadMarker);
          const args = { ...JSON.parse(JSON.stringify(baseLps))[svg.getAttribute('base')], ...JSON.parse(svg.getAttribute('altargs'))};
          const xMin = args['xMin'];
          const xMax = args['xMax'];
          const yMin = args['yMin'];
          const yMax = args['yMax'];
          const plotExtremePoints = [[0, 0], [xMax, 0], [xMax, yMax], [0, yMax]];
          let obj = args['obj'];
          if (Object.keys(args).includes('altObj')){
              obj = args['altObj'];
          }
          let initialIneqs = args['ineqs'];
          let ineqTextPlaces = args['ineqTextPlaces'];
          const removeConstraints = args['removeConstraints'] || [];
          const addConstraints = args['addConstraints'] || []
          if (removeConstraints.length > 0) {
              initialIneqs = initialIneqs.filter((x, i) => !removeConstraints.includes(i));
              ineqTextPlaces = ineqTextPlaces.filter((x, i) => !removeConstraints.includes(i));
          }
          if (addConstraints.length > 0) {
              for (const addConstr of addConstraints){
                  initialIneqs.push(addConstr[0]);
                  ineqTextPlaces.push(addConstr[1])
              }
          }
          const altFeasRegionTextPlace = args['altFeasRegionTextPlace']
          const showVertices = args['showVertices'] || false;
          const choosePoints = args['choosePoints'] || false;
          const chooseObjVals = args['chooseObjVals'] || false;
          const simplexStart = args['simplexStart'];
          const extraPoints = args['extraPoints'] || [];
          const extraText = args['extraText'] || [];
          const extraMathText = args['extraMathText'] || [];
          const extraLines = args['extraLines'] || [];
          const extraEqns = args['extraEqns'] || [];
          const plotIntegerFeasible = args['plotIntegerFeasible'] || false;
          let addFeasibleRegionText = args['addFeasibleRegionText'];
          if (addFeasibleRegionText === undefined) {
              addFeasibleRegionText = true;
          }
          const x1ObjStr = obj[0] == 0 ? '' : `${obj[0]}x_1`;
          const x2ObjStr = obj[1] == 0 ? '' : `${obj[1]}x_2`;
          const betweenObjStr = obj[0] == 0 ? '' : (obj[1] > 0 ? '+' : '');
          const objStr = x1ObjStr + betweenObjStr + x2ObjStr;
          const w = svg.getAttribute('width');
          const h = svg.getAttribute('height');
          const leq = String.fromCharCode(8804);
          const geq = String.fromCharCode(8805);
          const getObjVal = (x, y) => obj[0] * x + obj[1] * y;
          const unitPixToCoordX = (xMax - xMin) / w;
          const unitPixToCoordY = (yMax - yMin) / h;
          svg.style.marginLeft = -Math.abs(1 / unitPixToCoordX) / 2;
          
          // functions
          const coordToPix = (xCoord, yCoord) => {
              xPix = w * (xCoord - xMin) / (xMax - xMin);
              yPix = h - h * (yCoord - yMin) / (yMax - yMin);
              return [xPix, yPix]
          }
          const pixToCoord = (xPix, yPix) => {
              xCoord = xPix * ((xMax - xMin) / w) + xMin;
              yCoord = (yPix - h) * (-(yMax - yMin) / h) + yMin;
              return [xCoord, yCoord]
          }
          const lineBetweenCoords = (x1, y1, x2, y2, attrs) => {
              el = document.createElementNS('http://www.w3.org/2000/svg', 'line');
              const [x1Pix, y1Pix] = coordToPix(x1, y1);
              const [x2Pix, y2Pix] = coordToPix(x2, y2);
              el.setAttribute('x1', x1Pix);
              el.setAttribute('y1', y1Pix);
              el.setAttribute('x2', x2Pix);
              el.setAttribute('y2', y2Pix);
              attrs = attrs || {}
              attrs['style'] = attrs['style'] || 'stroke:black';
              for (const [k, v] of Object.entries(attrs)){
                  el.setAttribute(k, v);
              }
              svg.appendChild(el);
          }
          const addText = (text, x, y, attrs) => {
              txt = document.createElementNS('http://www.w3.org/2000/svg', 'text');
              txt.textContent = text;
              txt.setAttribute('x', x);
              txt.setAttribute('y', y);
              for (const [k, v] of Object.entries(attrs || {})){
                  txt.setAttribute(k, v);
              }
              svg.appendChild(txt);
          }
          const addMathText = (math, x, y, attrs) => {
              attrs = attrs || {};
              forObj = document.createElementNS('http://www.w3.org/2000/svg', 'foreignObject');
              mathEl = document.createElement('span');
              katex.render(math, mathEl, {
                  throwOnError: false
              });
              if (attrs['coordToPix'] || false) {
                  [x, y] = coordToPix(x, y)
              }
              forObj.setAttribute('x', x);
              forObj.setAttribute('y', y);
              attrs['height'] = attrs['height'] || '1.2rem';
              attrs['width'] = attrs['width'] || '15rem';
              attrs['font-size'] = attrs['font-size'] || '12pt';
              attrs['font-family'] = attrs['font-family'] || 'KaTeX_Main,Times New Roman,serif';
              for (const [k, v] of Object.entries(attrs || {})){
                  forObj.setAttribute(k, v);
              }
              forObj.appendChild(mathEl);
              textsToAdd.push(forObj);
          }
          const drawIneqs = () => {
              style = 'stroke:#777;padding:5pt';
              let ineqNum = 0;
              for ([xCoef, yCoef, rhs, sense] of ineqs) {
                  ineqNum += 1;
                  const ineqId = svgId + 'ineq' + ineqNum
                  plotEqn(xCoef, yCoef, rhs, {style: style, id: ineqId});
                  let [e1x, e1y, e2x, e2y] = getEqnEndpoints(xCoef, yCoef, rhs);
                  hoverLineId = svgId + 'ineq' + ineqNum + 'hoverLine';
                  lineBetweenCoords(e1x, e1y, e2x, e2y, {'style': 'stroke:black;stroke-width:5;opacity:0', 'id': hoverLineId})
                  const hoverLine = document.getElementById(hoverLineId);
                  polyId = svgId + 'ineq' + ineqNum + 'shaded';
                  ((xCoef, yCoef, rhs, sense, polyId) => {
                      hoverLine.onmouseover = () => {
                          const cornerPoints = plotExtremePoints;
                          let pts = getIntersectionWithPoly(xCoef, yCoef, rhs, cornerPoints, false);
                          const cpts = cornerPoints.filter(cp => ineqSatisfied(...cp, xCoef, yCoef, rhs, sense));
                          const getPtStr = (p) => p[0] + '---' + p[1];
                          const usedPtStrs = pts.map(p => getPtStr(p));
                          skipPts = [];
                          foundFirstCorner = false;
                          lastUsed = pts[pts.length - 1];
                          for (cp of cpts) {
                              cpStr = getPtStr(cp)
                              if (cpStr in usedPtStrs) {
                                  continue
                              }
                              if (foundFirstCorner) {
                                  usedPtStrs.push(cpStr);
                                  pts.push(cp);
                              } else {                            
                                  if (cp[0] == lastUsed[0] || cp[1] == lastUsed[1]) {
                                      foundFirstCorner = true;
                                      usedPtStrs.push(cpStr);
                                      pts.push(cp);
                                  } else {
                                      skipPts.push(cp);
                                  }
                              }
                          }
                          pts = pts.concat(skipPts);
                          polygonFromPoints(pts, {id: polyId, style: 'fill:rgb(212,212,212);fill:rgb(212,212,212,0.5)'});
                      }
                      hoverLine.onmouseout = () => {
                          shadePoly = document.getElementById(polyId)
                          if (!!shadePoly){
                              shadePoly.remove();
                          }
                      }
                  })(xCoef, yCoef, rhs, sense, polyId)
              }
          }
          const plotEqn = (xCoef, yCoef, rhs, attrs) => {
              lineBetweenCoords(...getEqnEndpoints(xCoef, yCoef, rhs), attrs);
          }
          const getEqnEndpoints = (xCoef, yCoef, rhs) => {
              if (xCoef === 0) {
                  pts = [0, rhs / yCoef, xMax, rhs / yCoef];
              } else if (yCoef === 0) {
                  pts = [rhs / xCoef, 0, rhs / xCoef, yMax];
              } else {
                  pts = [0, rhs / yCoef, rhs / xCoef, 0];
              }
              if (pts[1] < 0) {
                  pts[1] = (rhs - xCoef * xMax) / yCoef;
                  pts[0] = xMax;
              }
              if (pts[2] < 0) {
                  pts[2] = (rhs - yCoef * yMax) / xCoef;
                  pts[3] = yMax;
              }
              return pts
          }
          const drawTickMarks = () => {
              xTick = 0
              style = {'font-size': '10pt', 'font-family': 'KaTeX_Main,Times New Roman,serif'}
              while (xTick <= xMax) {
                  if (xTick >= 0) {
                      lineBetweenCoords(xTick, 0, xTick, (yMax - yMin) / 30);
                      [xText, yText] = coordToPix(xTick, -(yMax - yMin) / 30);
                      addText(xTick, xText - 4, yText + 4, style);
                      xTick += 1;
                  }
              }
              yTick = 0
              while (yTick <= yMax) {
                  if (yTick >= 0) {
                      lineBetweenCoords(0, yTick, (xMax - xMin) / 30, yTick);
                      [xText, yText] = coordToPix(-(xMax - xMin) / 30, yTick);
                      addText(yTick, xText - 4, yText + 4, style);
                      yTick += 1;
                  }
              }
          }
          const isFeasible = (x, y, returnViolated=false, altIneqs=undefined) => {
              let feasible = true;
              let violated = [];
              for ([xCoef, yCoef, rhs, sense] of (altIneqs || allIneqs)) {
                  if (!ineqSatisfied(x, y, xCoef, yCoef, rhs, sense)){
                      feasible = false;
                      if (returnViolated) {
                          violated.push([xCoef, yCoef, rhs])
                      } else {                        
                          break
                      }
                  }
              }
              if (returnViolated) {
                  return [feasible, violated];
              }
              return feasible
          }
          const onPlot = (x, y) => {
              if (x < 0 || x > xMax || y < 0 || y > yMax) {
                  return false
              }
              return true
          }
          const ineqSatisfied = (x, y, xCoef, yCoef, rhs, sense) => {
              if (sense === "l") {
                  return x * xCoef + y * yCoef <= rhs + 0.0001
              } else {
                  return x * xCoef + y * yCoef >= rhs - 0.0001
              }
          }
          const getVertices = (includePlotEdges=false) => {
              let ineqsToUse = allIneqs;
              if (includePlotEdges) {
                  ineqsToUse = ineqsToUse.concat([[1, 0, xMax, 'l'], [0, 1, yMax, 'l']]);
              }
              let intersections = [];
                  for ([i, [xCoef, yCoef, rhs, sense]] of ineqsToUse.entries()) {
                      for ([j, [xCoef1, yCoef1, rhs1, sense1]] of ineqsToUse.entries()){
                          if (j <= i){
                              continue
                          }
                          denom = xCoef * yCoef1 - xCoef1 * yCoef
                          if (denom === 0){
                              continue
                          }
                          num = xCoef * rhs1 - xCoef1 * rhs;
                          yIntersect = num / denom;
                          if (xCoef === 0) {
                              xIntersect = rhs1 / xCoef1;
                          } else {
                              xIntersect = (rhs / xCoef) - (yCoef / xCoef) * num / denom;
                          }
                          if (xIntersect == 0){
                              xIntersect = 0;
                          }
                          if (yIntersect == 0){
                              yIntersect = 0;
                          }
                          intersections.push([xIntersect || 0, yIntersect, i, j]);
                      }
                  }
                  let vertexStrs = [];
                  let vertices = [];
                  for ([x, y, i, j] of intersections) {
                      if (isFeasible(x, y) && onPlot(x, y)) {
                          vertices.push([x, y, i, j]);
                      }
                  }
                  orderedVertexIndices = [0];
                  while (orderedVertexIndices.length < vertices.length) {
                      nextIndex = [...vertices.entries()].filter((val, ind) => {
                          if (orderedVertexIndices.includes(ind)) {
                              return false
                          }
                          lastInd = orderedVertexIndices[orderedVertexIndices.length - 1];
                          return (
                              vertices[ind][2] == vertices[lastInd][2] ||
                              vertices[ind][2] == vertices[lastInd][3] ||
                              vertices[ind][3] == vertices[lastInd][2] ||
                              vertices[ind][3] == vertices[lastInd][3]
                          )
                      })[0][0]
                      orderedVertexIndices.push(nextIndex);
                  }
              if (vertices.length === 0) {
                  return []
              }
              return orderedVertexIndices.map(i => vertices[i].slice(0, 2))
          }
          const polygonFromPoints = (points, attrs) => {
              const poly = document.createElementNS('http://www.w3.org/2000/svg', 'polygon');
              poly.setAttribute('points', points.map(v => coordToPix(...v)).join(' '));
              for (const [k, v] of Object.entries(attrs || {})){
                  poly.setAttribute(k, v);
              }
              svg.appendChild(poly);
          }
          const shadeFeasibleRegion = () => {
              const verts = getVertices(true);
              if (verts.length === 0){
                  return
              }
              polygonFromPoints(verts, {'style': "fill:#ddd;stroke:black"})
              if (!!altFeasRegionTextPlace) {
                  const [xPix, yPix] = coordToPix(...altFeasRegionTextPlace);
              } else {
                  const xWeighted = verts.map(v => v[0]).reduce((a, b) => a + b) / verts.length;
                  const yWeighted = verts.map(v => v[1]).reduce((a, b) => a + b) / verts.length;
                  const [xPix, yPix] = coordToPix(xWeighted, yWeighted);
              }
              if (addFeasibleRegionText) {
                  addText("Feasible", xPix - 30, yPix, {'font-size': '12pt'});
                  addText("Region", xPix - 30, yPix + 20, {'font-size': '12pt'});
              }
          }
          const placePoint = (x, y, attrs) => {
              circ = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
              const [xPix, yPix] = coordToPix(x, y);
              circ.setAttribute('cx', xPix);
              circ.setAttribute('cy', yPix);
              circ.setAttribute('r', 3.5);
              for (const [k, v] of Object.entries(attrs || {})){
                  circ.setAttribute(k, v);
              }
              svg.appendChild(circ);
          }
          const plotVertices = () => {
              const vertices = getVertices();
              for ([x, y] of vertices) {
                  placePoint(x, y);
              }
          }
          const drawAxes = () => {
              const fontStyle = {'font-size': '12pt', 'font-family': 'KaTeX_Main,Times New Roman,serif'};
              lineBetweenCoords(0, 0, xMax, 0);
              xDiff = 10 * unitPixToCoordX
              yDiff = 4 * unitPixToCoordY
              polygonFromPoints([[xMax, 0], [xMax - xDiff, yDiff], [xMax - xDiff, -yDiff]], {'style': "fill:black;stroke:black"});
              [xLabelPix, yLabelPix] = coordToPix(Math.ceil(xMax) - 0.5, 0);
              addMathText('x_1', xLabelPix, yLabelPix, fontStyle);
              [xLabelPix, yLabelPix] = coordToPix(0, Math.ceil(yMax) - 0.5);
              addMathText('x_2', xLabelPix - 24, yLabelPix - 20, fontStyle);
              lineBetweenCoords(0, 0, 0, yMax);
              xDiff = 4 * unitPixToCoordX
              yDiff = 10 * unitPixToCoordY
              polygonFromPoints([[0, yMax], [xDiff, yMax - yDiff], [-xDiff, yMax - yDiff]], {'style': "fill:black;stroke:black"});
          }
          const labelIneqs = () => {
              for (i in ineqTextPlaces || []) {
                  ineq = initialIneqs[i];
                  ineqText = ''
                  ineqText += ineq[0] === 0 ? '' : (ineq[0] == 1 ? '' : ineq[0]) + 'x_1'
                  ineqText += ineq[1] === 0 ? '' : (ineqText === '' ? '' : ' + ') + (ineq[1] == 1 ? '' : ineq[1]) + 'x_2'
                  ineqText += ' ' + (ineq[3] === 'l' ? leq : geq) + ' ' + ineq[2];
                  fontStyle = {'font-size': '12pt'}
                  addMathText(ineqText, ...coordToPix(...ineqTextPlaces[i]), fontStyle);
              }
          }
          const getIntersectionWithPoly = (xCoef, yCoef, rhs, points, checkFeas=true, altIneqs=undefined) => {
              let intersections = [];
              let intersectionStrs = [];
              for (i=0; i<points.length; i++){
                  const [p1, p2] = points[i];
                  const [q1, q2] = points[(i + 1) % points.length];
                  const m1 = (p2 - q2) / (p1 - q1);
                  const b1 = p2 - m1 * p1;
                  const m2 = -xCoef / yCoef;
                  const b2 = rhs / yCoef;
                  if (m1 === m2) {
                      continue
                  }
                  if (Math.abs(m1) === Infinity) {
                      xIntersect = p1;
                      yIntersect = m2 * xIntersect + b2;
                  } else if (Math.abs(m2) === Infinity) {
                      xIntersect = rhs / xCoef;
                      yIntersect = m1 * xIntersect + b1
                  } else {
                      xIntersect = (b2 - b1) / (m1 - m2);
                      yIntersect = m1 * xIntersect + b1;
                  }
                  xIntersect = Math.round(1000000 * xIntersect) / 1000000;
                  yIntersect = Math.round(1000000 * yIntersect) / 1000000;
                  interStr = xIntersect + '---' + yIntersect;
                  p = [xIntersect, yIntersect]
                  if (!intersectionStrs.includes(interStr) && xIntersect === xIntersect && yIntersect === yIntersect) {
                      if ((!checkFeas || isFeasible(...p, false, altIneqs)) && onPlot(...p)) {
                          intersectionStrs.push(interStr);
                          intersections.push(p)
                      }
                  }
              }
              return intersections
          }
          const gcd = (a, b) => {
              if (!b) {
                  return Math.abs(a);
              }
              return Math.abs(gcd(b, a % b));
          }
          const addIntegerFeasiblePoints = () => {
              let xVal = Math.ceil(xMin);
              while (xVal <= xMax) {
                  let yVal = Math.ceil(yMin);
                  while (yVal <= yMax) {
                      if (isFeasible(xVal, yVal)) {
                          placePoint(xVal, yVal);
                      }
                      yVal += 1;
                  }
                  xVal += 1;
              }
          }
          const choosePointsFunc = (allIneqs) => {
              const underDiv = document.createElement('div');
              underDiv.classList = ['underPlot']
              parentDiv.appendChild(underDiv);
              const objDiv = document.createElement('div');
              objDiv.classList = ['pointChooseText'];
              underDiv.appendChild(objDiv);
              katex.render(`\\text{Objective: }${objStr}`, objDiv, {throwOnError: false});
              const pointChooseDiv = document.createElement('div');
              pointChooseDiv.classList = ['pointChooseDiv'];
              underDiv.appendChild(pointChooseDiv);
              const input1 = document.createElement('input');
              const label1 = document.createElement('label');
              label1.classList = ['pointChooseLabel']
              katex.render('x_1:', label1, {throwOnError: false});
              const input2 = document.createElement('input');
              const label2 = document.createElement('label');
              label2.classList = ['pointChooseLabel'];
              katex.render('x_2:', label2, {throwOnError: false});
              const textDiv = document.createElement('div');
              textDiv.classList = ['pointChooseText'];
              underDiv.appendChild(textDiv);
              katex.render('\\text{Select values for }x_1\\text{ and }x_2', textDiv, {throwOnError: false})
              for (inputEl of [input1, input2]) {
                  inputEl.setAttribute('type', 'number');
                  inputEl.setAttribute('min', 0);
                  inputEl.classList = ['pointChooseInput'];
              }
              input1.setAttribute('max', Math.floor(xMax));
              input2.setAttribute('max', Math.floor(yMax));  // todo: enforce min/max in onchange function
              const inputChangeFunc = () => {
                  [x1, x2] = [input1.value, input2.value];
                  const lineClass = 'violatedIneq' + svgId;
                  if (x1 == parseFloat(x1) && x2 == parseFloat(x2)){
                      for (violEl of [...document.getElementsByClassName(lineClass)]){
                          violEl.remove();
                      }
                      const pointId = svgId + 'placedPoint';
                      const pointEl = document.getElementById(pointId);
                      if (!!pointEl) {
                          pointEl.remove();
                      }
                      const [feas, violated] = isFeasible(x1, x2, true, allIneqs);
                      const color = feas ? 'black' : 'red';
                      textDiv.innerHTML = '';
                      if (feas) {
                          textDiv.textContent = `(${x1}, ${x2}) is feasible, objective value ${getObjVal(x1, x2)}.`
                      }
                      else {
                          textDiv.textContent = `(${x1}, ${x2}) is infeasible.`
                          for (v of violated) {
                              plotEqn(...v, {'style': 'stroke:red;stroke-width:0', 'class': 'violatedIneq ' + lineClass})
                          }
                      }
                      placePoint(input1.value, input2.value, {'id': pointId, 'style': `stroke:${color};fill:${color}`});
                  }
              }
              input1.addEventListener("change", inputChangeFunc);
              input2.addEventListener("change", inputChangeFunc);
              svg.onclick = (e) => {                
                  let rect = svg.getBoundingClientRect();
                  let x = e.clientX - rect.left;
                  let y = e.clientY - rect.top;
                  [xPix, yPix] = pixToCoord(x, y);
                  input1.value = Math.round(10 * xPix) / 10;
                  input2.value = Math.round(10 * yPix) / 10;
                  inputChangeFunc();
              }
              for (el of [label1, input1, label2, input2]) {
                  pointChooseDiv.appendChild(el);
              }
          }
          const chooseObjValsFunc = (allIneqs, verticesAndPlotEdges) => {
              const underDiv = document.createElement('div');
              underDiv.classList = ['underPlot']
              parentDiv.appendChild(underDiv);
              const pointChooseDiv = document.createElement('div');
              pointChooseDiv.classList = ['pointChooseDiv'];
              underDiv.appendChild(pointChooseDiv);
              const pointValDiv = document.createElement('div');
              pointValDiv.classList = ['pointChooseDiv'];
              underDiv.appendChild(pointChooseDiv);
              const input = document.createElement('input');
              const label = document.createElement('label');
              label.classList = ['pointChooseLabel'];
              katex.render(`\\text{Plotting objective: }${objStr}=`, label, {throwOnError: false});
              const textDiv = document.createElement('div');
              textDiv.classList = ['pointChooseText'];
              underDiv.appendChild(textDiv);
              textDiv.textContent = 'Select a value to plot an objective line.'
              input.setAttribute('type', 'number');
              input.setAttribute('min', 0);
              maxObjVal = 0;
              for (extreme of plotExtremePoints) {
                  exObjVal = getObjVal(...extreme);
                  if (exObjVal > maxObjVal) {
                      maxObjVal = exObjVal;
                  }
              }
              input.setAttribute('max', maxObjVal);
              input.classList = ['pointChooseInput'];
              const inputChangeFunc = () => {
                  z = input.value;
                  if (z == parseFloat(z)){
                      eqnId = svgId + 'objEqn';
                      eqnEl = document.getElementById(eqnId);
                      if (!!eqnEl) {
                          eqnEl.remove();
                      }
                      plotEqn(...obj, z, {id: eqnId});
                      const intersectPoints = getIntersectionWithPoly(...obj, z, verticesAndPlotEdges, true, allIneqs);
                      const intersectLineId = svgId + 'objLineIntersect';
                      intersectLine = document.getElementById(intersectLineId);
                      if (!!intersectLine) {
                          intersectLine.remove();
                      }
                      if (intersectPoints.length === 0) {
                          textDiv.textContent = 'No feasible solutions with objective value ' + z;
                      } else if (intersectPoints.length === 1) {
                          textDiv.textContent = `Single feasible solution (${intersectPoints[0]}) with objective value ${z}`;
                          placePoint(...intersectPoints[0], {'style': 'fill:purple', 'id': intersectLineId})
                      } else {
                          textDiv.textContent = `Multiple feasible solutions have objective value ${z}`;
                          lineBetweenCoords(...intersectPoints[0], ...intersectPoints[1], {'style': 'stroke:purple;stroke-width:2pt', 'id': intersectLineId});
                      }
                  }
              }
              input.addEventListener("change", inputChangeFunc);
              svg.onclick = (e) => {                
                  let rect = svg.getBoundingClientRect();
                  let x = e.clientX - rect.left;
                  let y = e.clientY - rect.top;
                  let z = getObjVal(...pixToCoord(x, y));
                  input.value = Math.round(10 * z) / 10;
                  inputChangeFunc();
              }
              for (el of [label, input]) {
                  pointChooseDiv.appendChild(el);
              }
          
          }
          const simplexStartFunc = () => {
              let nextPoint = simplexStart;
              let pointHistory = [];
              const underDiv = document.createElement('div');
              underDiv.classList = ['underPlot']
              parentDiv.appendChild(underDiv);
              const objDiv = document.createElement('div');
              objDiv.classList = ['pointChooseText'];
              underDiv.appendChild(objDiv);
              katex.render(`\\text{Objective: }${objStr}`, objDiv, {throwOnError: false});
              const currentPlaceText = document.createElement('div');
              currentPlaceText.classList = ['pointChooseText'];
              const possibleDirections = document.createElement('div');
              possibleDirections.classList = ['pointChooseText'];
              const status = document.createElement('div');
              status.classList = ['pointChooseText'];
              const buttonsDiv = document.createElement('div');
              buttonsDiv.classList = ['pointChooseText'];
              const backButton = document.createElement('button');
              backButton.textContent = '<<'
              const resetButton = document.createElement('button');
              resetButton.textContent = 'Reset'
              const forwardButton = document.createElement('button');
              forwardButton.textContent = '>>'
              buttonsDiv.appendChild(backButton);
              buttonsDiv.appendChild(resetButton);
              buttonsDiv.appendChild(forwardButton);
              underDiv.appendChild(currentPlaceText);
              underDiv.appendChild(possibleDirections);
              underDiv.appendChild(buttonsDiv);
              underDiv.appendChild(status);
              const simplexPointId = svgId + 'SimplexPoint';
              const getArrowClass = () => svgId + 'SimplexArrowDir';
              const getArrowIdFromCheckId = (checkId) => checkId + 'TargetArrow';
              const changePoint = () => {
                  currentPoint = pointHistory.length === 0 ? simplexStart : pointHistory[pointHistory.length - 1];
                  simplexPointEl = document.getElementById(simplexPointId);
                  if (!!simplexPointEl) {
                      simplexPointEl.remove();
                      for (arrowEl of [...document.getElementsByClassName(getArrowClass())]){
                          arrowEl.remove();
                      }
                  }
                  katex.render(
                      `\\text{Current solution: }(${currentPoint[0]}, ${currentPoint[1]}),\\text{ objective }${getObjVal(...currentPoint)}`,
                      currentPlaceText
                  );
                  const vertices = getVertices();
                  const vertInd = vertices.map((x, i) => i).filter(i => {
                      return vertices[i][0] === currentPoint[0] && vertices[i][1] === currentPoint[1]
                  })[0];
                  adjacents = [vertInd - 1, vertInd + 1].map(i => {
                      return vertices[(i + vertices.length) % vertices.length]    
                  });
                  adjDir = adjacents.map(adj => {
                      dir = [adj[0] - currentPoint[0], adj[1] - currentPoint[1]];
                      dirGcd = gcd(...dir);
                      return [dir[0] / dirGcd, dir[1] / dirGcd];
                  });
                  possibleDirections.innerHTML = '';
                  possibleDirections.textContent = 'Adjacent solution directions:'
                  const tab = document.createElement('table');
                  tab.classList = ['simplexDirectionTable'];
                  const dirHead = document.createElement('th');
                  dirHead.textContent = 'Direction';
                  const objHead = document.createElement('th');
                  objHead.innerHTML = '&Delta; Obj / Unit';
                  const useDir = document.createElement('th');
                  useDir.innerHTML = 'Use?';
                  tab.appendChild(dirHead);
                  tab.appendChild(objHead);
                  tab.appendChild(useDir);
                  possibleDirections.appendChild(tab);
                  dirGains = [];
                  const getCheckId = i => simplexPointId + 'DirCheck' + i
                  for ([i, adj] of adjDir.entries()) {
                      const tr = document.createElement('tr');
                      tab.appendChild(tr);
                      const dirTd = document.createElement('td');
                      dirTd.textContent = `(${adj[0]}, ${adj[1]})`;
                      adjDirNorm = Math.sqrt(adj[0] ** 2 + adj[1] ** 2);
                      unitObjGain = getObjVal(...adj) / adjDirNorm;
                      const arrowHeadCoord = adj.map((ad, iAd) => currentPoint[iAd] + 45 * unitPixToCoordX * ad / adjDirNorm);
                      const plotColor = unitObjGain > 0 ? goodDirColor : badDirColor;
                      attrs = {
                          'style': 'stroke-width:2pt;stroke:' + plotColor,
                          'marker-end': `url(#${plotColor}ArrowMarker)`,
                          'class': getArrowClass(),
                          'id': getArrowIdFromCheckId(getCheckId(i))
                      }
                      lineBetweenCoords(...currentPoint, ...arrowHeadCoord, attrs);
                      dirGains.push(unitObjGain);
                      const objTd = document.createElement('td');
                      objTd.textContent = Math.round(100 * unitObjGain) / 100;
                      const useTd = document.createElement('td');
                      const useInput = document.createElement('input');
                      useInput.id = getCheckId(i);
                      useInput.setAttribute('type', 'checkbox');
                      useInput.onchange = (e) => {
                          for (inputInd = 0; inputInd < adjacents.length; inputInd++){
                              inEl = document.getElementById(getCheckId(inputInd));
                              if (inEl !== e.target){
                                  inEl.checked = false;
                                  document.getElementById(getArrowIdFromCheckId(inEl.id)).classList.remove('simplexArrowChosen');
                              } else {
                                  if (e.target.checked) {
                                      nextPoint = adjacents[inputInd];
                                      document.getElementById(getArrowIdFromCheckId(e.target.id)).classList.add('simplexArrowChosen');
                                  } else {
                                      nextPoint = undefined;
                                      document.getElementById(getArrowIdFromCheckId(e.target.id)).classList.remove('simplexArrowChosen');
                                  }   
                              }                            
                              buttonStatusChange();
                          }
                      }
                      if (unitObjGain <= 0){
                          useInput.disabled = true;
                          tr.style.color = 'red';
                      }
                      useTd.appendChild(useInput);
                      tr.appendChild(dirTd);
                      tr.appendChild(objTd);
                      tr.appendChild(useTd);
                  }                
                  placePoint(...currentPoint, {'id': simplexPointId, 'r': '4.5'});
                  const maxDirGain = Math.max(...dirGains);
                  const numImprovingDirections = dirGains.filter(g => g > 0).length;
                  if (maxDirGain < 0) {
                      status.innerHTML = 'No improving directions, <b>optimal solution found!</b>';
                      nextPoint = undefined;
                  } else {
                      const bestInd = adjacents.map((adj, i) => i).filter(i => dirGains[i] === maxDirGain)[0];
                      const bestDir = adjDir[bestInd];
                      status.textContent = `${numImprovingDirections} improving direction${numImprovingDirections === 1 ? '.' : 's to choose from.'}`;
                      const bestCheck = document.getElementById(getCheckId(bestInd));
                      bestCheck.checked = true;
                      bestCheck.onchange({target: bestCheck});
                      nextPoint = adjacents[bestInd];
                  }
                  buttonStatusChange();
              }
              const buttonStatusChange = () => {                
                  backButton.disabled = pointHistory.length === 0;
                  forwardButton.disabled = !nextPoint;
              }
              forwardButton.onclick = () => {
                  pointHistory.push(nextPoint);
                  changePoint();
              }
              resetButton.onclick = () => {
                  nextPoint = undefined;
                  pointHistory = [];
                  changePoint();
              }          
              backButton.onclick = () => {
                  pointHistory.pop(pointHistory.length - 1);
                  changePoint();
              }
              changePoint();
          
          }

          // logic
          allSystemNums = new Set();
          textsToAdd = [];
          for ([xCoef, yCoef, rhs, sense, systemNums] of initialIneqs) {
              if (!!systemNums) {
                  for (sysNum of systemNums) {
                      allSystemNums.add(sysNum);
                  }
              }
          }
          if (allSystemNums.size === 0){
              allSystemNums.add(0);
          }
          labelIneqs();
          for (sysNum of allSystemNums) {
              ((sysNum) => {
                  ineqs = initialIneqs.filter(ineq => {
                      [xCoef, yCoef, rhs, sense, sysNums] = ineq;
                      if (!sysNums) {
                          return true
                      }
                      return sysNums.includes(sysNum)
                  })
                  allIneqs = ineqs.concat([[1, 0, 0, "g"], [0, 1, 0, "g"]]);
                  drawIneqs();
                  shadeFeasibleRegion();
                  drawTickMarks();
                  if (showVertices){
                      plotVertices();
                  }
                  drawAxes();
                  for (pt of extraPoints) {
                      placePoint(...pt);
                  }
                  for (ln of extraLines) {
                      lineBetweenCoords(...ln);
                  }
                  for (tx of extraText) {
                      addText(...tx);
                  }
                  for (tx of extraMathText) {
                      addMathText(...tx);
                  }
                  if (choosePoints) {
                      choosePointsFunc(allIneqs);
                  }
                  if (chooseObjVals) {
                      const verticesAndPlotEdges = getVertices(true);
                      chooseObjValsFunc(allIneqs, verticesAndPlotEdges);
                  }
                  if (simplexStart) {
                      simplexStartFunc();
                  }
                  if (plotIntegerFeasible) {
                      addIntegerFeasiblePoints();
                  }
              })(sysNum)
          }
          for (textObj of textsToAdd) {
              svg.appendChild(textObj);
          }
      }
      const drawAllSvgPlots = () => {
          for ([i, svgEl] of document.querySelectorAll('svg.lpDraw').entries()){
              ((i, svgEl) => {
                  drawPlot(svgEl, 'svg' + i);
              })(i, svgEl)
          }
      }
  </script>
  <style>
      .footnoteTooltipClose {
          color: #222;
          font-size: 30pt;
          font-weight: bold;
          margin-left: auto;
          margin-top: -1rem;
          margin-bottom: -1rem;
      }
      .footnoteTooltipClose:hover, .footnoteTooltipClose:focus {
          color: black;
          text-decoration: none;
          cursor: pointer;
      }
      .footnote-ref sup, .eqnRef {
          cursor: pointer;
          color: green !important;
      }
      .footnoteTooltip {
          background-color: #ebebeb;
          padding: 1rem;
          border: 1px solid #888;
          position: absolute;
          z-index: 1;
          width: 75%;
          left: 50%;
          transform: translateX(-50%);
          margin-top: 2rem;
          font-size: max(1rem, min(calc(0.9rem + 0.4vw), 22pt));
          overflow-x: auto;
          display: flex;
          flex-direction: column;
      }
      .eqnRef .footnoteTooltip {
          color: black;
      }
      .seeOriginalEq {
          font-size: 1rem;
          margin-left: auto;
      }
  </style>
  <script>
      function footnoteOnTooltipClick(id, innerHTML, refElOrId, origId) {
          innerHTML = innerHTML.replaceAll('@@@', '"');
          const tooltipEl = document.getElementById(id);
          if (tooltipEl == null) {
              const newEl = document.createElement("span");
              closeEl = document.createElement("div");
              closeEl.classList = ['footnoteTooltipClose'];
              closeEl.innerHTML = '&times;';
              newEl.appendChild(closeEl);
              if (typeof(refElOrId) === 'string'){
                  closeEl.setAttribute("onclick", "removeElById('" + id + "')");
                  document.getElementById(refElOrId).appendChild(newEl);
              } else {
                  closeEl.onclick = () => removeElById(id);
                  refElOrId.append(newEl);
              }
              newEl.id = id;
              newEl.innerHTML += innerHTML;
              newEl.classList = ['footnoteTooltip'];
              for (numEl of newEl.getElementsByClassName('eqnos-number')){
                  numEl.remove();
              }
              if (!!origId) {
                  seeOrigEl = document.createElement('a');
                  seeOrigEl.setAttribute('href', '#' + origId);
                  seeOrigEl.innerHTML = 'jump to';
                  seeOrigEl.classList = ['seeOriginalEq']
                  seeOrigEl.onclick = () => {
                      backEl = document.getElementById('back#' + origId + 'Arrow');
                      backEl.style.display = 'inline';
                      backEl.setAttribute('href', '#' + id)
                  }
                  newEl.appendChild(seeOrigEl);
              }
          } else {
              tooltipEl.remove();
          }
          
      }
      function removeElById(id) {
          document.getElementById(id).remove();
      }
  </script>
  <style>
      #main {
          font-size: max(1rem, min(calc(0.9rem + 0.4vw), 22pt));
          width: min(max(90%, calc(100% - min(60%, 350px) - 1rem)), 800px);
          position: absolute;
          left: 50%;
          transform: translateX(-50%);
          transition: margin-left .5s;
          padding: 20px;
          padding-bottom: 30px;
      }
      html {
          scroll-padding-top: 2.5rem;
          overflow-y: auto;
      }
      body {
          scroll-padding-top: 2.5rem;
          overflow-y: hidden;
          max-width: none !important;
      }
      .loadingMessage {
          text-align: center;
          margin-top: 40vh;
          font-size: 1.2rem;
      }
      blockquote {
          margin: 1rem 0.5rem;
          padding-left: 0.5em;
          padding-right: 0.5em;
          border-left: 2px solid #e6e6e6;
          border-right: 2px solid #e6e6e6;
          color: #444;
          background-color: #ebebeb;
      }
      blockquote p {
          padding-top: 0.5rem;
          padding-bottom: 0.5rem;
      }
      details {
          cursor: pointer;
      }
      figure {
          margin-inline: 0.5rem;
      }
      figure img {
          display: block;
          margin-left: auto;
          margin-right: auto;
          max-width: 100%;
      }
      figure figcaption {
          font-size: max(0.9rem, min(calc(0.8rem + 0.4vw), 20pt));;
          text-align: center;
      }
      a {
          color: blue;
      }
      a:visited {
          color: purple;
      }
      h1 {
          position: relative;
          margin-top: 5rem;
      }
      h1:before {
          content: '';
          position: absolute;
          width: 100%;
          height: 1px;
          background: black;
          bottom: 150%;
          left: 0;
      }
      *[role="doc-biblioref"] {
          color: green !important;
      }
      div.sourceCode {
          background-color: #dfdfdf;
          padding: 0.5rem;
          border: 1pt solid black;
          font-size: max(12pt, 1.1rem);
      }
      .copyButton {
          float: right;
          cursor: pointer;
      }
      .header-section-number::after {
          content: ':'
      }
      @keyframes fade {
          0%,100% { opacity: 0 }
          15% { opacity: 1 }
          85% { opacity: 1 }
      }
      .copyMessage {
          position: absolute;
          transform: translate(-2rem, -2.8rem);
          width: 4rem;
          font-size: max(10pt, 0.7rem);
          text-align: center;
          background-color: #eee;
          border: 1pt solid black;
          border-radius: 0.25rem;
          animation: fade 2s linear;
      }
      .backRefElement {
          margin-top: auto;
      }
      footer {
          position: fixed;
          bottom: 0;
          text-align: center;
          width: 100%;
          background: white;
          left: 50%;
          transform: translateX(-50%);
          border-top: 1pt solid lightgray;
          font-size: 0.7rem;
          display: flex;
          justify-content: space-between;
      }
      .embedIndent {
          margin: 0 1rem;
          display: none;
      }
      .lectureEmbedIframe {
          width: min(600px, 80vw);
          height: calc(9 * min(600px, 80vw) / 16);
      }
      .tinyText {
          font-size: 0.5rem;
      }
      .mathSmall {
          font-size: 1rem;
      }
      .katexSideBySide {
          align-self: center;
      }
      .katexSideBySide .katexContainer {
          overflow-x: hidden;
      }
      .basicCenter {
          position: relative;
          left: 50%;
          transform: translateX(-50%);
      }
  </style>
  <style>
      .ytEmbedContainer {
          position: relative;
          padding-bottom: 56.25%;
          height: 0;
          overflow: hidden;
          max-width: 100%;
      } .ytEmbedContainer iframe, .ytEmbedContainer object, .ytEmbedContainer embed {
          position: absolute;
          top: 0;
          left: 0;
          width: 100%;
          height: 100%;
      }
      .ytEmbedContainerContainer {
          max-width: 640px;
      }
  </style>
  <style>
      .theorem p {
          display: inline;
      }
      .theorem {
          border: 1pt solid gray;
          padding: 1rem;
          background-color: #eee;
          font-style: italic;
          margin: 0;
      }
      .theoremLabel {
          font-weight: bold;
          font-style: normal;
      }
      .proof::after {
          display: block;
          content: '\00220E';
          margin-top: -1.25rem;
          margin-bottom: 1rem;
      }
      .theorem .backRefElement {
          float: right;
      }
  </style>
  <script>
      BBGraphData = {
          bbTree1: {
              'edges': [
                  ['P', 'P^1', 'x_1 \\leq 2'],
                  ['P', 'P^2', 'x_1 \\geq 3']
              ],
              'nodes': {
                  'P': {lp: '\\frac{59}{7}', state: 'branched'},
                  'P^1': {},
                  'P^2': {}
              }
          }
      }
      
      BBGraphData.bbTree2 = JSON.parse(JSON.stringify(BBGraphData.bbTree1));
      BBGraphData.bbTree2.nodes['P^1'] = {lp: '\\frac{15}{2}', state: 'branched'};
      BBGraphData.bbTree2.nodes['P^3'] = {};
      BBGraphData.bbTree2.nodes['P^4'] = {};
      BBGraphData.bbTree2.edges.push(['P^1', 'P^3', 'x_2 \\leq 0']);
      BBGraphData.bbTree2.edges.push(['P^1', 'P^4', 'x_2 \\geq 1']);

      BBGraphData.bbTree3 = JSON.parse(JSON.stringify(BBGraphData.bbTree2));
      BBGraphData.bbTree3.nodes['P^2'] = {lp: '-\\infty', state: 'infeasible'};

      BBGraphData.bbTree4 = JSON.parse(JSON.stringify(BBGraphData.bbTree3));
      BBGraphData.bbTree4.nodes['P^4'] = {lp: '7', state: 'integer'};

      BBGraphData.bbTree5 = JSON.parse(JSON.stringify(BBGraphData.bbTree4));
      BBGraphData.bbTree5.nodes['P^3'] = {lp: '6', state: 'bounded'};
  </script>
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<script src='https://cdn.plot.ly/plotly-2.26.0.min.js'></script>
<div class="navbar">
    <div onclick="openCloseNav()" style="padding-left: 1rem; cursor: pointer; color: blue">Contents</div>
    <div style="text-align: center">IMSE 780</div>
    <div style="text-align: right; padding-right: 1rem">Fall 2023</div>
</div>
<div id="loader" class="loadingMessage">Loading...</div>
<nav id="TOC" role="doc-toc">
<div id="tocTop"></div>
<ul>
<li><a href="#welcome" id="toc-welcome"><span
class="toc-section-number">1</span> Welcome!</a>
<ul>
<li><a href="#course-materials" id="toc-course-materials"><span
class="toc-section-number">1.1</span> Course materials</a></li>
<li><a href="#notes-on-these-notes" id="toc-notes-on-these-notes"><span
class="toc-section-number">1.2</span> Notes on these notes</a></li>
</ul></li>
<li><a href="#introduction-to-or" id="toc-introduction-to-or"><span
class="toc-section-number">2</span> Introduction to OR</a>
<ul>
<li><a href="#what-is-operations-research"
id="toc-what-is-operations-research"><span
class="toc-section-number">2.1</span> What is Operations
Research?</a></li>
<li><a href="#example-or-problems" id="toc-example-or-problems"><span
class="toc-section-number">2.2</span> Example OR problems</a>
<ul>
<li><a href="#sec:tsp" id="toc-sec:tsp"><span
class="toc-section-number">2.2.1</span> Traveling Salesman
Problem</a></li>
<li><a href="#job-shop-scheduling" id="toc-job-shop-scheduling"><span
class="toc-section-number">2.2.2</span> Job-shop scheduling</a></li>
<li><a href="#portfolio-optimization"
id="toc-portfolio-optimization"><span
class="toc-section-number">2.2.3</span> Portfolio optimization</a></li>
</ul></li>
<li><a href="#or-in-practice" id="toc-or-in-practice"><span
class="toc-section-number">2.3</span> OR in practice</a>
<ul>
<li><a href="#origins-of-or" id="toc-origins-of-or"><span
class="toc-section-number">2.3.1</span> Origins of OR</a></li>
<li><a href="#case-studies" id="toc-case-studies"><span
class="toc-section-number">2.3.2</span> Case studies</a></li>
<li><a href="#edelman-prize" id="toc-edelman-prize"><span
class="toc-section-number">2.3.3</span> Edelman Prize</a></li>
</ul></li>
<li><a href="#topics-well-cover" id="toc-topics-well-cover"><span
class="toc-section-number">2.4</span> Topics weâ€™ll cover</a></li>
</ul></li>
<li><a href="#python-crash-course" id="toc-python-crash-course"><span
class="toc-section-number">3</span> Python crash course</a>
<ul>
<li><a href="#google-colab-notebooks"
id="toc-google-colab-notebooks"><span
class="toc-section-number">3.1</span> Google Colab notebooks</a></li>
<li><a href="#some-python-basics" id="toc-some-python-basics"><span
class="toc-section-number">3.2</span> Some Python basics</a></li>
<li><a href="#sec:pythonEnvironments"
id="toc-sec:pythonEnvironments"><span
class="toc-section-number">3.3</span> Other coding environments</a>
<ul>
<li><a href="#local-development" id="toc-local-development"><span
class="toc-section-number">3.3.1</span> Local development</a></li>
<li><a href="#cloud-hosted" id="toc-cloud-hosted"><span
class="toc-section-number">3.3.2</span> Cloud hosted</a></li>
</ul></li>
</ul></li>
<li><a href="#linear-programming" id="toc-linear-programming"><span
class="toc-section-number">4</span> Linear programming</a>
<ul>
<li><a href="#sec:exampleLp" id="toc-sec:exampleLp"><span
class="toc-section-number">4.1</span> An example LP</a>
<ul>
<li><a href="#formulating-our-first-lp"
id="toc-formulating-our-first-lp"><span
class="toc-section-number">4.1.1</span> Formulating our first
LP</a></li>
</ul></li>
<li><a href="#lp-terminology" id="toc-lp-terminology"><span
class="toc-section-number">4.2</span> LP terminology</a></li>
<li><a href="#sec:lpVisualized" id="toc-sec:lpVisualized"><span
class="toc-section-number">4.3</span> LP visualized</a>
<ul>
<li><a href="#solving-an-lp-visually"
id="toc-solving-an-lp-visually"><span
class="toc-section-number">4.3.1</span> Solving an LP visually</a></li>
<li><a href="#visualizing-other-scenarios"
id="toc-visualizing-other-scenarios"><span
class="toc-section-number">4.3.2</span> Visualizing other
scenarios</a></li>
</ul></li>
<li><a href="#sec:lpSoftware" id="toc-sec:lpSoftware"><span
class="toc-section-number">4.4</span> Solving LPs with software</a>
<ul>
<li><a href="#modeling-languages" id="toc-modeling-languages"><span
class="toc-section-number">4.4.1</span> Modeling languages</a></li>
<li><a href="#solvers" id="toc-solvers"><span
class="toc-section-number">4.4.2</span> Solvers</a></li>
<li><a href="#solving-our-lp-with-python"
id="toc-solving-our-lp-with-python"><span
class="toc-section-number">4.4.3</span> Solving our LP with
Python</a></li>
<li><a href="#sec:lpModelDataSep" id="toc-sec:lpModelDataSep"><span
class="toc-section-number">4.4.4</span> Model/data separation</a></li>
</ul></li>
<li><a href="#sec:lpForms" id="toc-sec:lpForms"><span
class="toc-section-number">4.5</span> LP forms</a>
<ul>
<li><a href="#standard-form" id="toc-standard-form"><span
class="toc-section-number">4.5.1</span> Standard form</a></li>
<li><a href="#minimization-problems"
id="toc-minimization-problems"><span
class="toc-section-number">4.5.2</span> Minimization problems</a></li>
<li><a href="#sec:lpConstraintTransform"
id="toc-sec:lpConstraintTransform"><span
class="toc-section-number">4.5.3</span> Different constraint
forms</a></li>
<li><a href="#sec:lpVariableBoundTransform"
id="toc-sec:lpVariableBoundTransform"><span
class="toc-section-number">4.5.4</span> Variable bounds</a></li>
<li><a href="#recap-of-allowed-forms"
id="toc-recap-of-allowed-forms"><span
class="toc-section-number">4.5.5</span> Recap of allowed forms</a></li>
<li><a href="#different-notation" id="toc-different-notation"><span
class="toc-section-number">4.5.6</span> Different notation</a></li>
</ul></li>
<li><a href="#sec:simplex" id="toc-sec:simplex"><span
class="toc-section-number">4.6</span> The simplex method</a>
<ul>
<li><a href="#corner-point-solutions"
id="toc-corner-point-solutions"><span
class="toc-section-number">4.6.1</span> Corner-point solutions</a></li>
<li><a href="#sec:simplexVisualized"
id="toc-sec:simplexVisualized"><span
class="toc-section-number">4.6.2</span> Simplex visualized</a></li>
<li><a href="#augmented-form-and-basic-solutions"
id="toc-augmented-form-and-basic-solutions"><span
class="toc-section-number">4.6.3</span> Augmented form and basic
solutions</a></li>
<li><a href="#sec:simplexExample" id="toc-sec:simplexExample"><span
class="toc-section-number">4.6.4</span> Solving the sample LP with
simplex</a></li>
<li><a href="#simplex-in-matrix-notation"
id="toc-simplex-in-matrix-notation"><span
class="toc-section-number">4.6.5</span> Simplex in matrix
notation</a></li>
<li><a href="#presenting-finally-the-simplex-algorithm-mostly"
id="toc-presenting-finally-the-simplex-algorithm-mostly"><span
class="toc-section-number">4.6.6</span> Presenting (finally) the simplex
algorithm (mostly)</a></li>
<li><a href="#sec:lpOtherConsiderations"
id="toc-sec:lpOtherConsiderations"><span
class="toc-section-number">4.6.7</span> Other considerations</a></li>
<li><a href="#the-revised-simplex-method"
id="toc-the-revised-simplex-method"><span
class="toc-section-number">4.6.8</span> The revised simplex
method</a></li>
</ul></li>
<li><a href="#sec:lpDuality" id="toc-sec:lpDuality"><span
class="toc-section-number">4.7</span> Duality</a>
<ul>
<li><a href="#sec:corporateTakeover"
id="toc-sec:corporateTakeover"><span
class="toc-section-number">4.7.1</span> The corporate takeover</a></li>
<li><a href="#defining-the-dual-lp" id="toc-defining-the-dual-lp"><span
class="toc-section-number">4.7.2</span> Defining the dual LP</a></li>
<li><a href="#properties-of-the-dual-lp"
id="toc-properties-of-the-dual-lp"><span
class="toc-section-number">4.7.3</span> Properties of the dual
LP</a></li>
<li><a href="#simplex-and-the-dual-problem"
id="toc-simplex-and-the-dual-problem"><span
class="toc-section-number">4.7.4</span> Simplex and the dual
problem</a></li>
<li><a href="#primaldual-feasibilityboundedness-relationships"
id="toc-primaldual-feasibilityboundedness-relationships"><span
class="toc-section-number">4.7.5</span> Primal/dual
feasibility/boundedness relationships</a></li>
</ul></li>
<li><a href="#sec:lpPostOpt" id="toc-sec:lpPostOpt"><span
class="toc-section-number">4.8</span> Post-optimality analysis</a>
<ul>
<li><a href="#sec:lpReopt" id="toc-sec:lpReopt"><span
class="toc-section-number">4.8.1</span> Re-optimization</a></li>
<li><a href="#sec:shadowPrices" id="toc-sec:shadowPrices"><span
class="toc-section-number">4.8.2</span> Shadow Prices</a></li>
<li><a href="#sec:sensitivityAnalysis"
id="toc-sec:sensitivityAnalysis"><span
class="toc-section-number">4.8.3</span> Sensitivity Analysis</a></li>
</ul></li>
<li><a href="#notes-and-further-reading"
id="toc-notes-and-further-reading"><span
class="toc-section-number">4.9</span> Notes and further reading</a></li>
</ul></li>
<li><a href="#integer-programming" id="toc-integer-programming"><span
class="toc-section-number">5</span> Integer programming</a>
<ul>
<li><a href="#definitions" id="toc-definitions"><span
class="toc-section-number">5.1</span> Definitions</a></li>
<li><a href="#sec:ipRoundingNotEnough"
id="toc-sec:ipRoundingNotEnough"><span
class="toc-section-number">5.2</span> Rounding is not enough</a></li>
<li><a href="#ip-modeling" id="toc-ip-modeling"><span
class="toc-section-number">5.3</span> IP modeling</a>
<ul>
<li><a href="#general-integer-variables"
id="toc-general-integer-variables"><span
class="toc-section-number">5.3.1</span> General integer
variables</a></li>
<li><a href="#sec:binVarTricks" id="toc-sec:binVarTricks"><span
class="toc-section-number">5.3.2</span> Binary variable tricks</a></li>
<li><a href="#sec:ipWordProblems" id="toc-sec:ipWordProblems"><span
class="toc-section-number">5.3.3</span> Example word problems</a></li>
<li><a href="#sec:ipModelDataSep" id="toc-sec:ipModelDataSep"><span
class="toc-section-number">5.3.4</span> Model/data separation</a></li>
</ul></li>
<li><a href="#solving-ips-with-software"
id="toc-solving-ips-with-software"><span
class="toc-section-number">5.4</span> Solving IPs with software</a>
<ul>
<li><a href="#solvers-1" id="toc-solvers-1"><span
class="toc-section-number">5.4.1</span> Solvers</a></li>
<li><a href="#sec:solvingIpsWithPython"
id="toc-sec:solvingIpsWithPython"><span
class="toc-section-number">5.4.2</span> Solving IPs with Python</a></li>
</ul></li>
<li><a href="#intro-to-complexity" id="toc-intro-to-complexity"><span
class="toc-section-number">5.5</span> Intro to complexity</a>
<ul>
<li><a href="#combinatorial-explosion"
id="toc-combinatorial-explosion"><span
class="toc-section-number">5.5.1</span> Combinatorial explosion</a></li>
<li><a href="#complexity-definitions"
id="toc-complexity-definitions"><span
class="toc-section-number">5.5.2</span> Complexity
â€œdefinitionsâ€</a></li>
<li><a href="#the-classes-mathcalp-and-mathcalnp"
id="toc-the-classes-mathcalp-and-mathcalnp"><span
class="toc-section-number">5.5.3</span> The classes <span
class="math inline">\mathcal{P}</span> and <span
class="math inline">\mathcal{NP}</span></a></li>
<li><a href="#mathcalnp-complete-and-mathcalnp-hard-problems"
id="toc-mathcalnp-complete-and-mathcalnp-hard-problems"><span
class="toc-section-number">5.5.4</span> <span
class="math inline">\mathcal{NP}</span>-complete and <span
class="math inline">\mathcal{NP}</span>-hard problems</a></li>
<li><a href="#what-makes-ips-hard" id="toc-what-makes-ips-hard"><span
class="toc-section-number">5.5.5</span> What makes IPs hard</a></li>
<li><a href="#all-hope-is-not-lost" id="toc-all-hope-is-not-lost"><span
class="toc-section-number">5.5.6</span> All hope is not lost</a></li>
</ul></li>
</ul></li>
<li><a href="#appendix" id="toc-appendix"><span
class="toc-section-number">6</span> Appendix</a>
<ul>
<li><a href="#sec:symbols" id="toc-sec:symbols"><span
class="toc-section-number">6.1</span> Special symbols</a></li>
<li><a href="#sec:linearAlgebra" id="toc-sec:linearAlgebra"><span
class="toc-section-number">6.2</span> Linear algebra review</a>
<ul>
<li><a href="#sec:matrixMath" id="toc-sec:matrixMath"><span
class="toc-section-number">6.2.1</span> Matrix math</a></li>
<li><a href="#properties-of-matrix-operations"
id="toc-properties-of-matrix-operations"><span
class="toc-section-number">6.2.2</span> Properties of matrix
operations</a></li>
<li><a href="#special-matrices" id="toc-special-matrices"><span
class="toc-section-number">6.2.3</span> Special matrices</a></li>
<li><a href="#rank-and-inverse" id="toc-rank-and-inverse"><span
class="toc-section-number">6.2.4</span> Rank and inverse</a></li>
<li><a href="#systems-of-equations" id="toc-systems-of-equations"><span
class="toc-section-number">6.2.5</span> Systems of equations</a></li>
<li><a href="#sec:elementaryRowOperations"
id="toc-sec:elementaryRowOperations"><span
class="toc-section-number">6.2.6</span> Elementary operations</a></li>
</ul></li>
<li><a href="#writing-mathematics-in-a-colab-notebook"
id="toc-writing-mathematics-in-a-colab-notebook"><span
class="toc-section-number">6.3</span> Writing mathematics in a Colab
notebook</a></li>
<li><a href="#sec:badIpModels" id="toc-sec:badIpModels"><span
class="toc-section-number">6.4</span> Examples of bad IP modeling</a>
<ul>
<li><a href="#boolean-algebra" id="toc-boolean-algebra"><span
class="toc-section-number">6.4.1</span> Boolean algebra</a></li>
</ul></li>
<li><a href="#sec:appendixSelectedProofs"
id="toc-sec:appendixSelectedProofs"><span
class="toc-section-number">6.5</span> Selected proofs</a></li>
</ul></li>
</ul>
</nav>
<div id="main">
<h1 data-number="1" id="welcome"><span
class="header-section-number">1</span> Welcome!</h1>
<div class="lectureVideoEmbed"
data-video-id="97611387a9ca4d1bae07842bec132e081d"
data-video-date="2023-08-21">
Going over the syllabus, class/instructor introduction.
</div>
<p>Youâ€™re reading the class notes for <em>IMSE 780: Methods of
Operations Research</em> taught at Kansas State University during the
Fall 2023 semester. This course is intended to give an overview of
Operations Research (OR) at the graduate level. After this course,
students will have a basic familiarity with various OR methodologies and
be able to recognize when the methods can be applied in real-life
scenarios. Students should also be able to apply the chosen methodology
via Python code.</p>
<h2 data-number="1.1" id="course-materials"><span
class="header-section-number">1.1</span> Course materials</h2>
<p>The core of this course will be taught from these notes.
Additionally, I encourage students to use the textbook <em>Introduction
to Operations Research</em> <span class="citation"
data-cites="classText">(<a href="#ref-classText"
role="doc-biblioref">Hillier and Lieberman 2021</a>)</span> as a
reference<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>. The syllabus, assignments, and
other course materials may be found via the <a
href="https://k-state.instructure.com/">class Canvas site</a>. Course
homeworks/assignments may be found <a id='toAssignments'>here</a>.</p>
<h2 data-number="1.2" id="notes-on-these-notes"><span
class="header-section-number">1.2</span> Notes on these notes</h2>
<p>I wrote the notes in this format in an attempt to alleviate all my
past frustrations from reading academic material in all formats. Things
like unlinked references, or links requiring context switches and
without back navigation. Or static elements that could be more effective
if animated or interactive. So I tried to fix some of those issues with
this format.</p>
<p>That means these notes were necessarily made with my desires in mind,
and not yours, the reader trying to learn from them. So Iâ€™d love any
feedback you have on how the notes are presented, or anything you think
I could add to help your learning. I canâ€™t guarantee Iâ€™ll be able to
change much substantial at this point, but at the very least future
iterations of these notes could incorporate your changes and help future
learners.</p>
<p>Also, errors. Iâ€™m trying my best to keep these notes free of typos
and factual errors, but inevitably several will slip through. Iâ€™d be
grateful if you can point these out as you see them. Iâ€™ll even keep a
leaderboard of who has pointed out the most errors, and will have a
prize at the end of the semester for the largest contributors.</p>
<p>I made these notes mostly for consumption on your web browser on a
laptop/desktop computer, or a tablet in landscape orientation. You can
still access them on your phone, of course, and Iâ€™ve tried to style
things such that the content is as usable as possible on a narrow
screen, but your best experience will be on a larger screen. If youâ€™d
like hard copies of these notes, your only option for now is to print
from your browser. With some extra work, I could make pdf versions
available as well, although you will necessarily lose some functionality
in that format. If this is something youâ€™d be interested in, please let
me know.</p>
<p>These notes were created for educational use. With proper
attribution, readers may freely copy, distribute, or produce derivative
work from this content, in whole or in part, for any non-commercial
use.</p>
<h1 data-number="2" id="introduction-to-or"><span
class="header-section-number">2</span> Introduction to OR</h1>
<div class="lectureVideoEmbed"
data-video-id="36726575b4244fecb73986d444ffae771d"
data-video-date="2023-08-23">
Chapter 2, Edelman prize, a little about Python at the end.
</div>
<p>In this section weâ€™ll cover the big picture questions: What is
Operations Research? Where did it come from? What can I do with it? I
hope to impress upon you that OR is a seriously set of tools, and that
it has a huge impact on the world today.</p>
<h2 data-number="2.1" id="what-is-operations-research"><span
class="header-section-number">2.1</span> What is Operations
Research?</h2>
<p>If youâ€™re like me, one of the first things youâ€™ll do when learning a
new subject is look it up on Wikipedia. As of this writing, <a
href="https://en.wikipedia.org/wiki/Operations_research">their page on
Operations Research</a> first defines OR as:</p>
<blockquote>
<p>The discipline that deals with the development and application of
analytical methods to improve decision-making.</p>
</blockquote>
<p>I think this is a good first definition! Continuing on a bit, the
article gets a little more specific:</p>
<blockquote>
<p>Employing techniques from other mathematical sciences, such as
modeling, statistics, and optimization, operations research arrives at
optimal or near-optimal solutions to decision-making problems.</p>
</blockquote>
<p>Right. So the practice of OR involves using mathematical techniques
to find the best decision possible in a given situation (â€œoptimalâ€ is
just fancy way of saying â€œbestâ€<a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a>).</p>
<h2 data-number="2.2" id="example-or-problems"><span
class="header-section-number">2.2</span> Example OR problems</h2>
<p>The above definitions were great, but maybe itâ€™s feeling a little too
abstract at this point. Fair enough. Letâ€™s outline a few common problems
in the OR space.</p>
<h3 data-number="2.2.1" id="sec:tsp"><span
class="header-section-number">2.2.1</span> Traveling Salesman
Problem</h3>
<p>There are many well-known problems in the world of OR, but I reckon
the <a
href="https://en.wikipedia.org/wiki/Travelling_salesman_problem">Traveling
Salesman Problem</a> (TSP) is the best-known and most-loved among them.
The setup is simple: Some old-timey door-to-door salesman is heading out
on the road to sell his product to the masses. He plans to visit a
certain group of cities, and thanks to his trusty atlas he knows the way
between any pair of cities. Less clear, however, is the shortest path
that will lead you through <em>all</em> of the cities, and this is the
aim of the TSP: In which order should you visit the cities such that
your total distance traveled is minimized?</p>
<p>As I said, this a famous problem in the OR space<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. I
think itâ€™s due to the simple, relatable exposition, paired with the fact
that it is actually quite computationally challenging. And yet despite
the challenges, modern methods are able to solve problem instances where
the number of cities is in the 10,000s! The image below shows the
optimal tour through selected cities in the continental US<a href="#fn4"
class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>.</p>
<figure>
<img
src="https://www.math.uwaterloo.ca/tsp/usa50/img/newsweek_medium.jpg"
alt="The shortest tour through 49 US cities (â€œWaterloo TSP,â€ n.d.)" />
<figcaption aria-hidden="true">The shortest tour through 49 US cities
<span class="citation" data-cites="tspPic">(<a href="#ref-tspPic"
role="doc-biblioref"><span>â€œWaterloo TSP,â€</span>
n.d.</a>)</span></figcaption>
</figure>
<h3 data-number="2.2.2" id="job-shop-scheduling"><span
class="header-section-number">2.2.2</span> Job-shop scheduling</h3>
<p>You run a machine shop, and have a certain number of jobs to complete
in a day. Each job requires a certain number of tasks to be done by one
of your many machines, and the tasks are at least partially ordered,
such that you must complete some of the tasks in a certain order. Each
machine can only work on one task at a time. You get to decide the work
schedule, assigning machines to tasks at certain times in the day. What
is the schedule that lets you complete all the jobs in the least amount
of time?</p>
<p>An example: You have a woodworking shop, and today youâ€™re making 20
table, 30 chairs, 15 doors, and 20 bookcases. Each of these jobs
requires some time on your table saw, your mill, and your belt sander.
And the order of operations matters, e.g.Â you have to cut a piece of
wood before you sand the edges. When you begin the day, what job will
you have each of your machines work on? And as they complete those jobs,
which ones should they take up next? How much time can you save with the
right schedule of work?</p>
<h3 data-number="2.2.3" id="portfolio-optimization"><span
class="header-section-number">2.2.3</span> Portfolio optimization</h3>
<p>You have some money to invest, and a list of potential project/assets
to invest in. Youâ€™d like to invest in a way that gives you a high
expected return, but there is risk involved as well. Each project comes
with its own risks, and some projects may be highly correlated such that
failure in one would suggest a high chance of failure in another. How
can you deploy your capital in a way that minimizes downside risk while
still likely generating a good profit?</p>
<h2 data-number="2.3" id="or-in-practice"><span
class="header-section-number">2.3</span> OR in practice</h2>
<p>So weâ€™ve given a few broad classes of OR problems, but these are
still just hypotheticals. Youâ€™d probably like some concrete examples,
instances where OR has been used in the real world, and what the results
were.</p>
<h3 data-number="2.3.1" id="origins-of-or"><span
class="header-section-number">2.3.1</span> Origins of OR</h3>
<p>Weâ€™ll come to the present day soon, but letâ€™s start with a (brief)
history lesson. Most sources trace the beginning of OR back to early
1900s and the two World Wars. This <em>research</em> on military
<em>operations</em> is where the disciplineâ€™s name derives. Hereâ€™s how
<span class="citation" data-cites="classText">Hillier and Lieberman (<a
href="#ref-classText" role="doc-biblioref">2021</a>)</span> explains
it:</p>
<blockquote>
<p>The roots of OR can be traced back many decades, when early attempts
were made to use a scientific approach in the management of
organizations. However, the beginning of the activity called operations
research has generally been attributed to the military services early in
World War II. Because of the war effort, there was an urgent need to
allocate scarce resources to the various military operations and to the
activities within each operation in an effective manner. Therefore, the
British and then the U.S. military management called upon a large number
of scientists to apply a scientific approach to dealing with this and
other strategic and tactical problems. In effect, they were asked to do
<em>research</em> on (military) <em>operations</em>. These teams of
scientists were the first OR teams. By developing effective methods of
using the new tool of radar, these teams were instrumental in winning
the Air Battle of Britain. Through their research on how to better
manage convoy and antisubmarine operations, they also played a major
role in winning the Battle of the North Atlantic. Similar efforts
assisted the Island Campaign in the Pacific.</p>
</blockquote>
<p>After the war, these techniques were adopted by industry as well. As
the sheer scale of organizations began to grow, so did the potential
benefit of the optimized systems brought by OR methodologies. As
techniques and (especially) computing power improved, the types and
scale of problems that were tackled continued to grow. Today almost all
major corporations benefit from OR.</p>
<h3 data-number="2.3.2" id="case-studies"><span
class="header-section-number">2.3.2</span> Case studies</h3>
<p>Your textbook handily comes full of case studies explaining how
companies have used OR to inform their decision-making. Below Iâ€™ve
copied part of the summary table. Check out the book to get more
background on anything that piques your interest.</p>
<figure>
<img src="images/or-case-studies.png"
alt="Selected OR case studies (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Selected OR case studies <span
class="citation" data-cites="classText">(<a href="#ref-classText"
role="doc-biblioref">Hillier and Lieberman 2021</a>)</span></figcaption>
</figure>
<p>Itâ€™s pretty staggering to look at the figures in the â€œAnnual Savingsâ€
column, which taken together sum to the billions. OR is an enormously
valuable tool.</p>
<h3 data-number="2.3.3" id="edelman-prize"><span
class="header-section-number">2.3.3</span> Edelman Prize</h3>
<p>Now, admittedly, some of those case studies are a little stale. But
donâ€™t fret, OR is still relevant in industry today. A great showcase for
the most recent impactful OR work is the annual Edelman Prize, awarded
by the <a href="https://www.informs.org/">Institute for Operations
Research and Management Science (INFORMS)</a>. The winners of this award
were judged to have demonstrated the best application of OR
methodologies in industry. You can take a look at the <a
href="https://3449182.fs1.hubspotusercontent-na1.net/hubfs/3449182/2023_Edelman_Gala_Book.pdf">program
for the 2023 edition of the award</a> and find cases submitted by names
like DHL, Huawei, Lyft, and the winner Walmart.</p>
<h2 data-number="2.4" id="topics-well-cover"><span
class="header-section-number">2.4</span> Topics weâ€™ll cover</h2>
<p>OR is a wide-ranging topic, and as such we canâ€™t cover everything.
Since the class is meant to be an overview, we wonâ€™t get overly deep
into any one topic either<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a>. But we should be able to cover the
basics in a handful of important topics, as well as getting you some
hand-on experience using these methods to solve problems. Iâ€™ve outlined
the planned programming below, but note that we are still early in the
semester, so some of this may be subject to change.</p>
<p>My main goal for this course is for you to be able to apply the
methods we learn. We will accomplish this using various packages written
for the Python programming language. While this is not a programming
course, I realize some of you may have limited (or no) knowledge of the
language, thus Iâ€™ve provided a small unit on the basics. But if you are
a true beginner this may not suffice, and you may need to spend time on
your own to get comfortable with it.</p>
<p>After that, we will jump into the first big success in Operations
Research history, linear programming. Weâ€™ll learn about the basics of
these models, a little history, and a few ways to solve them (with
special emphasis on the simplex method). Weâ€™ll also touch on the theory
of duality and sensitivity analysis.</p>
<p>After linear programming comes its cousin, integer programming. As
far as solving techniques, weâ€™ll focus on branch-and-bound and
branch-and-cut. Since integer programming is so powerful, we will spend
significant time talking about how to model these problems, and how to
set them up and solve them with Python.</p>
<p>Next will be several topics in nonlinear programming where we will
talk about convexity, optimality conditions, and selected solution
procedures.</p>
<p>We will also include a section on Stochastic Processes, where we will
cover topics in Markov chains, queueing theory, and perhaps Markov
Decision Processes.</p>
<p>There are a few other topics on my mind (dynamic programming, network
models) that I may decide to cover depending on time and class
interest.</p>
<h1 data-number="3" id="python-crash-course"><span
class="header-section-number">3</span> Python crash course</h1>
<div class="lectureVideoEmbed"
data-video-id="ec3e6d7c7e5e4e63bc3541c58c8a54c91d"
data-video-date="2023-08-25">
Python basics. The video cut off a bit at the end, but you donâ€™t miss
anything important.
</div>
<p>A main focus of the course is to show you how to model and solve
real-world problems. In order to do that, youâ€™ll need some programming
abilities. <a href="https://www.python.org/">Python</a> is a great
choice for this since it is widely-used and relatively easy to learn.
You may have some experience with Python already, which is great! If
youâ€™ve never used Python before, donâ€™t worry. Weâ€™ll spend a little time
on the basics here, and we wonâ€™t require you to do much out of the
ordinary. Beginners will want to get some more practice outside of
class.</p>
<h2 data-number="3.1" id="google-colab-notebooks"><span
class="header-section-number">3.1</span> Google Colab notebooks</h2>
<p>You can code Python in many different environments, but I think the
easiest way to get started is with <a
href="https://colab.google/">Google Colab</a>. This is a <a
href="https://jupyter.org/">Jupyter</a>-like<a href="#fn6"
class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>
notebook environment that is free to use and requires only a web
browser. Iâ€™ll be using this in class to go through coding examples. Note
that you need a Google account in order to fully use Colab<a href="#fn7"
class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a>.</p>
<p>In Colab (and other notebook environments) code is organized into
cells where related blocks of code are written. You can execute code one
cell at a time to work through the notebook and check outputs as you go.
Iâ€™ll use a Colab notebook in the next section to walk through some
basics of Python.</p>
<h2 data-number="3.2" id="some-python-basics"><span
class="header-section-number">3.2</span> Some Python basics</h2>
<p>Below, you should see a read-only image of a Colab notebook. The
notebook gives some exposition and samples of basic Python principles.
Click the â€œOpen in Colabâ€ button to open a copy in your browser.</p>
<script src="https://gist.github.com/dcd6305c13b79bbdba7c49dc5c76d3c7.js"></script>
<h2 data-number="3.3" id="sec:pythonEnvironments"><span
class="header-section-number">3.3</span> Other coding environments</h2>
<p>I suggest Colab because it is free and easy to set up, and it should
work well for what youâ€™ll need during the course. But it is far from the
only option for Python, and often not the best option depending on your
needs. Here are a few other options to explore on your own:</p>
<h3 data-number="3.3.1" id="local-development"><span
class="header-section-number">3.3.1</span> Local development</h3>
<p>Unlike Colab, where the computing is done on a cloud-based virtual
machine accessed through your web browser, these next few options run
completely on your local machine. Theyâ€™ll all require installing
Python<a href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a> along with other software, but you
wonâ€™t need an internet connection to use them. This is not an exhaustive
list, just tools that Iâ€™ve used and liked.</p>
<ul>
<li><a href="https://jupyter.org/">Jupyter</a>: The first popular
notebook environment for Python. It functions much like Colab does,
though there are minor differences. Several places offer web-hosted
versions of Jupyter too.</li>
<li><a href="https://www.jetbrains.com/pycharm/">Pycharm</a>: Pycharm is
an <a
href="https://en.wikipedia.org/wiki/Integrated_development_environment">IDE</a>
built for Python, and as such comes with support for debugging,
refactoring, run configurations, and more. There is a free version and a
pro version, but the free version has plenty of functionality and is
more than sufficient for the coding in this course.</li>
<li><a href="https://code.visualstudio.com/">Visual Studio Code</a>: VS
Code is a popular, free IDE that supports many different programming
languages. It is highly customizable and there is a broad ecosystem of
extensions that can enhance functionality.</li>
</ul>
<h3 data-number="3.3.2" id="cloud-hosted"><span
class="header-section-number">3.3.2</span> Cloud hosted</h3>
<p>There are several cloud-hosted options available for running Python.
Weâ€™ve already mentioned Colab, and there are myriad other places that
offer cloud-hosted notebooks at varying price points. Offerings that Iâ€™m
familiar with<a href="#fn9" class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a>:</p>
<ul>
<li><a href="https://ide.cloud.google.com">Google Cloud Shell/IDE</a>:
If you have a Google Cloud Platform account, you have access to a
cloud-based virtual machine known as the Google Cloud Shell. The shell
comes with Python and other common developer tools pre-installed, and
you can interact with it using their Cloud IDE, a hosted VS Code-like
environment. The shell runs a pretty small machine, but it is free to
use and you can use the IDE for up to 50 hours per week.</li>
<li><a
href="https://cloud.google.com/vertex-ai/docs/workbench/introduction">Vertex
AI Notebooks</a>: Managed Jupyter notebooks on Google Cloud Platform.
You do have to pay for the service and the associated compute time and
storage. There are similar offerings from <a
href="https://aws.amazon.com/sagemaker/notebooks/">Amazon Web
Services</a> and <a
href="https://learn.microsoft.com/en-us/azure/machine-learning/how-to-run-jupyter-notebooks?view=azureml-api-2">Microsoft
Azure</a></li>
<li><a href="https://www.gitpod.io/">Gitpod</a>: Gitpod is a service
that offers on-demand cloud development environments that are highly
customizable. This one is a little more advanced, and all machine
instances need to be backed by some <a
href="https://git-scm.com/">git</a> repository (e.g.Â on <a
href="https://github.com/">GitHub</a>). So I wouldnâ€™t start here, but
for the right use-case it is a nice service. Their free plan gets you up
to 50 hours per month.</li>
</ul>
<h1 data-number="4" id="linear-programming"><span
class="header-section-number">4</span> Linear programming</h1>
<div class="lectureVideoEmbed"
data-video-id="0b552ccb31c34eab8f6f6d658afd32c61d"
data-video-date="2023-08-28">
Intro to linear programming (sections 4.1-4.3)
</div>
<p>In the family of OR techniques, linear programming (LP) is certainly
the matriarch. It was among the first methods to be seriously studied
and find broad applications. To this day, LPs are relevant and used
across industry to inform decision-making and help best make use of
scarce resources.</p>
<p>So, what is an LP? Letâ€™s step back a bit - linear programming is a
special type of mathematical programming problem. The word
<em>programming</em>, in the language of the pre-computer-revolution era
where these topics were first studied, was more or less a synonym for
<em>planning</em>. So mathematical programming just means using math to
make a plan.</p>
<p>And the linear part? This refers to the form of the mathematical
objects used. All mathematical programs have <em>variables</em>
(quantities you get to set in order to get a desirable result),
<em>constraints</em> (limitations on how you can set your variables),
and an <em>objective</em> (the quantity you want to maximize/minimize).
In linear programming, all constraints and objectives must be
<em>linear</em> functions of your variables. Meaning, you can multiply
the variables by constants and add them together. No higher order terms,
like squaring a variable or multiplying two variables together. Weâ€™ll
see an example in the next section.</p>
<h2 data-number="4.1" id="sec:exampleLp"><span
class="header-section-number">4.1</span> An example LP</h2>
<p>Before we pile up too many definitions, maybe we should see an
example problem where we can get more hands-on. The following comes from
<span class="citation" data-cites="classText">Hillier and Lieberman (<a
href="#ref-classText" role="doc-biblioref">2021</a>)</span>, section
3.1.</p>
<blockquote>
<p>The Wyndor Glass Co.Â produces high-quality glass products, including
windows and glass doors. It has three plants. Aluminum frames and
hardware are made in Plant 1, wood frames are made in Plant 2, and Plant
3 produces the glass and assembles the products. Because of declining
earnings, top management has decided to revamp the companyâ€™s product
line. Unprofitable products are being discontinued, releasing production
capacity to launch two new products having large sales potential:</p>
<ul>
<li>Product 1: An 8-foot glass door with aluminum framing</li>
<li>Product 2: A 4 x 6 foot double-hung wood-framed window</li>
</ul>
<p>Product 1 requires some of the production capacity in Plants 1 and 3,
but none in Plant 2. Product 2 needs only Plants 2 and 3. The marketing
division has concluded that the company could sell as much of either
product as could be produced by these plants. However, because both
products would be competing for the same production capacity in Plant 3,
it is not clear which mix of the two products would be most
profitable.</p>
</blockquote>
<p>Together with management, the companyâ€™s OR team defines the problem
as follows:</p>
<blockquote>
<p>Determine what the production rates should be for the two products in
order to maximize their total profit, subject to the restrictions
imposed by the limited production capacities available in the three
plants. (Each product will be produced in batches of 20, so the
production rate is defined as the number of batches produced per week.)
Any combination of production rates that satisfies these restrictions is
permitted, including producing none of one product and as much as
possible of the other.</p>
</blockquote>
<p>The teamâ€™s next task is to gather data on production runs and
potential profits. The findings are summarized in the table below:</p>
<figure>
<img src="images/lp-example-data.png"
alt="Data for the Wyndor Glass Co.Â problem (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Data for the Wyndor Glass Co.Â problem
<span class="citation" data-cites="classText">(<a href="#ref-classText"
role="doc-biblioref">Hillier and Lieberman 2021</a>)</span></figcaption>
</figure>
<h3 data-number="4.1.1" id="formulating-our-first-lp"><span
class="header-section-number">4.1.1</span> Formulating our first LP</h3>
<p>How do we go about formulating this problem mathematically? We must
first decide on the <em>decision variables</em>, the quantities we get
to choose in order to affect profit. In this case, the variables are the
quantities of Product 1 and Product 2 that we choose to produce. We will
denote these quantities by <span class="math inline">x_1</span> and
<span class="math inline">x_2</span> respectively. That is, <span
class="math inline">x_1</span> is the number of batches of Product 1 we
will produce in a week, and <span class="math inline">x_2</span> is the
number of batches of Product 2 we produce in a week.</p>
<p>Next letâ€™s talk about the problemâ€™s <em>objective function</em>, the
quantity that we are trying to optimize. Naturally, weâ€™d like to
maximize profit. From the table, we know that we get $3,000 in profit
per batch of Product 1 and $5,000 per batch of Product 2. Thus the
formula</p>
<p><span class="math display">
3x_1 + 5x_2
</span></p>
<p>tells us (in thousands of dollars) how much profit we expect for a
given selection of <span class="math inline">x_1</span> and <span
class="math inline">x_2</span>.</p>
<p>Now, we canâ€™t select <span class="math inline">x_1</span> and <span
class="math inline">x_2</span> to be arbitrarily high. We are restricted
by the available production time at each plant. So we will add
<em>constraints</em> relating to these availabilities. We know that each
batch of Product 1 requires 1 hour of time in Plant 1, while Product 2
does not require any time at Plant 1. So, knowing that 4 hours of
production time is available per week, the constraint associated with
production at Plant 1 is simply <span class="math inline">x_1 \leq
4</span>. Similarly, at Plant 2, Product 2 is the only one that requires
processing, at 2 hours per batch. With 12 hours per week available, the
constraint for Plant 2 becomes <span class="math inline">2x_2 \leq
12</span>.<a href="#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a></p>
<p>What about Plant 3? Both products require time at this facility, so
they could both contribute to the depletion of its 18 hours per week.
Every batch of Product 1 requires 3 hours, while every batch of Product
2 requires 2 hours. So the constraint imposed by Plant 3 is simply <span
class="math inline">3x_1 + 2x_2 &lt;= 18</span>.</p>
<p>Lastly, we know that <span class="math inline">x_1</span> and <span
class="math inline">x_2</span> cannot be negative (there is no way to
produce a negative number of products), so <span class="math inline">x_1
\geq 0</span> and <span class="math inline">x_2 \geq 0</span> must be
part of our formulation as well. Bringing it all together, we can write
the problem formulation as:</p>
<p><span id="eq:prototypeLp" class="eqnos"><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq \ \ 4  \\
     &amp;&amp; 2x_2 &amp; \leq 12 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18 \\
     &amp;&amp; x_1,x_2 &amp; \geq \ \ 0
\end{align*}
</span><span class="eqnos-number">(1)</span></span></p>
<h2 data-number="4.2" id="lp-terminology"><span
class="header-section-number">4.2</span> LP terminology</h2>
<p>With this example in hand, letâ€™s get back to some definitions. The
<strong>decision variables</strong> are the quantities weâ€™re deciding
how to set. In our example these are <span
class="math inline">x_1</span> and <span class="math inline">x_2</span>,
the number of batches run per week for the two products. The
<strong>objective</strong> is the value weâ€™d like to optimize, which in
the example is the profit equation <span class="math inline">3x_1 +
5x_2</span>. In this case weâ€™d like to maximize the objective, but
minimization is possible as well. The <strong>constraints</strong> are
the limitations on how we set the decision variables, which in this case
is everything after the â€œs.t.â€<a href="#fn11" class="footnote-ref"
id="fnref11" role="doc-noteref"><sup>11</sup></a>. Notice that the final
constraint, <span class="math inline">x_1,x_2\geq0</span>, is really two
constraints so this is abusing notation a bit. But these types of
constraints (called <strong>variable bound</strong> constraints, or in
this case <em>non-negativity</em> constraints since they restrict
variables to <span class="math inline">\geq0</span>) are often treated
separately in solution techniques, so it is common to see them grouped
or written slightly differently like this. We call the rest of the
constraints the <strong>functional constraints</strong>.</p>
<p>A <strong>solution</strong> to an LP is any specification of values
for the decision variables. And I do mean <em>any</em><a href="#fn12"
class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>,
it doesnâ€™t matter if the values imply a good objective value or even if
they satisfy the constraints. They are still called a solution. Hence
each of:</p>
<ul>
<li><span class="math inline">x_1=0, x_2=0</span></li>
<li><span class="math inline">x_1=-20, x_2=6</span></li>
<li><span class="math inline">x_1=2, x_2=3</span></li>
</ul>
<p>are all solutions to our sample problem, even though the second one
violates non-negativity.</p>
<p>A <strong>feasible solution</strong> is a solution that satisfies all
of the problem constraints. In contrast, an <strong>infeasible
solution</strong> is one that violates <em>at least one</em> constraint.
The <strong>feasible region</strong> is the set of all feasible
solutions. It is possible for a problem to have no feasible solutions,
in which case the problem itself is said to be
<strong>infeasible</strong>.</p>
<p>When solving an LP, the goal is to find an <strong>optimal
solution</strong>, a feasible solution that gives the most favorable
value<a href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a> of the objective function. Notice
we said <em>an</em> optimal solution, not <em>the</em> optimal solution,
as it is entirely possible for a problem to have more than one solution
attain the optimal value. It is also possible to have no optimal
solutions at all, as in the case of an infeasible problem. Another
situation with no optimal solution is an <strong>unbounded</strong>
problem, where the objective value can become arbitrarily favorable.</p>
<h2 data-number="4.3" id="sec:lpVisualized"><span
class="header-section-number">4.3</span> LP visualized</h2>
<p>Letâ€™s get hands-on again to see our new definitions in action. Since
our sample problem includes only two decision variables, we can
visualize whatâ€™s going on in a plot:</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;choosePoints&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Here we have a plot with <span class="math inline">x_1</span> on the
horizontal axis, <span class="math inline">x_2</span> on the vertical
axis, and a line drawn for each <strong>constraint boundary</strong>
(the line that forms the boundary of what is permitted by the
corresponding constraint) for the constraints of eq.Â <a
href="#eq:prototypeLp">1</a>. Moreover, if you hover over a constraint
boundary, the side of the line satisfied by the inequality is shaded
light gray<a href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a>. The feasible region is the portion
of the plot where all the constraints are satisfied, and it is plainly
visible as the gray-shaded region in the bottom-left. Such an
intersection of linear inequalities is called a
<strong>polyhedron</strong>, and in cases such as this where the
polyhedron is bounded (i.e.Â doesnâ€™t go off to infinity in some
direction) we also call it a <strong>polytope</strong>.</p>
<p>If you click on the plot (or enter values in the text boxes) a
solution will be drawn. If the point is a feasible solution, it will be
colored black and the objective value at the solution is show below the
plot. Otherwise the solution is infeasible, the point will be colored
red, and the violated inequalities will flash.</p>
<p>How can we visualize the objective? Since the objective is given by
<span class="math inline">3x_1 + 5x_2</span>, any line we draw of the
form <span class="math inline">3x_1 + 5x_2 = Z</span> (for some number
<span class="math inline">Z</span>) will show the solutions that give
objective value <span class="math inline">Z</span>. You can try this
with the plot below: put your chosen <span class="math inline">Z</span>
value in the input box (or click on the plot to get a line going through
that point). The line will show up on the plot, and the intersection
with the feasible region (if any exists) will be highlighted. These
highlighted solutions each give objective value <span
class="math inline">Z</span>.</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;chooseObjVals&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<h3 data-number="4.3.1" id="solving-an-lp-visually"><span
class="header-section-number">4.3.1</span> Solving an LP visually</h3>
<p>We actually have the tools to solve this problem now. For problems in
two dimensions, it is fairly straightforward to draw a graph and see
where the best solution is. This is not a good (or usually even
feasible) method in practice, but for a toy problem it can really help
build some intuition.</p>
<p>Letâ€™s look back at the above plot. Since weâ€™re maximizing, weâ€™d like
to choose the largest <span class="math inline">Z</span> such that the
line intersects the feasible region. Letâ€™s start with something too big,
say <span class="math inline">Z=50</span>. When we plot that, we see it
is way too high above the feasible region. So we can start moving it
lower. Maybe go to <span class="math inline">Z=40</span>. Itâ€™s still
completely above the feasible region, so thatâ€™s not it either. Now jump
to <span class="math inline">Z=30</span>. This intersects the plot, but
there is a section of the feasible region above the line, and hence
feasible solutions with a better objective value.</p>
<p>So keep searching. When you come to <span
class="math inline">Z=36</span> the situation looks different. The line
intersects the plot at a single point, <span class="math inline">x_1=2,
x_2=6</span>. If you move the objective up just a little bit, say to
36.1, you get no intersection with the feasible region<a href="#fn15"
class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>.
Thus we know weâ€™ve found the optimal solution<a href="#fn16"
class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>,
and in this case it is unique.</p>
<h3 data-number="4.3.2" id="visualizing-other-scenarios"><span
class="header-section-number">4.3.2</span> Visualizing other
scenarios</h3>
<p>Let see some examples of the other scenarios we defined above. In
each case, weâ€™ll take our initial model eq.Â <a
href="#eq:prototypeLp">1</a> and modify it to show the desired
property.</p>
<h4>
An infeasible problem
</h4>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;addConstraints&quot;: [[[1, 3, 30, &quot;g&quot;], [5, 9.25]]], &quot;choosePoints&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>In this plot, weâ€™ve added the constraint <span
class="math inline">x_1 + 3x_2 \geq 30</span>. All the points satisfying
this inequality are well above the previous feasible region, so no
solutions are feasible.</p>
<h4>
An unbounded problem
</h4>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;removeConstraints&quot;: [0, 1], &quot;altFeasRegionTextPlace&quot;: [4.5, 3.5], &quot;chooseObjVals&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Here weâ€™ve removed two constraints, with the only one remaining being
<span class="math inline">2x_2 &lt;= 12</span>. We can see there is no
constraint on <span class="math inline">x_1</span> at all now, so we can
choose it arbitrarily large and still be in the feasible region<a
href="#fn17" class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a>.</p>
<h4>
Multiple optima
</h4>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;altObj&quot;: [6, 4], &quot;chooseObjVals&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>In this example, weâ€™ve altered the objective function to <span
class="math inline">6x_1 + 4x_2</span> so that it has the same slope as
one of our constraints. We can see by moving the objective up and down
that the optimal solution comes at <span
class="math inline">Z=36</span>, where the objective line intersects an
entire face (bounding line) of the feasible region. Since any point on
that bounding line attains the optimal objective value, they are all
optimal solutions.</p>
<h2 data-number="4.4" id="sec:lpSoftware"><span
class="header-section-number">4.4</span> Solving LPs with software</h2>
<div class="lectureVideoEmbed"
data-video-id="b84d7d439309417aabb870fd25751e001d"
data-video-date="2023-09-01">
Python coding environments (sectionÂ <a
href="#sec:pythonEnvironments">3.3</a>), solving LPs with Python
</div>
<p>Letâ€™s pause briefly now to explain, practically, how LPs can be
solved in the real world. By which I mean: if given an LP in practice,
what would you do to find the answer? Iâ€™m not talking about the theory
behind what LP solving software does (weâ€™ll get the that later), just
how to <em>use</em> the software. This wonâ€™t be a comprehensive
discussion, really just giving you enough to solve our example LP. Weâ€™ll
expand on this discussion some when we get to modeling in the integer
programming section.</p>
<p>There are two key components to solving mathematical programming
problems in practice: the modeling language and the solver.</p>
<h3 data-number="4.4.1" id="modeling-languages"><span
class="header-section-number">4.4.1</span> Modeling languages</h3>
<p>The job of a modeling language is to take a model specification like
eq.Â <a href="#eq:prototypeLp">1</a> and turn it into something the
computer can understand and solve. Some popular modeling languages are
their own standalone software, such as <a
href="https://ampl.com/">AMPL</a> and <a
href="https://www.gams.com/">GAMS</a>. The modeling languages weâ€™ll use
are instead shipped as Python<a href="#fn18" class="footnote-ref"
id="fnref18" role="doc-noteref"><sup>18</sup></a> libraries. Sometimes
these languages are built for use with a single solver, while others try
to be compatible with several different solvers.</p>
<h3 data-number="4.4.2" id="solvers"><span
class="header-section-number">4.4.2</span> Solvers</h3>
<p>The solver is the software that takes the modeled problem and applies
the necessary algorithms to solve it. There are several options here as
well. The best solvers all require paid licenses to use fully for
commercial purposes<a href="#fn19" class="footnote-ref" id="fnref19"
role="doc-noteref"><sup>19</sup></a>. The two biggest names in this
space are <a href="https://www.gurobi.com/">Gurobi</a> and <a
href="https://www.ibm.com/products/ilog-cplex-optimization-studio/cplex-optimizer">CPLEX</a>,
though <a
href="https://www.fico.com/en/products/fico-xpress-optimization">Xpress</a>
and <a href="https://www.shanshu.ai/copt/">COPT</a> are competitive as
well. There are also free, open-source options, but these generally
perform much worse than the commercial offerings. Some names in this
space are <a href="https://www.coin-or.org/">COIN-OR</a>, <a
href="https://www.gnu.org/software/glpk/">GLPK</a>, and <a
href="https://scipopt.org/">SCIP</a>.</p>
<h3 data-number="4.4.3" id="solving-our-lp-with-python"><span
class="header-section-number">4.4.3</span> Solving our LP with
Python</h3>
<p>In the following notebook, I show how we can model and solve our
sample LP in two different ways. The first way uses Gurobi as the solver
and its purpose-built Python library <code>gurobipy</code> as the
modeler. I should mention that since Gurobi is a commercial solver, we
need some sort of license for unrestricted use. However, we do get a
limited license automatically with the install of <code>gurobipy</code>
which is good for problems with up to 2000 variables and 2000 linear
constraints. This is pretty limiting for practical industry use, but
most everything weâ€™ll do in this class will fall comfortably within
those bounds.</p>
<p>The second option is a fully open-source option using PuLP, a Python
modeling language maintained by COIN-OR. By default, this will use
COIN-ORâ€™s linear programming solver CLP to solve the model. However, a
nice feature of PuLP is that it is solver-agnostic. This means that you
can use it to model your problem but switch between any of the popular
solvers (including the commercial ones). This is nice to avoid being
locked-in to a single solver. But it also may be slightly less
performant, or may lack some solver-specific features that come with a
solverâ€™s built-in API.</p>
<script src="https://gist.github.com/9c7e1b589a3efb40590606ba6eed102f.js"></script>
<h3 data-number="4.4.4" id="sec:lpModelDataSep"><span
class="header-section-number">4.4.4</span> Model/data separation</h3>
<p>Our Python models from the last notebook certainly work for the
sample problem, but thatâ€™s about it. The real power of programming comes
when you can write one bit of code that can be applied in a wide range
of contexts.</p>
<p>Our sample LP is in the form of a <em>resource allocation
problem</em>, where the decision is how much to engage in a certain set
of possible activities, while staying within the bounds of the available
resources. Weâ€™d be better off to use Python to set the <em>model
logic</em> for such a problem, leaving placeholders where we can inject
the particular <em>problem data</em> for any given instance. Weâ€™ll do
that in the next notebook.</p>
<script src="https://gist.github.com/0a3d429db92daf96fac2eeb23a3197f7.js"></script>
<h2 data-number="4.5" id="sec:lpForms"><span
class="header-section-number">4.5</span> LP forms</h2>
<div class="lectureVideoEmbed"
data-video-id="d82d2e52c5e74e7283d5b095d5f8a9031d"
data-video-date="2023-08-30">
LP forms, notation, and an intro to simplex
</div>
<p>Weâ€™re <em>almost</em> ready to talk about algorithms for solving LPs,
but first we should make a note on some different forms LPs can take.
Crucially, it will turn out that all the forms we talk about here are,
in a sense, equivalent. Thus no matter the specifics of how an LP is
presented, we know weâ€™ll be able to solve it using the general
methods.</p>
<h3 data-number="4.5.1" id="standard-form"><span
class="header-section-number">4.5.1</span> Standard form</h3>
<p>Our formulation of the sample LP in eq.Â <a
href="#eq:prototypeLp">1</a> is in what is known as <strong>standard
form</strong>. Generally, a linear program with <span
class="math inline">n</span> variables and <span
class="math inline">m</span> constraints is in standard form if it is
written as:</p>
<p><span id="eq:standardFormLp" class="eqnos"><span
class="math display">
\begin{align*}
\text{max}&amp;&amp; c_1x_1 + c_2x_2 + \cdots + c_nx_n &amp;&amp;
&amp;&amp; \\
\text{s.t.}&amp;&amp; a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n
&amp;&amp; \leq &amp;&amp; b_1 \\
     &amp;&amp; a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n &amp;&amp;
\leq &amp;&amp; b_2 \\
     &amp;&amp;                                            &amp;&amp;
\vdots &amp;&amp; \\
     &amp;&amp; a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n &amp;&amp;
\leq &amp;&amp; b_m \\
     &amp;&amp; x_1, x_2, \cdots , x_n &amp;&amp; \geq &amp;&amp; 0
\end{align*}
</span><span class="eqnos-number">(2)</span></span></p>
<p>Where all the <span class="math inline">a</span>, <span
class="math inline">b</span>, and <span class="math inline">c</span>
values (known as the <strong>problem data</strong>) are real numbers.
Our sample problem, and many other practical LP problems, are naturally
formulated like this. But it might at first glance feel a bit limiting.
What if youâ€™d rather minimize instead of maximizing? Or let your
variables take negative values? Weâ€™ll see in the following sections that
such considerations are indeed possible, and we can consider them in the
same framework as standard form problems.</p>
<h3 data-number="4.5.2" id="minimization-problems"><span
class="header-section-number">4.5.2</span> Minimization problems</h3>
<p>What if your optimization problem is a minimization problem and not a
maximization problem? For example, instead of maximizing profit, youâ€™d
like to minimize cost? No worries, it is actually quite straightforward
to convert from minimization to maximization - just turn everything
negative! The minimum cost is the same as the maximum â€œnegative costâ€
<span class="math inline">(-1\cdot\text{cost})</span>. So</p>
<p><span class="math display">
\text{min}\ c_1x_1 + c_2x_2 + \cdots + c_nx_n
</span></p>
<p>is the same as</p>
<p><span class="math display">
\text{max}-c_1x_1 -c_2x_2 - \cdots -c_nx_n.
</span></p>
<p>Since the problem data can be any real number (so, in particular,
negative numbers are fine) this still follows the form of eq.Â <a
href="#eq:standardFormLp">2</a>.</p>
<h3 data-number="4.5.3" id="sec:lpConstraintTransform"><span
class="header-section-number">4.5.3</span> Different constraint
forms</h3>
<p>What if you wanted â€œgreater than or equalâ€ constraints instead of
â€œless than or equalâ€ constraints? This is again another case of a sign
switch since if you take any inequality you can:</p>
<ul>
<li>multiply both sides by -1, and</li>
<li>switch the direction of the inequality</li>
</ul>
<p>to end up with a logically equivalent inequality<a href="#fn20"
class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a>.
Thus any inequality of the form:</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n \geq b_i
</span></p>
<p>can be written as</p>
<p><span class="math display">
-a_{i1}x_1 - a_{i2}x_2 - \cdots - a_{in}x_n \leq -b_i
</span></p>
<p>which brings us back into line with the standard form inequalities in
eq.Â <a href="#eq:standardFormLp">2</a>.</p>
<p>What about equality constraints? That is, constraints of the form</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n = b_i.
</span></p>
<p>Can these be converted into standard form? The answer is yes, but it
comes at the cost of an extra constraint in the formulation. Because
using the above constraint has the same effect as using these two in
combination:</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n \leq b_i \\
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n \geq b_i
</span></p>
<p>Now, that second inequality does not fit in standard form since it is
a â€œ<span class="math inline">\geq</span>â€ constraint, but we already
know how to convert it. So the final standard-form-conforming
formulation is:</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n \leq b_i \\
-a_{i1}x_1 - a_{i2}x_2 - \cdots - a_{in}x_n \leq -b_i
</span></p>
<p>Great, so we can go from equality constraints to inequality
constraints, but what about the other way? That is possible too, but
this time weâ€™ll need to add a <em>variable</em> to the formulation. In
particular, to convert the inequality</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n \leq b_i
</span></p>
<p>to equality form, weâ€™ll add a so-called <strong>slack
variable</strong> <span class="math inline">s_i</span>. Weâ€™ll enforce
<span class="math inline">s_i\geq0</span> and rewrite the constraint
as</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n + s_i = b_i.
</span></p>
<p>This works since, for any selection of the <span
class="math inline">x</span> values that satisfies the inequality, we
can simply select the value of <span class="math inline">s_i</span> as
the difference between <span class="math inline">b_i</span> and the
<span class="math inline">a_{i1}x_1 + a_{i2}x_2 + \cdots +
a_{in}x_n</span>, i.e.Â the <em>slack</em> in the constraint. Going the
other way, any variable selections that satisfy the equality will also
satisfy the inequality since, by rearranging the equality, we get</p>
<p><span class="math display">
a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n = b_i - s_i
</span></p>
<p>and <span class="math inline">s_i</span> is non-negative, so the
left-hand side is less than (or equal to) <span
class="math inline">b_i</span>.</p>
<h3 data-number="4.5.4" id="sec:lpVariableBoundTransform"><span
class="header-section-number">4.5.4</span> Variable bounds</h3>
<p>In the standard form problem, we enforce that all of our variables
are non-negative. But what if we donâ€™t want any explicit bounds on the
variables? Is this a different class of problems? As it turns out, we
can freely switch back and forth between non-negative variables and
these so-called <strong>unrestricted</strong> or <strong>free
variables</strong>.</p>
<p>How do we do the transformations? The first direction is
straightforward; say you have a formulation with non-negative variables
and youâ€™d like to remove the variable bounds. Well, we still have the
functional constraints, where we are allowed to use inequalities. So
weâ€™ll â€œremoveâ€ the variable bound constraint <span
class="math inline">x_j\geq0</span> by creating a new functional
constraint</p>
<p><span class="math display">
a_1x_1 + \cdots + a_jx_j + \cdots + a_nx_n \leq b
</span></p>
<p>where <span class="math inline">b=0</span>, <span
class="math inline">a_j=-1</span>, and all other coefficients equal
<span class="math inline">0</span> (i.e.Â <span
class="math inline">-x_j\leq0\Leftrightarrow x_j\geq 0</span>).</p>
<p>Now the less obvious transformation. Say we have a formulation where
the variable <span class="math inline">x_j</span> is unrestricted. How
do we convert to non-negative variables? One way is to define two more
variables, call them <span class="math inline">w_j</span> and <span
class="math inline">z_j</span>, which will be our new non-negative
variables. What weâ€™ll do is simply replace <span
class="math inline">x_j</span> with <span
class="math inline">w_j-z_j</span>, so that the constraints become</p>
<p><span class="math display">
a_{i1}x_1 + \cdots + a_{ij}w_j - a_{ij}z_j + \cdots + a_{in}x_n \leq b_i
</span></p>
<p>for each <span class="math inline">i</span><a href="#fn21"
class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a>,
and a similar replacement is done in the objective function.</p>
<h3 data-number="4.5.5" id="recap-of-allowed-forms"><span
class="header-section-number">4.5.5</span> Recap of allowed forms</h3>
<p>As a recap: we defined the standard form LP where the objective is
maximized, the functional constraints are <span
class="math inline">\leq</span> inequalities, and variables are
non-negative. But it turns out there are several equivalent ways to
formulate LPs, namely:</p>
<ul>
<li>Objectives can be either minimized or maximized.</li>
<li>Constraints can be in <span class="math inline">\leq</span>, <span
class="math inline">\geq</span>, or <span class="math inline">=</span>
form.</li>
<li>Variables may be bounded or not.</li>
</ul>
<p>Crucially, any of these forms can be transformed into any of the
others, so no matter how we specify a particular LP, any of the results
and techniques we discuss here apply!</p>
<h3 data-number="4.5.6" id="different-notation"><span
class="header-section-number">4.5.6</span> Different notation</h3>
<p>Last up for this section, letâ€™s discuss notation. I donâ€™t know about
you, but I get a little overwhelmed when I look at formulations like
eq.Â <a href="#eq:standardFormLp">2</a>. Thereâ€™s a lot to look at there,
and while I think itâ€™s good initially to see things written in full
detail with simple notation like this, returns begin diminishing
quickly. Especially in a case like this where thereâ€™s a lot of
repetition with minimal changes from line to line.</p>
<p>So, from here on out and where appropriate, Iâ€™ll start using more
concise notation. For example, eq.Â <a href="#eq:standardFormLp">2</a>
can be written more concisely like so:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \sum_{j=1}^n c_jx_j    &amp; \\
\text{s.t.}&amp;&amp; \sum_{j=1}^n a_{ij}x_j &amp; \leq b_i\quad \forall
i\in\{1,...,m\} \\
     &amp;&amp; x_j                    &amp; \geq 0\quad \forall
j\in\{1,...,n\}
\end{align*}
</span></p>
<p>This looks much cleaner to my eyes, and each line communicates
different important information about the formulation. But to benefit
from the compactness, one needs to be familiar with the notation used. I
assume everyone reading this has seen the summation notation <span
class="math inline">\sum</span> before, but some other notation (set
inclusion <span class="math inline">\in</span> and â€œfor allâ€ <span
class="math inline">\forall</span> in particular) may be new. And
sometimes new is intimidating. But fear not! These things get clearer
and clearer the more you see them, and I think the benefit is worth it.
There is a section in the appendix (sectionÂ <a
href="#sec:symbols">6.1</a>) dedicated to special symbols. Beyond that,
if youâ€™re ever confused about something, you can always ask me!</p>
<p>Weâ€™ll see more notation like the above as we formulate more specific
problems, but for much of the theory sections to come I actually much
prefer matrix notation. You should already be familiar with linear
algebra (sectionÂ <a href="#sec:linearAlgebra">6.2</a> in the appendix
gives a brief review), so you should be able to notice how matrix
algebra fits nicely with the formulations weâ€™ve already given. For some
<span class="math inline">m\times n</span> matrix <span
class="math inline">\mathbf{A}</span> and <span
class="math inline">n</span> vector <span
class="math inline">\mathbf{x}</span>, if we multiply them we have:</p>
<p><span class="math display">
\begin{align*}
\mathbf{A}\mathbf{x}&amp;=\begin{bmatrix}
    a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
    a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn} \\
\end{bmatrix}\begin{bmatrix}
    x_1 \\ x_2 \\ \vdots \\ x_n
\end{bmatrix}\\
&amp;=\begin{bmatrix}
    a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n \\
    a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n \\
    \vdots \\
    a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n \\
\end{bmatrix}
\end{align*}
</span></p>
<p>which looks just like the constraint section of the standard form LP
eq.Â <a href="#eq:standardFormLp">2</a>. Due to the conciseness, my
favorite notation for the standard form LP is</p>
<p><span id="eq:standardFormLpMatrix" class="eqnos"><span
class="math display">
\begin{align*}
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}\\
\text{s.t.}&amp;&amp; \mathbf{A}\mathbf{x}&amp;\leq\mathbf{b}\\
     &amp;&amp; \mathbf{x}&amp;\geq\mathbf{0}
\end{align*}
</span><span class="eqnos-number">(3)</span></span></p>
<p>Much nicer on the eyes, right!</p>
<p>Further, you may have noticed that though weâ€™ve devoted significant
time to it already, we havenâ€™t formally defined linear programming yet!
I was waiting for this moment to do so. A <strong>linear
program</strong> is an optimization problem in the form of eq.Â <a
href="#eq:standardFormLpMatrix">3</a>.</p>
<h2 data-number="4.6" id="sec:simplex"><span
class="header-section-number">4.6</span> The simplex method</h2>
<div class="lectureVideoEmbed"
data-video-id="3bffb2e146dc437488375242ef326b511d"
data-video-date="2023-09-06">
Simplex walkthrough. Unfortunately I do some board work in this one but
didnâ€™t switch the recording to focus on the board, so some of that might
be hard to make out.
</div>
<p>Weâ€™re just about ready to talk about LP solving algorithms, and weâ€™re
of course starting with the <strong>simplex method</strong> (also
sometimes called the <strong>simplex algorithm</strong>). Arguably the
most important breakthrough in the history of OR was the development of
the simplex method by George Dantzig<a href="#fn22" class="footnote-ref"
id="fnref22" role="doc-noteref"><sup>22</sup></a> during the late
1940s<a href="#fn23" class="footnote-ref" id="fnref23"
role="doc-noteref"><sup>23</sup></a>. It was perhaps the first practical
algorithm developed for linear programming, and it continues to be the
workhorse in linear and integer programming solvers today<a href="#fn24"
class="footnote-ref" id="fnref24"
role="doc-noteref"><sup>24</sup></a>.</p>
<h3 data-number="4.6.1" id="corner-point-solutions"><span
class="header-section-number">4.6.1</span> Corner-point solutions</h3>
<p>Before we get to the algorithm itself, letâ€™s take a moment to dwell
on some geometric insights the method relies on. Weâ€™ll return to our
sample problem eq.Â <a href="#eq:prototypeLp">1</a> and once again weâ€™ll
graph it below.</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;showVertices&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>This time weâ€™ve also plotted the solutions in the corners of the
feasible region, because they are important to the simplex algorithm. We
call these solutions <strong>corner-point feasible (CPF)
solutions</strong><a href="#fn25" class="footnote-ref" id="fnref25"
role="doc-noteref"><sup>25</sup></a> or <strong>vertices</strong><a
href="#fn26" class="footnote-ref" id="fnref26"
role="doc-noteref"><sup>26</sup></a>, which are feasible solutions that
come at the intersection of two constraint boundaries (in the general
case, for LPs in standard form eq.Â <a href="#eq:standardFormLp">2</a>
with <span class="math inline">n</span> decision variables, the CPF
solutions come at the intersection of <span class="math inline">n</span>
constraints boundaries).</p>
<p>The simplex algorithm makes use of the following key fact of linear
programs:</p>
<div id="thm:cornerPointOpt" class="theorem">
<p>If a linear program has an optimal solution (i.e.Â not unbounded or
infeasible), then it has an optimal solution that is a corner-point
solution.</p>
</div>
<div class="proof" for="thm:cornerPointOpt" data-placement="appendix">
<p>We wonâ€™t actually give a full proof of this theorem, instead weâ€™ll
only consider the case of a standard form LP (eq.Â <a
href="#eq:standardFormLpMatrix">3</a>) with only two decision variables.
Those of you that are familiar with <a
href="https://en.wikipedia.org/wiki/Mathematical_induction">proofs by
induction</a> may be able to see how to generalize this to any number of
variables.</p>
<p>In two dimensions we can visualize this, so letâ€™s continue to use the
sample LP of eq.Â <a href="#eq:prototypeLp">1</a> as our example. Any
feasible solution to a two-dimensional LP must fall under exactly one of
these categories:</p>
<ol type="1">
<li>An interior solution (not on any constraint boundaries).</li>
<li>On a single constraint boundary.</li>
<li>A corner-point feasible (CPF) solution (i.e.Â at the intersection of
two constraint boundaries).</li>
</ol>
<p>What we can show is that for any solution of type 1 or 2, we can find
a CPF solution with equal or greater objective value, and we will
illustrate this in the plot below. To that end, suppose we have some
solutions <span class="math inline">\mathbf{z}</span> on the interior of
the feasible region, and <span class="math inline">\mathbf{y}</span>
that lies on a single constraint boundary.</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;extraPoints&quot;: [[2, 1], [3, 4.5]], &quot;extraLines&quot;: [[2, 1, 3, 1.5, {&quot;style&quot;: &quot;stroke-width:2pt;stroke:black&quot;, &quot;marker-end&quot;: &quot;url(#blackArrowMarker)&quot;}], [3, 4.5, 2.5, 5.25, {&quot;style&quot;: &quot;stroke-width:2pt;stroke:black&quot;, &quot;marker-end&quot;: &quot;url(#blackArrowMarker)&quot;}]], &quot;extraMathText&quot;: [[&quot;y&quot;, 3.25, 5, {&quot;coordToPix&quot;: true}], [&quot;z&quot;, 1.75, 1.75, {&quot;coordToPix&quot;: true}], [&quot;v&quot;, 2, 5.75, {&quot;coordToPix&quot;: true}], [&quot;u&quot;, 3.25, 1.75, {&quot;coordToPix&quot;: true}]]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Let <span class="math inline">\mathbf{v}</span> be a (unit) vector
that points in the same direction as the constraint boundary that <span
class="math inline">\mathbf{y}</span> is on. Let <span
class="math inline">\mathbf{c}</span> be the vector of objective
function coefficients (so in our sample LP we would have <span
class="math inline">\mathbf{c}=\begin{bmatrix}3\\5\end{bmatrix}</span>).
The objective value at solution <span
class="math inline">\mathbf{y}</span> is <span
class="math inline">\mathbf{y}\mathbf{c}</span>. In contrast, if we move
some amount <span class="math inline">\delta</span> from <span
class="math inline">\mathbf{y}</span> along direction <span
class="math inline">\mathbf{v}</span>, the objective value is (due to
distributivity of matrix operations) <span
class="math inline">(\mathbf{y} + \delta\mathbf{v})\mathbf{c}=
\mathbf{y}\mathbf{c}+ \delta\mathbf{v}\mathbf{c}</span>.</p>
<p>If <span class="math inline">\mathbf{v}\mathbf{c}\geq0</span>, then
moving from <span class="math inline">\mathbf{y}</span> along the
constraint boundary in the direction of <span
class="math inline">\mathbf{v}</span> improves the objective value. So
we can continue in that direction until we meet another constraint,
yielding a CPF solution with greater-or-equal objective value than <span
class="math inline">y</span>. If, on the other hand, <span
class="math inline">\mathbf{v}\mathbf{c}&lt;0</span>, then we can move
in the direction of <span class="math inline">-\mathbf{v}</span> to a
CPF solution with greater objective value than <span
class="math inline">\mathbf{y}</span>. So either way, there is some CPF
solution with objective value at least as good as <span
class="math inline">\mathbf{y}</span>.</p>
<p>The proof for the interior point <span
class="math inline">\mathbf{z}</span> is very similar. Select some
direction <span class="math inline">\mathbf{u}</span>, and then travel
from <span class="math inline">\mathbf{z}</span> along directions <span
class="math inline">\mathbf{u}</span> or <span
class="math inline">\mathbf{u}</span> until you hit a constraint
boundary. One of these points will yield an objective value at least as
good as <span class="math inline">\mathbf{z}</span>, and it will be on
either:</p>
<ul>
<li>The intersection of two constraints, in which case weâ€™ve found the
CPF solution with at least as good a value as <span
class="math inline">\mathbf{z}</span>.</li>
<li>A single constraint, in which case we can repeat the procedure shown
above for <span class="math inline">\mathbf{y}</span> to find the CPF
solution.</li>
</ul>
<p>In either case, weâ€™ve found our required CPF solution, thus the proof
is complete.</p>
</div>
<p>Thanks to this theorem<a href="#fn27" class="footnote-ref"
id="fnref27" role="doc-noteref"><sup>27</sup></a> we know that we only
need to check CPF solutions when solving an LP! We make use of this fact
during the simplex method, which only checks CPF solutions. We wonâ€™t
check <em>every</em><a href="#fn28" class="footnote-ref" id="fnref28"
role="doc-noteref"><sup>28</sup></a> CPF solution, though. The key to
simplex is that we jump from one CPF solution to the next while taking
care that each move improves the objective value.</p>
<p>In fact, the set of solutions we can move to in any iteration is
limited to only the solutions that are adjacent to the current solution.
In a standard-form LP with <span class="math inline">n</span> decision
variables, two CPF solutions are <strong>adjacent</strong> if they share
<span class="math inline">n-1</span> constraint boundaries. Recall that
CPF solutions lie at the intersection of <span
class="math inline">n</span> constraint boundaries, so we can also say
that two adjacent CPF solutions share all but one boundary in
common.</p>
<p>We have all the definitions now to describe simplex in a nutshell:
The simplex method solves a linear programming problem by successively
moving from one CPF solution to another, adjacent CPF solution, making
sure each such move improves the objective function, until no such
improvement exists<a href="#fn29" class="footnote-ref" id="fnref29"
role="doc-noteref"><sup>29</sup></a>.</p>
<h3 data-number="4.6.2" id="sec:simplexVisualized"><span
class="header-section-number">4.6.2</span> Simplex visualized</h3>
<p>Now that we have the basic idea, letâ€™s go ahead and walk through the
steps of the simplex algorithm. We wonâ€™t go fully general on our first
time through, though. Letâ€™s again consider our sample problem of eq.Â <a
href="#eq:prototypeLp">1</a>, which weâ€™ve plotted again below. This
time, though, the plot contains some controls that let us step through
the simplex method one iteration at a time. I should stress that the
simplex method does not work <em>exactly</em> like what weâ€™ll talk
through below, but all the intuitions are the same and the exercise is,
I think, a useful one.</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;simplexStart&quot;: [0, 0]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>The first step is to find an initial CPF solution. In our case (and
lots of practical instances too) the solution <span
class="math inline">(0, 0)</span> is a feasible solution, and a corner
point as well. Itâ€™s not a particularly desirable solution in the context
of our problem since it brings us no profit, but we donâ€™t care about
desirability yet.</p>
<p>After initialization, we begin the algorithmâ€™s main loop. First we
have to determine if there are any adjacent CPF solutions with improving
objective value. Recall that an adjacent solution will share <span
class="math inline">n-1</span> constraint boundaries with the current
solution. Since weâ€™re in two dimensions, the adjacent solutions share
one constraint boundary with the current solution. To find the adjacent
solutions, we travel out from <span class="math inline">(0,0)</span>
along the two boundary lines it sits on, which in this case are the two
axes. Thus the two directions we can move in are <span
class="math inline">(1,0)</span> and <span
class="math inline">(0,1)</span>.</p>
<p>How do we know if a solution in any particular direction is improving
the objective value? Letâ€™s consider the direction <span
class="math inline">(1,0)</span>. Since weâ€™re moving from <span
class="math inline">(0,0)</span> to some point in the direction of <span
class="math inline">(1,0)</span>, the resulting solution will look like
<span class="math inline">(0,0) + \alpha(1,0)</span> for some number
<span class="math inline">\alpha</span>. The objective value of any
point <span class="math inline">\mathbf{x}</span> is <span
class="math inline">\mathbf{c}\mathbf{x}</span> where <span
class="math inline">\mathbf{c}</span> is the vector of objective
coefficients (which is <span class="math inline">(3,5)</span> in our
sample problem). So the objective value of <span
class="math inline">(0,0) + \alpha(1,0)</span> is</p>
<p><span class="math display">
([0\ 0] + \alpha[1\ 0])\begin{bmatrix}3\\5\end{bmatrix}
</span></p>
<p>and since matrix multiplication distributes through addition, this is
the same as</p>
<p><span class="math display">
[0\ 0]\begin{bmatrix}3\\5\end{bmatrix} + \alpha[1\
0]\begin{bmatrix}3\\5\end{bmatrix}.
</span></p>
<p>That first term, <span class="math inline">[0\
0]\begin{bmatrix}3\\5\end{bmatrix}</span>, is just the objective value
associated with the current solution <span
class="math inline">(0,0)</span>. So the second term <span
class="math inline">\alpha[1\ 0]\begin{bmatrix}3\\5\end{bmatrix}</span>,
is the <em>improvement</em> associated with the move.</p>
<p>We have two directions in which we can move, <span
class="math inline">(1,0)</span> and <span
class="math inline">(0,1)</span>. To keep things standardized weâ€™ll want
to re-scale our directions to be unit vectors (i.e.Â vectors with length
one), but in this case theyâ€™re already unit vectors. The improvements
associated with unit moves in these directions are <span
class="math inline">[1\ 0]\begin{bmatrix}3\\5\end{bmatrix}=3</span> and
<span class="math inline">[0\
1]\begin{bmatrix}3\\5\end{bmatrix}=5</span>. These are both positive
numbers, and since weâ€™re trying to maximize the objective value, that
means that solutions in either direction are improvements.</p>
<p>All that information is summarized in the table below the plot. The
two directions are listed, as well as the per-unit change in objective
function (under the heading <span class="math inline">\Delta</span> Obj
/ Unit<a href="#fn30" class="footnote-ref" id="fnref30"
role="doc-noteref"><sup>30</sup></a>). Since both directions improve the
objective, you have the option to choose either one using the checkboxes
in the final column.</p>
<p>Letâ€™s go ahead and choose the <span class="math inline">(0,1)</span>
direction, since it gives the highest per-unit objective change<a
href="#fn31" class="footnote-ref" id="fnref31"
role="doc-noteref"><sup>31</sup></a>. Press the forward button on the
plot, and youâ€™ll see it finds the adjacent solution in that direction,
<span class="math inline">(0,6)</span>, and the directions to its
adjacent solutions. But only one of the directions is improving, so we
choose to move in that direction <span class="math inline">(1,0)</span>
to the adjacent CPF solution <span class="math inline">(2,6)</span>. At
this point none of the adjacent directions are improvements, so the
current point is optimal and the algorithm is finished.</p>
<p>One thing to note before we move on: All the information we gather
during an iteration is in some sense â€œlocalâ€ to the current CPF
solution. We compute only the <em>directions</em> to the neighboring
solutions, not the actual solutions themselves. Only once we decide on a
direction do we find the actual CPF solution. This is because finding
the solutions is much more expensive computationally speaking, and weâ€™d
like to defer that step and only compute solutions when necessary. This
isnâ€™t such a big deal on a small, two-dimensional example like this, but
in larger scale instances this saves a good amount of time.</p>
<h3 data-number="4.6.3" id="augmented-form-and-basic-solutions"><span
class="header-section-number">4.6.3</span> Augmented form and basic
solutions</h3>
<p>Weâ€™ll return again to our sample problem from eq.Â <a
href="#eq:prototypeLp">1</a>. The first thing weâ€™ll need to do is change
the form of the problem. While we modeled the sample problem in standard
form eq.Â <a href="#eq:standardFormLpMatrix">3</a>, the simplex method
requires constraints in equality form (along with the non-negative
variables and maximizing the objective). We call this the
<strong>augmented form</strong> linear program, which we write as</p>
<p><span id="eq:augmentedFormLpMatrix" class="eqnos"><span
class="math display">
\begin{align*}
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}\\
\text{s.t.}&amp;&amp; \mathbf{A}\mathbf{x}&amp;=\mathbf{b}\\
     &amp;&amp; \mathbf{x}&amp;\geq\mathbf{0}
\end{align*}
</span><span class="eqnos-number">(4)</span></span></p>
<p>To transform our sample problem into augmented form, weâ€™ll steal a
trick from sectionÂ <a href="#sec:lpConstraintTransform">4.5.3</a>. Weâ€™ll
turn the inequality constraints into equations by adding a slack
variable to each constraint, yielding the following formulation:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 + x_3 &amp; = \ \ 4  \\
     &amp;&amp; 2x_2 + x_4 &amp; = 12 \\
     &amp;&amp; 3x_1 + 2x_2 + x_5 &amp; = 18 \\
     &amp;&amp; x_1,x_2,x_3,x_4,x_5 &amp; \geq \ \ 0
\end{align*}
</span></p>
<p>We call <span class="math inline">x_3</span> the <em>slack
variable</em> for the first constraint because its value in a feasible
solution tells you how far away the solutionâ€™s values for <span
class="math inline">x_1</span> and <span class="math inline">x_2</span>
were from the constraint boundary in eq.Â <a
href="#eq:prototypeLp">1</a>.</p>
<p>Simplex involves lots of matrix manipulations, so letâ€™s rewrite this
in matrix form. Following usual convention, weâ€™ll also add an extra
variable <span class="math inline">Z</span> which is equal to the
problemâ€™s objective value. So in this case, we have</p>
<p><span class="math display">
Z = 3x_1 + 5x_2.
</span></p>
<p>Additionally, weâ€™ll go rogue a bit and neglect writing the
non-negativity constraints. Theyâ€™re still there, but the simplex
algorithm will take care of them implicitly. So in matrix form, our
problem looks like:</p>
<p><span class="math display">
\begin{bmatrix}
1 &amp; -3 &amp; -5 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1  &amp;  0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0  &amp;  2 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 3  &amp;  2 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 4 \\ 12 \\ 18
\end{bmatrix}
</span></p>
<p>Recall in sectionÂ <a href="#sec:simplexVisualized">4.6.2</a> we made
use of <span class="thmRef" for="thm:cornerPointOpt"></span> to solve
the LP, jumping from CPF solution to CPF solution while increasing the
objective value at every step. Weâ€™ll do similar algebraically now, but
instead of a CPF solution (which made sense in the standard-form world
of eq.Â <a href="#eq:standardFormLpMatrix">3</a>) weâ€™ll make use of
<strong>basic feasible (BF) solutions</strong>, the augmented-form
analogue. Indeed, the only real difference between corner-point and
basic solutions is whether or not the slack variables are included.</p>
<p>That said, basic solutions have their own important properties.
Studying the system of equations in the above matrix, we see that we
have 5 variables but only 3 (linearly independent) constraints. As you
may recall from linear algebra class, this means we have 2 <em>degrees
of freedom</em>, and thus two of the variables may be set arbitrarily
while solving the system. In the simplex method, these two variables
will take the value 0. The variables set to 0 are called the
<strong>non-basic variables</strong>. We can then solve the system of
equations to retrieve values for the other 3 variables, which are called
the <strong>basic variables</strong>, and collectively the
<strong>basis</strong>. Together, the values of the basic and non-basic
variables make up a <strong>basic solution</strong>.</p>
<p>The key properties of basic solutions are the following (quoting from
<span class="citation" data-cites="classText">Hillier and Lieberman (<a
href="#ref-classText" role="doc-biblioref">2021</a>)</span>):</p>
<blockquote>
<ul>
<li>Each variable is designated as either a nonbasic variable or a basic
variable.</li>
<li>The number of basic variables equals the number of functional
constraints (now equations). Therefore, the number of nonbasic variables
equals the total number of variables minus the number of functional
constraints.</li>
<li>The nonbasic variables are set equal to zero.</li>
<li>The values of the basic variables are obtained as the simultaneous
solution of the system of equations (functional constraints in augmented
form).</li>
<li>If the basic variables satisfy the non-negativity constraints, the
basic solution is a BF solution.</li>
</ul>
</blockquote>
<p>Two BF solutions are said to be <strong>adjacent</strong> if <em>all
but one</em> of their non-basic variables are the same. Note that this
means also that all but one of their basic variables are the same. Also
note that we donâ€™t mean that these basic variables take on the same
<em>values</em>, just that the identity of the variables are the same.
So e.g.Â one basic solution with basic variables <span
class="math inline">x_1, x_2</span> and <span
class="math inline">x_3</span> is adjacent to another solution with
basic variables <span class="math inline">x_1, x_2, x_4</span>, no
matter the values taken by those variables in the respective
solutions.</p>
<h3 data-number="4.6.4" id="sec:simplexExample"><span
class="header-section-number">4.6.4</span> Solving the sample LP with
simplex</h3>
<p>To recap with our new terminology, the goal of the simplex method is
to take an LP in augmented form, and iteratively move from one BF
solution to another, adjacent BF solution while improving the objective
value at every step. Weâ€™ve already converted our sample problem to
augmented form, summarized by the following matrix:</p>
<p><span id="eq:simplexExampleMatrix1" class="eqnos"><span
class="math display">
\begin{bmatrix}
1 &amp; -3 &amp; -5 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1  &amp;  0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0  &amp;  2 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 3  &amp;  2 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 4 \\ 12 \\ 18
\end{bmatrix}
</span><span class="eqnos-number">(5)</span></span></p>
<h4>
Find an initial BF Solution
</h4>
<p>Weâ€™d like to start iterating between adjacent BF solutions, but to do
that we need a BF solution to start with. Weâ€™ll go into more details on
how to find initial BF solutions later in sectionÂ <a
href="#sec:lpOtherConsiderations">4.6.7</a>, but for now letâ€™s notice
that using the slack variables as the initial basis will make this
system very easy to solve. Why? Since <span
class="math inline">x_1</span> and <span class="math inline">x_2</span>
are non-basic, we set their values to 0. Thus the system eq.Â <a
href="#eq:simplexExampleMatrix1">5</a> reduces to:</p>
<p><span class="math display">
\begin{bmatrix}
1 &amp; -3 &amp; -5 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1  &amp;  0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0  &amp;  2 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 3  &amp;  2 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ 0 \\ 0 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 4 \\ 12 \\ 18
\end{bmatrix}
</span></p>
<p>or, equivalently:</p>
<p><span class="math display">
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 4 \\ 12 \\ 18
\end{bmatrix}
</span></p>
<p>So the initial BF solution is <span class="math inline">(x_1, x_2,
x_3, x_4, x_5)</span> = <span class="math inline">(0, 0, 4, 12,
18)</span>, yielding objective value <span
class="math inline">Z=0</span>.</p>
<p>This BF solution was easy to solve for because of how the system was
set up. The portion of the matrix corresponding to the basic variables
was essentially an identity matrix, so we just needed to read the values
off the right-hand side. Indeed, as we move from one BF solution to
another, we will explicitly manipulate the matrix (using basic row
operations, as in sectionÂ <a
href="#sec:elementaryRowOperations">6.2.6</a>) to yield an identity
structure in the basic columns.</p>
<p>But weâ€™re not there yet. We just have an initial BF solution, and
need to figure out how to move to an adjacent one while improving the
objective value. Recall that adjacent solutions share all their basic
variables in common except 1, so the decisions to make are</p>
<ol type="1">
<li>Does an improving solution exist?</li>
<li>If so, which of the current non-basic variables should we move into
the basis?</li>
<li>In light of the last decision, which of the current basic variables
should we remove from the basis?</li>
</ol>
<h4>
Optimality test
</h4>
<p>To decide whether an improving adjacent solution exists, weâ€™ll take a
look at the top row of our matrix eq.Â <a
href="#eq:simplexExampleMatrix1">5</a>, which we set up to track the
objective value <span class="math inline">Z</span>. When multiplied by
the variable vector, that top row currently reads as <span
class="math inline">Z - 3x_1 - 5x_2 = 0</span>, simply a rearranging of
the usual objective <span class="math inline">Z = 3x_1 + 5x_2</span>.
Thus a negative value in the top row indicates that including that
variable in the basis will improve the objective value. Since we have
negative values in the top row, we conclude that the current solution is
not optimal.</p>
<h4>
Determine the incoming variable
</h4>
<p>Since both <span class="math inline">x_1</span> and <span
class="math inline">x_2</span> have negative values in the objective
row, we now have two choices of incoming basic variables that will
improve the objective value. As we did in sectionÂ <a
href="#sec:simplexVisualized">4.6.2</a>, we will choose the variable
that gives the highest such improvement per unit change in the variable,
which in this case is <span class="math inline">x_2</span> (which has a
coefficient of -5 in the top row, vs.Â -3 for <span
class="math inline">x_1</span>).</p>
<h4>
Determine the outgoing variable
</h4>
<p>Weâ€™ve decided that we want <span class="math inline">x_2</span> to
enter the basis, i.e.Â weâ€™d like its value to increase from 0 in the
current solution to some positive value in the next solution. What
effect does increasing <span class="math inline">x_2</span> have on the
constraints? All of the equations are currently satisfied, so changing
the value of <span class="math inline">x_2</span> means that we must
change the values of other variables to compensate. Luckily, the way the
matrix is set up, each constraint has only one basic variable with a
non-zero coefficient. For example, the third row of eq.Â <a
href="#eq:simplexExampleMatrix1">5</a>, when multiplied out, reads:</p>
<p><span class="math display">
2x_2 + x_4 = 12.
</span></p>
<p>Importantly, <span class="math inline">x_4</span> is the only
non-basic variable in this constraint, and this is the <em>only</em>
constraint that <span class="math inline">x_4</span> shows up in (due to
the identity matrix structure in the basic variables). So each unit
increase in <span class="math inline">x_2</span> will require a 2-unit
<em>decrease</em> in <span class="math inline">x_4</span> to balance the
constraint. Since each variable (and so in particular, <span
class="math inline">x_4</span>) must stay non-negative, we can only
increase <span class="math inline">x_2</span> from 0 to 6 and still
remain feasible.</p>
<p>So we carry out this procedure with each constraint in eq.Â <a
href="#eq:simplexExampleMatrix1">5</a> (rows 2-4). <span
class="math inline">x_2</span> has a coefficient of 0 in the second row,
so this constraint will not be violated no matter how much we change
<span class="math inline">x_2</span>. Row four gives the equation <span
class="math inline">x_1 + 2x_2 + x_5 = 18</span>, so again a unit
increase in <span class="math inline">x_2</span> requires a 2-unit
decrease in <span class="math inline">x_5</span>. Since the right-hand
side is 18, we can only increase <span class="math inline">x_2</span> to
9 before <span class="math inline">x_5</span> will go negative.</p>
<p>Letâ€™s summarize what weâ€™ve done now: for each constraint, weâ€™ve
compared the contribution of <span class="math inline">x_2</span> to the
contribution of the corresponding basic variable. We saw above that when
the coefficient on <span class="math inline">x_2</span> is zero for a
given constraint, then changing the value of <span
class="math inline">x_2</span> will not affect that constraint at all.
We didnâ€™t have an example of this, but if the coefficient on <span
class="math inline">x_2</span> were negative then increasing <span
class="math inline">x_2</span> is counteracted by an <em>increase</em>
in the current basic variable. Variables must be non-negative, but there
is no <em>upper</em> bound, so we are free to increase a variable as
much as we want. Thus the only constraints that restrict <span
class="math inline">x_2</span> are the ones where the coefficient on
<span class="math inline">x_2</span> is strictly positive.</p>
<p>So the rows where the <span class="math inline">x_2</span>
coefficient is positive are where we need to worry about the current
basic variable going negative, and where we need to calculate how much
<span class="math inline">x_2</span> can increase before that happens.
You may or may not have noticed, but because of the identity matrix
structure in the basis, all we need to do for this calculation is divide
the right-hand side (rhs) value by the coefficient on <span
class="math inline">x_2</span> in each constraint! Thus our concern is
the following ratios:</p>
<p><span class="math display">
x_2\text{ column: }\begin{bmatrix}0 \\ 2 \\ 2\end{bmatrix}\
\text{ rhs: }\begin{bmatrix}4 \\ 12 \\ 18\end{bmatrix}\
\text{ ratio: }\begin{bmatrix}- \\ 12/2 \\ 18/2\end{bmatrix} =
\begin{bmatrix}- \\ 6 \\ 9\end{bmatrix}
</span></p>
<p>Then the variable leaving the basis should be the one in the
constraint that gives the smallest such ratio (we call this process the
<strong>minimum ratio test</strong>). Why? As we discussed above, the
ratio in each column is the bound on how much we can increase the
entering variable before the basic variable decreases to 0. So we must
take the minimum such increase in order to keep the entire system
feasible. In our case, the minimum ratio comes in the second constraint.
The basic variable included in that constraint is <span
class="math inline">x_4</span>, so we must choose <span
class="math inline">x_4</span> to leave the basis<a href="#fn32"
class="footnote-ref" id="fnref32"
role="doc-noteref"><sup>32</sup></a>.</p>
<h4>
Solve the new system
</h4>
<p>Now that weâ€™ve identified the variables entering and exiting the
basis, what remains is to find the values of the variables at the new
solution. Since <span class="math inline">x_1</span> and <span
class="math inline">x_4</span> are non-basic, their values will be 0. To
find the other values, weâ€™ll essentially do <a
href="https://en.wikipedia.org/wiki/Gaussian_elimination">Gaussian
elimination</a> on the matrix system eq.Â <a
href="#eq:simplexExampleMatrix1">5</a> to yield an identity matrix
structure over the columns corresponding to our basis.</p>
<p>Our basis variable swap came from the modelâ€™s second constraint,
which corresponds to row 3 in the matrix. This will be the â€œidentityâ€
row for the entering variable <span class="math inline">x_2</span>, so
weâ€™ll multiply that row by <span class="math inline">1/2</span> to get a
new matrix:</p>
<p><span class="math display">
\begin{bmatrix}
1 &amp; -3 &amp; -5 &amp; 0 &amp; 0   &amp; 0 \\
0 &amp; 1  &amp;  0 &amp; 1 &amp; 0   &amp; 0 \\
0 &amp; 0  &amp;  1 &amp; 0 &amp; 1/2 &amp; 0 \\
0 &amp; 3  &amp;  2 &amp; 0 &amp; 0   &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 4 \\ 6 \\ 18
\end{bmatrix}
</span></p>
<p>To complete the identity matrix structure, we must change all other
coefficients in the <span class="math inline">x_2</span> column to equal
zero. So weâ€™ll do the following:</p>
<ul>
<li>Multiply the third row by 5 and add it to the first row.</li>
<li>Multiply the third row by -2 and add it to the fourth row.</li>
</ul>
<p>Our new matrix will have the identity structure weâ€™re after:</p>
<p><span id="eq:simplexExampleMatrix2" class="eqnos"><span
class="math display">
\begin{bmatrix}
1 &amp; -3 &amp; 0 &amp; 0 &amp; 5/2 &amp; 0 \\
0 &amp; 1  &amp; 0 &amp; 1 &amp; 0   &amp; 0 \\
0 &amp; 0  &amp; 1 &amp; 0 &amp; 1/2 &amp; 0 \\
0 &amp; 3  &amp; 0 &amp; 0 &amp; -1  &amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
30 \\ 4 \\ 6 \\ 6
\end{bmatrix}
</span><span class="eqnos-number">(6)</span></span></p>
<p>Lastly, as before, we can simply read the values of the objective and
the basic variables from the rhs of the system: <span
class="math inline">Z=30, x_3=4, x_2=6, x_5=6</span>.</p>
<h4>
Keep iterating
</h4>
<p>Weâ€™ve now completed initialization and the first iteration of the
method. So we continue iterating, starting from the optimality testing
phase. In this case, the non-basic variable <span
class="math inline">x_1</span> has a negative coefficient in the top row
of eq.Â <a href="#eq:simplexExampleMatrix2">6</a>, so we do not have on
optimal solution.</p>
<p>The other non-basic variable, <span class="math inline">x_4</span>,
has a positive coefficient in the top row. So <span
class="math inline">x_1</span> is our only candidate for entering the
basis. Now letâ€™s set up our ratio test:</p>
<p><span class="math display">
x_1\text{ column: }\begin{bmatrix}1 \\ 0 \\ 3\end{bmatrix}\
\text{ rhs: }\begin{bmatrix}4 \\ 6 \\ 6\end{bmatrix}\
\text{ ratio: }\begin{bmatrix}4/1 \\ - \\ 6/3\end{bmatrix} =
\begin{bmatrix}4 \\ - \\ 2\end{bmatrix}
</span></p>
<p>Then at most we can increase <span class="math inline">x_1</span> to
2, as going any further will make <span class="math inline">x_5</span>
(the basic variable in the last constraint) negative. So weâ€™ll replace
<span class="math inline">x_5</span> with <span
class="math inline">x_1</span> as the basic variable in the last
constraint. Using elimination to build our identity structure yields the
following matrix:</p>
<p><span id="eq:simplexExampleFinalMatrix" class="eqnos"><span
class="math display">
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 &amp;  3/2 &amp;    1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp;  1/3 &amp; -1/3 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp;  1/2 &amp;    0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; -1/3 &amp;  1/3 \\
\end{bmatrix}
\begin{bmatrix}
Z \\ x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5
\end{bmatrix}
=
\begin{bmatrix}
36 \\ 2 \\ 6 \\ 2
\end{bmatrix}
</span><span class="eqnos-number">(7)</span></span></p>
<p>Thus our new solution is <span class="math inline">x_1=2, x_2=6,
x_3=2, x_4=0</span>, and <span class="math inline">x_5=0</span><a
href="#fn33" class="footnote-ref" id="fnref33"
role="doc-noteref"><sup>33</sup></a>. Since the top row has all positive
coefficients, increasing these variables would only serve to decrease
the objective. So weâ€™ve passed the optimality test, and can terminate
with the optimal solution!</p>
<h3 data-number="4.6.5" id="simplex-in-matrix-notation"><span
class="header-section-number">4.6.5</span> Simplex in matrix
notation</h3>
<div class="lectureVideoEmbed"
data-video-id="aa0f8c8329cd4138a5313757a8f8f1a51d"
data-video-date="2023-09-08">
Simplex with matrices
</div>
<p>Now that we have the mechanics down, letâ€™s tidy up our presentation
of the simplex method by writing out the steps in matrix notation.
Recall that for simplex we need equality constraints and non-negative
variables, so our problem is formulated as in eq.Â <a
href="#eq:augmentedFormLpMatrix">4</a>. Additionally, we will assume
that the <span class="math inline">m\times n</span> matrix <span
class="math inline">A</span> is has rank <span
class="math inline">m</span> and is <em>non-singular</em>, so in
particular <span class="math inline">n\geq m</span> and there are no
<em>redundant</em> constraints (which would be any constraint that is a
linear combination of some of the others). The rank assumption can be
done without loss of generality, because any redundant system can be
reduced to non-redundant by removing constraints<a href="#fn34"
class="footnote-ref" id="fnref34"
role="doc-noteref"><sup>34</sup></a>.</p>
<p>At each step of the simplex method, the matrix calculations required
rely on the sub-matrix of <span class="math inline">\mathbf{A}</span>
corresponding to the basic variables. Letâ€™s recall eq.Â <a
href="#eq:simplexExampleMatrix1">5</a>, the initial set of equations
defining our sample LP when we solved it in sectionÂ <a
href="#sec:simplexExample">4.6.4</a>. In this case, our matrix <span
class="math inline">\mathbf{A}</span> is given by</p>
<p><span class="math display">
\mathbf{A}= \begin{bmatrix}
1  &amp;  0 &amp; 1 &amp; 0 &amp; 0 \\
0  &amp;  2 &amp; 0 &amp; 1 &amp; 0 \\
3  &amp;  2 &amp; 0 &amp; 0 &amp; 1 \\
\end{bmatrix}
</span></p>
<p>The sub-matrix weâ€™re after at any given iteration, which weâ€™ll call
<span class="math inline">\mathbf{B}</span> is the subset of columns
corresponding to our basic variables. Our initial basis in sectionÂ <a
href="#sec:simplexExample">4.6.4</a> was <span
class="math inline">\{x_3, x_4, x_5\}</span>, and so the matrix of
interest in the first iteration was</p>
<p><span class="math display">
\mathbf{B}= \begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \\
\end{bmatrix}
</span>.</p>
<p>The vector of variables <span class="math inline">\mathbf{x}</span>
can similarly be segmented into the parts corresponding to basic
variables, which weâ€™ll call <span
class="math inline">\mathbf{x}_B</span>, and non-basic variables <span
class="math inline">\mathbf{x}_N</span>. So for our example problem at
the first iteration we had:</p>
<p><span class="math display">
\mathbf{x}=\begin{bmatrix}x_1\\x_2\\x_3\\x_4\\x_5\end{bmatrix}\quad\mathbf{x}_B=\begin{bmatrix}x_3\\x_4\\x_5\end{bmatrix}\quad\mathbf{x}_N=\begin{bmatrix}x_1\\x_2\end{bmatrix}
</span></p>
<p>To solve the system of equations at any iteration, we applied
elementary row operations to create an identity matrix in the columns
corresponding to our basis. But since <span
class="math inline">\mathbf{B}</span> is non-singular, it has an inverse
<span class="math inline">\mathbf{B}^{-1}</span> such that <span
class="math inline">\mathbf{B}^{-1}\mathbf{B}=\mathbf{I}</span>, where
<span class="math inline">\mathbf{I}</span> is an identity matrix. So
really, all of our row operations amounted to pre-multiplying the system
of equations by <span class="math inline">\mathbf{B}^{-1}</span>.</p>
<p>Given this, watch what happens when we pre-multiply both sides of our
constraints by <span class="math inline">\mathbf{B}^{-1}</span>:</p>
<div class="mathSmall">
<p><span id="eq:basicVariableValues" class="eqnos"><span
class="math display">
\begin{align*}
\mathbf{A}\mathbf{x}= \mathbf{b}
&amp; \Leftrightarrow \mathbf{B}^{-1}\mathbf{A}\mathbf{x}=
\mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\text{pre-mult by
}\mathbf{B}^{-1}) \\
&amp; \Leftrightarrow
\mathbf{B}^{-1}\mathbf{A}\begin{bmatrix}\mathbf{x}_B\\\mathbf{x}_N\end{bmatrix}
= \mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\text{partition }x\text{
into basic/non-basic}) \\
&amp; \Leftrightarrow
\mathbf{B}^{-1}\mathbf{A}\begin{bmatrix}\mathbf{x}_B\\\mathbf{0}\end{bmatrix}
= \mathbf{B}^{-1}\mathbf{b}&amp;&amp;
\quad(\mathbf{x}_N=\mathbf{0}\text{ in basic solutions}) \\
&amp; \Leftrightarrow \mathbf{B}^{-1}\mathbf{B}\mathbf{x}_B =
\mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\mathbf{x}_N=\mathbf{0}\text{
takes out other columns of }\mathbf{A}) \\
&amp; \Leftrightarrow \mathbf{I}\mathbf{x}_B =
\mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\text{definition of inverse})
\\
&amp; \Leftrightarrow \mathbf{x}_B = \mathbf{B}^{-1}\mathbf{b}&amp;&amp;
\quad(\text{definition of identity})
\end{align*}
</span><span class="eqnos-number">(8)</span></span></p>
</div>
<p>So getting the variable values at a basic solution is as simple as
taking <span class="math inline">\mathbf{x}_N=\mathbf{0}</span> and
<span class="math inline">\mathbf{x}_B=\mathbf{B}^{-1}\mathbf{b}</span>.
If we similarly partition the objective vector <span
class="math inline">\mathbf{c}</span> into <span
class="math inline">\mathbf{c}_B</span> (corresponding to the basic
variables) and <span class="math inline">\mathbf{c}_N</span> (non-basic
variables) then the objective value at that solution is:</p>
<p><span class="math display">
\begin{align*}
\mathbf{c}\mathbf{x}&amp; = \mathbf{c}_B\mathbf{x}_B +
\mathbf{c}_N\mathbf{x}_N &amp;&amp; \\
&amp; = \mathbf{c}_B\mathbf{x}_B &amp;&amp;
\quad(\mathbf{x}_N=\mathbf{0}) \\
&amp; = \mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\text{sub
above value for }\mathbf{x}_B) \\
\end{align*}
</span></p>
<p>So we know how to find the solution for any given basis, but what
about determining entering and exiting variables? In sectionÂ <a
href="#sec:simplexExample">4.6.4</a> we used the information from the
objective (top) row of our problem matrix, so letâ€™s re-introduce that
here. We can summarize all of our problem information in the following
matrix formulation:</p>
<p><span id="eq:simplexMatrixAllInfo" class="eqnos"><span
class="math display">
\begin{bmatrix}
1 &amp; -\mathbf{c}\\
\mathbf{0}&amp; \mathbf{A}
\end{bmatrix}
\begin{bmatrix}
Z \\ \mathbf{x}
\end{bmatrix}
=
\begin{bmatrix}
0 \\ \mathbf{b}
\end{bmatrix}
</span><span class="eqnos-number">(9)</span></span></p>
<p>where once again <span class="math inline">Z</span> is a â€œvariableâ€
representing the objective value. Note that this matches exactly with
eq.Â <a href="#eq:simplexExampleMatrix1">5</a> from sectionÂ <a
href="#sec:simplexExample">4.6.4</a>.</p>
<h4>
The magic matrix
</h4>
<p>We know from linear algebra that any sequence of elementary matrix
operations can be performed simultaneously via matrix multiplication.
All we did during the iterations sectionÂ <a
href="#sec:simplexExample">4.6.4</a> was apply elementary row operations
to the original matrix, so if we can find the correct matrix, recovering
all the relevant information is as simple as multiplying by that matrix.
With that in mind, let me present to you the following matrix<a
href="#fn35" class="footnote-ref" id="fnref35"
role="doc-noteref"><sup>35</sup></a>.</p>
<p><span id="eq:magicMatrix" class="eqnos"><span class="math display">
\begin{bmatrix}1 &amp; \mathbf{c}_B\mathbf{B}^{-1}\\ \mathbf{0}&amp;
\mathbf{B}^{-1}\end{bmatrix}
</span><span class="eqnos-number">(10)</span></span></p>
<p>Watch what happens when we pre-multiply this on the right-hand side
of eq.Â <a href="#eq:simplexMatrixAllInfo">9</a>:</p>
<p><span class="math display">
\begin{bmatrix}1 &amp; \mathbf{c}_B\mathbf{B}^{-1}\\ \mathbf{0}&amp;
\mathbf{B}^{-1}\end{bmatrix}
\begin{bmatrix}
0 \\ \mathbf{b}
\end{bmatrix}
=
\begin{bmatrix}
\mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}\\ \mathbf{B}^{-1}\mathbf{b}
\end{bmatrix}
</span></p>
<p>The top of the result is the objective value <span
class="math inline">Z</span> at the current basis solution, and the
bottom give the values of <span class="math inline">\mathbf{x}_B</span>.
So it looks like eq.Â <a href="#eq:magicMatrix">10</a> is precisely the
matrix we need to encapsulate all the operations we did during a simplex
iteration. Of course, any multiplication we apply on one side of an
equation must also be applied to the other side to keep the system
valid. So letâ€™s apply pre-multiply eq.Â <a href="#eq:magicMatrix">10</a>
on the left-hand side of eq.Â <a href="#eq:simplexMatrixAllInfo">9</a> as
well:</p>
<p><span class="math display">
\begin{bmatrix}1 &amp; \mathbf{c}_B\mathbf{B}^{-1}\\ \mathbf{0}&amp;
\mathbf{B}^{-1}\end{bmatrix}
\begin{bmatrix}
1 &amp; -\mathbf{c}\\
\mathbf{0}&amp; \mathbf{A}
\end{bmatrix}
= \begin{bmatrix}1 &amp; \mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}\\ \mathbf{0}&amp; \mathbf{B}^{-1}\mathbf{A}\end{bmatrix}
</span></p>
<p>So for any given basis, the information we require for the simplex
method is all present in the following system:</p>
<p><span id="eq:simplexMatrixGeneralized" class="eqnos"><span
class="math display">
\begin{bmatrix}1 &amp; \mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}\\ \mathbf{0}&amp; \mathbf{B}^{-1}\mathbf{A}\end{bmatrix}
\begin{bmatrix}Z \\ \mathbf{x}\end{bmatrix}
=
\begin{bmatrix}
\mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}\\ \mathbf{B}^{-1}\mathbf{b}
\end{bmatrix}
</span><span class="eqnos-number">(11)</span></span></p>
<p>The top row coefficients <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}</span> are often called the <strong>reduced costs</strong> of
the variables at the current solution.</p>
<p>Maybe this looks a little messy when seeing it the first time, but
donâ€™t let that scare you! Look at all the constituent elements of this
system. <span class="math inline">\mathbf{A}, \mathbf{b}</span>, and
<span class="math inline">\mathbf{c}</span> are all just
vectors/matrices from the problem definition. The only thing you need to
do from iteration to iteration is choose the basis, invert <span
class="math inline">\mathbf{B}</span> (which is just a sub-matrix of
<span class="math inline">\mathbf{A}</span>), then multiply!</p>
<p>To finish off this section, letâ€™s use Python to verify that the
system we recover from eq.Â <a href="#eq:simplexMatrixGeneralized">11</a>
matches with what we got during the iterations in sectionÂ <a
href="#sec:simplexExample">4.6.4</a>.</p>
<script src="https://gist.github.com/e5817bc5b1eb52dce2737969e0ee0c83.js"></script>
<h3 data-number="4.6.6"
id="presenting-finally-the-simplex-algorithm-mostly"><span
class="header-section-number">4.6.6</span> Presenting (finally) the
simplex algorithm (mostly)</h3>
<p>While we still have some edge cases and gotchas to discuss, we have
what we need to now succinctly specify the core of the simplex
algorithm. Remember, we assume any LP being solved by the simplex method
has been converted (by means of the techniques in sectionÂ <a
href="#sec:lpForms">4.5</a>) to the equality-constrained form of eq.Â <a
href="#eq:augmentedFormLpMatrix">4</a>.</p>
<ul>
<li><em>Initialize</em>: Determine an initial BF solution (weâ€™ll discuss
general methods for this in sectionÂ <a
href="#sec:lpOtherConsiderations">4.6.7</a>).</li>
<li><em>Iterate</em>:
<ul>
<li><em>Test for optimality</em>: Examine the values of <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}</span> (i.e.Â the reduced costs, from the top row of eq.Â <a
href="#eq:simplexMatrixGeneralized">11</a>) corresponding to the
non-basic variables. If all coefficients are non-negative, terminate
with the optimal solution. Otherwise, continue with the iteration.</li>
<li><em>Determine the entering basic variable</em>: Select some variable
whose coefficient in <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}</span> is negative.</li>
<li><em>Determine the exiting basic variable</em>: Suppose the entering
variable from the last step corresponds to the <span
class="math inline">j</span>th column of the original constraint matrix
<span class="math inline">A</span>. Perform the <em>minimum ratio
test</em> from sectionÂ <a href="#sec:simplexExample">4.6.4</a>, dividing
the entries of the vector <span
class="math inline">\mathbf{B}^{-1}\mathbf{b}</span> (the right-hand
side of the constraints portion of eq.Â <a
href="#eq:simplexMatrixGeneralized">11</a>) by the entries in the <span
class="math inline">j</span>th column of <span
class="math inline">\mathbf{B}^{-1}\mathbf{A}</span>. For the exiting
variable, select the basic variable corresponding to the row with the
smallest positive ratio.</li>
</ul></li>
</ul>
<p>And thatâ€™s it!</p>
<h3 data-number="4.6.7" id="sec:lpOtherConsiderations"><span
class="header-section-number">4.6.7</span> Other considerations</h3>
<div class="lectureVideoEmbed"
data-video-id="aa5bd6de00194e58bdfae5570433587c1d"
data-video-date="2023-09-11">
Finishing simplex, starting duality
</div>
<p>Letâ€™s now discuss some implementation details that add slight
complications to the simplex algorithm, and would need to be taken care
of in any LP solving software.</p>
<h4>
Determining the initial BF solution
</h4>
<p>In our sample problem, determining an initial BF solution was simple
because of the slack variables we added to convert the problem to
equality form. But this wonâ€™t always be possible. By way of example,
suppose in our sample LP eq.Â <a href="#eq:prototypeLp">1</a> the problem
requires plant 3 to operate at full capacity. Then the third constraint
becomes an equality constraint, <span class="math inline">3x_1 + 2x_2 =
18</span>. Once slack variables are added to the other constraints, we
have the following formulation:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 + x_3 &amp; = \ \ 4 \\
&amp;&amp; 2x_2 + x_4 &amp; = 12 \\
&amp;&amp; 3x_1 + 2x_2 &amp; = 18 \\
&amp;&amp; x_1,x_2,x_3,x_4 &amp; \geq \ \ 0
\end{align*}
</span></p>
<p>There is no longer a nice identity matrix structure on which to base
our initial BF solution. In this case, a good trick is to add an extra,
so-called <strong>artificial variable</strong> to the formulation.
Additionally, we will add this variable to the objective function with a
<em>huge</em> negative coefficient denoted by <span
class="math inline">M</span>, a trick known as the <strong>Big M
method</strong>. For the above problem, the artificial variable
formulation will look like:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 - M\hat x_5&amp; \\
\text{s.t.}&amp;&amp; x_1 + x_3 &amp; = \ \ 4 \\
&amp;&amp; 2x_2 + x_4 &amp; = 12 \\
&amp;&amp; 3x_1 + 2x_2 + \hat x_5 &amp; = 18 \\
&amp;&amp; x_1,x_2,x_3,x_4,\hat x_5 &amp; \geq \ \ 0
\end{align*}
</span></p>
<p>Note that we require the artificial variable to be non-negative to
conform with eq.Â <a href="#eq:augmentedFormLpMatrix">4</a>, the form
required for simplex. It is further worth noting that the right-hand
side of the constraint needs to be non-negative to keep <span
class="math inline">\hat x_5\geq0</span> in the initial solution. This
is no big deal though, since if the right-hand side were negative we
could simply multiply both sides of the constraint by <span
class="math inline">-1</span> and use the resultant constraint in the
formulation instead.</p>
<p>What good will this do us? We can initialize simplex now with <span
class="math inline">x_3, x_4</span>, and <span class="math inline">\hat
x_5</span> as our original basis. Further, due to the massive penalty to
the objective for including <span class="math inline">\hat x_5</span> in
a solution, the artificial variable will eventually leave the basis if
possible. So we keep running simplex until either:</p>
<ul>
<li><span class="math inline">\hat x_5</span> drops out of the basis, at
which point we can remove it from the problem completely and continue
iterating simplex as usual.</li>
<li>We find an optimal solution to the artificial problem that includes
<span class="math inline">\hat x_5&gt;0</span>, in which case the
original problem was infeasible.</li>
</ul>
<p>Note that in this example we added only one artificial variable, but
it is possible that an artificial variable needs to be added for every
constraint. Either way the method is the same: make sure the right-hand
sides are non-negative, add the artificial variables, and keep iterating
through simplex until the artificial variables are gone.</p>
<h4>
Choosing the entering basic variable
</h4>
<p>We may choose the entering basic variable to be any non-basic
variable with a negative coefficient for <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}</span>. If there are multiple qualifying non-basic variables,
a common rule-of-thumb is to select the variable whose coefficient has
the largest absolute value. This is not guaranteed to be a
<em>better</em> choice than any of the others. But the thinking is,
might as well try the variable that gives you the most bang for your
buck as far as objective value change.</p>
<p>But what if there is a tie for the largest absolute value among
negative coefficients? You can just pick arbitrarily. As we mentioned,
simplex doesnâ€™t really care that the largest absolute value is selected
anyway. So no special tie-breaking rule is required here.</p>
<h4>
Tie for the exiting basic variable
</h4>
<p>We determine the exiting variable based on <em>minimum ratio
test</em>. But what if the minimum ratio is shared between multiple
basic variables? Unlike in the case of the entering basic variable,
there actually <em>is</em> something to worry about in this case.</p>
<p>Letâ€™s recall what the minimum ratio test was calculating. In each
row, we were determining how much we could increase the value of the
entering variable before the corresponding basic variable becomes zero.
A tie in the minimum ratio test would mean that multiple of the current
basic variables would take on a value of 0 when the entering variable
joins the basis. Thus in the next basic solution, at least one basic
variable will have a value of 0. Such a BF solution is called a
<strong>degenerate</strong> solution, and the 0-valued basic variables
are called degenerate variables.</p>
<p>Degeneracy can cause issues for the simplex method. In particular, if
a degenerate basic variable is the exiting variable in a subsequent
simplex iteration, then the entering variable cannot increase in value
from zero without making the degenerate variable take a negative value.
So even with the basis change, the solution stayed the same from one
iteration to the next. Even worse, this could continue in a cycle such
that simplex never stops iterating!</p>
<p>Luckily these looping conditions are exceedingly rare in practical
problems. Furthermore, there are rules for selecting the exiting basic
variable that are guaranteed to avoid this infinite looping scenario
(see e.g. <span class="citation" data-cites="simplexPivotNoLoops">Bland
(<a href="#ref-simplexPivotNoLoops"
role="doc-biblioref">1977</a>)</span>), though we wonâ€™t cover them in
this course.</p>
<h4>
No exiting basic variable
</h4>
<p>Recall that during the minimum ratio test for determining the exiting
basic variable, we only consider ratios in the rows where the
coefficient on the entering variable is strictly positive. This is
because a 0 or negative coefficient would imply that the entering
variable could be increased arbitrarily without violating either the
corresponding constraint or non-negativity for the corresponding basic
variable. If <em>every</em> such coefficient were <span
class="math inline">\leq 0</span>, this would imply that the entire
system remains feasible no matter how much the entering variable is
increased.</p>
<p>Recall that we selected an entering variable whose inclusion would
improve the objective value. But if the entering variable can be
increased indefinitely, then also the objective can be increased
indefinitely, so our problem is unbounded. So if at any point the
simplex method comes to an iteration where the entering variableâ€™s
coefficients are all <span class="math inline">\leq0</span>, we
terminate and declare the problem unbounded.</p>
<h3 data-number="4.6.8" id="the-revised-simplex-method"><span
class="header-section-number">4.6.8</span> The revised simplex
method</h3>
<p>Weâ€™ll end this section on the simplex method with a note on the
so-called <strong>revised simplex method</strong>. Recall that every
iteration of the simplex method requires us to find <span
class="math inline">\mathbf{B}^{-1}</span>, the inverse of the columns
of <span class="math inline">\mathbf{A}</span> corresponding to the
basis variables. In practice, doing this inversion can be
computationally expensive. But it is possible to cut down on the
computation time by applying a nice trick to derive <span
class="math inline">\mathbf{B}^{-1}</span> for the current iteration
from the inverted matrix from the previous iteration. We wonâ€™t bother
with the details here, but you can read about it in <span
class="citation" data-cites="classText">Hillier and Lieberman (<a
href="#ref-classText" role="doc-biblioref">2021</a>)</span>, section
5.4.</p>
<h2 data-number="4.7" id="sec:lpDuality"><span
class="header-section-number">4.7</span> Duality</h2>
<p>In this section weâ€™ll discuss the important concept of LP duality.
This neat bit of theory will allow us to prove the correctness of the
simplex method, and open up avenues to potentially solve LPs faster in
practice. Weâ€™ll also see its fingerprints when discussing
post-optimality analysis in sectionÂ <a href="#sec:lpPostOpt">4.8</a>.
But before we get there, letâ€™s start with some light fiction.</p>
<h3 data-number="4.7.1" id="sec:corporateTakeover"><span
class="header-section-number">4.7.1</span> The corporate takeover</h3>
<p>Suppose you really want to get into the glass manufacturing business.
You figure that Wyndor Glass Co.Â (the company from sectionÂ <a
href="#sec:exampleLp">4.1</a>, where we derived our sample LP eq.Â <a
href="#eq:prototypeLp">1</a>) might be willing to sell you time in their
facilities. But you donâ€™t just want <em>some</em> time, you have big
plans and could really use <em>all</em> their facility time for the next
week. You decide to propose to buy their facility time at a cost of
<span class="math inline">y_i</span> per hour in facility <span
class="math inline">i\in\{1, 2, 3\}</span>. How do you know what price
to propose?</p>
<p>You know a little bit about linear programming now, so you decide to
solve an LP to guide your decision. Naturally, you want to pay the least
amount possible for their facility time. Since the facilities are open
for 4, 12, and 18 hours per week respectively, your objective is to
minimize <span class="math inline">4y_1 + 12y_2 + 18y_3</span>.</p>
<p>But how do you know if Wyndor will accept your offer? At a minimum,
you know that they wonâ€™t accept anything less than $3,000 for an hour at
Plant 1 plus three hours at Plant 3. Why? Youâ€™ve done your homework.
With that time Wyndor can produce a full batch of Product 1 at a profit
of that same $3,000 figure. Similarly, youâ€™ll need to at least $5,000
for two hours each at Plant 2 and Plant 3, to account for their profit
on batches of Product 2. And they certainly wonâ€™t be <em>paying</em> you
to take their valuable facility time, so for each Plant <span
class="math inline">i</span> you must have <span
class="math inline">y_i\geq 0</span>.</p>
<p>Brining it all together, you get this formulation:</p>
<p><span id="eq:prototypeLpDual" class="eqnos"><span
class="math display">
\begin{align*}
\text{min}&amp;&amp; 4y_1 + 12y_2 + 18y_3 &amp; \\
\text{s.t.}&amp;&amp;  y_1 +  3y_3 &amp; \geq 3 \\
     &amp;&amp; 2y_2 +  2y_3 &amp; \geq 5 \\
     &amp;&amp; y_1,y_2,y_3 &amp; \geq 0
\end{align*}
</span><span class="eqnos-number">(12)</span></span></p>
<p>You quickly throw together a Colab notebook to solve this problem.
You know that Wyndor can make $36,000 per week with their resources, so
the difference between that and the optimal solution solution to this LP
is pure profit for you. With visions of riches dancing through your
head, you run the notebook and find the optimal objective value is â€¦</p>
<script src="https://gist.github.com/f5076b20215d0fb98009ba74b83bb930.js"></script>
<p>â€¦ that same $36,000? What an odd coincidence.</p>
<h3 data-number="4.7.2" id="defining-the-dual-lp"><span
class="header-section-number">4.7.2</span> Defining the dual LP</h3>
<div class="lectureVideoEmbed"
data-video-id="ef7be5c2f335464abb0d0b06c1796b761d"
data-video-date="2023-09-13">
Duality redux, plus some post-optimality analysis.
</div>
<p>Actually, this is no coincidence at all. Itâ€™s simply a consequence of
LP duality. For every LP, there is a second, associated LP that relates
to it in a special way. We call the second LP the <strong>dual</strong>
LP, and the original the <strong>primal</strong>. As it turns out, the
problem eq.Â <a href="#eq:prototypeLpDual">12</a> we just formulated is
the dual problem of our original sample LP eq.Â <a
href="#eq:prototypeLp">1</a>.</p>
<p>Letâ€™s look a little closer at the relationship between eq.Â <a
href="#eq:prototypeLp">1</a> and eq.Â <a
href="#eq:prototypeLpDual">12</a>. To make things more obvious, letâ€™s
write them out next to each other in matrix form. Weâ€™ll also rearrange
the order of the data and variable matrices in the dual problem:</p>
<div class="mathSmall">
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \begin{bmatrix}3 &amp;
5\end{bmatrix}\begin{bmatrix}x_1 \\ x_2\end{bmatrix} &amp;
&amp; \quad
\text{min}&amp;&amp; \begin{bmatrix}y_1 &amp; y_2 &amp;
y_3\end{bmatrix}\begin{bmatrix}4 \\ 12 \\ 18\end{bmatrix} &amp;
\\
\text{s.t.} &amp;&amp; \begin{bmatrix}1 &amp; 0 \\ 0 &amp; 2 \\ 3 &amp;
2\end{bmatrix}\begin{bmatrix}x_1 \\ x_2\end{bmatrix} &amp; \leq
\begin{bmatrix}4 \\ 12 \\ 18\end{bmatrix}
&amp; \quad
\text{s.t.} &amp;&amp; \begin{bmatrix}y_1 &amp; y_2 &amp;
y_3\end{bmatrix}\begin{bmatrix}1 &amp; 0 \\ 0 &amp; 2 \\ 3 &amp;
2\end{bmatrix} &amp; \geq \begin{bmatrix}3 &amp; 5\end{bmatrix}
\\
&amp;&amp; x_1,x_2 &amp; \geq 0
&amp; \quad
&amp;&amp; y_1,y_2,y_3 &amp; \geq 0
\end{align*}
</span></p>
</div>
<p>Side-by-side like this, itâ€™s easy to see the connection. The
constraint matrix didnâ€™t change at all, though weâ€™re pre-multiplying the
variables in the dual as opposed to post-multiplying in the primal.
Further, the constraint right-hand side values from the primal became
the objective coefficients in the dual, and vice-versa. Itâ€™s kinda like
the whole problem fell on its side<a href="#fn36" class="footnote-ref"
id="fnref36" role="doc-noteref"><sup>36</sup></a>.</p>
<p>In general, the dual for the standard form LP is defined as
follows:</p>
<p><span id="eq:standardLpDual" class="eqnos"><span
class="math display">
\begin{align*}
&amp;\textbf{primal:}
&amp;&amp;&amp;&amp;&amp;&amp;\quad\textbf{dual:}&amp;&amp;&amp;\\
&amp;\text{max}&amp;&amp; \mathbf{c}\mathbf{x}&amp;
&amp;&amp;&amp;\quad
\text{min}&amp;&amp; \mathbf{y}\mathbf{b}&amp;
\\
&amp;\text{s.t.} &amp;&amp; \mathbf{A}\mathbf{x}\leq\mathbf{b}&amp;
&amp;&amp;&amp;\quad
\text{s.t.} &amp;&amp; \mathbf{y}\mathbf{A}\geq\mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{x}\geq0 &amp;
&amp;&amp;&amp;\quad
&amp;&amp; \mathbf{y}\geq0 &amp;
\end{align*}
</span><span class="eqnos-number">(13)</span></span></p>
<p>But what if your problem is in a different form? Can we still talk
about its dual in the same way? As you might have guessed, there is
indeed a dual problem for your LP no matter how it is stated. The
following gives another primal/dual pair (notice the lack of a
non-negativity requirement for the dual variables):</p>
<p><span id="eq:augmentedLpDual" class="eqnos"><span
class="math display">
\begin{align*}
&amp;\textbf{primal:}
&amp;&amp;&amp;&amp;&amp;&amp;\quad\textbf{dual:}&amp;&amp;&amp;\\
&amp;\text{max}&amp;&amp; \mathbf{c}\mathbf{x}&amp;
&amp;&amp;&amp;\quad
\text{min}&amp;&amp; \mathbf{y}\mathbf{b}&amp;
\\
&amp;\text{s.t.} &amp;&amp; \mathbf{A}\mathbf{x}=\mathbf{b}&amp;
&amp;&amp;&amp;\quad
\text{s.t.} &amp;&amp; \mathbf{y}\mathbf{A}\geq\mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{x}\geq0 &amp;
&amp;&amp;&amp;\quad
&amp;&amp;&amp;
\end{align*}
</span><span class="eqnos-number">(14)</span></span></p>
<div id="thm:dualEqualityForm" class="theorem">
<p>The systems in eq.Â <a href="#eq:augmentedLpDual">14</a> give a valid
primal/dual pair.</p>
</div>
<div class="proof" for="thm:dualEqualityForm" data-placement="appendix">
<p>The concept for this proof is to transform the primal problem from
eq.Â <a href="#eq:augmentedLpDual">14</a> into inequality form so that we
can use the definition of eq.Â <a href="#eq:standardLpDual">13</a> to get
the corresponding dual problem, then see what shakes out. To that end,
letâ€™s use our trick from sectionÂ <a
href="#sec:lpConstraintTransform">4.5.3</a> to convert to inequality
constraints by replacing each <span class="math inline">=</span>
constraint by one <span class="math inline">\leq</span> and one <span
class="math inline">\geq</span> constraint:</p>
<p><span class="math display">
\begin{align*}
&amp;\text{max}&amp;&amp; \mathbf{c}\mathbf{x}&amp;
&amp;&amp;&amp;\quad
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}&amp;
\\
&amp;\text{s.t.} &amp;&amp; \mathbf{A}\mathbf{x}=\mathbf{b}&amp;
&amp;&amp; = \qquad&amp;\quad
\text{s.t.} &amp;&amp;
\begin{bmatrix}\mathbf{A}\\-\mathbf{A}\end{bmatrix}\mathbf{x}\leq
\begin{bmatrix}\mathbf{b}\\-\mathbf{b}\end{bmatrix} &amp;
\\
&amp;&amp;&amp; \mathbf{x}\geq0 &amp;
&amp;&amp;&amp;\quad
&amp;&amp; \mathbf{x}\geq0&amp;
\end{align*}
</span></p>
<p>Now we can use eq.Â <a href="#eq:standardLpDual">13</a> to find the
dual. For reasons that will become clear later, weâ€™ll replace the usual
<span class="math inline">\mathbf{y}</span> variable vector with two
separate vectors <span class="math inline">\mathbf{w}</span> and <span
class="math inline">\mathbf{z}</span>, corresponding to the positive and
negative constraint matrices.</p>
<p><span class="math display">
\begin{align*}
&amp;\text{min}&amp;&amp;
\begin{bmatrix}\mathbf{w}&amp;\mathbf{z}\end{bmatrix}\begin{bmatrix}\mathbf{b}\\-\mathbf{b}\end{bmatrix}
&amp;
\\
&amp;\text{s.t.} &amp;&amp;
\begin{bmatrix}\mathbf{w}&amp;\mathbf{z}\end{bmatrix}\begin{bmatrix}\mathbf{A}\\-\mathbf{A}\end{bmatrix}\geq
\mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{w},\mathbf{z}\geq0 &amp;
\end{align*}
</span></p>
<p>Now, watch what happens when we multiply out the objective: <span
class="math inline">\begin{bmatrix}\mathbf{w}&amp;\mathbf{z}\end{bmatrix}\begin{bmatrix}\mathbf{b}\\-\mathbf{b}\end{bmatrix}
= \mathbf{w}\mathbf{b}- \mathbf{z}\mathbf{b}</span>, and because of the
distributive property of matrix multiplication, we have <span
class="math inline">\mathbf{w}\mathbf{b}- \mathbf{z}\mathbf{b}=
(\mathbf{w}-\mathbf{z})\mathbf{b}</span>. Similar can be done with the
constraints, giving:</p>
<p><span class="math display">
\begin{align*}
&amp;\text{min}&amp;&amp;
\begin{bmatrix}\mathbf{w}&amp;\mathbf{z}\end{bmatrix}\begin{bmatrix}\mathbf{b}\\-\mathbf{b}\end{bmatrix}
&amp;
&amp;&amp;&amp;\quad
\text{min}&amp;&amp; (\mathbf{w}-\mathbf{z})\mathbf{b}&amp;
\\
&amp;\text{s.t.} &amp;&amp;
\begin{bmatrix}\mathbf{w}&amp;\mathbf{z}\end{bmatrix}\begin{bmatrix}\mathbf{A}\\-\mathbf{A}\end{bmatrix}\geq
\mathbf{c}&amp;
&amp;&amp; = \qquad&amp;\quad
\text{s.t.} &amp;&amp; (\mathbf{w}-\mathbf{z})\mathbf{A}\geq
\mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{w},\mathbf{z}\geq0 &amp;
&amp;&amp;&amp;\quad
&amp;&amp; \mathbf{w},\mathbf{z}\geq0 &amp;
\end{align*}
</span></p>
<p>Perhaps this looks familiar. This is exactly the trick we highlighted
in sectionÂ <a href="#sec:lpVariableBoundTransform">4.5.4</a> for
transforming between non-negative variables and unrestricted variables.
We can consider <span class="math inline">\mathbf{w}</span> and <span
class="math inline">\mathbf{z}</span> as the respective â€œpositiveâ€ and
â€œnegativeâ€ parts of some other variable <span
class="math inline">\mathbf{y}</span>. Because <span
class="math inline">\mathbf{w}</span> and <span
class="math inline">\mathbf{z}</span> always appear together in the
formulation as <span class="math inline">\mathbf{w}-\mathbf{z}</span>,
we can replace <span class="math inline">\mathbf{w}-\mathbf{z}</span> by
the unrestricted <span class="math inline">\mathbf{y}</span> and get an
equivalent formulation. So the dual turns into</p>
<p><span class="math display">
\begin{align*}
&amp;\text{min}&amp;&amp; (\mathbf{w}-\mathbf{z})\mathbf{b}&amp;
&amp;&amp;&amp;\quad
\text{min}&amp;&amp; \mathbf{y}\mathbf{b}&amp;
\\
&amp;\text{s.t.} &amp;&amp;
(\mathbf{w}-\mathbf{z})\mathbf{A}\geq\mathbf{c}&amp;
&amp;&amp; = \qquad&amp;\quad
\text{s.t.} &amp;&amp; \mathbf{y}\mathbf{A}\geq \mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{w},\mathbf{z}\geq0 &amp;
&amp;&amp;&amp;\quad
&amp;&amp; &amp;
\end{align*}
</span></p>
<p>which is precisely the dual form from eq.Â <a
href="#eq:augmentedLpDual">14</a>.</p>
</div>
<h3 data-number="4.7.3" id="properties-of-the-dual-lp"><span
class="header-section-number">4.7.3</span> Properties of the dual
LP</h3>
<p>A nice fact about duality is that the primal-dual relationship is
symmetric, i.e.</p>
<div id="thm:dualOfDual" class="theorem">
<p>The dual of the dual problem is equivalent to the primal problem.</p>
</div>
<div class="proof" for="thm:dualOfDual" data-placement="appendix">
<p>The steps required for his proof are encapsulated in the following
diagram:</p>
<div class="mathSmall">
<p><span class="math display">
\begin{align*}
&amp;\text{min}&amp;&amp; \mathbf{y}\mathbf{b}&amp;
&amp;&amp;&amp;
\text{max}&amp;&amp; -\mathbf{y}\mathbf{b}&amp;
\\
&amp;\text{s.t.} &amp;&amp; \mathbf{y}\mathbf{A}\leq\mathbf{c}&amp;
&amp;&amp;\Rightarrow\qquad&amp;
\text{s.t.} &amp;&amp; -\mathbf{y}\mathbf{A}\geq-\mathbf{c}&amp;
\\
&amp;&amp;&amp; \mathbf{y}\geq0 &amp;
&amp;&amp;(\times -1)\quad&amp;
&amp;&amp; \mathbf{y}\geq0 &amp;
\\
\\
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;\Downarrow\text{(dual)}&amp;\\
\\
&amp;\text{max}&amp;&amp; \mathbf{c}\mathbf{x}&amp;
&amp;&amp;&amp;
\text{min}&amp;&amp; -\mathbf{c}\mathbf{x}&amp;
\\
&amp;\text{s.t.} &amp;&amp; \mathbf{A}\mathbf{x}\geq\mathbf{b}&amp;
&amp;&amp;\Leftarrow\qquad&amp;
\text{s.t.} &amp;&amp; -\mathbf{A}\mathbf{x}\leq-\mathbf{b}&amp;
\\
&amp;&amp;&amp; \mathbf{x}\geq0 &amp;
&amp;&amp;(\times -1)\quad&amp;
&amp;&amp; \mathbf{x}\geq0 &amp;
\end{align*}
</span></p>
</div>
<p>The top-left problem is the dual of the standard form LP. We donâ€™t
know how to take its dual correctly, so we should put it in the form of
eq.Â <a href="#eq:standardFormLpMatrix">3</a> since we know what that
dual looks like (eq.Â <a href="#eq:standardLpDual">13</a>). Using our
tricks from sectionÂ <a href="#sec:lpForms">4.5</a>, we multiply the
objective by -1 to convert from minimization to maximization, and we
multiply both sides of the inequalities by <span
class="math inline">-\mathbf{I}</span> to change from <span
class="math inline">\geq</span> constraints to <span
class="math inline">\leq</span> constraints, obtaining the top-right
problem.</p>
<p>We move from the top-right to the bottom-right simply by taking the
dual from eq.Â <a href="#eq:standardLpDual">13</a>. So we switch the
objective function coefficients with the constraint right-hand side,
change from maximization to minimization, and multiply the variables on
the other side of the constraint matrix.</p>
<p>The move from bottom-right to bottom-left is the same as the move
from top-left to top-right, i.e.Â multiplying the objective by -1 and the
constraints by <span class="math inline">-\mathbf{I}</span>. What we end
up with is precisely the original standard-form problem eq.Â <a
href="#eq:standardFormLpMatrix">3</a>.</p>
</div>
<p>The solutions to the primal and dual problems hold a special
relationship too, in that the objective value from one always bounds the
possible objective values for the other:</p>
<div id="thm:weakDuality" class="theorem"
data-display-name="weak duality">
<p>If <span class="math inline">\mathbf{x}</span> is a feasible solution
for the primal problem and <span class="math inline">\mathbf{y}</span>
is a feasible solution for the dual problem, then</p>
<p><span class="math display">
\mathbf{c}\mathbf{x}\leq\mathbf{y}\mathbf{b}.
</span></p>
</div>
<div class="proof" for="thm:weakDuality">
<p>The proof for this is just some simple linear algebra. <span
class="math inline">\mathbf{x}</span> being feasible for the primal
problem means <span
class="math inline">\mathbf{A}\mathbf{x}\leq\mathbf{b}</span>.
Pre-multiplying both sides by <span
class="math inline">\mathbf{y}</span> will give us: <span
class="math display">
\mathbf{A}\mathbf{x}\leq\mathbf{b}
\Leftrightarrow
\mathbf{y}\mathbf{A}\mathbf{x}\leq\mathbf{y}\mathbf{b}.
</span> Note the above wouldnâ€™t necessarily hold if some values of <span
class="math inline">\mathbf{y}</span> were negative, but since <span
class="math inline">\mathbf{y}</span> is feasible for the dual we must
have <span class="math inline">\mathbf{y}\geq0</span>, by definition of
the dual problem.</p>
<p>Similarly, with <span class="math inline">\mathbf{y}</span> being
feasible to the dual, we have <span
class="math inline">\mathbf{y}\mathbf{A}\geq\mathbf{c}</span>.
Post-multiplying both sides by <span
class="math inline">\mathbf{x}</span> (which similarly must be
non-negative) gives: <span class="math display">
\mathbf{y}\mathbf{A}\geq\mathbf{c}
\Leftrightarrow
\mathbf{y}\mathbf{A}\mathbf{x}\geq\mathbf{c}\mathbf{x}.
</span></p>
<p>Combining the two resultant inequalities gives us what we need: <span
class="math display">
\mathbf{c}\mathbf{x}\leq\mathbf{y}\mathbf{A}\mathbf{x}\leq\mathbf{y}\mathbf{b}.
</span></p>
</div>
<p>An immediate corollary<a href="#fn37" class="footnote-ref"
id="fnref37" role="doc-noteref"><sup>37</sup></a> of <span
class="thmRef" for="thm:weakDuality"></span> is the following:</p>
<div id="thm:dualSameValueThenOptimal" class="theorem"
data-thm-type="corollary">
<p>If <span class="math inline">\mathbf{x}</span> is a solution to the
primal problem and <span class="math inline">\mathbf{y}</span> is a
solution to the dual problem such that <span
class="math inline">\mathbf{c}\mathbf{x}=\mathbf{y}\mathbf{b}</span>,
then <span class="math inline">\mathbf{x}</span> and <span
class="math inline">\mathbf{y}</span> are optimal solutions to the
primal and dual problems, respectively.</p>
</div>
<div class="proof" for="thm:dualSameValueThenOptimal">
<p>Since <span class="math inline">\mathbf{y}</span> is feasible for the
dual problem, <span class="thmRef" for="thm:weakDuality"></span> tells
us that no primal solution can have a value higher than <span
class="math inline">\mathbf{y}\mathbf{b}</span>. Then since <span
class="math inline">\mathbf{c}\mathbf{x}=\mathbf{y}\mathbf{b}</span>,
<span class="math inline">\mathbf{x}</span> attains this highest
possible value, thus it is optimal. A similar argument gives that <span
class="math inline">\mathbf{y}</span> is optimal for the dual.</p>
</div>
<p>Among other things, <span class="thmRef"
for="thm:weakDuality"></span> tells us that the problem eq.Â <a
href="#eq:prototypeLpDual">12</a> we formulated in sectionÂ <a
href="#sec:corporateTakeover">4.7.1</a> had no hopes of attaining an
objective value higher than the optimal for eq.Â <a
href="#eq:prototypeLp">1</a>. So 36 was the highest value we could have
hoped for. And it turns out we were actually able to attain that value
in the dual problem. Was this just luck? No, as it turns out, thanks to
the following theorem.</p>
<div id="thm:strongDuality" class="theorem"
data-display-name="strong duality">
<p>If <span class="math inline">\mathbf{x}^*</span> is an optimal
solution for the primal problem and <span
class="math inline">\mathbf{y}^*</span> is an optimal solution for the
dual problem, then</p>
<p><span class="math display">
\mathbf{c}\mathbf{x}^*=\mathbf{y}^*\mathbf{b}.
</span></p>
</div>
<div class="proof" for="thm:strongDuality">
<p>For this proof weâ€™ll make use of the alternate primal/dual
formulation of eq.Â <a href="#eq:augmentedLpDual">14</a> and our
knowledge of the simplex method. By assumption, the primal problem has
an optimal solution <span class="math inline">x^*</span>. Thus in the
final simplex iteration the reduced costs are all non-negative. That is,
for the optimal basis we have <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-
\mathbf{c}\geq0</span> (you may want to check eq.Â <a
href="#eq:simplexMatrixGeneralized">11</a> to refresh your memory on
what the system of equations looks like for a given simplex basis).</p>
<p>Letâ€™s take the vector <span class="math inline">\mathbf{y}</span>
defined as <span
class="math inline">\mathbf{y}=\mathbf{c}_B\mathbf{B}^{-1}</span>.
Subbing that into the above inequality, we have <span
class="math display">
\mathbf{y}\mathbf{A}- \mathbf{c}\geq0 \Leftrightarrow
\mathbf{y}\mathbf{A}\geq\mathbf{c}
</span> which implies that <span class="math inline">\mathbf{y}</span>
is a feasible solution for the dual. Furthermore, noting that <span
class="math inline">\mathbf{x}_B^*=\mathbf{B}^{-1}\mathbf{b}</span> (by
eq.Â <a href="#eq:basicVariableValues">8</a>), we have <span
class="math display">
\begin{align*}
\mathbf{y}\mathbf{b}&amp;=
\mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}&amp;&amp; \quad(\text{definition
of }\mathbf{y}) \\
     &amp;= \mathbf{c}_B\mathbf{x}^*_B &amp;&amp; \quad(\text{above
note}) \\
     &amp;= \mathbf{c}\mathbf{x}^* &amp;&amp; \quad(\mathbf{x}_N =
\mathbf{0}) \\
\end{align*}
</span></p>
<p>So not only is <span class="math inline">\mathbf{y}</span> feasible
for the dual, its objective value in the dual is equivalent to the
objective value for <span class="math inline">\mathbf{x}^*</span> in the
primal. So by <span class="thmRef"
for="thm:dualSameValueThenOptimal"></span> <span
class="math inline">\mathbf{y}^*</span> is an optimal solution for the
dual, and <span class="math inline">\mathbf{x}^*,\mathbf{y}^*</span>
satisfy the condition of the theorem.</p>
</div>
<h3 data-number="4.7.4" id="simplex-and-the-dual-problem"><span
class="header-section-number">4.7.4</span> Simplex and the dual
problem</h3>
<p>Hold on a second - do you see what we did in that last proof? We
proved the theorem, sure, but thereâ€™s more. This proof was constructive,
meaning that we didnâ€™t just prove that the primal and dual optimal
values are equal, we showed how to find <span
class="math inline">\mathbf{y}^*</span> from <span
class="math inline">\mathbf{x}^*</span>. Not only that, but we showed
how to derive <span class="math inline">\mathbf{y}^*</span> <em>using
the simplex method</em>! Simplex gives its own proof of optimality! All
that time setting up the simplex method in sectionÂ <a
href="#sec:simplex">4.6</a> we only gestured at why it works. But now we
have the proof of correctness sitting right in front of us!</p>
<div id="thm:simplexWorks" class="theorem">
<p>Given a linear program with a bounded objective, the simplex method
will terminate at an optimal solution. Moreover, an optimal solution to
the dual problem may be retrieved from the optimal basis via <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}</span>.</p>
</div>
<div class="proof" for="thm:simplexWorks">
<p>Weâ€™ll first note that technically we need to bypass the cycling issue
from degenerate solutions discussed in sectionÂ <a
href="#sec:lpOtherConsiderations">4.6.7</a>. But assuming that is taken
care of, the simplex method terminates at some solution <span
class="math inline">\mathbf{x}^*</span>. Taking the associated basis and
following the steps of the proof to <span class="thmRef"
for="thm:strongDuality"></span>, we obtain a solution <span
class="math inline">\mathbf{y}^*=\mathbf{c}_B\mathbf{B}^{-1}</span> such
that <span class="math inline">\mathbf{y}^*\mathbf{b}=
\mathbf{c}\mathbf{x}^*</span>. Thus by <span class="thmRef"
for="thm:dualSameValueThenOptimal"></span> <span
class="math inline">x^*</span> and <span class="math inline">y^*</span>
are both optimal for their respective problems.</p>
</div>
<p>Also implied by the proof of <span class="thmRef"
for="thm:strongDuality"></span>: Taking <span
class="math inline">\mathbf{y}=\mathbf{c}_B\mathbf{B}^{-1}</span> for
the any basis gives us a solution <span
class="math inline">\mathbf{y}</span> to the dual problem such that
<span class="math inline">\mathbf{y}^*\mathbf{b}=
\mathbf{c}_B\mathbf{x}_B^*</span>. However, due to <span class="thmRef"
for="thm:strongDuality"></span>, we know that no <em>feasible</em>
solution to <span class="math inline">\mathbf{y}</span> can have any
value lower than the optimal <span
class="math inline">\mathbf{c}\mathbf{x}^*</span>. So the <span
class="math inline">\mathbf{y}</span> generated is feasible if and only
if the basis generating it is optimal for the primal problem.</p>
<p>We now know that the simplex method will generate optimal solutions
for <em>both</em> the primal problem <em>and</em> the dual problem. This
gives us an opportunity: what if for some reason we believe simplex will
run faster on the dual problem than it would on the primal problem. As
an example, the number of constraints in a problem is often related to
the number of simplex iterations required to solve it. Since the
constraints in the primal correspond directly to variables in the dual
(and vice-versa) if you have a problem with many more constraints than
variables, it stands to reason that simplex may solve the dual problem
faster than the primal. Since simplex gives solutions to both the primal
and dual problems (and the dual of the dual is the primal), running
simplex on the dual may get us an optimal solution faster.</p>
<p>Another notion worth mentioning is the <strong>dual simplex</strong>
method. We will not discuss it in any detail here,<a href="#fn38"
class="footnote-ref" id="fnref38" role="doc-noteref"><sup>38</sup></a>
but it is an algorithm applied to the primal problem whose steps look as
if it were regular simplex being applied to the dual problem. It can be
useful to have both methods (primal and dual simplex) available when
solving an LP, and most solvers do exactly this.</p>
<h3 data-number="4.7.5"
id="primaldual-feasibilityboundedness-relationships"><span
class="header-section-number">4.7.5</span> Primal/dual
feasibility/boundedness relationships</h3>
<p>To wrap up the duality section, letâ€™s discuss how the feasibility and
boundedness of the primal and dual problems relate to one another. The
possibilities are summarized in the following result:</p>
<div id="thm:primalDualRelations" class="theorem">
<p>The following relationships always hold between the primal LP and its
associated dual:</p>
<ol type="1">
<li>If the primal problem is feasible with a bounded objective, then so
is the dual.</li>
<li>If the primal problem is feasible but with an unbounded objective,
then the dual is infeasible.</li>
<li>If the primal problem is infeasible, then the dual has either no
feasible solutions or an unbounded objective function.</li>
</ol>
</div>
<div class="proof" for="thm:primalDualRelations">
<p>Case 1 follows directly from <span class="thmRef"
for="thm:simplexWorks"></span>. Case 2 is a corollary of weak duality
(<span class="thmRef" for="thm:weakDuality"></span>), since the
existence of a dual solution would immediately bound the primal
objective.</p>
<p>Case 3 can be proven by contradiction using <span class="thmRef"
for="thm:simplexWorks"></span> (and <span class="thmRef"
for="thm:dualOfDual"></span>): Suppose that the dual is neither
infeasible nor unbounded. Then it must be feasible with a bounded
objective, which by <span class="thmRef" for="thm:simplexWorks"></span>
means that applying simplex to this problem will yield an optimal, and
therefore feasible, solution to the primal as well, a contradiction.</p>
</div>
<h2 data-number="4.8" id="sec:lpPostOpt"><span
class="header-section-number">4.8</span> Post-optimality analysis</h2>
<p>After a linear program has been solved, it is often the case that
youâ€™d like to consider separate, but similar scenarios for you problem
of interest. In the case of our example LP eq.Â <a
href="#eq:prototypeLp">1</a>, the company might like to know how much
the solution would change if they could add another hour of production
time to one of their facilities. Additionally, often when a problem is
formulated, the exact data (<span class="math inline">\mathbf{A},
\mathbf{b}, \mathbf{c}</span>) that is used is only an estimate, or
subject to decisions made by upper management. In these cases we might
like to know something about how the objective could change with small
updates to these values. These activities all fall under the heading of
<strong>post-optimality analysis</strong>, and LP theory gives us some
tools for dealing with them.</p>
<h3 data-number="4.8.1" id="sec:lpReopt"><span
class="header-section-number">4.8.1</span> Re-optimization</h3>
<p>In the simplest and most general case, say that weâ€™ve already solved
a very large LP, and for whatever reason we need to make a few tweaks to
the problem and see how the solution changes. One approach to this could
be to re-run simplex from scratch on the new problem. But for very large
LPs, a better approach may be <strong>re-optimization</strong>, which is
essentially a way to â€œstart where you left offâ€ on the previous problem.
The idea is to start from the previous optimal basis and deduce how
changes in the data affect the simplex information from eq.Â <a
href="#eq:simplexMatrixGeneralized">11</a>.</p>
<p>The advantage here is that since the original problem is very similar
to the one being solved now, the new optimal solution is likely to be
â€œnearbyâ€ to the old optimal solution, and thus we can hope that fewer
simplex iterations are needed to complete the re-optimization process
when compared to re-solving the problem from scratch. It is very
possible that, even with the changes, the previous optimal solution is
still optimal for the new problem, which you could know by checking the
newly-calculated reduced costs. Even if the old solution is no longer
optimal, it may still be feasible, allowing you to continue the simplex
algorithm from there. Lastly, even if the old solution is no longer
feasible for the new problem, a few iterations of the <em>dual</em>
simplex algorithm may take you to an optimal solution.</p>
<h3 data-number="4.8.2" id="sec:shadowPrices"><span
class="header-section-number">4.8.2</span> Shadow Prices</h3>
<p>Consider a resource allocation problem, like e.g.Â our sample LP
eq.Â <a href="#eq:prototypeLp">1</a>, where the problem is of the form
eq.Â <a href="#eq:standardFormLpMatrix">3</a> and the constraints denote
how much of each resource is needed for each possible activity. In these
cases, at the optimal basis the reduced costs <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}-\mathbf{c}</span>
corresponding to the slack variable for each constraint denote the
so-called <strong>shadow price</strong> of the associated resource.</p>
<p>Letâ€™s look again eq.Â <a href="#eq:simplexExampleFinalMatrix">7</a>,
which was how our system looked after we completed the simplex method
while solving the sample LP in sectionÂ <a
href="#sec:simplexExample">4.6.4</a>. The final three coefficients in
the top row are the shadow prices of the three resources, i.e.Â an hour
of production capacities at Plants 1, 2, and 3, respectively. Looking at
the system, we see a shadow price of 0 for Plant 1, a price of <span
class="math inline">\frac{3}{2}</span> for Plant 2, and a price of <span
class="math inline">1</span> for Plant 3.</p>
<p>How do we interpret these shadow prices? Letâ€™s consider Plant 3,
whose shadow price is 1. In the context of the final simplex iteration,
that same value 1 was the reduced cost on <span
class="math inline">x_5</span>, the slack variable for the Plant 3
constraint. We interpret that to mean that a small increase in <span
class="math inline">x_5</span> would decrease the objective value by
$1,000 per unit, which is why we decided not to bring <span
class="math inline">x_5</span> into the basis. Since <span
class="math inline">x_5</span> is the <em>slack</em> in the Plant 3
constraint, we can interpret an increase in <span
class="math inline">x_5</span> as <em>taking away</em> capacity from
Plant 3. So we could also interpret that reduced cost as telling us that
taking away capacity from Plant 3 would cost us $1,000 per hour. On the
flip side, this should also mean that <em>increasing</em> capacity at
Plant 3 would be worth and extra $1,000 per hour to us.</p>
<p>This insight is the key to interpreting the shadow price. It is the
amount we would expect the objective to increase if we could gain a
<em>little more</em><a href="#fn39" class="footnote-ref" id="fnref39"
role="doc-noteref"><sup>39</sup></a> of a given resource, and hence also
the maximum <em>price</em> weâ€™d be willing to pay in order to secure
this increase.</p>
<p>So in our sample problem, we should be willing to pay $1,500 for an
extra hour of capacity at Plant 2, and $1,000 for an extra hour at Plant
3. But the shadow price for Plant 1 is 0. Why is that? Well, in the
optimal solution to the sample problem, we only use 2 of the available 4
hours at Plant 1. We already have 2 hours of capacity there that we
arenâ€™t using, so why would we pay anybody for even more?</p>
<p>Another nice interpretation for the shadow price comes from the dual
problem. Recall in sectionÂ <a href="#sec:corporateTakeover">4.7.1</a>
when we formulated our â€œcorporate takeoverâ€ problem eq.Â <a
href="#eq:prototypeLpDual">12</a>, which we later found was actually the
dual to our sample LP. In that formulation, the variables <span
class="math inline">y_1, y_2, y_3</span> represented how much weâ€™d be
willing to pay for time at Wyndorâ€™s three facilities, and when we ran
the notebook in sectionÂ <a href="#sec:corporateTakeover">4.7.1</a> the
optimal values for these variables were again those same values from
above, <span class="math inline">0, \frac{3}{2}</span>, and <span
class="math inline">1</span>. Of course, it should be no surprise that
these are exactly equal to the shadow prices, as weâ€™ve already seen the
connection between the two in the proof to <span class="thmRef"
for="thm:simplexWorks"></span>.</p>
<h3 data-number="4.8.3" id="sec:sensitivityAnalysis"><span
class="header-section-number">4.8.3</span> Sensitivity Analysis</h3>
<div class="lectureVideoEmbed"
data-video-id="02852e5c6cf44834912154ba1636a5851d"
data-video-date="2023-09-15">
Wrapping up sensitivity analysis and LP. Discussed HW2, particularly
question 5. Video cuts off, but you donâ€™t really miss anything.
</div>
<p><strong>Sensitivity analysis</strong> is the process of determining
how small changes in problem data can alter the optimal solution. As
explained in <span class="citation" data-cites="classText">Hillier and
Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span>, section 7.2,</p>
<blockquote>
<p>one assumption of linear programming is that all the parameters of
the model (<span class="math inline">a_{ij}</span>, <span
class="math inline">b_i</span>, and <span
class="math inline">c_j</span>) are known constants. Actually, the
parameter values used in the model normally are just estimates based on
a prediction of future conditions. The data obtained to develop these
estimates often are rather crude or nonexistent, so that the parameters
in the original formulation may represent little more than quick rules
of thumb provided by busy line personnel. The data may even represent
deliberate overestimates or underestimates to protect the interests of
the estimators.</p>
</blockquote>
<p>Thus it is valuable to know if changes in problem data will have
outsized effects on the optimal solution. In this section, weâ€™ll discuss
ways to determine the so-called <em>allowable range</em> for different
values, meaning the values a particular coefficient can take without
changing the optimal solution.</p>
<p>For the sake of brevity, weâ€™ll only carry out this analysis for the
right-hand side values <span class="math inline">b_i</span>. Changes in
other problem data are covered in section 7.2 of <span class="citation"
data-cites="classText">Hillier and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span>.</p>
<h4>
Changing a single rhs value
</h4>
<p>Suppose after running simplex you would like to consider changes to
the right-hand side values, from <span
class="math inline">\mathbf{b}</span> to <span
class="math inline">\mathbf{\hat b}</span>. From eq.Â <a
href="#eq:simplexMatrixGeneralized">11</a>, we know that the values of
<span class="math inline">\mathbf{b}</span> affect only the right-hand
side of the final matrix system. So, in particular, the reduced costs on
all variables will stay the same. Thus if the new right-hand side values
<span class="math inline">\mathbf{B}^{-1}\mathbf{\hat b}</span> are all
non-negative, weâ€™re still at the optimal solution.</p>
<p>Letâ€™s take our the Wyndor Glass problem as an example. sample LP
eq.Â <a href="#eq:prototypeLp">1</a>. <span class="citation"
data-cites="classText">Hillier and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span> gives the following
exposition:</p>
<blockquote>
<p>Sensitivity analysis is begun for the original Wyndor Glass
Co.Â problem by examining the optimal values of the <span
class="math inline">y_i</span> dual variables <span
class="math inline">( y_1^* = 0, y_2^* = \frac{3}{2}, y_3^*=1)</span>.
These shadow prices give the marginal value of each resource <span
class="math inline">i</span> (the available production capacity of Plant
<span class="math inline">i</span>) for the activities (two new
products) under consideration, where marginal value is expressed in the
units of <span class="math inline">Z</span> (thousands of dollars of
profit per week). As discussed previously, the total profit from these
activities can be increased $1,500 per week (<span
class="math inline">y_2^*</span> times $1,000 per week) for each
additional unit of resource 2 (hour of production time per week in Plant
2) that is made available. This increase in profit holds for relatively
small changes that do not affect the feasibility of the current basic
solution (and so do not affect the <span
class="math inline">y_i^*</span> values). Consequently, the OR team has
investigated the marginal profitability from the other current uses of
this resource to determine if any are less than $1,500 per week. This
investigation reveals that one old product is far less profitable. The
production rate for this product already has been reduced to the minimum
amount that would justify its marketing expenses. However, it can be
discontinued altogether, which would provide an additional 12 units of
resource 2 for the new products. Thus, the next step is to determine the
profit that could be obtained from the new products if this shift were
made. This shift changes <span class="math inline">b_2</span> from 12 to
24 in the linear programming model.</p>
</blockquote>
<p>So weâ€™d like to know what happens when we change <span
class="math inline">b_2</span> from 12 to 24. As a first step, letâ€™s
take a look at the plot for this problem with the modified
constraint:</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;chooseObjVals&quot;: true, &quot;yMax&quot;: 14.99, &quot;removeConstraints&quot;: [2], &quot;addConstraints&quot;: [[[0, 2, 24, &quot;l&quot;], [6, 13.1]]]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Compared to our first plot of this problem from sectionÂ <a
href="#sec:lpVisualized">4.3</a>, we see that the bounding line for the
constraint on <span class="math inline">x_2</span> has been moved way
up, such that this constraint does not even touch the feasible region
anymore<a href="#fn40" class="footnote-ref" id="fnref40"
role="doc-noteref"><sup>40</sup></a>. How might this affect the
solution?</p>
<p>Letâ€™s go ahead and calculate the altered right-hand side according to
eq.Â <a href="#eq:simplexMatrixGeneralized">11</a>. Following the
formulas, weâ€™ll get <span class="math display">
Z = \mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}= 54,\qquad \begin{bmatrix}x_3
\\ x_2 \\ x_1\end{bmatrix} = \mathbf{x}_B = \mathbf{B}^{-1}\mathbf{b}=
\begin{bmatrix}6 \\ 12 \\ -2\end{bmatrix}
</span> at our previous optimal basis. For simplex, a negative
right-hand side means a negative value for a basic variable, and thus an
infeasible solution. So our old optimal basis is no longer feasible.</p>
<p>What happened here? In terms of the plots, the original basic
solution came at the intersection of the constraints <span
class="math inline">3x_1 + 2x_2 \leq 18</span> and <span
class="math inline">2x_2 \leq 12</span>. That intersection used to be in
the feasible region, but when the second constraint was changed to <span
class="math inline">2x_2 \leq 24</span> the intersection changed to
somewhere off the plot entirely.</p>
<p>So finding the optimal solution to our new problem requires a change
of basis. Starting from a primal-infeasible basis, the best way to
proceed is an application of the dual simplex method to regain
feasibility<a href="#fn41" class="footnote-ref" id="fnref41"
role="doc-noteref"><sup>41</sup></a>. Doing so would bring us to a new
basis of <span class="math inline">(x_4, x_2, x_3)</span> and a new
optimal solution of <span class="math inline">(x_1, x_2, x_3, x_4, x_5)
= (0, 9, 4, 6, 0)</span>, which has a corresponding objective value of
<span class="math inline">Z=45</span>.</p>
<h4>
Determining the allowable range
</h4>
<p>Letâ€™s recap what weâ€™ve done here. We were considering a change to the
right-hand side values of our LP. Our analysis involved changing the
right-hand side then re-optimizing. We found that increasing <span
class="math inline">b_2</span> by 12 changed our optimal basis and
increased the objective value by 9, from 36 to 45. But wait, the shadow
price on <span class="math inline">b_2</span> in the original model was
<span class="math inline">\frac{3}{2}</span>, so why didnâ€™t we get an
increase of <span class="math inline">9\times\frac{3}{2}=13.5</span>?
And weâ€™re already past the re-optimization section, so why did we run
simplex again?</p>
<p>On the shadow price issue: We mentioned when introducing shadow
prices in sectionÂ <a href="#sec:shadowPrices">4.8.2</a> that they are
only valid <em>locally</em>, i.e.Â they hold from â€œsmallâ€ changes in the
resource, but if changes become too big then all bets are off. But how
big is too big? Weâ€™ll explore that next, and we wonâ€™t even (fully) run
simplex to do it!</p>
<p>Letâ€™s first set some notation. Weâ€™ll use the capital greek letter
<span class="math inline">\Delta</span> to denote the â€œchange inâ€ some
value, so that <span class="math inline">\Delta b_2</span> is the amount
we change <span class="math inline">b_2</span> for the analysis. So in
our previous example, we had <span class="math inline">\Delta b_2 = 24 -
12 = 12</span>. Weâ€™d like to find the range of values for <span
class="math inline">\Delta b_2</span> such that our previous basis is
still optimal.</p>
<p>Letâ€™s first consider feasibility. Recall that a basic solution is
feasible if and only if all the variable values are non-negative, which
from eq.Â <a href="#eq:simplexMatrixGeneralized">11</a> gives us <span
class="math inline">\mathbf{B}^{-1}\mathbf{b}\geq0</span>. At the
optimal solution to our sample problem, we have</p>
<p><span class="math display">
\mathbf{B}^{-1}= \begin{bmatrix}
1 &amp; \frac{1}{3} &amp; -\frac{1}{3} \\
0 &amp; \frac{1}{2} &amp; 0 \\
0 &amp; -\frac{1}{3} &amp; \frac{1}{3}
\end{bmatrix}
</span></p>
<p>Changing <span class="math inline">b_2</span> to <span
class="math inline">b_2 + \Delta b_2</span> turns the requirement
into:</p>
<p><span class="math display">
\begin{align*}
&amp;&amp;
\begin{bmatrix}
1 &amp; \frac{1}{3} &amp; -\frac{1}{3} \\
0 &amp; \frac{1}{2} &amp; 0 \\
0 &amp; -\frac{1}{3} &amp; \frac{1}{3}
\end{bmatrix}
\begin{bmatrix}
4 \\ 12 + \Delta b_2 \\ 18
\end{bmatrix}
&amp;\geq\mathbf{0}\\
\Leftrightarrow &amp;&amp;
\begin{bmatrix}
2 + \frac{1}{3}\Delta b_2 \\
6 + \frac{1}{2}\Delta b_2 \\
2 - \frac{1}{3}\Delta b_2 \\
\end{bmatrix}
&amp;\geq\mathbf{0}
\end{align*}
</span></p>
<p>The first inequality implies <span class="math inline">\Delta
b_2\geq-6</span>, the second implies <span class="math inline">\Delta
b_2\geq-12</span>, and the third implies <span
class="math inline">\Delta b_2\leq 6</span>. So to satisfy all three
simultaneously, we need to keep <span class="math inline">-6\leq\Delta
b_2\leq6</span>, the equivalent of saying <span
class="math inline">6\leq b_2\leq 18</span>.</p>
<p>So keeping <span class="math inline">6\leq b_2\leq 18</span> gives a
feasible solution, but is the old basis still optimal? It turns out that
we can answer that very simply, by noticing that changes to <span
class="math inline">\mathbf{b}</span> have no effect on the reduced cost
vector <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}\mathbf{A}-\mathbf{c}</span>.
Since this basis was optimal for the original, those same reduced costs
must still be non-negative, so the old optimal basis is still optimal
whenever <span class="math inline">\Delta b_2</span> is in the
acceptable range.</p>
<p>As for how much the objective changes, letâ€™s recall (again from
eq.Â <a href="#eq:simplexMatrixGeneralized">11</a>) that the objective
value at a basic solution is given by <span
class="math inline">Z=\mathbf{c}_B\mathbf{B}^{-1}\mathbf{b}</span>.
Weâ€™ve already calculated <span
class="math inline">\mathbf{c}_B\mathbf{B}^{-1}= \begin{bmatrix}0 &amp;
\frac{3}{2} &amp; 1\end{bmatrix}</span> at the optimal basis, and thus
altering <span class="math inline">b_2</span> gives us</p>
<p><span class="math display">
Z = \begin{bmatrix}0 &amp; \frac{3}{2} &amp;
1\end{bmatrix}\begin{bmatrix}4 \\ 12 + \Delta b_2 \\ 18\end{bmatrix}
  = 36 + \frac{3}{2}\Delta b_2.
</span></p>
<p>So our interpretation of the shadow price holds over this range as
well.</p>
<p>Lastly, letâ€™s take a look at the plots of the problem when we take
<span class="math inline">b_2</span> at the limits of its allowable
range. First, for <span class="math inline">b_2=6</span>:</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;chooseObjVals&quot;: true, &quot;removeConstraints&quot;: [2], &quot;addConstraints&quot;: [[[0, 2, 6, &quot;l&quot;], [6, 4.1]]]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>And for <span class="math inline">b_2=18</span>.</p>
<svg width="350" height="350" class="lpDraw" base="prototypeLp" altArgs="{&quot;chooseObjVals&quot;: true, &quot;removeConstraints&quot;: [2], &quot;addConstraints&quot;: [[[0, 2, 18, &quot;l&quot;], [6, 10.1]]]}">
Sorry, your browser does not support inline SVG.
</svg>
<p>We wonâ€™t spend much time dwelling on this, but notice how the
original optimal solution came at the intersection of the second and
third constraints of eq.Â <a href="#eq:prototypeLp">1</a>. Now on these
two plots, the optimal is still at that intersection, while also adding
a third intersecting constraint<a href="#fn42" class="footnote-ref"
id="fnref42" role="doc-noteref"><sup>42</sup></a>. Moving any further
would make that intersection infeasible, which is why the allowable
range stops there.</p>
<h2 data-number="4.9" id="notes-and-further-reading"><span
class="header-section-number">4.9</span> Notes and further reading</h2>
<p>The presentation in this section followed very closely to various
sections in chapters 3-7 in <span class="citation"
data-cites="classText">Hillier and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span>. Many of the proofs in sectionÂ <a
href="#sec:lpDuality">4.7</a> were adapted from <span class="citation"
data-cites="bertsimas-LPbook">Bertsimas and Tsitsiklis (<a
href="#ref-bertsimas-LPbook" role="doc-biblioref">1997</a>)</span>. Some
other topics for the interested reader to follow up on:</p>
<ul>
<li>We briefly mentioned <em>dual simplex</em> and some of its uses in
these notes. <span class="citation" data-cites="classText">Hillier and
Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span> section 8.1 covers it in more
detail.</li>
<li>When covering sensitivity analysis (sectionÂ <a
href="#sec:sensitivityAnalysis">4.8.3</a>) we only considered changes to
a single rhs value. <span class="citation"
data-cites="classText">Hillier and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span> (section 7.2) covers further
cases, like analyzing changes in other problem data, or simultaneous
changes in multiple rhs values.</li>
<li>Section 7.4 in <span class="citation" data-cites="classText">Hillier
and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span> briefly discusses <em>robust
optimization</em>, where the setup includes ranges of potential values
of model data, and the goal is to find solutions that will be feasible
and close to optimal for the entire set of potential problem data.</li>
<li>Simplex is not the only algorithm for solving LPs. Sections 4.9 and
8.4 of <span class="citation" data-cites="classText">Hillier and
Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span> study so-called <em>interior
point</em> algorithms for linear programs. These algorithms have an
interesting role in the history of LP. Most notably, many of these
methods have been proven to terminate in a number of steps
<em>polynomial</em> in the size of the LP considered, a feat that has
not been duplicated for the simplex method. But even with this
theoretical advantage, the interior point methods are not usually faster
than simplex in practice. Even so, most solvers will include an interior
point method that will be called upon in certain circumstances.</li>
</ul>
<p>The K-State IMSE department offers <a
href="https://catalog.k-state.edu/preview_course_nopop.php?catoid=54&amp;coid=375882">IMSE
881</a>, a full semester course devoted to linear programming
theory.</p>
<h1 data-number="5" id="integer-programming"><span
class="header-section-number">5</span> Integer programming</h1>
<div class="lectureVideoEmbed"
data-video-id="82e9cb1ddf1b4cbbaa625d040d42b0891d"
data-video-date="2023-09-18">
Integer programming definitions, intro to modeling IPs. I forgot to turn
on my lapel mic at the beginning of class (about the first 7 minutes),
though the room mic was on and seemed to pick up most everything ok.
</div>
<p>In this section we will introduce integer programming (IP), which is
an of extension of linear programming that includes restrictions that
some (or all) of the decision variables must take integer values. While
this may initially seem like a small tweak, the addition of these
integrality<a href="#fn43" class="footnote-ref" id="fnref43"
role="doc-noteref"><sup>43</sup></a> constraints is actually quite
powerful, and will allow us to model all types of interesting problems
that linear programming could not handle. The added expressiveness comes
with a tradeoff, though, as integer programs generally take much more
effort to solve than their linear counterparts.</p>
<p>For this course, we will discuss some preliminaries before moving on
to IP modeling techniques. Weâ€™ll spend more time on modeling here than
in the LP section, in order to explore the flexibility integer programs
provide and discuss some of the tricks that can be used to set up
problems of all types. Weâ€™ll finish our practical discussion with a
section on solving IPs with Python. On the theoretical side, weâ€™ll touch
a bit on the theory that helps explain what makes solving IPs so
difficult. Weâ€™ll then get into solution techniques, including
branch-and-bound and cutting plane procedures.</p>
<h2 data-number="5.1" id="definitions"><span
class="header-section-number">5.1</span> Definitions</h2>
<p>Weâ€™ll consider a few forms of integer programs in this course. A
<strong>(pure) integer (linear) program</strong><a href="#fn44"
class="footnote-ref" id="fnref44" role="doc-noteref"><sup>44</sup></a>
(<strong>IP</strong>)<a href="#fn45" class="footnote-ref" id="fnref45"
role="doc-noteref"><sup>45</sup></a> is a linear program where
<em>all</em> the decision variables are required to be integer, i.e.Â it
is a problem of the form<a href="#fn46" class="footnote-ref"
id="fnref46" role="doc-noteref"><sup>46</sup></a>:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}\\
\text{s.t.}&amp;&amp; \mathbf{A}\mathbf{x}&amp;\leq\mathbf{b}\\
     &amp;&amp; \mathbf{x}&amp;\in\mathbb{I}^n_+
\end{align*}
</span></p>
<p>In contrast, a <strong>mixed integer (linear) program</strong>
(<strong>MIP</strong>) is a linear program where some, but not
necessarily all, of the decision variables are required to be integer,
i.e.</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}+ \mathbf{h}\mathbf{y}\\
\text{s.t.}&amp;&amp; \mathbf{A}\mathbf{x}+
\mathbf{G}\mathbf{y}&amp;\leq\mathbf{b}\\
     &amp;&amp; \mathbf{x}&amp;\in\mathbb{I}^n_+ \\
     &amp;&amp; \mathbf{y}&amp;\geq\mathbf{0}
\end{align*}
</span></p>
<p>A MIP is more flexible that a pure IP, but much of the theory we
cover will be easier to talk about for IPs. When we present results for
IPs, know that they can likely be extended to MIPs as well, but with
some minor modifications.</p>
<p>A <strong>binary integer (linear) program</strong>
(<strong>BIP</strong>) is a subclass of IPs where the variables are
restricted not just to integers, but to either one of the values <span
class="math inline">0</span> or <span class="math inline">1</span>. Thus
we can define a BIP as having the form:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \mathbf{c}\mathbf{x}\\
\text{s.t.}&amp;&amp; \mathbf{A}\mathbf{x}&amp;\leq\mathbf{b}\\
     &amp;&amp; \mathbf{x}&amp;\in\{0,1\}^n
\end{align*}
</span></p>
<p>A BIP is sometimes also called a <strong>0-1 integer (linear)
program</strong>.</p>
<p>As you can see, every IP by definition has an associated LP
underlying it, obtained from the IP by removing the integrality
constraints. This underlying LP is very important in the study of
integer programs, and is known as the IPâ€™s <strong>LP
relaxation</strong> or <strong>linear relaxation</strong><a href="#fn47"
class="footnote-ref" id="fnref47"
role="doc-noteref"><sup>47</sup></a>.</p>
<h2 data-number="5.2" id="sec:ipRoundingNotEnough"><span
class="header-section-number">5.2</span> Rounding is not enough</h2>
<p>Right about now, you may be wondering how important IPâ€™s integer
restriction really is. Canâ€™t we just solve the related LP, round the
solution to the nearest integer, then be done with it?</p>
<p>Theoretically, the answer is a resounding no. Practically, the answer
may change depending on your requirements. But letâ€™s try to illustrate
why the rounding method could be problematic. Consider the following
integer program:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 12x_1 + 10x_2 &amp; \\
\text{s.t.}&amp;&amp; -7x_1 + 5x_2 &amp; \leq 5 \\
     &amp;&amp;  9x_1 +  7x_2 &amp; \leq 54 \\
     &amp;&amp; x_1,x_2 &amp; \in\mathbb{I}_+
\end{align*}
</span></p>
<p>Weâ€™ve shown this 2-dimensional IP in a plot below. Shaded in gray is
the feasible region to the problemâ€™s LP relaxation. The plotted points
are all the feasible solutions to the IP, i.e.Â the points inside the LP
relaxationâ€™s feasible region which are also integer. In this case, you
can verify graphically that the optimal solution to the LP relaxation is
<span class="math inline">(x_1, x_2)=(2.5, 4.5)</span> with an objective
value of 75.</p>
<svg width="350" height="350" class="lpDraw" base="roundingIp" altArgs="{&quot;chooseObjVals&quot;: true}">
Sorry, your browser does not support inline SVG.
</svg>
<p>Say weâ€™d like to find our integer solution by simply rounding the
optimal LP relaxation solution. The first difficulty would be
determining which way (up vs.Â down) to round the numbers. But another,
more fundamental difficulty is that there is no guarantee that
<em>any</em> rounded solution will be feasible. Indeed, that is the case
we find ourselves in here, as each of the rounded solutions <span
class="math inline">(2, 4), (2, 5), (3, 4)</span>, and <span
class="math inline">(3, 5)</span> are infeasible<a href="#fn48"
class="footnote-ref" id="fnref48"
role="doc-noteref"><sup>48</sup></a>.</p>
<p>Ok, so say instead you just want to find the feasible integer
solution that is closest to the LP relaxation solution. Putting aside
the question of how to do that, there is no guarantee that even that
solution will be the optimal integer solution. Indeed, in this example
the closest feasible integer solutions are <span class="math inline">(2,
3)</span> and <span class="math inline">(3, 3)</span>, of which <span
class="math inline">(3, 3)</span> has the best objective value at 66.
But in fact the best integer solution is <span
class="math inline">(6,0)</span> with an objective value of 72, a 9%
increase!</p>
<p>Even worse still, weâ€™ll often formulate BIPs such that the
interpretation of the 0-1 variable is whether or not to take some
action. For some types of problems, itâ€™s not at all uncommon for the LP
relaxation solution to a BIP to be every variable taking the value <span
class="math inline">0.5</span>! Such a solution would leave you no clue
as to which direction you should round the solutions. In these cases,
considering only the LP relaxation gives you no hint whatsoever about
how to proceed.</p>
<h2 data-number="5.3" id="ip-modeling"><span
class="header-section-number">5.3</span> IP modeling</h2>
<p>Hopefully the preceding section gave you some appreciation for why
integrality constraints can be useful. The aim for this section is to
give you a broader idea of what situations can be modeled with IPs. Of
particular interest is the use of binary variables to encode different
types of logic in our models.</p>
<h3 data-number="5.3.1" id="general-integer-variables"><span
class="header-section-number">5.3.1</span> General integer
variables</h3>
<p>The most straightforward application if IPs is modeling an LP where
the decision variables canâ€™t be fractional. For example, say youâ€™re
building an optimization model to decide how many washing machines to
buy for your fleet of laundromats. There is no way to meaningfully buy,
say, half of a washing machine to deploy in your stores. This is a case
where integer-valued decisions are required.</p>
<p>As far as writing out the model, it is as simple as adding a <span
class="math inline">\mathbf{x}\in\mathbb{I}^n</span> line to your
formulation. For example, suppose in the Wyndor Glass sample LP (eq.Â <a
href="#eq:prototypeLp">1</a>) we can only make whole batches of each
product. A new formulation would look like:</p>
<p><span id="eq:wyndorIp" class="eqnos"><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq \ \ 4  \\
     &amp;&amp; 2x_2 &amp; \leq 12 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+
\end{align*}
</span><span class="eqnos-number">(15)</span></span></p>
<p>Weâ€™ve seen in sectionÂ <a href="#sec:ipRoundingNotEnough">5.2</a> that
the optimal solution can change quite a bit when moving from real-valued
variables to integral ones, motivating the IP solution techniques weâ€™ll
be exploring later.</p>
<h3 data-number="5.3.2" id="sec:binVarTricks"><span
class="header-section-number">5.3.2</span> Binary variable tricks</h3>
<p>Finding solutions with general integer values is great. But in my
opinion the real power in integer programming comes from using binary
variables to encode new kinds of logic that you canâ€™t replicate in a
linear program. In this section, we will explore some of these binary
variable tricks. Weâ€™ll consider eq.Â <a href="#eq:wyndorIp">15</a>, our
new integer version of the Wyndor glass problem, as a jumping-off point
for our examples.</p>
<h4>
Either/or constraints
</h4>
<p>For our first example, letâ€™s consider a scenario where exactly one
out of two constraints needs to be satisfied, and we get to decide which
one to enforce as part of the problem. For example, letâ€™s consider a
modification to the Wyndor glass IP eq.Â <a href="#eq:wyndorIp">15</a>
where we have the potential to build a new facility to replace Plant 3.
This new facility would be available for only 13 hours per week.
However, due to updated technology, producing batches of each product
will take less time: Product 1 will require 2 hours at the new Plant 3,
while Product 2 will require only 1 hour. In effect, weâ€™d like to
replace the old Plant 3 constraint with something like:</p>
<p><span class="math display">
\begin{align*}
\text{either}&amp;&amp;3x_1 + 2x_2 \leq 18 \\
\text{or}    &amp;&amp;2x_1 + x_2 \leq 13
\end{align*}
</span></p>
<p>There is no â€œnativeâ€ facility for this type of constraint in IP,
weâ€™re still stuck with only linear functions of our decision variables.
But we can implement this â€œeither/orâ€ logic by adding an auxiliary,
binary variable <span class="math inline">y</span> to the problem in a
certain fashion<a href="#fn49" class="footnote-ref" id="fnref49"
role="doc-noteref"><sup>49</sup></a>. Consider the following IP:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq \ \ 4  \\
     &amp;&amp; 2x_2 &amp; \leq 12 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18 + My \\
     &amp;&amp; 2x_1 + x_2 &amp; \leq 13 + M(1 - y)\\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+ \\
     &amp;&amp; y &amp; \in \ \{0, 1\}
\end{align*}
</span></p>
<p>Here, <span class="math inline">M</span><a href="#fn50"
class="footnote-ref" id="fnref50" role="doc-noteref"><sup>50</sup></a>
is some sufficiently large constant (something like 100 would be more
than sufficient in this case).</p>
<p>What did we accomplish by adding <span class="math inline">y</span>
and <span class="math inline">M</span> in this manner? First, letâ€™s
notice that the new constraints are still linear functions of the
variables. (Remember, <span class="math inline">M</span> is a constant
and not a variable.) Now, think what it would mean if <span
class="math inline">y=1</span>. In that case, the constraint</p>
<p><span class="math display">
3x_1 + 2x_2 \leq 18 + My
</span></p>
<p>becomes</p>
<p><span class="math display">
3x_1 + 2x_2 \leq \textit{some very large number}
</span></p>
<p>so that any reasonable setting of the <span
class="math inline">\mathbf{x}</span> variables will satisfy it.
Meanwhile, the constraint</p>
<p><span class="math display">
2x_1 + x_2 \leq 13 + M(1 - y)
</span></p>
<p>becomes just</p>
<p><span class="math display">
2x_1 + x_2 \leq 13
</span></p>
<p>So if we choose <span class="math inline">y=1</span>, then only the
constraint <span class="math inline">2x_1 + x_2 \leq 13</span> will
matter, i.e.Â weâ€™re using the new facility. Similarly, if we set <span
class="math inline">y=0</span>, then the only constraint that matters is
<span class="math inline">3x_1 + 2x_2 \leq 18</span>, i.e.Â weâ€™re not
using the new facility and making due with the old one. Thus weâ€™ve
successfully recreated the either/or logic using linear constraints and
binary variables!</p>
<h4>
Functions taking one of <span class="math inline">n</span> possible
values
</h4>
<p>Sometimes the right-hand side of your linear constraints might be
able to take one of several distinct values. As an example, letâ€™s say
that Wyndorâ€™s Plant 3 may be open for additional hours at some extra
cost. It may remain open for 3 extra hours at a cost of $2,000, or it
may remain open for 6 extra hours at a cost of $4,500. How could eq.Â <a
href="#eq:wyndorIp">15</a> be modified to take this into account? Take a
look at this formulation:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 - 2y_1 - 4.5y_2 &amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq \ \ 4  \\
     &amp;&amp; 2x_2 &amp; \leq 12 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18 + 3y_1 + 6y_2 \\
     &amp;&amp; y_1 + y_2 &amp; \leq \ \ 1 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+ \\
     &amp;&amp; y_1,y_2 &amp; \in \ \{0, 1\}
\end{align*}
</span></p>
<p>By constraining <span class="math inline">y_1 + y_2 \leq 1</span>, we
allow only <span class="math inline">(y_1, y_2)\in\{(0, 0),(1, 0),(0,
1)\}</span>. If <span class="math inline">(y_1,y_2)=(0,0)</span> this
would reduce back to the original problem. If <span
class="math inline">(y_1,y_2)=(1,0)</span> then weâ€™d have the situation
where the plant is open for 3 extra hours, and weâ€™ve reduced our profits
by $2,000 to account for the extra cost. Similarly, if <span
class="math inline">(y_1,y_2)=(0,1)</span> then weâ€™ll have an extra 6
hours of use in the plant, but at the required cost of $4,500.</p>
<h4>
Setup costs
</h4>
<p>A common occurrence in OR problems is a setup cost involved in
participating in some activity. Suppose in the Wyndor problem that the
three facilities did not exist yet, so they need to decide which
facilities to build as well as the ultimate product mix. Say that in
order to build any of the plants, theyâ€™d need to take out a loan that
they plan to pay back with their weekly profits for the foreseeable
future. If the weekly payback for any given facility is $6,000, how can
we model this with an integer program? Take a look at the following
formulation:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 - 6y_1 - 6y_2 -6y_3&amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq \ \ 4y_1  \\
     &amp;&amp; 2x_2 &amp; \leq 12y_2 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18y_3 \\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+ \\
     &amp;&amp; y_1,y_2,y_3 &amp; \in \{0, 1\}
\end{align*}
</span></p>
<p>Weâ€™ve added new binary variables, <span class="math inline">y_1,
y_2</span>, and <span class="math inline">y_3</span>, which weâ€™d like to
interpret as a value of <span class="math inline">1</span> for <span
class="math inline">y_i</span> means that facility <span
class="math inline">i</span> will be built, and a value of <span
class="math inline">0</span> means it wonâ€™t be built. How does that
alter the formulation? We know that building a facility will cost us
$6,000 weekly over the loan term, so weâ€™ll subtract $6,000 from our
weekly profits for any facility via the term <span
class="math inline">-6y_i</span> in the objective. Furthermore, we can
only use the time in each facility if it is built. So the constants on
right-hand sides of the original formulation are all now multiplied by
the corresponding <span class="math inline">y_i</span> variable. This
way, if we decide not to build the facility by setting <span
class="math inline">y_i=0</span>, there is no time available at the
(non-existent) facility. Otherwise, its time is available as usual.</p>
<h4>
Boolean algebra
</h4>
<div class="lectureVideoEmbed"
data-video-id="c73d5c4374034d25b0f305548fd8ddc41d"
data-video-date="2023-09-20">
A quick recap of HW3, then more IP modeling.
</div>
<p>Given binary variables <span class="math inline">x_1, x_2</span> we
can mimic the basic operations from <a
href="https://en.wikipedia.org/wiki/Boolean_algebra">Boolean algebra</a>
(AND, OR, XOR) in integer programs. In each case, weâ€™ll do this with an
auxiliary binary variable <span class="math inline">y</span>. For each
operation, Iâ€™ll show the associated truth table (telling the values of
<span class="math inline">y</span> that should correspond to each
possible value of <span class="math inline">x_1, x_2</span>) and the
corresponding set of linear constraints. Itâ€™s a good exercise to go
through each row of the table and verify that the constraints do indeed
enforce the relation.</p>
<ul>
<li>AND: <span class="math inline">y=1</span> if and only if <span
class="math inline">x_1=x_2=1</span>:
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
   \begin{align*}
   y&amp;\leq x_1 \\
   y&amp;\leq x_2 \\
   y&amp;\geq x_1 + x_2 - 1 \\
   x_1, x_2, y &amp; \in \{0,1\}
   \end{align*}
   </span>
</div>
</div></li>
<li>OR: <span class="math inline">y=1</span> if and only if <em>at
least</em> one of <span class="math inline">x_1</span> or <span
class="math inline">x_2</span> equals <span
class="math inline">1</span>:
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
   \begin{align*}
   y&amp;\leq x_1 + x_2 \\
   y&amp;\geq x_1 \\
   y&amp;\geq x_2 \\
   x_1, x_2, y &amp; \in \{0,1\}
   \end{align*}
   </span>
</div>
</div></li>
<li>XOR: <span class="math inline">y=1</span> if and only if
<em>exactly</em> one of <span class="math inline">x_1</span> or <span
class="math inline">x_2</span> equals <span
class="math inline">1</span>:
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
   \begin{align*}
   y&amp;\leq x_1 + x_2 \\
   y&amp;\geq x_1 - x_2 \\
   y&amp;\geq x_2 - x_1 \\
   y&amp;\leq 2 - x_1 - x_2 \\
   x_1, x_2, y &amp; \in \{0,1\}
   \end{align*}
   </span>
</div>
</div></li>
</ul>
<p>(It occurred to me while presenting this that maybe it would be
helpful to provide some <em>incorrect</em> formulations for these
concepts, in order to illustrate what might go wrong while modeling. You
can find this in the appendix, sectionÂ <a
href="#sec:badIpModels">6.4</a>)</p>
<p>Note that these constraint sets wouldnâ€™t normally constitute an IP on
their own, but instead they would be just a subset of the constraints
youâ€™d find inside a larger, more complex problem. Letâ€™s consider the
following addition to the Wyndor IP: The company realizes that they
cannot use the full 18 hours available at Plant 3 if they produce
<em>both</em> Product 1 and Product 2 during a given week, since theyâ€™ll
require some down time in order to set up the line for a change in
product. They anticipate this setup to take 2 hours away from their
production time.</p>
<p>Weâ€™ll alter eq.Â <a href="#eq:wyndorIp">15</a> by including three
additional, binary variables <span class="math inline">y_1, y_2</span>,
and <span class="math inline">z</span>. Weâ€™ll set up the <span
class="math inline">y_i</span> variables so that <span
class="math inline">y_i=1</span> if we plan to produce any of Product
<span class="math inline">i</span> (i.e.Â <span
class="math inline">x_i&gt;0</span>), and weâ€™ll let <span
class="math inline">z=1</span> if and only if <span
class="math inline">y_1=y_2=1</span>. The formulation follows:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 3x_1 + 5x_2 &amp; \\
\text{s.t.}&amp;&amp; y_1 &amp; \leq x_1 \\
     &amp;&amp; My_1 &amp; \geq x_1 \\
     &amp;&amp; y_2 &amp; \leq x_2 \\
     &amp;&amp; My_2 &amp; \geq x_2 \\
     &amp;&amp; z&amp;\leq y_1 \\
     &amp;&amp; z&amp;\leq y_2 \\
     &amp;&amp; z&amp;\geq y_1 + y_2 - 1\\
     &amp;&amp; x_1 &amp; \leq \ \ 4  \\
     &amp;&amp; 2x_2 &amp; \leq 12 \\
     &amp;&amp; 3x_1 + 2x_2 &amp; \leq 18 - 2z \\
     &amp;&amp; x_1,x_2 &amp; \in \ \mathbb{I}_+ \\
     &amp;&amp; y_1,y_2,z &amp; \in \ \{0, 1\}
\end{align*}
</span></p>
<p>The constraints</p>
<p><span class="math display">
\begin{align*}
y_i &amp; \leq x_i \\
My_i &amp; \geq x_i \\
\end{align*}
</span></p>
<p>(with sufficiently large <span class="math inline">M</span>) serve to
ensure that <span class="math inline">y_i=1</span> if and only if <span
class="math inline">x_i&gt;0</span> (which, since we have <span
class="math inline">x_i\in\mathbb{I}</span>, also means <span
class="math inline">x_i\geq1</span>)<a href="#fn51" class="footnote-ref"
id="fnref51" role="doc-noteref"><sup>51</sup></a>. The next constraints
involving <span class="math inline">y_1, y_2</span>, and <span
class="math inline">z</span> are exactly the AND logical constraints
from above, ensuring that <span class="math inline">z=1</span> if and
only if both <span class="math inline">y_1</span> and <span
class="math inline">y_2</span> are 1 (and hence <span
class="math inline">x_1,x_2&gt;0</span>). The final modification comes
in the Plant 3 resource constraint</p>
<p><span class="math display">
3x_1 + 2x_2 \leq 18 - 2z
</span></p>
<p>which serves to reduce the available production time when both
products are being produced.</p>
<h3 data-number="5.3.3" id="sec:ipWordProblems"><span
class="header-section-number">5.3.3</span> Example word problems</h3>
<div class="lectureVideoEmbed"
data-video-id="f24c71ae75c74c6ab8fe1f1146ccea831d"
data-video-date="2023-09-22">
Even ore IP modeling. Tried to address the confusion from last lecture,
then modeled a few more word problems.
</div>
<p>Here we present the sample scenarios in section 12.4 of <span
class="citation" data-cites="classText">Hillier and Lieberman (<a
href="#ref-classText" role="doc-biblioref">2021</a>)</span>, and talk
about how to model each scenario. Each formulation will require some
tricks with binary variables.</p>
<h4>
Resource allocation with extra restrictions
</h4>
<blockquote>
<p>The Research and Development Division of the GOOD PRODUCTS COMPANY
has developed three possible new products. However, to avoid undue
diversification of the companyâ€™s product line, management has imposed
the following restriction:</p>
<p>Restriction 1: From the three possible new products, at most two
should be chosen to be produced.</p>
<p>Each of these products can be produced in either of two plants. For
administrative reasons, management has imposed a second restriction in
this regard.</p>
<p>Restriction 2: Just one of the two plants should be chosen to be the
sole producer of the new products.</p>
<p>The production cost per unit of each product would be essentially the
same in the two plants. However, because of differences in their
production facilities, the number of hours of production time needed per
unit of each product might differ between the two plants. These data are
given in Table 12.2, along with other relevant information, including
marketing estimates of the number of units of each product that could be
sold per week if it is produced. The objective is to choose the
products, the plant, and the production rates of the chosen products so
as to maximize total profit.</p>
</blockquote>
<figure>
<img src="images/ip-example-1-data.png"
alt="Data for the Good Products Company problem (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Data for the Good Products Company
problem <span class="citation" data-cites="classText">(<a
href="#ref-classText" role="doc-biblioref">Hillier and Lieberman
2021</a>)</span></figcaption>
</figure>
<p>This feels a lot like the Wyndor Glass problem, but there are several
extra restrictions put in. First of all, we have a bound on the number
of items sold per week, but this is something that we could handle in
plain old linear programming. More interesting are Restriction 1 and
Restriction 2, which will require us to add some binary variables to the
formulation and carefully set up the constraints to enforce the desired
logic. To that end, letâ€™s examine the following model<a href="#fn52"
class="footnote-ref" id="fnref52"
role="doc-noteref"><sup>52</sup></a>:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; 5x_1 + 7x_2 + 3x_3&amp; \\
\text{s.t.}&amp;&amp; x_1 &amp; \leq 7y_1  \\
     &amp;&amp; x_2 &amp; \leq 5y_2 \\
     &amp;&amp; x_3 &amp; \leq 9y_3 \\
     &amp;&amp; y_1 + y_2 + y_3 &amp; \leq 2 \\
     &amp;&amp; 3x_1 + 4x_2 + 2x_3 &amp; \leq 30 + My_4 \\
     &amp;&amp; 4x_1 + 6x_2 + 2x_3 &amp; \leq 40 + M(1 - y_4) \\
     &amp;&amp; x_1,x_2,x_3 &amp; \in \ \mathbb{I}_+ \\
     &amp;&amp; y_1,y_2,y_3,y_4 &amp; \in \{0, 1\}
\end{align*}
</span></p>
<p>Without the <span class="math inline">y_i</span> variables, this is
essentially just another resource allocation problem like the integer
version of the Wyndor problem eq.Â <a href="#eq:wyndorIp">15</a>. But now
we have variables <span class="math inline">y_1, y_2, y_3</span> to
account for the problemâ€™s Restriction 1, and <span
class="math inline">y_4</span> accounts for Restriction 2.</p>
<p>How does it work? Well, <span class="math inline">y_4</span> is
applying the either/or constraint trick we saw earlier in sectionÂ <a
href="#sec:binVarTricks">5.3.2</a>. Notice that if <span
class="math inline">y_4=1</span> (and <span class="math inline">M</span>
is selected large enough) then the constraint on production in Plant 1
has so much slack that any reasonable settings of the <span
class="math inline">x_i</span> variables will not violate it. Thus the
only constraint in effect is the Plant 2 resource constraint. So the
interpretation is that <span class="math inline">y_4=1</span> means that
Plant 2 is the plant chosen to satisfy Restriction 2. Similarly, <span
class="math inline">y_4=0</span> means that Plant 1 is the one selected
plant that handles the production.</p>
<p>How about the other <span class="math inline">y_i</span> variables?
Notice that if <span class="math inline">y_i=0</span> for any <span
class="math inline">i</span>, then the corresponding constraint on <span
class="math inline">x_i</span> becomes <span
class="math inline">x_i\leq0</span>, meaning that Product <span
class="math inline">i</span> cannot be produced. Otherwise, if <span
class="math inline">y_i=1</span>, then <span
class="math inline">x_i</span> is only bounded by the weekly sales
potential from the table, and thus Product <span
class="math inline">i</span> <em>is</em> allowed to be produced. Then
adding the constraint <span class="math inline">y_1 + y_2 + y_3 \leq
2</span> codifies the requirement that at most 2 of the products may be
produced.</p>
<h4>
Violating proportionality
</h4>
<blockquote>
<p>The SUPERSUDS CORPORATION is developing its marketing plans for next
yearâ€™s new products. For three of these products, the decision has been
made to purchase a total of five TV spots for commercials on national
television networks. The problem we will focus on is how to allocate the
five spots to these three products, with a maximum of three spots (and a
minimum of zero) for each product.</p>
<p>The following table shows the estimated impact of allocating zero,
one, two, or three spots to each product. This impact is measured in
terms of the profit (in units of millions of dollars) from the
additional sales that would result from the spots, considering also the
cost of producing the commercial and purchasing the spots. The objective
is to allocate five spots to the products so as to maximize the total
profit.</p>
</blockquote>
<figure>
<img src="images/ip-example-2-data.png"
alt="Data for the Supersuds Corporation problem (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Data for the Supersuds Corporation
problem <span class="citation" data-cites="classText">(<a
href="#ref-classText" role="doc-biblioref">Hillier and Lieberman
2021</a>)</span></figcaption>
</figure>
<p>Your first thought for modeling this may be to have integer variables
<span class="math inline">x_1, x_2, x_3</span>, with the value of <span
class="math inline">x_i</span> denoting the number of TV spots allocated
to product <span class="math inline">i</span>. But this wonâ€™t work,
because the objective violates the so-called <em>proportionality
assumption</em> for linear functions, i.e.Â that each extra unit of a
variable affects the value of the function by the same amount. That is
not true here, e.g.Â for product 1 doubling from 1 spot to 2 does not
double the profit.</p>
<p>Instead, letâ€™s define a separate binary variable for each product and
each possible selection of TV spots for the product. So weâ€™ll have a
binary variables <span class="math inline">y_{ij}</span> such that <span
class="math inline">y_{ij}=1</span> if and only if we decide on <span
class="math inline">j</span> TV spots for product <span
class="math inline">i</span>, and otherwise <span
class="math inline">y_{ij}=0</span>. With this setup, our model would
look like:</p>
<div class="mathSmall">
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; y_{11} + 3y_{12} + 3y_{13} + 2y_{22} + 3y_{23} -
y_{31} + 2y_{32} + 4y_{33}&amp; \\
\text{s.t.}&amp;&amp; y_{11} + y_{12} + y_{13} &amp; \leq 1 \\
     &amp;&amp; y_{21} + y_{22} + y_{23} &amp; \leq 1 \\
     &amp;&amp; y_{31} + y_{32} + y_{33} &amp; \leq 1 \\
     &amp;&amp; y_{11} + 2y_{12} + 3y_{13} + y_{21} + 2y_{22} + 3y_{23}
+ y_{31} + 2y_{32} + 3y_{33} &amp; \leq 5 \\
     &amp;&amp; y_{ij} &amp; \in \{0,1\} \ \ \forall\ i,j
\end{align*}
</span></p>
</div>
<p>The objective is straightforward, coming directly from the numbers in
the table. As for the constraints, lets start with the first three. We
shouldnâ€™t have something like, say, both <span
class="math inline">y_{11}=1</span> and <span
class="math inline">y_{12}=1</span>, since it doesnâ€™t make sense to
allocate both <span class="math inline">1</span> and <span
class="math inline">2</span> spots for the same product. At most one of
<span class="math inline">y_{i1}, y_{i2}</span>, or <span
class="math inline">y_{i3}</span> can be chosen which is why weâ€™ve
included the</p>
<p><span class="math display">
y_{i1} + y_{i2} + y_{i3} \leq 1
</span></p>
<p>constraints.</p>
<p>What about the final (functional) constraint? The left-hand side of
the constraint sums up the total number of TV spots that are allocated.
So the reason that, for example, we see the term <span
class="math inline">3y_{13}</span> is that selecting <span
class="math inline">y_{13}=1</span> allocates 3 spots to product 1, thus
making use of 3 of the available 5 slots. Then the 5 on the right-hand
side enforces that at most 5 TV spots are allocated overall.</p>
<h4>
Covering all characteristics
</h4>
<blockquote>
<p>SOUTHWESTERN AIRWAYS needs to assign its crews to cover all its
upcoming flights. We will focus on the problem of assigning three crews
based in San Francisco to the flights listed in the first column of the
following table. The other 12 columns show the 12 feasible sequences of
flights for a crew. (The numbers in each column indicate the order of
the flights.) Exactly three of the sequences need to be chosen (one per
crew) in such a way that every flight is covered. (It is permissible to
have more than one crew on a flight, where the extra crews would fly as
passengers, but union contracts require that the extra crews would still
need to be paid for their time as if they were working.) The cost of
assigning a crew to a particular sequence of flights is given (in
thousands of dollars) in the bottom row of the table. The objective is
to minimize the total cost of the three crew assignments that cover all
the flights.</p>
</blockquote>
<figure>
<img src="images/ip-example-3-data.png"
alt="Data for the Southwestern Airways problem (Hillier and Lieberman 2021)" />
<figcaption aria-hidden="true">Data for the Southwestern Airways problem
<span class="citation" data-cites="classText">(<a href="#ref-classText"
role="doc-biblioref">Hillier and Lieberman 2021</a>)</span></figcaption>
</figure>
<p>We can model this problem in the following way, with the binary
variable <span class="math inline">x_i=1</span> if we assign sequence
<span class="math inline">i</span> to some crew, and otherwise <span
class="math inline">x_i=0</span>:</p>
<div class="mathSmall">
<p><span class="math display">
\begin{align*}
\text{min}&amp;&amp; 2x_1 + 3x_2 + 4x_3 + 6x_4 + 7x_5 + 5x_6 &amp; \\
     &amp;&amp; + 7x_7 + 8x_8 + 9x_9 + 9x_{10} + 8x_{11} + 9x_{12}&amp;
\\
\text{s.t.}&amp;&amp; x_1 + x_4 + x_7 + x_{10} &amp; \geq 1
\qquad  \text{(SF to LA)} \\
     &amp;&amp; x_2 + x_5 + x_8 + x_{11} &amp; \geq 1 \qquad \text{(SF
to Den)} \\
     &amp;&amp; x_3 + x_6 + x_9 + x_{12} &amp; \geq 1 \qquad \text{(SF
to Sea)} \\
     &amp;&amp; x_4 + x_7 + x_9 + x_{10} + x_{12} &amp; \geq 1 \qquad
\text{(LA to Chi)} \\
     &amp;&amp; x_1 + x_6 + x_{10} + x_{11} &amp; \geq 1 \qquad
\text{(LA to SF)} \\
     &amp;&amp; x_4 + x_5 + x_9 &amp; \geq 1 \qquad \text{(Chi to Den)}
\\
     &amp;&amp; x_7 + x_8 + x_{10} + x_{11} + x_{12} &amp; \geq 1 \qquad
\text{(Chi to Sea)} \\
     &amp;&amp; x_2 + x_4 + x_5 + x_9 &amp; \geq 1 \qquad \text{(Den to
SF)} \\
     &amp;&amp; x_5 + x_8 + x_{11} &amp; \geq 1 \qquad \text{(Den to
Chi)} \\
     &amp;&amp; x_3 + x_7 + x_8 + x_{12} &amp; \geq 1 \qquad \text{(Sea
to SF)} \\
     &amp;&amp; x_6 + x_9 + x_{10} + x_{11} + x_{12} &amp; \geq 1 \qquad
\text{(Sea to LA)} \\
     &amp;&amp; \sum_{j=1}^{12} x_j &amp; = 3 \qquad \text{(3 crews)} \\
     &amp;&amp; x_j &amp; \in \{0,1\} \ \ \ \forall\ j
\end{align*}
</span></p>
</div>
<p>The objective function is straightforward: if we assign one of the
sequences to some crew, then we must pay the costs according to the
bottom row of the table. Our constraints are that we are required to
cover every flight. Take the first constraint for example. This is the
constraint that enforces that we must have some crew flying from SF to
LA. Which sequences contain that flight? From the first row in the
table, we see this leg is included in sequences 1, 4, 7, and 10. So we
are required to select at least one of those sequences to make sure
there is a crew flying from SF to LA, hence we have the constraint <span
class="math inline">x_1 + x_4 + x_7 + x_{10} \geq 1</span>.</p>
<p>In the final formulation, we follow this logic for every flight in
the table. Lastly, we are required to make an assignment for three
crews, which we encode with the <span
class="math inline">\sum_{j=1}^{12} x_j = 3</span> constraint.</p>
<h3 data-number="5.3.4" id="sec:ipModelDataSep"><span
class="header-section-number">5.3.4</span> Model/data separation</h3>
<p>The above ad-hoc modeling is useful, but in real applications we
often have to solve different, but similarly structured models on some
regular schedule. Weâ€™d prefer not to write a new model from scratch
every time we need to solve one. As we discussed in sectionÂ <a
href="#sec:lpModelDataSep">4.4.4</a>, the best practice is to write<a
href="#fn53" class="footnote-ref" id="fnref53"
role="doc-noteref"><sup>53</sup></a> a base, general model which encodes
all the logic for the problem, then inject the relevant problem data
when an instance needs to be solved.</p>
<p>To that end, in this section weâ€™ll present some generalized IP
formulations for common OR problems.</p>
<h4>
Knapsack
</h4>
<p>Weâ€™ll start with a simple one, the <a
href="https://en.wikipedia.org/wiki/Knapsack_problem">knapsack
problem</a>. The classical framing is something like this: youâ€™re going
on a camping trip. The weight you can carry in your backpack is limited
to <span class="math inline">W\in\mathbb{R}</span>. There are <span
class="math inline">n</span> items you can take with you, and for each
<span class="math inline">j\in\{1,2,\dots,n\}</span>, item <span
class="math inline">j</span> has some weight <span
class="math inline">w_j</span> and some value to you <span
class="math inline">v_j</span>. The goal is to select which items to
take with you, subject to the weight constraint, such that the total
value of the items taken is maximized.</p>
<p>We can model this problem with binary variables <span
class="math inline">x_j</span>, <span
class="math inline">j\in\{1,2,\dots,n\}</span> so that <span
class="math inline">x_j=1</span> if we choose to take item <span
class="math inline">j</span>, and otherwise <span
class="math inline">x_j=0</span>. The formulation looks like:</p>
<p><span class="math display">
\begin{align*}
\text{max}&amp;&amp; \sum_{j=1}^n v_jx_j&amp; \\
\text{s.t.}&amp;&amp; \sum_{j=1}^n w_jx_j&amp;\leq W \\
&amp;&amp;x_j&amp;\in\{0, 1\} \ \ \forall \ j\in\{1,2,\dots,n\}
\end{align*}
</span></p>
<h4>
Set covering
</h4>
<p>The <a href="https://en.wikipedia.org/wiki/Set_cover_problem">set
covering problem</a> is another classic OR problem with several
applications (the Southwestern Airlines crew scheduling problem in
sectionÂ <a href="#sec:ipWordProblems">5.3.3</a> was one example). In
abstract terms, the idea is that there is some set of items <span
class="math inline">S</span>, and some number of <span
class="math inline">n</span> subsets<a href="#fn54" class="footnote-ref"
id="fnref54" role="doc-noteref"><sup>54</sup></a> <span
class="math inline">S_j\subseteq S</span>, <span
class="math inline">j\in\{1,2,\dots,n\}</span>. The idea is to choose
some collection of the subsets so that every member of <span
class="math inline">S</span> is also present in at least one subset.</p>
<p>Ok, that was a mouthful, letâ€™s try to explain with an example.
Remember the airline crew scheduling problem referenced above? In that
case, the base set <span class="math inline">S</span> was the set of
flight segments that the airline needed to fly (SF to LA, Chicago to
Denver, etc.). The <span class="math inline">S_j</span> subsets were the
feasible flight sequences, like sequence 6 from the table that consisted
of flying from SF to Seattle, then Seattle to LA, and finally LA to SF.
Our job was to select the flight sequences such that every flight
segment was flown at least once<a href="#fn55" class="footnote-ref"
id="fnref55" role="doc-noteref"><sup>55</sup></a>.</p>
<p>Letâ€™s give one more example to motivate our formulation. Say a new
city is deciding where to place their fire stations. They require that
every neighborhood in the city can be reached in under 5 minutes by at
least one fire station. There are <span class="math inline">n</span>
potential building sites for the new stations, and <span
class="math inline">m</span> different neighborhoods in the city (so
<span class="math inline">S=\{1,2,\dots,m\}</span>). For each potential
building site <span class="math inline">j\in\{1,2,\dots,n\}</span>,
there is a set <span class="math inline">S_j\subseteq S</span> of
neighborhoods that can be reached from that site in under 5 minutes.
There is also a cost <span class="math inline">c_j\in\mathbb{R}</span>
associated with building a station at site <span
class="math inline">j</span>. How can the city minimize building costs
while still meeting the requirements?</p>
<p>Our formulation will include binary variables <span
class="math inline">x_j</span> with the interpretation that a station
will be built at site <span class="math inline">j</span> if and only if
<span class="math inline">x_j=1</span>. The formulation follows<a
href="#fn56" class="footnote-ref" id="fnref56"
role="doc-noteref"><sup>56</sup></a>:</p>
<p><span class="math display">
\begin{align*}
\text{min}&amp;&amp; \sum_{j=1}^n c_jx_j&amp; \\
\text{s.t.}&amp;&amp; \sum_{j:i\in S_j} x_j&amp;\geq 1 &amp; \forall
i\in\{1,2,\dots,m\}\\
&amp;&amp;x_j&amp;\in\{0, 1\} &amp; \forall \ j\in\{1,2,\dots,n\}
\end{align*}
</span></p>
<h4>
Traveling salesman
</h4>
<p>Weâ€™ve touched on the traveling salesman problem (TSP) already, way
back in sectionÂ <a href="#sec:tsp">2.2.1</a>. This is the famous problem
where a salesman has a list of cities to visit and needs to find the
shortest possible path that leads him through every city before
returning to the starting point.</p>
<p>To formalize things a bit, say the salesman needs to visit a list of
<span class="math inline">n</span> cities, and the distances between any
two cities <span class="math inline">i,j\in\{1,\dots,n\}, i\neq j</span>
is known and denoted as <span class="math inline">d_{ij}</span><a
href="#fn57" class="footnote-ref" id="fnref57"
role="doc-noteref"><sup>57</sup></a>. Weâ€™ll use binary variables <span
class="math inline">x_{ij}</span> for each <span
class="math inline">i,j\in\{1,\dots,n\}, i\neq j</span>, with the
interpretation that <span class="math inline">x_{ij}=1</span> if and
only if the salesman chooses to travel directly from city <span
class="math inline">i</span> to city <span class="math inline">j</span>
as part of his path. A first attempt at this model might look like
this:</p>
<p><span class="math display">
\begin{align*}
\text{min}&amp;&amp;
\sum_{i\in\{1,\dots,n\}}\sum_{j\in\{1,\dots,n\}:j\neq i}
d_{ij}x_{ij}&amp; \\
\text{s.t.}&amp;&amp; \sum_{j\in\{1,\dots,n\}:j\neq i} x_{ij} &amp;=
1&amp;&amp; \forall \ i\in\{1,\dots,n\}\\
&amp;&amp; \sum_{i\in\{1,\dots,n\}:i\neq j} x_{ij} &amp;= 1&amp;&amp;
\forall \ j\in\{1,\dots,n\}\\
&amp;&amp;x_{ij}&amp;\in\{0, 1\} &amp;&amp; \forall \ i\neq j
\end{align*}
</span></p>
<p>On first inspection, this <em>looks like</em> itâ€™s a correct
formulation. There are two groups of constraints above. In the first
group you set some <span class="math inline">i</span>, then amongst all
<span class="math inline">j\neq i</span> you ensure that exactly one
<span class="math inline">x_{ij}</span> equals <span
class="math inline">1</span>. This has the effect of enforcing that the
salesman leaves every town exactly once. The second group of constraints
does something similar, enforcing that the salesman arrives in every
town exactly once.</p>
<p>So, whatâ€™s the problem? It might not be evident initially<a
href="#fn58" class="footnote-ref" id="fnref58"
role="doc-noteref"><sup>58</sup></a>, but this formulation does nothing
to eliminate so-called <em>subtours</em> in the formulation. That is to
say, the feasible solutions to the above model include a solution where
the salesman visits, say, the first half of the cities in one tour and
the second half of the cities in a second, separate tour, with no links
between the two. A solution including subtours is illustrated below.</p>
<figure>
<img src="images/subtours.png" alt="TSP subtours (Wolsey 2020)" />
<figcaption aria-hidden="true">TSP subtours <span class="citation"
data-cites="wolsey2020">(<a href="#ref-wolsey2020"
role="doc-biblioref">Wolsey 2020</a>)</span></figcaption>
</figure>
<p>To recover a valid formulation, weâ€™ll need to include constraints
that make these subtours impossible. How might we do that? Consider the
above image, where we see a subtour among cities 3, 8, and 9. We can
keep this from happening by way of a constraint that ensures that the
salesman travels at least once between some city in the set <span
class="math inline">\{3, 8, 9\}</span> and another city not in that set,
i.e.Â a city in the complement set <span class="math inline">\{1, 2, 4,
5, 6, 7, 10\}</span>. That is, we can add the constraint:</p>
<p><span class="math display">
\sum_{i\in\{3, 8, 9\}}\sum_{j\in\{1, 2, 4, 5, 6, 7, 10\}}x_{ij} \geq 1
</span></p>
<p>Alternatively, we could write the constraint in terms of just the
original set <span class="math inline">\{3, 8, 9\}</span> by restricting
the number of edges between set members to less than 3 (the size of the
set).</p>
<p><span class="math display">
\sum_{i\in\{3, 8, 9\}}\sum_{j\in\{3, 8, 9\}}x_{ij} \leq 2
</span></p>
<p>Of course, this constraint will only eliminate the possibility of
that one subtour (and its complement). There are plenty of other
subtours possible, one for essentially every subset of <span
class="math inline">\{1,\dots,n\}</span>. So a truly valid formulation
for the TSP must include one of these <strong>subtour elimination
constraints</strong> for every<a href="#fn59" class="footnote-ref"
id="fnref59" role="doc-noteref"><sup>59</sup></a> subset <span
class="math inline">S\subseteq\{1,\dots,n\}</span><a href="#fn60"
class="footnote-ref" id="fnref60" role="doc-noteref"><sup>60</sup></a>.
Such a formulation including these constraints<a href="#fn61"
class="footnote-ref" id="fnref61" role="doc-noteref"><sup>61</sup></a>
could look like<a href="#fn62" class="footnote-ref" id="fnref62"
role="doc-noteref"><sup>62</sup></a>:</p>
<div class="mathSmall">
<p><span class="math display">
\begin{align*}
\text{min}&amp;&amp;
\sum_{i\in\{1,\dots,n\}}\sum_{j\in\{1,\dots,n\}:j\neq i}
d_{ij}x_{ij}&amp; \\
\text{s.t.}&amp;&amp; \sum_{j\in\{1,\dots,n\}:j\neq i} x_{ij} &amp;=
1&amp;&amp; \forall \ i\in\{1,\dots,n\}\\
&amp;&amp; \sum_{i\in\{1,\dots,n\}:i\neq j} x_{ij} &amp;= 1&amp;&amp;
\forall \ j\in\{1,\dots,n\}\\
&amp;&amp; \sum_{i\in S}\sum_{j\in S:i\neq j}x_{ij} &amp;\leq |S|-1
&amp;&amp; \forall \ S\subseteq \{1,\dots,n\}, S\neq\emptyset\\
&amp;&amp;x_{ij}&amp;\in\{0, 1\} &amp;&amp; \forall \ i\neq j
\end{align*}
</span></p>
</div>
<h2 data-number="5.4" id="solving-ips-with-software"><span
class="header-section-number">5.4</span> Solving IPs with software</h2>
<p>Letâ€™s now talk a bit about using software to solve integer
programming problems. This discussion is an extension to the one we
already had in sectionÂ <a href="#sec:lpSoftware">4.4</a>, where we spoke
about solvers in the context of linear programs. Much of what we said
there applies here as well, and there is significant overlap between the
best LP solvers and best IP solvers.</p>
<h3 data-number="5.4.1" id="solvers-1"><span
class="header-section-number">5.4.1</span> Solvers</h3>
<p>Speaking of, letâ€™s talk a bit more about IP solvers. In my opinion,
integer programs sit in something of a sweet spot where the types of
problems you can model are broad and useful, while at the same time
software has improved to a point that the models are viable to be solved
within reasonable time frames. To illustrate the effects of recent
software improvements, letâ€™s consider the case of Gurobi. The company
was founded 2008. As of their latest major version release (10.0) in
November 2022, <a
href="https://www.gurobi.com/features/gurobi-optimizer-delivers-unmatched-performance/">they
reported a 75x speedup</a> in solve times over the 1.1 version. Note
that this includes just the software improvements, not taking into
account the hardware advances in that period as well.</p>
<p>As mentioned earlier, there are basically two classes of solvers
available: the free, open source ones (<a
href="https://www.coin-or.org/">CBC</a>, <a
href="https://scipopt.org/">SCIP</a>, <a
href="https://highs.dev/">HiGHS</a>), and the commercial (paid) ones (<a
href="https://www.gurobi.com/">Gurobi</a>, <a
href="https://www.ibm.com/products/ilog-cplex-optimization-studio/cplex-optimizer">CPLEX</a>,
<a
href="https://www.fico.com/en/products/fico-xpress-optimization">Xpress</a>,
<a href="https://www.shanshu.ai/copt/">COPT</a>). As far as performance,
you generally get what you pay for. For the last couple decades,
regularly updated performance benchmarks for these solvers have been
published <span class="citation" data-cites="solverBenchmarks">(<a
href="#ref-solverBenchmarks" role="doc-biblioref"><span>â€œMittelmann
Benchmarks,â€</span> n.d.</a>)</span>. The <a
href="https://plato.asu.edu/ftp/milp.html">latest MIP benchmarks</a><a
href="#fn63" class="footnote-ref" id="fnref63"
role="doc-noteref"><sup>63</sup></a> are indicative of the usual trend,
that the commercial offerings can solve far more of the test instances
within the specified time limit, and the solve times are generally 5-10x
faster<a href="#fn64" class="footnote-ref" id="fnref64"
role="doc-noteref"><sup>64</sup></a>.</p>
<p>License costs for this software can be expensive, but you donâ€™t
always need to pay a lot to use them. You can usually download and use
the big commercial solvers on smaller problems in non-commercial
contexts, with limits on the number of variables and constraints in your
models. But the limits are such that they would generally not be
offering a large benefit over the free solvers anyway. More useful for
you, the commercial solvers do offer free licenses to students and
academics for non-commercial use, and these licenses do not come with
any size limitations<a href="#fn65" class="footnote-ref" id="fnref65"
role="doc-noteref"><sup>65</sup></a>. Lastly, even commercial users can
request free (but temporary) trial licenses for development purposes,
letting you â€œtry before you buyâ€ when you have a new use case in
mind.</p>
<h3 data-number="5.4.2" id="sec:solvingIpsWithPython"><span
class="header-section-number">5.4.2</span> Solving IPs with Python</h3>
<p>Now that weâ€™ve got some modeling down, letâ€™s see how we can implement
the models using Python code. In the following notebook, we illustrate
how to set up several of the models explored above, with special
attentions paid to the generalized models of sectionÂ <a
href="#sec:ipModelDataSep">5.3.4</a>.</p>
<script src="https://gist.github.com/73f227dfef3ba217c11fe80db18d6b5f.js"></script>
<h2 data-number="5.5" id="intro-to-complexity"><span
class="header-section-number">5.5</span> Intro to complexity</h2>
<p>Iâ€™ve mentioned already that IPs are much harder to solve than LPs,
and in playing with some of the last notebooks you may have seen how
solve times can increase with relatively small increases in the size of
the random instances we solve. It turns out there is some deep theory
that goes toward explaining why we have such difficulties. This theory
is known as <strong>computational complexity theory</strong>, which is
concerned with how much effort is required to solve problems of
different types. We wonâ€™t be able to do much more than scratch the
surface of it here, but I thought it was important enough to explain a
bit of the basics<a href="#fn66" class="footnote-ref" id="fnref66"
role="doc-noteref"><sup>66</sup></a>.</p>
<h3 data-number="5.5.1" id="combinatorial-explosion"><span
class="header-section-number">5.5.1</span> Combinatorial explosion</h3>
<p>Letâ€™s consider again that notebook we just saw in sectionÂ <a
href="#sec:solvingIpsWithPython">5.4.2</a>. Scroll down to the end where
we solve some randomly-generated TSP instances. Letâ€™s solve some more
instances, starting with 5 cities. When you run the cell, youâ€™ll see the
logs provided by the Gurobi solver. One of the first lines should read
â€œOptimize a model with 20 rows, 20 columns, and 60 nonzeros.â€ What does
this mean? Well, there is a matrix underlying every IP or LP we solve,
and these stats tell you about the size of this matrix. Just like when
we set up problems to solve simplex, the rows correspond to the model
constraints, and the columns correspond to the variables. The number of
non-zeros refers to the numerical values inside the matrix,
corresponding to each time a variable has a non-zero coefficient in some
constraint.</p>
<p>What weâ€™re interested in is how the problem size grows as we increase
the number of cities. Changing to 6 cities, we see â€œ47 rows, 30 columns
and 210 nonzerosâ€. For 7 cities it is â€œ70 rows, 42 columns and 756
nonzerosâ€. The following table shows the story for different numbers of
cities:</p>
<table>
<tr>
<th>
Cities
</th>
<th>
Rows
</th>
<th>
Columns
</th>
<th>
Nonzeros
</th>
</tr>
<tr>
<td>
5
</td>
<td>
20
</td>
<td>
20
</td>
<td>
60
</td>
</tr>
<tr>
<td>
6
</td>
<td>
47
</td>
<td>
30
</td>
<td>
210
</td>
</tr>
<tr>
<td>
7
</td>
<td>
70
</td>
<td>
42
</td>
<td>
756
</td>
</tr>
<tr>
<td>
8
</td>
<td>
170
</td>
<td>
56
</td>
<td>
1344
</td>
</tr>
<tr>
<td>
9
</td>
<td>
264
</td>
<td>
72
</td>
<td>
2232
</td>
</tr>
<tr>
<td>
10
</td>
<td>
647
</td>
<td>
90
</td>
<td>
8550
</td>
</tr>
<tr>
<td>
11
</td>
<td>
1034
</td>
<td>
110
</td>
<td>
28380
</td>
</tr>
</table>
<p>Immediately we see that the number of variables grow pretty quickly,
but itâ€™s nothing compared to the numbers of constraints and nonzeros.
And there is a good reason I stopped the table at 11 cities: choosing 12
cities or more takes us beyond the size limit of the Gurobi trial
license. But by altering the code (not actually adding constraints, just
counting how often we would have done so) we can continue counting the
number of variables and constraints that would be added for larger
problem (Iâ€™m ignoring nonzeros now). I went ahead and did that for a few
more numbers of cities, and Iâ€™ll show these extended results in the
following plot:</p>
<div class="plotlyLineChart" data-plot-data="[
    {
        &quot;x&quot;: [5,6,7,8,9,10,11,12,13,14,15],
        &quot;y&quot;: [20,47,70,170,264,647,1034,2521,4108,9921,16398],
        &quot;type&quot;: &quot;scatter&quot;,
        &quot;name&quot;: &quot;Rows&quot;
    }, {
        &quot;x&quot;: [5,6,7,8,9,10,11,12,13,14,15],
        &quot;y&quot;: [20,30,42,56,72,90,110,132,156,182,210],
        &quot;type&quot;: &quot;scatter&quot;,
        &quot;name&quot;: &quot;Columns&quot;
    }
]"
data-plot-layout="{&quot;xaxis&quot;: {&quot;title&quot;: &quot;Cities&quot;}}">

</div>
<p>The plot for the number of columns just looks like a straight line,
but itâ€™s really not. You can toggle lines on or off in the plot by
clicking on the corresponding legend text, go ahead and do that to see
the columns line by itself. It has an upward curve as well. In fact, we
can easily characterize the number of columns in the model in terms of
the number of cities. The variables are simply pairs of cities, so if
there are <span class="math inline">n</span> cities then there are <span
class="math inline">n(n-1)\approx n^2</span> city pairs<a href="#fn67"
class="footnote-ref" id="fnref67" role="doc-noteref"><sup>67</sup></a>.
But the number of rows in the model is largely determined by the number
of subtour elimination constraints, and we have one of those for every
<em>subset</em> of the <span class="math inline">n</span> cities<a
href="#fn68" class="footnote-ref" id="fnref68"
role="doc-noteref"><sup>68</sup></a>. For a set with <span
class="math inline">n</span> elements, there are <span
class="math inline">2^n</span> possible subsets<a href="#fn69"
class="footnote-ref" id="fnref69"
role="doc-noteref"><sup>69</sup></a>.</p>
<p>So even though the <span class="math inline">n^2</span> columns grows
markedly faster than linear, in the face of the truly exponential growth
of <span class="math inline">2^n</span> constraints the plot might as
well be a straight line. The difference between polynomial (e.g.Â <span
class="math inline">n^2</span>) and exponential growth is at the center
of the theory we will now explore. Unfortunately, for most integer
programs, an exponential growth rate like this is difficult (perhaps
impossible) to avoid.</p>
<h3 data-number="5.5.2" id="complexity-definitions"><span
class="header-section-number">5.5.2</span> Complexity â€œdefinitionsâ€</h3>
<p>Weâ€™d now like to formalize the type of discussion we had above, where
we tried to tie the <em>size</em> of a problem (e.g., the number of
cities in a TSP) to the <em>number of steps</em> required to solve the
problem (e.g., the number of constraints we need to generate). But since
complexity isnâ€™t a main focus of this course, we wonâ€™t be very formal
with our definitions. For the purposes of this class, weâ€™ll define the
<strong>size</strong> of an instance of a given problem to be the size
of a file on your computer that saves all the problem data. Of course,
there could be several different ways to save the same problem data,
some being more efficient than others. So letâ€™s say, again very
informally, that the file is â€œclose toâ€ as efficient as possible at
saving the data.</p>
<p>For a TSP with <span class="math inline">n</span> cities, how big of
a file will we need? At a minimum, weâ€™ll need to save the distances
between each pair of cities, and there are <span
class="math inline">\approx n^2</span> of these pairs to consider.
Furthermore, the actual distance numbers being saved also make a
difference, since it takes less disk space to save a file with the
number 1 in it than a file with the number 1,000,000,000,000,000<a
href="#fn70" class="footnote-ref" id="fnref70"
role="doc-noteref"><sup>70</sup></a>. But it is important to note that
the amount of space needed to store a number is not proportional to the
number itself, but rather its logarithm, in the same way that it doesnâ€™t
take twice as many digits to write 300 than it does to write 150 even
though the first number is twice the second. They both take three digits
to write, because <span class="math inline">2 &lt;
\log_{10}(150)\approx\log_{10}(300) &lt; 3</span><a href="#fn71"
class="footnote-ref" id="fnref71"
role="doc-noteref"><sup>71</sup></a>.</p>
<p>Now, say you have an algorithm that solves a given problem type.
Weâ€™re interested in the number of â€œelementary calculationsâ€ (think
addition, multiplication, etc.) required to solve any instance of a
problem with size <span class="math inline">s</span>. That number of
steps, written as a function of <span class="math inline">s</span>, is
called the <strong>running time</strong> of the algorithm. Weâ€™ll say
that an algorithm is <strong>polynomial</strong> (or
<strong>polynomial-time</strong>) if the number of steps required is
<span class="math inline">&lt; s^r</span> for some <span
class="math inline">r\in\mathbb{R}</span>.</p>
<p>Although weâ€™re ultimately working with optimization problems, the
questions weâ€™ll be focusing on here relate to <strong>decision
problems</strong>, i.e.Â questions for which the answer is either yes or
no. But the two notions are related, in that given any optimization
problem we can form a â€œdecision versionâ€ of the problem. For example,
the TSP asks you to find a minimum length tour that visits every city.
The decision version would be something like â€œis there a tour that
visits every city with length at most <span
class="math inline">k</span>â€ for some number <span
class="math inline">k</span><a href="#fn72" class="footnote-ref"
id="fnref72" role="doc-noteref"><sup>72</sup></a>.</p>
<p>Finally, I should note that while it may look like Iâ€™m being lazy in
approximating e.g.Â <span class="math inline">n(n-1)\approx n^2</span>
(for the number of variables in our TSP model), it is actually a defacto
rule in the theory to â€œnot sweat the small stuffâ€<a href="#fn73"
class="footnote-ref" id="fnref73" role="doc-noteref"><sup>73</sup></a>.
The important thing is how the function grows as <span
class="math inline">n</span> grows, and for <span
class="math inline">n(n-1) = n^2 - n</span> and <span
class="math inline">n</span> very large, that <span
class="math inline">-n</span> term adds very little. Similarly, in the
TSP model we only added a constraint for about half of the possible
subsets, so there were more like <span class="math inline">2^n/2</span>
constraints. But weâ€™re comfortable approximating that by <span
class="math inline">2^n</span> because what matters is more the
<em>shape</em> of the curve than the magnitude.<a href="#fn74"
class="footnote-ref" id="fnref74"
role="doc-noteref"><sup>74</sup></a></p>
<h3 data-number="5.5.3" id="the-classes-mathcalp-and-mathcalnp"><span
class="header-section-number">5.5.3</span> The classes <span
class="math inline">\mathcal{P}</span> and <span
class="math inline">\mathcal{NP}</span></h3>
<p>With these loose definitions in hand, weâ€™re now ready to discuss the
two most famous complexity classes, and a way to win a million
dollars.</p>
<p>The first of these famous classes is <span
class="math inline">\mathcal{NP}</span><a href="#fn75"
class="footnote-ref" id="fnref75" role="doc-noteref"><sup>75</sup></a>.
For a problem to be in <span class="math inline">\mathcal{NP}</span>, it
must be true that given any instance for which the answer is â€œyesâ€,
there is a polynomial-time algorithm verifying the â€œyesâ€ answer.
Importantly, this algorithm is allowed to take a â€œsmallâ€ (polynomial in
the instance size) â€œhintâ€ as input as well as the instance. The idea is
that if someone found out the answer, they could prove it to you
easily.</p>
<p>Taking TSP as an example, if I claim for some instance that there
<em>is</em><a href="#fn76" class="footnote-ref" id="fnref76"
role="doc-noteref"><sup>76</sup></a> a tour with length at most <span
class="math inline">k</span>, I can just provide you with a conforming
tour (ordering of the cities), then you can verify it yourself in
polynomial time by checking the length of that tour. So TSP is in the
class <span class="math inline">\mathcal{NP}</span>, as are (the
decision versions of) LP, IP, and all the optimization problems weâ€™ll
encounter in this class.</p>
<p>The next important class is <span
class="math inline">\mathcal{P}</span>, which is the class of decision
problems in <span class="math inline">\mathcal{NP}</span> for which
there exists a polynomial-time algorithm to solve it (i.e.Â determine
whether the answer is â€œyesâ€ or â€œnoâ€). This would include simple problems
like determining if a list of numbers is in numerical order. It also
includes some perhaps surprising problems, like determining whether a
given number is prime. In fact, the decision version of our old friend
linear programming is also in the class <span
class="math inline">\mathcal{P}</span><a href="#fn77"
class="footnote-ref" id="fnref77"
role="doc-noteref"><sup>77</sup></a>.</p>
<p>By way of the above definition, we know that <span
class="math inline">\mathcal{P}\subseteq\mathcal{NP}</span>, i.e.Â every
problem that is polynomial-time solvable is polynomial-time verifiable.
A reasonable question, then, is whether there are problems in <span
class="math inline">\mathcal{NP}</span> that are not in <span
class="math inline">\mathcal{P}</span> (i.e.Â problems that are easy to
verify but difficult to solve). Or is that not the case, so that <span
class="math inline">\mathcal{P}=\mathcal{NP}</span>? The answer isâ€¦
well, we actually donâ€™t know the answer! People have been working at
this since the 1970s when these classes were first formalized, but a
proof either way has still remained elusive. There would be interesting
consequences to a proof in either direction<a href="#fn78"
class="footnote-ref" id="fnref78" role="doc-noteref"><sup>78</sup></a>.
The interest is so high that in the year 2000 the Clay Mathematics
Institute named the <span class="math inline">\mathcal{P}</span>
vs.Â <span class="math inline">\mathcal{NP}</span> problem among its 7 <a
href="https://www.claymath.org/millennium-problems/">Millennium Prize
Problems</a>, a list of important unsolved problems in a wide array of
mathematical fields. The institute will award $1 million to anyone who
resolves a problem from the list<a href="#fn79" class="footnote-ref"
id="fnref79" role="doc-noteref"><sup>79</sup></a>.</p>
<h3 data-number="5.5.4"
id="mathcalnp-complete-and-mathcalnp-hard-problems"><span
class="header-section-number">5.5.4</span> <span
class="math inline">\mathcal{NP}</span>-complete and <span
class="math inline">\mathcal{NP}</span>-hard problems</h3>
<p>While the main question in the field, <span
class="math inline">\mathcal{P}\stackrel{?}{=}\mathcal{NP}</span>,
remains unsolved, there are still interesting things to be said about
problems inside <span class="math inline">\mathcal{NP}</span>. One of
the most important notions is that of <span
class="math inline">\mathcal{NP}</span>-completeness. Central to this
theory is the notion of a <strong>problem reduction</strong>, which is a
way of taking an instance of one problem, applying some â€œsmallâ€
(polynomially many) number of tweaks to it, then recovering an instance
of a new problem. A problem is said to be <strong><span
class="math inline">\mathcal{NP}</span>-complete</strong> if it is in
<span class="math inline">\mathcal{NP}</span> and additionally there
exists a way to reduce any other <span
class="math inline">\mathcal{NP}</span> problem to it<a href="#fn80"
class="footnote-ref" id="fnref80"
role="doc-noteref"><sup>80</sup></a>.</p>
<p>Because of this property, one can think of the class of <span
class="math inline">\mathcal{NP}</span>-complete problems as the set of
the â€œhardestâ€ problems in <span class="math inline">\mathcal{NP}</span>.
This is because a polynomial-time algorithm for an <span
class="math inline">\mathcal{NP}</span>-complete problem would
automatically imply a polynomial-time algorithm for any other <span
class="math inline">\mathcal{NP}</span>-complete problem (by first
applying the polynomial-time reduction, then running the polynomial-time
solution algorithm). It turns out that (the decision version of) IP, as
well as TSP, knapsack, set covering, and several other interesting
problems we can model with IPs, are all <span
class="math inline">\mathcal{NP}</span>-complete.</p>
<p>There is also a related notion called <span
class="math inline">\mathcal{NP}</span>-hardness. A problem is
considered <strong><span
class="math inline">\mathcal{NP}</span>-hard</strong> if, once again,
there exists a polynomial-time reduction from any <span
class="math inline">\mathcal{NP}</span> problem to it. But unlike with
<span class="math inline">\mathcal{NP}</span>-completeness, an <span
class="math inline">\mathcal{NP}</span>-hard problem does not need to be
a member of <span class="math inline">\mathcal{NP}</span> itself. This
allows us to talk about problems of interest that are not decision
problems, e.g.Â optimization problems like integer programming.</p>
<h3 data-number="5.5.5" id="what-makes-ips-hard"><span
class="header-section-number">5.5.5</span> What makes IPs hard</h3>
<p>It is this theory that lies at the heart of why IPs are so hard to
solve in practice. Since nobody has proven <span
class="math inline">\mathcal{P}\neq\mathcal{NP}</span> we cannot say
with <em>absolute certainty</em> that no efficient method for solving
IPs exists. But the fact remains that IP is an <span
class="math inline">\mathcal{NP}</span>-hard problem, and after decades
of research, nobody has been able to reduce theoretical run times down
below something exponential in the input size. And this is true not just
for IPs, but for <em>any</em> of the <a
href="https://en.wikipedia.org/wiki/List_of_NP-complete_problems">myriad
<span class="math inline">\mathcal{NP}</span>-complete</a> and <span
class="math inline">\mathcal{NP}</span>-hard problems. Even beyond the
â€œnobody has done it yetâ€ argument, there are other interesting reasons
why most would conjecture <span
class="math inline">\mathcal{P}\neq\mathcal{NP}</span> over <span
class="math inline">\mathcal{P}=\mathcal{NP}</span> (see e.g.Â <a
href="https://scottaaronson.blog/?p=1720">this blog post</a> from a
well-known theoretical computer scientist). Given the state of things,
what weâ€™ll see in this chapter is that the solution methods currently
used for IPs can all induce exponentially<a href="#fn81"
class="footnote-ref" id="fnref81" role="doc-noteref"><sup>81</sup></a>
growing run-times.</p>
<p>But Iâ€™d like to point out, itâ€™s the run times that matter here, and
not the number of possible solutions. Letâ€™s take TSP as an example, for
which there are indeed exponentially many possible solutions, <span
class="math inline">2^n</span> potential tours for an <span
class="math inline">n</span>-city instance. But the number of potential
solutions is not the factor that determines complexity. After all, if I
gave you a list of <span class="math inline">n</span> cities and asked
you to put it in alphabetical order, you wouldnâ€™t lament the <span
class="math inline">2^n</span> potential orderings of the cities and
declare it impossible to find the correct one (the best <a
href="https://en.wikipedia.org/wiki/Sorting_algorithm">sorting
algorithm</a> run times scale like <span class="math inline">n\log
n</span>). And linear programs have <em>infinitely many</em> feasible
solutions, but as weâ€™ve discussed LPs are solvable in polynomial time<a
href="#fn82" class="footnote-ref" id="fnref82"
role="doc-noteref"><sup>82</sup></a>.</p>
<h3 data-number="5.5.6" id="all-hope-is-not-lost"><span
class="header-section-number">5.5.6</span> All hope is not lost</h3>
<p>Given the above, it seems thereâ€™s ample reason to be pessimistic
about the quest to find sub-exponential algorithms for integer programs.
Does that mean that, given some integer program of more than modest
size, we should simply bow our heads and wallow in misery, knowing an
optimal solution will forever elude us? Of course not!</p>
<p>First off, there is still a possibility for a proof that <span
class="math inline">\mathcal{P}=\mathcal{NP}</span>! But even in a world
where <span class="math inline">\mathcal{P}\neq\mathcal{NP}</span>, we
still have a chance. The theory is all about how run times grow as the
size goes to infinity, but there is nothing in the theory that says at
what size the problems become intractable. Itâ€™s entirely possible that
the size of the problems youâ€™re working on are small enough to solve in
reasonable time.</p>
<p>For example, TSPs have been solved where the number of cities is in
the 10,000s, and problems with hundreds of cities can often be solved
within seconds<a href="#fn83" class="footnote-ref" id="fnref83"
role="doc-noteref"><sup>83</sup></a>. Further, the knapsack problem is
<span class="math inline">\mathcal{NP}</span>-hard, but algorithms exist
for it where the run time is exponential only in the size of the largest
value coefficient, not the number of items considered. So if youâ€™re
dealing with knapsack problems where the objective value coefficients
are guaranteed to not be too large, solving the problem is suddenly
efficient.</p>
<p>Another note is that weâ€™re talking about optimization problems where
we want to provably find the best answer. But in practice, maybe you
donâ€™t need the absolute best answer. Perhaps it is possible to run a
heuristic that finds a â€œgood enoughâ€ answer in a reasonable amount of
time. (Although there is a whole section of complexity theory dedicated
to approximation algorithms as well, and sometimes finding decent
approximations is just as hard as finding actual optimal solutions).</p>
<p>All this to say - IPs are hard in general, and some are just too big
to solve in a reasonable amount of time. But the gap between <span
class="math inline">0</span> and â€œtoo bigâ€ can be substantial, and the
number of useful instances within that gap is immense. Furthermore, a
good knowledge of the usual solution techniques can help you model your
problem in a way that is more likely to be solvable.</p>
<!-- {insertSection:sections/integer_programming/branch_and_bound.md} -->
<!-- {insertSection:sections/integer_programming/cutting_planes.md} -->
<!-- {insertSection:sections/integer_programming/easy_ips.md} -->
<!-- {insertSection:sections/integer_programming/theory_to_practice.md} -->
<!-- {insertSection:sections/integer_programming/notes.md} -->
<h1 data-number="6" id="appendix"><span
class="header-section-number">6</span> Appendix</h1>
<h2 data-number="6.1" id="sec:symbols"><span
class="header-section-number">6.1</span> Special symbols</h2>
<ul>
<li><span class="math inline">\mathbb{R}</span>: The set of real
numbers, i.e.Â anything on the number line between (though not
including!) <span class="math inline">-\infty</span> and <span
class="math inline">\infty</span>.</li>
<li><span class="math inline">\mathbb{R}_+</span>: The set of
non-negative real numbers, i.e.Â anything in <span
class="math inline">\mathbb{R}</span> that is greater than or equal to
0.</li>
<li><span class="math inline">\mathbb{I}</span>: The set of integer
numbers, i.e.Â whole numbers from the set <span
class="math inline">\mathbb{R}</span>.</li>
<li><span class="math inline">\mathbb{I}_+</span>: The set of
non-negative integer numbers, i.e.Â anything in <span
class="math inline">\mathbb{I}</span> that is greater than or equal to
0.</li>
<li><span class="math inline">\{\cdots\}</span>: Set notation. Items
inside the curly brackets are the elements of the set, so <span
class="math inline">\{0,1\}</span> is the 2-element set consisting of
just the numbers 0 and 1.</li>
<li><span class="math inline">\in</span>: Set inclusion. When we write
<span class="math inline">x\in S</span>, we mean that <span
class="math inline">x</span> is an element of the set <span
class="math inline">S</span>. For example, we could write <span
class="math inline">\pi\in\mathbb{R}</span>, meaning the number <span
class="math inline">\pi</span> is a real number.</li>
<li><span class="math inline">\subseteq</span>: Subset. For two sets
<span class="math inline">S, S&#39;</span>, we say <span
class="math inline">S&#39;\subseteq S</span> (said â€œ<span
class="math inline">S&#39;</span> is a subset of <span
class="math inline">S</span>â€) if every element of <span
class="math inline">S&#39;</span> is also an element of <span
class="math inline">S</span>.</li>
<li><span class="math inline">|S|</span>: Size of a set. This denotes
the number of elements in a set, so e.g.Â <span
class="math inline">|\{1,5,7,12\}|=4</span>.</li>
<li><span class="math inline">\emptyset</span>: Empty set. A set with no
elements.</li>
<li><span class="math inline">\forall</span>: For all. We use this
symbol when we want to specify that something should be done for all
elements in some set. So if weâ€™re writing out the constraints for some
model and we say <span class="math inline">x_j\geq 0\ \forall\ j\in\{1,
2, \cdots, n\}</span> weâ€™re just saying that each of <span
class="math inline">x_1, x_2, \cdots, x_n</span> should be
non-negative.</li>
<li><span class="math inline">\{x: x\textit{ satisfies some
condition}\}</span>: Conditional set. This represents the set of all
<span class="math inline">x</span> such that <span
class="math inline">x</span> satisfies the condition to the right of the
colon (:). For example, <span class="math inline">\{n\in\mathbb{I}:5\leq
n\leq 10\}</span> is the set of all integers between 5 and 10,
i.e.Â <span class="math inline">\{5,6,7,8,9,10\}</span></li>
<li><span class="math inline">S^m</span>: The set of vectors with <span
class="math inline">m</span> elements, all of which are from some set
<span class="math inline">S</span>. For example, <span
class="math inline">\mathbb{R}^3</span> is the set of 3-element, real
number vectors. So we could say <span class="math display">
    \begin{bmatrix}1 \\ 2.64 \\ -3\end{bmatrix}\in\mathbb{R}^3.
</span></li>
<li><span class="math inline">S^{m\times n}</span>: The set of matrices
with <span class="math inline">m</span> rows and <span
class="math inline">n</span> columns, whose elements are from some set
<span class="math inline">S</span>. For example, <span
class="math inline">\mathbb{I}^{m\times n}</span> is the set of <span
class="math inline">m\times n</span> matrices whose entries are all
integers. So we could say <span class="math display">
\begin{bmatrix}4 &amp; 3 &amp; 9 &amp; 6\\ 0 &amp; 4 &amp; 8 &amp; 5\\ 7
&amp; 7 &amp; 2 &amp; 1\end{bmatrix} \in \mathbb{I}^{3\times 4}.
</span></li>
<li><span class="math inline">\mathbf{0}</span>: A matrix (or vector)
with all entries equal to 0 (the size of the matrix is usually clear by
context).</li>
<li><span class="math inline">\mathbf{I}</span>: A square matrix with
all entries equal to 0, except the diagonal where all entries equal 1
(the size of the matrix is usually clear by context). This looks like:
<span class="math display">\begin{bmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 1 \\
\end{bmatrix}</span></li>
<li><span class="math inline">\Leftrightarrow</span>: If and only if. It
indicates the the statement to the left is logically equivalent to the
statement on the right, e.g.Â <span class="math inline">a &gt; b
\Leftrightarrow -a &lt; -b</span>.</li>
<li><span class="math inline">\lfloor x \rfloor</span>: The â€œfloorâ€ of
the number <span class="math inline">x\in\mathbb{R}</span>, i.e.Â the
value resulting from rounding <span class="math inline">x</span> down to
the nearest integer. So <span class="math inline">\lfloor 1.3
\rfloor=1</span>.</li>
<li><span class="math inline">\lceil x \rceil</span>: The â€œceilingâ€ of
the number <span class="math inline">x\in\mathbb{R}</span>, i.e.Â the
value resulting from rounding <span class="math inline">x</span> up to
the nearest integer. So <span class="math inline">\lceil 1.3
\rceil=2</span>.</li>
</ul>
<h2 data-number="6.2" id="sec:linearAlgebra"><span
class="header-section-number">6.2</span> Linear algebra review</h2>
<p>Linear algebra is the study of math involving matrices, vectors, and
linear transformations. A <strong>matrix</strong> (the basic object of
linear algebra) is a rectangular array of numbers. For example,</p>
<p><span class="math display">
\mathbf{A}=\begin{bmatrix} 2 &amp; 4 \\ 7 &amp; 0 \\ 6 &amp; 3
\end{bmatrix}
</span></p>
<p>is a <span class="math inline">3\times 2</span> matrix. A matrix is
said to be <strong>square</strong> if it has the same number of rows and
columns.</p>
<p>In these notes, we will usually denote matrices with boldface,
uppercase letters.</p>
<h3 data-number="6.2.1" id="sec:matrixMath"><span
class="header-section-number">6.2.1</span> Matrix math</h3>
<p>We say Matrices <span class="math inline">\mathbf{A}</span>, <span
class="math inline">\mathbf{B}</span> are <strong>equal</strong> if
<em>all</em> of their elements are equal. First off, that means <span
class="math inline">\mathbf{A}</span> and <span
class="math inline">\mathbf{B}</span> must have the same number of rows
<span class="math inline">m</span> and columns <span
class="math inline">n</span>. Additionally, if we write notate the
entries of the matrices like:</p>
<p><span id="eq:matrixDef" class="eqnos"><span class="math display">
\mathbf{A} = \begin{bmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn} \\
\end{bmatrix}
</span><span class="eqnos-number">(16)</span></span></p>
<p>and</p>
<p><span class="math display">
\mathbf{B} = \begin{bmatrix}
b_{11} &amp; b_{12} &amp; \cdots &amp; b_{1n} \\
b_{21} &amp; b_{22} &amp; \cdots &amp; b_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
b_{m1} &amp; b_{m2} &amp; \cdots &amp; b_{mn} \\
\end{bmatrix}.
</span></p>
<p>Then we say <span class="math inline">\mathbf{A}=\mathbf{B}\ </span>
if and only if <span class="math inline">\ a_{11}=b_{11}</span>, <span
class="math inline">a_{12}=b_{12}</span>, â€¦ and so on.</p>
<p><strong>Addition</strong> is only defined for two matrices of the
same size. For two <span class="math inline">m\times n</span> matrices
<span class="math inline">\mathbf{A}</span> and <span
class="math inline">\mathbf{B}</span>, we have</p>
<p><span class="math display">
\mathbf{A} + \mathbf{B} = \begin{bmatrix}
a_{11} + b_{11} &amp; a_{12} + b_{12} &amp; \cdots &amp; a_{1n} + b_{1n}
\\
a_{21} + a_{21} &amp; a_{22} + a_{22} &amp; \cdots &amp; a_{2n} + a_{2n}
\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{m1} + a_{m1} &amp; a_{m2} + a_{m2} &amp; \cdots &amp; a_{mn} + a_{mn}
\\
\end{bmatrix}
</span></p>
<p>For matrices, <strong>multiplication</strong> <span
class="math inline">\mathbf{A}\mathbf{B}</span> is only defined when the
the second dimension of <span class="math inline">\mathbf{A}</span>
equals the first dimension of <span
class="math inline">\mathbf{B}</span>. So, if <span
class="math inline">\mathbf{A}</span> is an <span
class="math inline">m\times n</span> matrix (for some <span
class="math inline">m, n</span>), we need <span
class="math inline">B</span> to be an <span class="math inline">n\times
s</span> matrix (for some <span class="math inline">s</span>). In this
case, we define their product as the matrix <span
class="math inline">\mathbf{C}</span> having entries</p>
<p><span class="math display">
c_{ij} = \sum_{k=1}^n a_{ik}b_{kj}.
</span></p>
<p>Here is a small example to see it in action:</p>
<p><span class="math display">
\begin{align*}
\begin{bmatrix}0&amp;1\\2&amp;3\\4&amp;5\end{bmatrix}
\begin{bmatrix}6&amp;7\\8&amp;9\end{bmatrix}
&amp;=
\begin{bmatrix}
0\cdot6 + 1\cdot8 &amp; 0\cdot7 + 1\cdot9 \\
2\cdot6 + 3\cdot8 &amp; 2\cdot7 + 3\cdot9 \\
4\cdot6 + 5\cdot8 &amp; 4\cdot7 + 5\cdot9 \\
\end{bmatrix}\\
&amp;=
\begin{bmatrix}8&amp;9\\36&amp;41\\64&amp;73\end{bmatrix}
\end{align*}
</span></p>
<p>There is a simpler form of multiplication available between a matrix
<span class="math inline">\mathbf{A}</span> and a scalar (a single
number) <span class="math inline">s</span>, where each element of the
product is simply the corresponding element of <span
class="math inline">\mathbf{A}</span> multiplied by <span
class="math inline">s</span>, i.e.</p>
<p><span class="math display">
s\mathbf{A}= \begin{bmatrix}
sa_{11} &amp; sa_{12} &amp; \cdots &amp; sa_{1n} \\
sa_{21} &amp; sa_{22} &amp; \cdots &amp; sa_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
sa_{m1} &amp; sa_{m2} &amp; \cdots &amp; sa_{mn} \\
\end{bmatrix}
</span></p>
<h3 data-number="6.2.2" id="properties-of-matrix-operations"><span
class="header-section-number">6.2.2</span> Properties of matrix
operations</h3>
<p>The above matrix operations satisfy the following properties:</p>
<ul>
<li>Associativity of addition:<span class="math display">(\mathbf{A}+
\mathbf{B}) + \mathbf{C} = \mathbf{A}+ (\mathbf{B} +
\mathbf{C})</span></li>
<li>Associativity of multiplication:<span
class="math display">\mathbf{A}(\mathbf{B}\mathbf{C}) =
(\mathbf{A}\mathbf{B})\mathbf{C}</span></li>
<li>Commutativity of addition:<span class="math display">\mathbf{A}+
\mathbf{B} = \mathbf{B} + \mathbf{A}</span></li>
<li>Distributivity:<span class="math display">\mathbf{A}(\mathbf{B} +
\mathbf{C}) = \mathbf{A}\mathbf{B} + \mathbf{A}\mathbf{C}</span></li>
</ul>
<p>You may notice that multiplication does not commute, i.e.Â <span
class="math inline">\mathbf{A}\mathbf{B} \neq
\mathbf{B}\mathbf{A}</span>. Indeed, in the general case where <span
class="math inline">\mathbf{A}</span> is an <span
class="math inline">m\times n</span> matrix and <span
class="math inline">\mathbf{B}</span> is an <span
class="math inline">n\times s</span> matrix, the product <span
class="math inline">\mathbf{B}\mathbf{A}</span> is not even defined if
<span class="math inline">m\neq s</span>. Even if <span
class="math inline">m=s</span> and the product is defined, the result
needs not be the same.</p>
<h3 data-number="6.2.3" id="special-matrices"><span
class="header-section-number">6.2.3</span> Special matrices</h3>
<p>A <strong>vector</strong> is a special type of matrix with either a
single column or a single row, e.g.</p>
<p><span class="math display">
\mathbf{x}=\begin{bmatrix} 1 \\ 9 \\ 3 \end{bmatrix}
</span></p>
<p>is a <strong>column vector</strong> and <span
class="math display">\mathbf{x}=\begin{bmatrix} 1 &amp; 9 &amp; 3
\end{bmatrix}</span> is a <strong>row vector</strong>. In these notes,
vectors will usually be denoted with with boldface, lowercase letters. A
convention in some texts, which we will not follow here, is for vectors
to be assumed as column vectors unless explicitly transposed. For these
notes, we will let context dictate whether a vector is a row vector or a
column vector (it is usually clear).</p>
<p>An <strong>identity matrix</strong>, denoted by <span
class="math inline">\mathbf{I}</span>, is a square vector whose elements
are all 0s expect for 1s along the diagonal, i.e.</p>
<p><span class="math display">
\mathbf{I}= \begin{bmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 1 \\
\end{bmatrix}
</span></p>
<p>The main property of identity matrices is that multiplying another
(properly sizes) matrix does not alter it, i.e.Â we have</p>
<p><span class="math display">
\mathbf{I}\mathbf{A}= \mathbf{A},\quad \mathbf{A}\mathbf{I}= \mathbf{A}.
</span></p>
<p>Note that we usually donâ€™t explicitly specify the size of <span
class="math inline">\mathbf{I}</span>, since it is usually clear from
the context.</p>
<p>The <strong>null matrix</strong> or <strong>zero matrix</strong>,
denoted by <span class="math inline">\mathbf{0}</span> is a matrix (or
vector) with all entries equal to 0. Again, we will usually not
explicitly specify its size since it will be clear from context. The
zero matrix satisfies:</p>
<p><span class="math display">
\mathbf{A}+ \mathbf{0}= \mathbf{A},\quad \mathbf{0}\mathbf{A}=
\mathbf{0},\quad \mathbf{A}\mathbf{0}= \mathbf{A}.
</span></p>
<p>Note that <span class="math inline">\mathbf{I}</span> and <span
class="math inline">\mathbf{0}</span> play roles in matrix operations
similar to the roles of 1 and 0 (respectively) in arithmetic.</p>
<h3 data-number="6.2.4" id="rank-and-inverse"><span
class="header-section-number">6.2.4</span> Rank and inverse</h3>
<p>A set of vectors <span class="math inline">\mathbf{x}_1,
\mathbf{x}_2, \dots, \mathbf{x}_m</span> is said to be <strong>linearly
dependent</strong> if there exists <span class="math inline">m</span>
numbers <span class="math inline">c_1, c_2, \dots, c_m</span>, some of
which are not zeros, such that</p>
<p><span class="math display">
c_1\mathbf{x}_1 + c_2\mathbf{x}_2 + \cdots + c_m\mathbf{x}_m =
\mathbf{0}.
</span></p>
<p>Otherwise, the vectors are said to be <strong>linearly
independent</strong>. For example, the vectors</p>
<p><span class="math display">
\mathbf{x}_1 = [1, 1, 1],\quad \mathbf{x}_2 = [0, 1, 1],\quad
\mathbf{x}_3 = [2, 5, 5],
</span></p>
<p>if we take <span class="math inline">c_1 = 2</span>, <span
class="math inline">c_2 = 3</span>, and <span class="math inline">c_3 =
-1</span> then we have</p>
<p><span class="math display">
\begin{align*}
2\mathbf{x}_1 + 3\mathbf{x}_2 - x_3 &amp; = [2, 2, 2] + [0, 3, 3] - [2,
5, 5]\\
                    &amp; = [0, 0, 0]
\end{align*}
</span></p>
<p>so the vectors are linearly dependent.</p>
<p>The <strong>rank</strong> of a set of vectors is the largest number
of linearly independent vectors that can be chosen from the space. So
e.g.Â the rank of <span class="math inline">\{\mathbf{x}_1, \mathbf{x}_2,
\mathbf{x}_3\}</span> from above is 2.</p>
<p>Matrices also have a notion of rank. The <strong>row rank</strong> of
a matrix is the rank of its set of row vectors, while the <strong>column
rank</strong> of the matrix is the rank of its set of column vectors. An
important result in linear algebra is that, for any matrix, the row rank
and column rank are the same. Thus we can talk about the
<strong>rank</strong> of a matrix, being equal to either the row rank or
the column rank.</p>
<p>Suppose <span class="math inline">\mathbf{A}</span> is an <span
class="math inline">n\times n</span> (square) matrix. We say <span
class="math inline">\mathbf{A}</span> is <strong>non-singular</strong>
if it has rank <span class="math inline">n</span>. Otherwise, if the
rank is less than <span class="math inline">n</span>, we way it is
<strong>singular</strong>. Importantly, if <span
class="math inline">\mathbf{A}</span> is non-singular, there is a unique
non-singular matrix <span class="math inline">\mathbf{A}^{-1}</span>
such that</p>
<p><span class="math display">
\mathbf{A}\mathbf{A}^{-1}= \mathbf{I}= \mathbf{A}^{-1}\mathbf{A}.
</span></p>
<p>We call the matrix <span class="math inline">\mathbf{A}^{-1}</span>
the <strong>inverse</strong> of <span
class="math inline">\mathbf{A}</span>. Furthermore, singular matrices do
not have inverses.</p>
<h3 data-number="6.2.5" id="systems-of-equations"><span
class="header-section-number">6.2.5</span> Systems of equations</h3>
<p>Matrices are great for concisely stating systems of linear equations,
linear equations in some set of variables youâ€™d like to hold true
simultaneously. For example, the set of equations</p>
<p><span class="math display">
2x_1 + 3x_2 = 7\\
5x_1 - 4x_2 = 6
</span></p>
<p>can alternatively be stated as:</p>
<p><span class="math display">
\begin{bmatrix}
2 &amp; 3 \\
5 &amp; -4
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
7 \\ 6
\end{bmatrix}
</span></p>
<h3 data-number="6.2.6" id="sec:elementaryRowOperations"><span
class="header-section-number">6.2.6</span> Elementary operations</h3>
<p>There are certain elementary operations one can perform on a system
of linear equations that donâ€™t have an effect on the solution of the
system. Iâ€™ll state these operations in terms of rows, but similar
operations exist for columns as well:</p>
<ul>
<li>Interchange two rows: <span class="math display">
\begin{bmatrix}
2 &amp; 3 \\
5 &amp; -4
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
7 \\ 6
\end{bmatrix}
\Leftrightarrow
\begin{bmatrix}
5 &amp; -4 \\
2 &amp; 3
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
6 \\ 7
\end{bmatrix}
</span></li>
<li>Multiply a row by a non-zero number, e.g.Â multiplying the top row by
two: <span class="math display">
\begin{bmatrix}
2 &amp; 3 \\
5 &amp; -4
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
7 \\ 6
\end{bmatrix}
\Leftrightarrow
\begin{bmatrix}
4 &amp; 6 \\
5 &amp; -4
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
14 \\ 6
\end{bmatrix}
</span></li>
<li>Adding a multiple of one row to another row, e.g.Â multiplying the
first row by 2 and adding it to the second: <span class="math display">
\begin{bmatrix}
2 &amp; 3 \\
5 &amp; -4
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
7 \\ 6
\end{bmatrix}
\Leftrightarrow
\begin{bmatrix}
2 &amp; 3 \\
9 &amp; 2
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}
=
\begin{bmatrix}
7 \\ 20
\end{bmatrix}
</span></li>
</ul>
<h2 data-number="6.3" id="writing-mathematics-in-a-colab-notebook"><span
class="header-section-number">6.3</span> Writing mathematics in a Colab
notebook</h2>
<p>Besides writing Python code, another useful feature of a Colab
notebook is the ability to use â€œtextâ€ cells to write Markdown. <a
href="https://en.wikipedia.org/wiki/Markdown">Markdown</a> provides a
convenient way to render formatted text, and in fact the notes you are
reading now were written using it. The flavor of Markdown implemented in
Colab allows for the addition of <a
href="https://en.wikipedia.org/wiki/LaTeX">LaTeX</a> syntax for
rendering mathematical symbols. Colab is far from the only place where
you can use Markdown, but as usual it is simple to set up and use right
out of the box.</p>
<p>In the following notebook, Iâ€™ve included examples of how to render
mathematical symbols inside Colab. This is far from a comprehensive
guide, sticking to items I think might be useful for the class. I came
across a more extensive guide you may want to check out <a
href="https://ashki23.github.io/markdown-latex.html">here</a>.</p>
<script src="https://gist.github.com/eea93b3fac7b6040bcb074e95b4e5076.js"></script>
<h2 data-number="6.4" id="sec:badIpModels"><span
class="header-section-number">6.4</span> Examples of bad IP
modeling</h2>
<p>When modeling problems as integer programs, and especially when using
binary variables to encode some type of logic, it can be very easy to
<em>think</em> youâ€™ve come up with a valid formulation, only to solve
the problem and get an answer that you werenâ€™t expecting due to some bad
constraints. In this section, Iâ€™ll give some sample â€œbadâ€ IP models that
do not properly enforce the logic they were meant to, and discuss how
things went wrong.</p>
<h3 data-number="6.4.1" id="boolean-algebra"><span
class="header-section-number">6.4.1</span> Boolean algebra</h3>
<p>Letâ€™s consider the Boolean algebra operations we modeled in
sectionÂ <a href="#sec:binVarTricks">5.3.2</a>. Weâ€™ll show wrong ways to
model each of AND, OR, and XOR, and explain why they donâ€™t work as
required. In each model, we want the binary variable <span
class="math inline">y</span> to equal the output of the specified
Boolean function applied to binary variables <span
class="math inline">x_1</span> and <span
class="math inline">x_2</span>.</p>
<ul>
<li><p>AND: Hereâ€™s the truth table and an example
<strong>incorrect</strong> formulation:</p>
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
\begin{align*}
y&amp;\leq x_1 \\
y&amp;\leq x_2 \\
y&amp;\geq \frac{1}{2}(x_1 + x_2) \\
  x_1, x_2, y &amp; \in \{0,1\}
\end{align*}
</span>
</div>
</div>
<p>It is easy to look at this and say something like: â€œwhen <span
class="math inline">x_1=x_2=1</span> then the third constraint makes
<span class="math inline">y=1</span>, and otherwise one of <span
class="math inline">y\leq x_1</span> or <span class="math inline">y\leq
x_2</span> will force <span class="math inline">y=0</span>â€. And while
that statement is true, it fails to account for the fact that all
constraints are active in an integer program, and we donâ€™t get to pick
and choose which ones to enforce based on the situation.</p>
<p>Once we start considering every constraint, we see that if only one
of <span class="math inline">x_1</span> or <span
class="math inline">x_2</span> equal 1 then there is no feasible value
for <span class="math inline">y</span>. For example, suppose that we
have <span class="math inline">x_1=1</span> and <span
class="math inline">x_2=0</span>. Then the second constraint will say
<span class="math inline">y\leq0</span>, while the third constraint will
say <span class="math inline">y\geq1/2</span>, and these two clearly
canâ€™t be satisfied simultaneously. As a result, any model with this as
part of the constraints will not be able to return a solution where
<span class="math inline">x_1+x_2=1</span>, which is probably not what
you wanted.</p></li>
<li><p>OR: Once again, hereâ€™s the truth table and a <strong>bad</strong>
formulation:</p>
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
  \begin{align*}
  y&amp;\geq x_1 \\
  y&amp;\geq x_2 \\
  x_1, x_2, y &amp; \in \{0,1\}
  \end{align*}
  </span>
</div>
</div>
<p>This will correctly force <span class="math inline">y=1</span> in
situations where either <span class="math inline">x_1</span> or <span
class="math inline">x_2</span> (or both) are <span
class="math inline">1</span>, but it fails to properly account for the
converse, i.e.Â the top row of the truth table when <span
class="math inline">x_1=x_2=0</span>. These constraints will allow
either <span class="math inline">y=0</span> or <span
class="math inline">y=1</span> in that case, instead of enforcing <span
class="math inline">y=0</span> like we want.</p></li>
<li><p>XOR: The truth table and <strong>improper</strong>
formulation:</p>
<div style="display:flex;justify-content:space-around">
<div>
<table>
<tbody>
<tr style="border-bottom:1px solid black">
<th>
<span class="math inline">x_1</span>
</th>
<th>
<span class="math inline">x_2</span>
</th>
<th style="border-left:1px solid black">
<span class="math inline">y</span>
</th>
</tr>
<tr>
<td>
0
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
<tr>
<td>
0
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0
</td>
<td style="border-left:1px solid black">
1
</td>
</tr>
<tr>
<td>
1
</td>
<td>
1
</td>
<td style="border-left:1px solid black">
0
</td>
</tr>
</tbody style='border:none'>
</table>
</div>
<div class="katexSideBySide">
<span class="math display">
  \begin{align*}
  y&amp;\leq x_1 + x_2 \\
  y&amp;\geq x_1 \\
  y&amp;\geq x_2 \\
  y&amp;\leq x_1 - x_2 \\
   x_1, x_2, y &amp; \in \{0,1\}
  \end{align*}
  </span>
</div>
</div>
<p>We could once again be tricked by this formulation if we only
consider certain constraints for certain scenarios. We could say:</p>
<ul>
<li>Constraint 1 forces <span class="math inline">y=0</span> when <span
class="math inline">x_1=0,x_2=0</span></li>
<li>Constraint 2 forces <span class="math inline">y=1</span> when <span
class="math inline">x_1=1,x_2=0</span></li>
<li>Constraint 3 forces <span class="math inline">y=1</span> when <span
class="math inline">x_1=0,x_2=1</span></li>
<li>Constraint 4 forces <span class="math inline">y=0</span> when <span
class="math inline">x_1=1,x_2=1</span></li>
</ul>
<p>and think that weâ€™ve satisfied all of our requirements. The catch, as
with our AND formulation, is that these constraints must be considered
<em>simultaneously</em> in <em>every</em> situation. So for example, in
the situation <span class="math inline">x_1=0,x_2=1</span> we would
indeed get the third constraint forcing <span
class="math inline">y=1</span>. But weâ€™d also have the fourth constraint
forcing <span class="math inline">y\leq-1</span>, meaning that the
constraints can not all be satisfied in this case. Thus a model with
this as part of the constraint set could never return a solution with
<span class="math inline">x_1=0, x_2=1</span>, incorrectly cutting off
an entire segment of the problemâ€™s feasible region.</p></li>
</ul>
<h2 data-number="6.5" id="sec:appendixSelectedProofs"><span
class="header-section-number">6.5</span> Selected proofs</h2>
<p>This section contains proofs to selected statements in the main
text.</p>
<h1 id="References">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="doc-bibliography">
<div id="ref-bertsimas-LPbook" class="csl-entry" role="doc-biblioentry">
Bertsimas, D., and J. N. Tsitsiklis. 1997. <em>Introduction to Linear
Optimization</em>. Athena Scientific.
</div>
<div id="ref-simplexPivotNoLoops" class="csl-entry"
role="doc-biblioentry">
Bland, Robert G. 1977. <span>â€œNew Finite Pivoting Rules for the Simplex
Method.â€</span> <em>Mathematics of Operations Research</em> 2 (2):
103â€“7. <a
href="http://www.jstor.org/stable/3689647">http://www.jstor.org/stable/3689647</a>.
</div>
<div id="ref-tspPursuit" class="csl-entry" role="doc-biblioentry">
Cook, William J. 2012. <em>In Pursuit of the Traveling Salesman:
Mathematics at the Limits of Computation</em>. Princeton University
Press. <a
href="http://www.jstor.org/stable/j.ctt7t8kc">http://www.jstor.org/stable/j.ctt7t8kc</a>.
</div>
<div id="ref-classText" class="csl-entry" role="doc-biblioentry">
Hillier, F. S., and G. J. Lieberman. 2021. <em>Introduction to
Operations Research</em>. McGraw-Hill Education. <a
href="https://books.google.com/books?id=gnhSzQEACAAJ">https://books.google.com/books?id=gnhSzQEACAAJ</a>.
</div>
<div id="ref-kleeMinty" class="csl-entry" role="doc-biblioentry">
Klee, Victor, and George J. Minty. 1970. <span>â€œHOW GOOD IS THE SIMPLEX
ALGORITHM.â€</span> In. <a
href="https://api.semanticscholar.org/CorpusID:117965841">https://api.semanticscholar.org/CorpusID:117965841</a>.
</div>
<div id="ref-solverBenchmarks" class="csl-entry" role="doc-biblioentry">
<span>â€œMittelmann Benchmarks.â€</span> n.d. <a
href="https://plato.asu.edu/bench.html">https://plato.asu.edu/bench.html</a>.
</div>
<div id="ref-tspPic" class="csl-entry" role="doc-biblioentry">
<span>â€œWaterloo TSP.â€</span> n.d. <a
href="https://www.math.uwaterloo.ca/tsp/"
class="uri">https://www.math.uwaterloo.ca/tsp/</a>.
</div>
<div id="ref-wolsey2020" class="csl-entry" role="doc-biblioentry">
Wolsey, L. A. 2020. <em>Integer Programming</em>. Wiley. <a
href="https://books.google.com/books?id=3yhPwwEACAAJ">https://books.google.com/books?id=3yhPwwEACAAJ</a>.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The most recent version of this textbook is the 11th
edition, which came out in 2021. But much of the content quoted here
comes from the 10th edition from 2015. Nothing about the course will
require you to have a certain edition, or any book at all. But I think
itâ€™s a very useful reference.<a href="#fnref1" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn2"><p>The pedant in me wants to point out that this word
â€œoptimalâ€ is horribly misused in conversation fairly regularly, in the
form of the misguided phrase â€œmore optimalâ€. As I mentioned, â€œoptimalâ€
really just means â€œbestâ€, and â€œbestâ€ is not on a sliding scale; either
you have the best answer or you donâ€™t. One choice canâ€™t be â€œmore bestâ€
than another, just as one solution canâ€™t be â€œmore optimalâ€ than another.
I think Iâ€™m fighting a losing battle on this, but maybe for the sake of
this course we can all agree to never put the words â€œmoreâ€ and â€œoptimalâ€
next to each other? Thanks.<a href="#fnref2" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn3"><p>Thereâ€™s a neat book all about the TSP, <span
class="citation" data-cites="tspPursuit">Cook (<a href="#ref-tspPursuit"
role="doc-biblioref">2012</a>)</span>, written by a great professor that
I took a course from while getting my PhD. Itâ€™s more popularly focused
than technical, so itâ€™s a surprisingly smooth read. Highly
recommended!<a href="#fnref3" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn4"><p>You can tell from the image that this map is pretty old.
<a href="https://www.math.uwaterloo.ca/tsp/usa50/">The site from which
it came</a> tells a neat story about how this instance was solved, by
hand, way back in 1954! There are some other interesting bits there too,
well worth a read in my opinion.<a href="#fnref4" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn5"><p>If you <em>are</em> looking for a deep dive, Iâ€™d suggest
checking out the other classes in our Masters of Operations Research
program.<a href="#fnref5" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn6"><p>Itâ€™s not exactly like Jupyter, but the same in spirit.
Also, donâ€™t worry if you donâ€™t know about Jupyter or coding notebooks
yet.<a href="#fnref6" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn7"><p>This shouldnâ€™t be a huge hurdle. If you donâ€™t have one
already you can always create a burner account for the sake of the
class.<a href="#fnref7" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn8"><p>You can check out <a
href="https://www.python.org/downloads/">Pythonâ€™s downloads page</a> or
go with <a href="https://www.anaconda.com/">Anaconda</a> for an expanded
built-in toolset.<a href="#fnref8" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn9"><p>Iâ€™m listing lots of Google Cloud products because thatâ€™s
the cloud platform Iâ€™ve used most, but the other big providers have
similar offerings.<a href="#fnref9" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn10"><p>You might look at this and think â€œthat just means <span
class="math inline">x_2 \leq 6</span>.â€ You would be correct, and it
would be completely valid to use that constraint instead.<a
href="#fnref10" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn11"><p>The â€œs.t.â€ is an abbreviation for â€œsubject toâ€ and is
used in formulations leading into the constraints section.<a
href="#fnref11" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn12"><p>So long as weâ€™re talking about real numbers, of course.
Something like <span class="math inline">x_1=\text{blue}</span>, <span
class="math inline">x_2=\text{elephant}</span> is just nonsense and
isnâ€™t a solution to our problem.<a href="#fnref12" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn13"><p>The smallest value if we have a minimization problem,
or the largest value for a maximization problem.<a href="#fnref13"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn14"><p>I couldnâ€™t think of a good way to do this with touch
events, so this part doesnâ€™t work as well on a mobile device. Sorry.<a
href="#fnref14" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn15"><p>Actually, my little widget here is not perfect.
Depending how small of a decimal you add, you may get it to tell you
there are optimal solutions at a slightly higher objective value. This
is due to choosing a precision that this setup really canâ€™t handle. It
is worth mentioning that even the most sophisticated solvers can have
issues with rounding errors and numerical stability, but theyâ€™re
generally very good. As long as you are careful with your formulations
you usually wonâ€™t run into issues.<a href="#fnref15"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn16"><p>Truth be told, this isnâ€™t a rigorous proof of
optimality, at least in the strict sense of mathematical proofs. But the
solution methods weâ€™ll study later do give such proofs.<a
href="#fnref16" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn17"><p>In most practical applications, infeasiblity is a good
indicator that you modeled something incorrectly. Like in this example,
it doesnâ€™t make sense that we could make arbitrarily many of some
product. So if you find a problem youâ€™re working on is infeasible, itâ€™s
a good idea to double-check your formulation.<a href="#fnref17"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn18"><p>There are similar packages available in other popular
programming languages as well.<a href="#fnref18" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn19"><p>Most come with limited licenses for noncommercial uses,
and also offer free unrestricted licenses for students and academics.<a
href="#fnref19" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn20"><p>A quick example: <span class="math inline">x \leq
10</span> means the exact same thing as <span class="math inline">-x
\geq -10</span>.<a href="#fnref20" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn21"><p>You can think of <span class="math inline">y_j</span>
as the â€œpositive partâ€ and <span class="math inline">z_j</span> as the
â€œnegative partâ€ of <span class="math inline">x_j</span>. Note that we
havenâ€™t done anything to enforce that only one of <span
class="math inline">y_j</span> and <span class="math inline">z_j</span>
are nonzero at a time. So for example if some solution to the original
formulation had <span class="math inline">x_j=2</span> then in the new
formulation we could have <span class="math inline">y_j=2</span> and
<span class="math inline">z_j=0</span>, or we could just as easily have
something like <span class="math inline">y_j=12, z_j=10</span> or <span
class="math inline">y_j=106.7, z_j=104.7</span>.<a href="#fnref21"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn22"><p>Iâ€™m not mentioning a lot of people by name in these
notes, but I couldnâ€™t skip Dantzig. Mostly I wanted to bring up this
famous story: A student comes late to class one day, sees two problems
written on the board, and assumes they are the dayâ€™s assigned homework.
The problems are more difficult than usual, but he solves them. When he
turns them in, the professor is elated - these werenâ€™t homework problems
at all, but rather famous unsolved problems in the field! You can find
several versions of this story out there, citing several different
people as the supposed student. Turns out <a
href="https://www.snopes.com/fact-check/the-unsolvable-math-problem/#6oJOtz9WKFQUHhbw.99">this
actually happened, and the student was Dantzig</a>.<a href="#fnref22"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn23"><p>Thereâ€™s a neat story, quoting from <span
class="citation" data-cites="tspPursuit">Cook (<a href="#ref-tspPursuit"
role="doc-biblioref">2012</a>)</span>, in <a
href="https://punkrockor.com/2014/04/29/happiness-is-assuming-the-world-is-linear/">this
blog post</a> (yes, OR blogs are a thing). Itâ€™s specifically about
Dantzig first introducing the simplex method during a talk in 1948, and
more generally about understanding your assumptions ðŸ˜€.<a
href="#fnref23" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn24"><p>Interestingly, several other linear programming
algorithms have been devised whose theoretical properties seem to
suggest they would be more efficient. But in practice that hasnâ€™t been
the case. Simplex continues to be the best algorithm in practice for the
widest array of problems.<a href="#fnref24" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn25"><p>There are corner-point infeasible solutions as well,
which sit at intersections outside the feasible region<a href="#fnref25"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn26"><p>Iâ€™m used to calling them vertices, but the textbook
tends to call them corner-point solutions, which I like as a more
helpful, descriptive term. Iâ€™ll try to stick to corner-point solution
for the notes, but I expect to slip up a few times, especially during
lectures.<a href="#fnref26" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn27"><p>For those that are not aware, a
<strong>theorem</strong> is a mathematical statement that has been
proven to be true, based on some set of standard axioms. Anything I cite
as a theorem in these notes, you can be confident it holds true, even if
we donâ€™t work through a rigorous proof.<a href="#fnref27"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn28"><p>At least not generally - for common variants of the
simplex method, there exist examples where every CPF solution is visited
during execution (<span class="citation" data-cites="kleeMinty">(<a
href="#ref-kleeMinty" role="doc-biblioref">Klee and Minty
1970</a>)</span> is the first, most famous example). But this isnâ€™t
usually an issue in practice.<a href="#fnref28" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn29"><p>This is really the key takeaway from our whole
discussion in this section, and if this is the only thing you remember
about the simplex method 10 years from now Iâ€™ll still be satisfied. This
is the key insight, you can always re-learn the details later.<a
href="#fnref29" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn30"><p>The greek capital letter <span
class="math inline">\Delta</span> is commonly used to denote an amount
of change, and in these context is often read as â€œchange in.â€<a
href="#fnref30" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn31"><p>Note that having the highest per-unit change doesnâ€™t
necessarily make it the â€œbestâ€ choice in any particular way. It may be
that choosing a different (but still improving) direction will mean that
we finish the algorithm faster. But in general we canâ€™t tell beforehand,
so we often just choose the direction with the highest change as
convenient rule-of-thumb.<a href="#fnref31" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn32"><p>It is also possible to have a tie in the minimum ratio
test. This is another special case that weâ€™ll cover later.<a
href="#fnref32" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn33"><p>Now might be a good time to check out the simplex
visualization in sectionÂ <a href="#sec:simplexVisualized">4.6.2</a> and
see if you understand the interpretation of the slack variable values in
the solutions weâ€™ve found.<a href="#fnref33" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn34"><p>Note also that if you came to the equality-constrained
problem (<span
class="math inline">\mathbf{A}\mathbf{x}=\mathbf{b}</span>) via a
transformation from the inequality form (<span
class="math inline">\mathbf{A}\mathbf{x}\leq\mathbf{b}</span>) by adding
slack variables, the slack variables themselves guarantee full row
rank.<a href="#fnref34" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn35"><p>Sorry to just present this to you as if itâ€™s a mystical
gift from the gods. We could have totally derived it ourselves, but I
didnâ€™t think it was worth the class time.<a href="#fnref35"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn36">This â€œfell on its sideâ€ thing is easier to see if you
post-multiply the dual variables instead:
<div class='mathSmall'>
<p>$$ <span class="math display">\begin{align*}
\text{min}&amp;&amp; \begin{bmatrix}4 &amp; 12 &amp;
18\end{bmatrix}\begin{bmatrix}y_1 \\ y_2 \\ y_3\end{bmatrix} &amp; \\
\text{s.t.} &amp;&amp; \begin{bmatrix}1 &amp; 0 &amp; 3 \\ 0 &amp; 2
&amp; 2\end{bmatrix}\begin{bmatrix}y_1 \\ y_2 \\ y_3\end{bmatrix} &amp;
\geq \begin{bmatrix}3 \\ 5\end{bmatrix} \\
&amp;&amp; y_1,y_2,y_3 &amp; \geq 0
\end{align*}</span></p>
<p><span class="math display">
&lt;/div&gt;
</span><a href="#fnref36" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn37"><p>A <em>corollary</em> is like a theorem, and we could
just as easily have called this a theorem as well. But generally we use
the word corollary when the result follows almost directly from a result
presented previously.<a href="#fnref37" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn38"><p>Interested readers can check <span class="citation"
data-cites="classText">Hillier and Lieberman (<a href="#ref-classText"
role="doc-biblioref">2021</a>)</span>, section 8.1.<a href="#fnref38"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn39"><p>If you increase it too much, interactions from other
constraints may change the effect. How much is too much? Weâ€™ll explore
this question in sectionÂ <a href="#sec:sensitivityAnalysis">4.8.3</a><a
href="#fnref39" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn40"><p>This might be a first hint that our problem has changed
significantly.<a href="#fnref40" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn41"><p>We arenâ€™t covering dual simplex in this course, but I
think itâ€™s good for you to know that it exists, and in particular that
it has a role to play in sensitivity analysis or re-optimization.<a
href="#fnref41" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn42"><p>This also introduces potential degeneracy issues, but
weâ€™ll ignore that for the purposes of this class.<a href="#fnref42"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn43"><p>In this context, we use the word <em>integral</em> to
mean â€œof or denoted by an integerâ€ (which, as of the time of writing, is
the second definition provided by Google when searching the word). I
agree itâ€™s somewhat confusing since the word has a separate common
meaning when used in casual conversation, and even a separate meaning in
mathematics that youâ€™re familiar with from calculus.<a href="#fnref43"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn44"><p>Of course, you could also talk about non-linear
optimization problems with integer variable restrictions. Still, the
terminology <em>integer programming</em> is usually restricted to
integer extensions to LPs.<a href="#fnref44" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn45"><p>Some sources will include an â€œLâ€ (for â€œlinearâ€) in the
initialism as well. So if you see things like ILP, MILP, or BILP in
other texts, know that these are likely the same as what weâ€™re calling
IP, MIP, and BIP.<a href="#fnref45" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn46"><p>New notation alert: as mentioned in sectionÂ <a
href="#sec:symbols">6.1</a>, the symbol <span
class="math inline">\mathbb{I}</span> stands for the set of integer
numbers. The <span class="math inline">+</span> in the subscript means
that we are considering non-negative integers (though this is just a
convention, as we saw with linear programs in sectionÂ <a
href="#sec:lpForms">4.5</a> we can bypass non-negativity with certain
formulation tricks). The <span class="math inline">n</span> in the
superscript is just from the dimension of the vector <span
class="math inline">\mathbf{x}</span>, in this case meaning that a valid
selection for <span class="math inline">\mathbf{x}</span> must consist
of <span class="math inline">n</span> such integers.<a href="#fnref46"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn47"><p>The notion of a <em>relaxation</em> shows up in other
places in optimization theory as well. In general, a relaxation <span
class="math inline">R</span> of some minimization problem <span
class="math inline">P</span> is another optimization problem such that
the set of feasible solutions to <span class="math inline">P</span> is a
subset of the feasible solutions to <span class="math inline">R</span>.
Further, for any solution <span class="math inline">x</span> to <span
class="math inline">P</span>, the objective value at <span
class="math inline">x</span> in <span class="math inline">R</span> is
less than or equal to the objective value at <span
class="math inline">x</span> in <span class="math inline">P</span> (in
the case of the LP relaxation to an IP, the objective values are equal).
Relaxations are usually easier to solve than the original problem and
can be useful as approximations or in bounding <span
class="math inline">P</span>â€™s possible objective values.<a
href="#fnref47" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn48"><p>I should point out that, in a practical application,
there is often some wiggle room in the (sometimes shoddily estimated)
problem data such that you could fudge a little and make one of these
rounded solutions work. This may or may not be an option depending on
your scenario.<a href="#fnref48" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn49"><p>Another way to approach this particular problem may be
to just solve two different IPs, one with the first constraint and one
with the second, then compare the resultant solutions. But itâ€™s not too
hard to imagine a scenario where perhaps a new build is considered for
each facility, and with enough facilities you wouldnâ€™t want to do a new
model for each possible combination of new/old facilities.<a
href="#fnref49" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn50"><p>This is the second time weâ€™ve seen <span
class="math inline">M</span> represent some very large number - itâ€™s a
recurring theme in OR.<a href="#fnref50" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn51"><p>Verify this by seeing what the constraints reduce to
when <span class="math inline">x_i=0</span> versus when <span
class="math inline">x_i&gt;0</span>.<a href="#fnref51"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn52"><p>For some reason, the presentation of this problem in
the textbook leaves the <span class="math inline">x_i</span> variables
are real-valued instead of integers. I figure integers are more
realistic, and since weâ€™re in the IP portion of the notes, why not do it
that way?<a href="#fnref52" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn53"><p>Ideally in computer code.<a href="#fnref53"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn54"><p>New notation: when we write <span
class="math inline">S&#39;\subseteq S</span>, we mean to say that <span
class="math inline">S&#39;</span> is a subset of <span
class="math inline">S</span>. That is, <span
class="math inline">S</span> and <span class="math inline">S&#39;</span>
are both sets, and every element of <span
class="math inline">S&#39;</span> is also an element of <span
class="math inline">S</span>.<a href="#fnref54" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn55"><p>Plus an extra constraint on the number of flight
segments to choose - this constraint is not included in the classical
set covering problem.<a href="#fnref55" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn56"><p>Note the new notation in the second summation, <span
class="math inline">\{j:i\in S_j\}</span>. We call this the â€œconditional
setâ€ notation in sectionÂ <a href="#sec:symbols">6.1</a>. It means the
set of all <span class="math inline">j</span> such that the condition
<span class="math inline">i\in S_j</span> is true.<a href="#fnref56"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn57"><p>If <span class="math inline">d_{ij}=d_{ji}</span> for
all <span class="math inline">i,j</span> then we call it a <em>symmetric
TSP</em>. But this doesnâ€™t need to hold for our formulations to work.<a
href="#fnref57" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn58"><p>I canâ€™t tell you how many times Iâ€™ve come up with what
I thought was a valid formulation for a problem, only to solve the model
and get some invalid result because I overlooked some subtle case my
model didnâ€™t cover. Modeling a given IP is not always as straightforward
as it might initially appear.<a href="#fnref58" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn59"><p>Technically we donâ€™t need <em>every</em> subset, since
the same constraint will cover both the selected subset and its
complement (e.g.Â the constraint above will eliminate the possibility of
subtours in both sets <span class="math inline">\{3, 8, 0\}</span> and
<span class="math inline">\{1, 2, 4, 5, 6, 7, 10\}</span>). Further,
subsets of size 1 are technically covered by the basic â€œleave every city
onceâ€ constraints.<a href="#fnref59" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn60"><p>If youâ€™re thinking â€œthat could be a lot of
constraintsâ€, youâ€™re right. It can be a problem. Weâ€™ll be coming back to
this observation later.<a href="#fnref60" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn61"><p>In fact, you could make due with <em>only</em> the
subtour elimination constraints, since the original functional
constraints are essentially just subtour elimination constraints for the
subtours of size <span class="math inline">n-1</span>.<a href="#fnref61"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn62"><p>Two bits of new notation here. First, <span
class="math inline">\emptyset</span> represents an empty set, i.e.Â a set
with no elements. Technically, <span
class="math inline">\emptyset</span> is a subset of all other sets, but
we donâ€™t want to consider it in our formulation so weâ€™ll explicitly
exclude it. Second, <span class="math inline">|S|</span> denotes the
size of a set, i.e.Â the number of elements in it.<a href="#fnref62"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn63"><p>Youâ€™ll notice some of the big names (specifically CPLEX
and Xpress) are missing from these benchmarks. They used to be included
as well, but there was some bit of drama from a few years back that led
to the big commercial solvers asking to be excluded from these public
benchmarks. Gurobi has since returned.<a href="#fnref63"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn64"><p>Note that, due to the nature of the benchmarks, the
reported speed differences underestimate the differences on larger
problems that are more likely to be of interest in industry
applications.<a href="#fnref64" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn65"><p>You may want to take advantage of this for your class
project.<a href="#fnref65" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn66"><p>Actually, I think I alluded to complexity earlier in
class and told you we wouldnâ€™t cover it. But I just couldnâ€™t help
myself, so here we are.<a href="#fnref66" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn67"><p>Note that the order matters here, i.e.Â traveling from
New York to DC is not the same as traveling from DC to New York. If
order didnâ€™t matter, we could divide the number by 2.<a href="#fnref67"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn68"><p>Actually, the way we modeled it in the notebook, we
only used about half of the subsets, since the subtour elimination
constraints suffice for both the subset they are built on and the
complement set.<a href="#fnref68" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn69"><p>Why? Think about it like this: to create a subset one
has to decide, for each element of the set, whether to include it or
not. This gives you 2 choices <span class="math inline">n</span>
independent times, or <span class="math inline">2^n</span> total
choices.<a href="#fnref69" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn70"><p>We can also talk about, say, dividing all the numbers
by their greatest common denominator in order to save space, but we
wonâ€™t worry about that here.<a href="#fnref70" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn71"><p>If weâ€™re talking about saving files on a computer that
uses bits instead of digits, weâ€™d take the logarithm with a base of 2
instead of 10.<a href="#fnref71" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn72"><p>There is in fact a deeper link between decision and
optimization problems. It is a little beyond the scope of this course to
formalize, but Iâ€™ll mention here: If the associated decision problem is
solvable in polynomial time, then so is the optimization problem (one
can solve the decision problem over and over again, and if you use a
so-called bisection search on the objective function to guide which
decision problems you solve, youâ€™ll only have to do so polynomially many
times).<a href="#fnref72" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn73"><p>Formally, we would use whatâ€™s known as â€œ<a
href="https://en.wikipedia.org/wiki/Big_O_notation">big O notation</a>â€,
which works like this: For two functions <span
class="math inline">f</span> and <span class="math inline">g</span>, we
say that <span class="math inline">f(n)\in O(g(n))</span> if there are
some numbers <span class="math inline">c\in\mathbb{R}_+,
n&#39;\in\mathbb{R}</span> such that <span
class="math inline">|f(n)|\leq c\cdot g(n)</span> for all <span
class="math inline">n &gt; n&#39;</span>. Essentially, <span
class="math inline">g</span> dominates <span
class="math inline">f</span> in the limit (subject to some constant
factor). From the definition, it is clear that <span
class="math inline">n(n-1)\in O(n^2)</span>.<a href="#fnref73"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn74"><p>This may seem unintuitive at first, and is the main
point of conflict between the theory and the real world. Indeed, in any
practical application, it would make a great deal of difference if your
algorithm required <span class="math inline">2n^2</span> steps versus
<span class="math inline">10^{1000}n^2</span> steps. If itâ€™s any
consolation, in practice humongous constants like this do not tend to
occur. Itâ€™s also common for constants to start out higher when an
algorithm is first introduced, only to be reduced as more research is
put into the problem.<a href="#fnref74" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn75"><p>The name <span class="math inline">\mathcal{NP}</span>
stands for â€œnon-deterministic polynomial timeâ€ and is a leftover from
the very first formalization of this notion, which came from so-called
<a
href="https://en.wikipedia.org/wiki/Nondeterministic_Turing_machine">non-deterministic
Turing machines</a>. I wish the name were more indicative of the â€œeasily
verifiableâ€ notion we present here, but the nomenclature is well
entrenched now and weâ€™re well past the point of no return.<a
href="#fnref75" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn76"><p>Crucially, the ability to prove is one-sided. The
definition said we need only be able to verify instances for which the
answer is â€œyesâ€. We need not be able to do anything for â€œnoâ€
instances.<a href="#fnref76" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn77"><p>This result is due to analysis on various
interior-point methods for LP, and interestingly not for the simplex
method. As weâ€™ve hinted at, there are various implementation details you
need to hash out to run simplex in practice, and nobody has ever proven
that any version of simplex is guaranteed to finish in polynomial
time.<a href="#fnref77" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn78"><p>For instance, if <span
class="math inline">\mathcal{P}\neq\mathcal{NP}</span> then weâ€™d know
definitively that scalable algorithms for solving integer programs
cannot exist. Meanwhile, if <span
class="math inline">\mathcal{P}=\mathcal{NP}</span>, then many of the
algorithms we use today for cryptography (to, for example, keep your
bank credentials safe while shopping online) are unsafe in principal and
potentially vulnerable to attack. People also like to get philosophical
when discussing the implications of <span
class="math inline">\mathcal{P}=\mathcal{NP}</span>, making provocative
claims like â€œthere is no difference between someone whe can appreciate
art and an artistâ€ or â€œanyone who can recognize good music is as
talented as Mozartâ€. Thereâ€™s truth in these statements as metaphors, but
sometimes I find it hard to tell if these people actually mean them
literally. As far as Iâ€™m concerned, these sweeping metaphysical claims
donâ€™t follow from the theory.<a href="#fnref78" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn79"><p>Interestingly, the (so far) <a
href="https://en.wikipedia.org/wiki/Grigori_Perelman">only person to
solve one of these problems</a> turned down the money.<a href="#fnref79"
class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn80"><p>This may feel like a high bar to clear, since there are
many different <span class="math inline">\mathcal{NP}</span> problems,
so proving that <em>any</em> of them can be reduced to a given problem
of interest feels like an impossible amount of work. In practice,
researchers identified a problem called <a
href="https://en.wikipedia.org/wiki/Boolean_satisfiability_problem"><em>satisfiability</em>
(or <em>SAT</em>)</a> which encapsulates exactly this notion of <span
class="math inline">\mathcal{NP}</span>-completeness. Then, once you
have <em>some</em> <span
class="math inline">\mathcal{NP}</span>-complete problem, proving
another is <span class="math inline">\mathcal{NP}</span>-complete
requires just reducing a known <span
class="math inline">\mathcal{NP}</span>-complete problem to your problem
of interest.<a href="#fnref80" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn81"><p>Like I did with â€œmore optimalâ€ before, I canâ€™t help but
point out another of my linguistic pet peeves here. Youâ€™ll often here
people talk about something â€œgrowing exponentiallyâ€ in plain English,
but it almost never fits the mathematical definition, i.e.Â the growth
rate with respect to some factor <span class="math inline">n</span> is
proportional to <span class="math inline">p^n</span> for some <span
class="math inline">p\in\mathbb{R}</span>. People will say it when the
growth rate is only quadratic (grows like <span
class="math inline">n^2</span>). Iâ€™ve seen people label literal
<em>linear growth</em> as exponential, and I want to tear my hair out.
But the most egregious thing is when people say something grows
exponentially when they only have two data points, like â€œtotal sales
this year grew exponentially over last yearâ€™s total sales.â€ Umm, you
only have two data points. You can draw literally any kind of curve
between two data points, so I guess you <em>could</em> draw an
exponential curve too, but come on. What justifies you calling it
exponential over quadratic or linear or <em>literally anything
else</em>?<a href="#fnref81" class="footnote-back"
role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn82"><p>You might object that there only finitely many
corner-point solutions, and these are the only ones that matter. Thatâ€™s
fair, but Iâ€™ll point out that the number of corner points still grows
exponentially, and there are other optimization problems with infinitely
many solutions that are still polynomial-time solvable.<a
href="#fnref82" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn83"><p>Thatâ€™s not to say that the IP formulation we coded for
the TSP can solve instances of this size. The best TSP solvers use IP
techniques, but they donâ€™t use the full model as we formulated. Later in
class, I plan to show an example where we solve a TSP with Gurobi but
without adding every subtour elimination constraint up front.<a
href="#fnref83" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
</ol>
</section>
<script>
    printerFunc = () => {
        header = document.getElementsByClassName('navbar')[0];
        footer = document.getElementsByTagName('footer')[0];
        header.style.visibility = 'hidden';
        footer.style.visibility = 'hidden';
        window.print();
        setTimeout(() => {})
    }
    window.onafterprint = function(){
        header.style.visibility = 'visible';
        footer.style.visibility = 'visible';
    }
</script>
</div>
<div id="classModeDiv"></div>
<footer>
    <div style="width:3rem"></div>
    <small>&copy; Copyright 2023, Jeffrey Pavelka</small>
    <div style='cursor:pointer;margin:0 1rem' onclick="printerFunc()">&#128438;</div>
</footer>
</body>
</html>
