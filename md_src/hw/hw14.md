<div class='assignmentContainer' id='Homework 14' sub-name='Markov decision processes' due='2023-12-08' grading-notes-link='https://colab.research.google.com/drive/1vicur2RHdxs91wcXzRXZx9jf51-Y8R2f?usp=sharing'><div>

1. (3pts) Consider the sample MDP from the class notes (section 7.4.1). Currently, an overhaul of the machine in state 2 costs \$4,000. Leaving everything else the same, how much would the overhaul cost need to increase (to the nearest \$100) before overhauling in state 2 is no longer part of the optimal policy?

1. (6pts)* Every Saturday night a man plays poker at his home with the same group of friends. If he provides refreshments for the group (at an expected cost of \$14) on any given Saturday night, the group will begin the following Saturday night in a good mood with probability $\frac{7}{8}$ and in a bad mood with probability $\frac{1}{8}$. However, if he fails to provide refreshments, the group will begin the following Saturday night in a good mood with probability $\frac{1}{8}$ and in a bad mood with probability $\frac{7}{8}$, regardless of their mood this Saturday. Furthermore, if the group begins the night in a bad mood and then he fails to provide refreshments, the group will gang up on him so that he incurs expected poker losses of \$75. Under other circumstances, he averages no gain or loss on his poker play. The man wishes to find the policy regarding when to provide refreshments that will minimize his (long-run) expected average cost per week.
   a. Formulate this problem as a Markov decision process by identifying the states and decisions and then finding the $C_{ik}$.
   b. Identify the optimal stationary deterministic policy.

1. (6pts)\*  When a tennis player serves, he gets two chances to serve in bounds. If he fails to do so twice, he loses the point. If he attempts to serve an ace, he serves in bounds with probability $\frac{3}{8}$. If he serves a lob, he serves in bounds with probability $\frac{7}{8}$. If he serves an ace in bounds, he wins the point with probability $\frac{2}{3}$. With an inbounds lob, he wins the point with probability $\frac{1}{3}$. If the cost is 1 for each point lost and -1 for each point won, the problem is to determine the optimal serving strategy to minimize the (long-run) expected average cost per point. (Hint: Let state 0 denote point over, two serves to go on next point; and let state 1 denote one serve left.)
   a. Formulate this problem as a Markov decision process by identifying the states and decisions and then finding the $C_{ik}$.
   b. Identify the optimal stationary deterministic policy.
</div>
</div>
