## Notes and further reading

Our discussion of Markov chains included only the discrete-time version. @classText also covers a bit on the continuous-time version in section 28.8. There are also several classes of queueing models that we didn't cover, if you're interested you can peruse sections 17.7-17.9 in @classText. For more extensive coverage on stochastic processes and probability models, I highly recommend @ross2007introduction.

Both @classText and @ross2007introduction also contain sections on simulation, which is a technique for analyzing stochastic processes where the interactions and underlying distributions make key metrics hard to derive mathematically. We did see something like this in the videos in +@sec:reinforcementLearning (basically anywhere he used the words "Monte Carlo", he was talking about simulation). This is a key technique used by OR professionals.

When it comes to Markov decision processes, the standard reference is @puterman2014markov. As mentioned already, the standard reference for reinforcement learning is @sutton2018reinforcement.

As far as other courses, the K-State IMSE department offers several courses that extend on ideas from this section. You can read up on these in the [course catalog](https://catalog.k-state.edu/content.php?catoid=58&navoid=11444):

- IMSE 643 - Industrial Simulation
- IMSE 865 - Simulation of Industrial Management Systems
- IMSE 866 - Applied Stochastic Processes
- IMSE 867 - Stochastic Programming
- IMSE 971 - Industrial Queuing Processes
